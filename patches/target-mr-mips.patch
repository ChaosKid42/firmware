diff -Nru a/include/kernel-defaults.mk b/include/kernel-defaults.mk
--- a/include/kernel-defaults.mk	2013-07-22 21:50:17.784312111 +0200
+++ b/include/kernel-defaults.mk	2013-07-23 02:51:14.692156671 +0200
@@ -6,7 +6,7 @@
 #
 
 KERNEL_MAKEOPTS := -C $(LINUX_DIR) \
-	HOSTCFLAGS="$(HOST_CFLAGS) -Wall -Wmissing-prototypes -Wstrict-prototypes" \
+	HOSTCFLAGS="$(HOST_CFLAGS) -w" \
 	CROSS_COMPILE="$(KERNEL_CROSS)" \
 	ARCH="$(LINUX_KARCH)" \
 	KBUILD_HAVE_NLS=no \
diff -Nru a/package/netifd/Makefile b/package/netifd/Makefile
--- a/package/netifd/Makefile	2013-07-22 21:50:30.062312836 +0200
+++ b/package/netifd/Makefile	2013-07-23 01:21:30.192271909 +0200
@@ -7,7 +7,8 @@
 PKG_SOURCE_PROTO:=git
 PKG_SOURCE_URL:=git://nbd.name/luci2/netifd.git
 PKG_SOURCE_SUBDIR:=$(PKG_NAME)-$(PKG_VERSION)
-PKG_SOURCE_VERSION:=2674941b06c1ec67f1aff1bff9212e1372106641
+#PKG_SOURCE_VERSION:=2674941b06c1ec67f1aff1bff9212e1372106641
+PKG_SOURCE_VERSION:=05b414d194e99d2f06c4325e2e5d856bec922eac
 PKG_SOURCE:=$(PKG_NAME)-$(PKG_VERSION)-$(PKG_SOURCE_VERSION).tar.gz
 PKG_MAINTAINER:=Felix Fietkau <nbd@openwrt.org>
 # PKG_MIRROR_MD5SUM:=
diff -Nru a/package/netifd/patches/500-cross.patch b/package/netifd/patches/500-cross.patch
--- a/package/netifd/patches/500-cross.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/package/netifd/patches/500-cross.patch	2013-07-23 01:35:02.404510693 +0200
@@ -0,0 +1,15 @@
+diff --git a/CMakeLists.txt b/CMakeLists.txt
+index 74cb080..2076fc9 100644
+--- a/CMakeLists.txt
++++ b/CMakeLists.txt
+@@ -18,8 +18,9 @@ SET(SOURCES
+ 	ubus.c)
+ 
+ 
++find_library(json NAMES json-c json)
+ SET(LIBS
+-	ubox ubus uci json blobmsg_json)
++	ubox ubus uci ${json} blobmsg_json)
+ 
+ IF (NOT DEFINED LIBNL_LIBS)
+   SET(LIBNL_LIBS -lnl)
Bin√§rdateien a/.svn/wc.db and b/.svn/wc.db sind verschieden.
diff -Nru a/target/linux/generic/config-2.6.31 b/target/linux/generic/config-2.6.31
--- a/target/linux/generic/config-2.6.31	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/config-2.6.31	2013-07-22 22:05:43.000000000 +0200
@@ -0,0 +1,2748 @@
+# CONFIG_6PACK is not set
+# CONFIG_8139CP is not set
+# CONFIG_8139TOO is not set
+# CONFIG_9P_FS is not set
+# CONFIG_AB3100_CORE is not set
+# CONFIG_ACCESSIBILITY is not set
+# CONFIG_ACENIC is not set
+# CONFIG_ACER_WMI is not set
+# CONFIG_ACORN_PARTITION is not set
+# CONFIG_ADAPTEC_STARFIRE is not set
+# CONFIG_ADFS_FS is not set
+# CONFIG_ADM6996_PHY is not set
+# CONFIG_ADM8211 is not set
+CONFIG_AEABI=y
+# CONFIG_AFFS_FS is not set
+# CONFIG_AFS_FS is not set
+# CONFIG_AF_RXRPC is not set
+# CONFIG_AGP is not set
+CONFIG_AIO=y
+# CONFIG_AIRO is not set
+# CONFIG_AIRO_CS is not set
+# CONFIG_ALIM7101_WDT is not set
+# CONFIG_ALTERA_PCIE_CHDMA is not set
+# CONFIG_AMD8111_ETH is not set
+# CONFIG_AMIGA_PARTITION is not set
+# CONFIG_ANDROID is not set
+CONFIG_ANON_INODES=y
+# CONFIG_APPLICOM is not set
+# CONFIG_AR8216_PHY is not set
+# CONFIG_AR9170_USB is not set
+# CONFIG_ARCH_AAEC2000 is not set
+# CONFIG_ARCH_AT91 is not set
+# CONFIG_ARCH_CLPS711X is not set
+# CONFIG_ARCH_DAVINCI is not set
+# CONFIG_ARCH_EBSA110 is not set
+# CONFIG_ARCH_EP93XX is not set
+CONFIG_ARCH_FLATMEM_ENABLE=y
+# CONFIG_ARCH_FOOTBRIDGE is not set
+# CONFIG_ARCH_GEMINI is not set
+# CONFIG_ARCH_H720X is not set
+# CONFIG_ARCH_IMX is not set
+# CONFIG_ARCH_INTEGRATOR is not set
+# CONFIG_ARCH_IOP13XX is not set
+# CONFIG_ARCH_IOP32X is not set
+# CONFIG_ARCH_IOP33X is not set
+# CONFIG_ARCH_IXP2000 is not set
+# CONFIG_ARCH_IXP23XX is not set
+# CONFIG_ARCH_IXP4XX is not set
+# CONFIG_ARCH_KIRKWOOD is not set
+# CONFIG_ARCH_KS8695 is not set
+# CONFIG_ARCH_L7200 is not set
+# CONFIG_ARCH_LH7A40X is not set
+# CONFIG_ARCH_LOKI is not set
+# CONFIG_ARCH_MMP is not set
+# CONFIG_ARCH_MSM is not set
+# CONFIG_ARCH_MV78XX0 is not set
+# CONFIG_ARCH_MXC is not set
+# CONFIG_ARCH_NETX is not set
+# CONFIG_ARCH_NS9XXX is not set
+# CONFIG_ARCH_OMAP is not set
+# CONFIG_ARCH_ORION5X is not set
+# CONFIG_ARCH_PNX4008 is not set
+# CONFIG_ARCH_PXA is not set
+# CONFIG_ARCH_REALVIEW is not set
+# CONFIG_ARCH_RPC is not set
+# CONFIG_ARCH_S3C2410 is not set
+# CONFIG_ARCH_S3C64XX is not set
+# CONFIG_ARCH_SA1100 is not set
+# CONFIG_ARCH_SHARK is not set
+# CONFIG_ARCH_STMP3XXX is not set
+# CONFIG_ARCH_U300 is not set
+# CONFIG_ARCH_VERSATILE is not set
+# CONFIG_ARCH_W90X900 is not set
+# CONFIG_ARCNET is not set
+# CONFIG_ARM_UNWIND is not set
+CONFIG_ARPD=y
+# CONFIG_ARTHUR is not set
+CONFIG_ASK_IP_FIB_HASH=y
+# CONFIG_ASUS_OLED is not set
+# CONFIG_ASYNC_TX_DMA is not set
+# CONFIG_AT24 is not set
+# CONFIG_AT76C50X_USB is not set
+# CONFIG_ATA is not set
+# CONFIG_ATALK is not set
+# CONFIG_ATARI_PARTITION is not set
+# CONFIG_ATA_ACPI is not set
+# CONFIG_ATA_GENERIC is not set
+# CONFIG_ATA_NONSTANDARD is not set
+# CONFIG_ATA_OVER_ETH is not set
+# CONFIG_ATA_PIIX is not set
+CONFIG_ATA_SFF=y
+# CONFIG_ATH5K is not set
+# CONFIG_ATH9K is not set
+# CONFIG_ATL1 is not set
+# CONFIG_ATL1C is not set
+# CONFIG_ATL1E is not set
+# CONFIG_ATL2 is not set
+# CONFIG_ATM is not set
+# CONFIG_ATMEL is not set
+# CONFIG_ATM_AMBASSADOR is not set
+# CONFIG_ATM_BR2684 is not set
+CONFIG_ATM_BR2684_IPFILTER=y
+# CONFIG_ATM_CLIP is not set
+CONFIG_ATM_CLIP_NO_ICMP=y
+# CONFIG_ATM_DRIVERS is not set
+# CONFIG_ATM_DUMMY is not set
+# CONFIG_ATM_ENI is not set
+# CONFIG_ATM_FIRESTREAM is not set
+# CONFIG_ATM_FORE200E is not set
+# CONFIG_ATM_FORE200E_MAYBE is not set
+# CONFIG_ATM_HE is not set
+# CONFIG_ATM_HORIZON is not set
+# CONFIG_ATM_IA is not set
+# CONFIG_ATM_IDT77252 is not set
+# CONFIG_ATM_LANAI is not set
+# CONFIG_ATM_LANE is not set
+# CONFIG_ATM_MPOA is not set
+# CONFIG_ATM_NICSTAR is not set
+# CONFIG_ATM_SOLOS is not set
+# CONFIG_ATM_TCP is not set
+# CONFIG_ATM_ZATM is not set
+# CONFIG_AUDIT is not set
+# CONFIG_AUTOFS4_FS is not set
+# CONFIG_AUTOFS_FS is not set
+# CONFIG_AUXDISPLAY is not set
+# CONFIG_AX25 is not set
+# CONFIG_AX25_DAMA_SLAVE is not set
+# CONFIG_AX88796 is not set
+# CONFIG_B3DFG is not set
+# CONFIG_B43 is not set
+# CONFIG_B43LEGACY is not set
+# CONFIG_B44 is not set
+# CONFIG_BACKLIGHT_LCD_SUPPORT is not set
+CONFIG_BASE_FULL=y
+CONFIG_BASE_SMALL=0
+# CONFIG_BASLER_EXCITE is not set
+# CONFIG_BATTERY_BQ27000_HDQ is not set
+# CONFIG_BATTERY_BQ27x00 is not set
+# CONFIG_BATTERY_DS2760 is not set
+# CONFIG_BATTERY_DS2782 is not set
+# CONFIG_BATTERY_MAX17040 is not set
+# CONFIG_BAYCOM_EPP is not set
+# CONFIG_BAYCOM_PAR is not set
+# CONFIG_BAYCOM_SER_FDX is not set
+# CONFIG_BAYCOM_SER_HDX is not set
+# CONFIG_BCM43XX is not set
+CONFIG_BCM43XX_DEBUG=y
+CONFIG_BCM43XX_DMA=y
+CONFIG_BCM43XX_DMA_AND_PIO_MODE=y
+# CONFIG_BCM43XX_DMA_MODE is not set
+CONFIG_BCM43XX_PIO=y
+# CONFIG_BCM43XX_PIO_MODE is not set
+# CONFIG_BCMA is not set
+# CONFIG_BEFS_FS is not set
+# CONFIG_BFS_FS is not set
+# CONFIG_BINARY_PRINTF is not set
+# CONFIG_BINFMT_AOUT is not set
+CONFIG_BINFMT_ELF=y
+# CONFIG_BINFMT_MISC is not set
+# CONFIG_BLINK is not set
+# CONFIG_BLK_CPQ_CISS_DA is not set
+# CONFIG_BLK_CPQ_DA is not set
+CONFIG_BLK_DEV=y
+# CONFIG_BLK_DEV_3W_XXXX_RAID is not set
+# CONFIG_BLK_DEV_4DRIVES is not set
+# CONFIG_BLK_DEV_AEC62XX is not set
+# CONFIG_BLK_DEV_ALI14XX is not set
+# CONFIG_BLK_DEV_ALI15X3 is not set
+# CONFIG_BLK_DEV_AMD74XX is not set
+# CONFIG_BLK_DEV_ATIIXP is not set
+# CONFIG_BLK_DEV_BSG is not set
+# CONFIG_BLK_DEV_CMD640 is not set
+# CONFIG_BLK_DEV_CMD64X is not set
+# CONFIG_BLK_DEV_COW_COMMON is not set
+# CONFIG_BLK_DEV_CRYPTOLOOP is not set
+# CONFIG_BLK_DEV_CS5520 is not set
+# CONFIG_BLK_DEV_CS5530 is not set
+# CONFIG_BLK_DEV_CS5535 is not set
+# CONFIG_BLK_DEV_CS5536 is not set
+# CONFIG_BLK_DEV_CY82C693 is not set
+# CONFIG_BLK_DEV_DAC960 is not set
+# CONFIG_BLK_DEV_DELKIN is not set
+# CONFIG_BLK_DEV_DTC2278 is not set
+# CONFIG_BLK_DEV_FD is not set
+# CONFIG_BLK_DEV_GENERIC is not set
+# CONFIG_BLK_DEV_HD is not set
+# CONFIG_BLK_DEV_HD_IDE is not set
+# CONFIG_BLK_DEV_HD_ONLY is not set
+# CONFIG_BLK_DEV_HPT34X is not set
+# CONFIG_BLK_DEV_HPT366 is not set
+# CONFIG_BLK_DEV_HT6560B is not set
+# CONFIG_BLK_DEV_IDEACPI is not set
+# CONFIG_BLK_DEV_IDECD is not set
+# CONFIG_BLK_DEV_IDECS is not set
+# CONFIG_BLK_DEV_IDEDMA_FORCED is not set
+# CONFIG_BLK_DEV_IDEFLOPPY is not set
+# CONFIG_BLK_DEV_IDEPCI is not set
+# CONFIG_BLK_DEV_IDEPNP is not set
+# CONFIG_BLK_DEV_IDESCSI is not set
+# CONFIG_BLK_DEV_IDETAPE is not set
+# CONFIG_BLK_DEV_IDE_SATA is not set
+CONFIG_BLK_DEV_INITRD=y
+# CONFIG_BLK_DEV_INTEGRITY is not set
+# CONFIG_BLK_DEV_IO_TRACE is not set
+# CONFIG_BLK_DEV_IT8172 is not set
+# CONFIG_BLK_DEV_IT8213 is not set
+# CONFIG_BLK_DEV_IT821X is not set
+# CONFIG_BLK_DEV_JMICRON is not set
+# CONFIG_BLK_DEV_LOOP is not set
+# CONFIG_BLK_DEV_NBD is not set
+# CONFIG_BLK_DEV_NS87415 is not set
+# CONFIG_BLK_DEV_OFFBOARD is not set
+# CONFIG_BLK_DEV_OPTI621 is not set
+# CONFIG_BLK_DEV_PDC202XX_NEW is not set
+# CONFIG_BLK_DEV_PDC202XX_OLD is not set
+# CONFIG_BLK_DEV_PIIX is not set
+# CONFIG_BLK_DEV_PLATFORM is not set
+# CONFIG_BLK_DEV_QD65XX is not set
+# CONFIG_BLK_DEV_RAM is not set
+# CONFIG_BLK_DEV_RZ1000 is not set
+# CONFIG_BLK_DEV_SC1200 is not set
+# CONFIG_BLK_DEV_SD is not set
+# CONFIG_BLK_DEV_SIIMAGE is not set
+# CONFIG_BLK_DEV_SIS5513 is not set
+# CONFIG_BLK_DEV_SL82C105 is not set
+# CONFIG_BLK_DEV_SLC90E66 is not set
+# CONFIG_BLK_DEV_SR is not set
+# CONFIG_BLK_DEV_SVWKS is not set
+# CONFIG_BLK_DEV_SX8 is not set
+# CONFIG_BLK_DEV_TC86C001 is not set
+# CONFIG_BLK_DEV_TRIFLEX is not set
+# CONFIG_BLK_DEV_TRM290 is not set
+# CONFIG_BLK_DEV_UB is not set
+# CONFIG_BLK_DEV_UMC8672 is not set
+# CONFIG_BLK_DEV_UMEM is not set
+# CONFIG_BLK_DEV_VIA82CXXX is not set
+# CONFIG_BLK_DEV_XIP is not set
+CONFIG_BLOCK=y
+# CONFIG_BNX2 is not set
+# CONFIG_BONDING is not set
+# CONFIG_BOOT_TRACER is not set
+# CONFIG_BPQETHER is not set
+CONFIG_BRIDGE=y
+# CONFIG_BRIDGE_EBT_802_3 is not set
+# CONFIG_BRIDGE_EBT_AMONG is not set
+# CONFIG_BRIDGE_EBT_ARP is not set
+# CONFIG_BRIDGE_EBT_ARPREPLY is not set
+# CONFIG_BRIDGE_EBT_BROUTE is not set
+# CONFIG_BRIDGE_EBT_DNAT is not set
+# CONFIG_BRIDGE_EBT_IP is not set
+# CONFIG_BRIDGE_EBT_IP6 is not set
+# CONFIG_BRIDGE_EBT_LIMIT is not set
+# CONFIG_BRIDGE_EBT_LOG is not set
+# CONFIG_BRIDGE_EBT_MARK is not set
+# CONFIG_BRIDGE_EBT_MARK_T is not set
+# CONFIG_BRIDGE_EBT_NFLOG is not set
+# CONFIG_BRIDGE_EBT_PKTTYPE is not set
+# CONFIG_BRIDGE_EBT_REDIRECT is not set
+# CONFIG_BRIDGE_EBT_SNAT is not set
+# CONFIG_BRIDGE_EBT_STP is not set
+# CONFIG_BRIDGE_EBT_T_FILTER is not set
+# CONFIG_BRIDGE_EBT_T_NAT is not set
+# CONFIG_BRIDGE_EBT_ULOG is not set
+# CONFIG_BRIDGE_EBT_VLAN is not set
+# CONFIG_BRIDGE_NETFILTER is not set
+# CONFIG_BRIDGE_NF_EBTABLES is not set
+# CONFIG_BROADCOM_PHY is not set
+CONFIG_BROKEN_ON_SMP=y
+# CONFIG_BSD_DISKLABEL is not set
+# CONFIG_BSD_PROCESS_ACCT is not set
+# CONFIG_BSD_PROCESS_ACCT_V3 is not set
+# CONFIG_BT is not set
+# CONFIG_BTRFS_FS is not set
+# CONFIG_BT_BNEP is not set
+CONFIG_BT_BNEP_MC_FILTER=y
+CONFIG_BT_BNEP_PROTO_FILTER=y
+# CONFIG_BT_CMTP is not set
+# CONFIG_BT_HCIBCM203X is not set
+# CONFIG_BT_HCIBFUSB is not set
+# CONFIG_BT_HCIBLUECARD is not set
+# CONFIG_BT_HCIBPA10X is not set
+# CONFIG_BT_HCIBT3C is not set
+# CONFIG_BT_HCIBTSDIO is not set
+# CONFIG_BT_HCIBTUART is not set
+# CONFIG_BT_HCIBTUSB is not set
+# CONFIG_BT_HCIDTL1 is not set
+# CONFIG_BT_HCIUART is not set
+CONFIG_BT_HCIUART_BCSP=y
+CONFIG_BT_HCIUART_H4=y
+# CONFIG_BT_HCIUART_LL is not set
+# CONFIG_BT_HCIUSB is not set
+CONFIG_BT_HCIUSB_SCO=y
+# CONFIG_BT_HCIVHCI is not set
+# CONFIG_BT_HIDP is not set
+# CONFIG_BT_L2CAP is not set
+# CONFIG_BT_RFCOMM is not set
+CONFIG_BT_RFCOMM_TTY=y
+# CONFIG_BT_SCO is not set
+CONFIG_BUG=y
+# CONFIG_C2PORT is not set
+# CONFIG_CAN is not set
+# CONFIG_CAPI_AVM is not set
+# CONFIG_CAPI_EICON is not set
+# CONFIG_CAPI_TRACE is not set
+CONFIG_CARDBUS=y
+# CONFIG_CARDMAN_4000 is not set
+# CONFIG_CARDMAN_4040 is not set
+# CONFIG_CASSINI is not set
+# CONFIG_CB710_CORE is not set
+# CONFIG_CC_OPTIMIZE_FOR_SIZE is not set
+# CONFIG_CDROM_PKTCDVD is not set
+# CONFIG_CFG80211 is not set
+# CONFIG_CGROUPS is not set
+# CONFIG_CHELSIO_T1 is not set
+# CONFIG_CHELSIO_T3 is not set
+# CONFIG_CHR_DEV_OSST is not set
+# CONFIG_CHR_DEV_SCH is not set
+# CONFIG_CHR_DEV_SG is not set
+# CONFIG_CHR_DEV_ST is not set
+# CONFIG_CICADA_PHY is not set
+# CONFIG_CIFS is not set
+# CONFIG_CIFS_DEBUG2 is not set
+# CONFIG_CIFS_EXPERIMENTAL is not set
+CONFIG_CIFS_POSIX=y
+CONFIG_CIFS_STATS=y
+# CONFIG_CIFS_STATS2 is not set
+# CONFIG_CIFS_WEAK_PW_HASH is not set
+# CONFIG_CIFS_XATTR is not set
+CONFIG_CLASSIC_RCU=y
+CONFIG_CLS_U32_MARK=y
+CONFIG_CLS_U32_PERF=y
+CONFIG_CMDLINE=""
+# CONFIG_CNIC is not set
+# CONFIG_CODA_FS is not set
+# CONFIG_COMEDI is not set
+# CONFIG_COMPAT_BRK is not set
+CONFIG_COMPAT_NET_DEV_OPS=y
+# CONFIG_CONFIGFS_FS is not set
+# CONFIG_CONNECTOR is not set
+CONFIG_CONSTRUCTORS=y
+# CONFIG_CONTEXT_SWITCH_TRACER is not set
+# CONFIG_COPS is not set
+# CONFIG_CORE_DUMP_DEFAULT_ELF_HEADERS is not set
+# CONFIG_CPU_DCACHE_DISABLE is not set
+# CONFIG_CPU_FREQ is not set
+# CONFIG_CPU_IDLE is not set
+# CONFIG_CRAMFS is not set
+# CONFIG_CRASH_DUMP is not set
+# CONFIG_CRC16 is not set
+CONFIG_CRC32=y
+# CONFIG_CRC7 is not set
+# CONFIG_CRC_CCITT is not set
+# CONFIG_CRC_ITU_T is not set
+# CONFIG_CRC_T10DIF is not set
+CONFIG_CROSSCOMPILE=y
+CONFIG_CRYPTO=y
+# CONFIG_CRYPTO_AEAD is not set
+# CONFIG_CRYPTO_AES is not set
+# CONFIG_CRYPTO_AES_586 is not set
+# CONFIG_CRYPTO_ALGAPI is not set
+# CONFIG_CRYPTO_ALGAPI2 is not set
+# CONFIG_CRYPTO_ANSI_CPRNG is not set
+# CONFIG_CRYPTO_ANUBIS is not set
+# CONFIG_CRYPTO_ARC4 is not set
+# CONFIG_CRYPTO_AUTHENC is not set
+# CONFIG_CRYPTO_BLKCIPHER is not set
+# CONFIG_CRYPTO_BLOWFISH is not set
+# CONFIG_CRYPTO_CAMELLIA is not set
+# CONFIG_CRYPTO_CAST5 is not set
+# CONFIG_CRYPTO_CAST6 is not set
+# CONFIG_CRYPTO_CBC is not set
+# CONFIG_CRYPTO_CCM is not set
+# CONFIG_CRYPTO_CRC32C is not set
+# CONFIG_CRYPTO_CRC32C_INTEL is not set
+# CONFIG_CRYPTO_CRYPTD is not set
+# CONFIG_CRYPTO_CTR is not set
+# CONFIG_CRYPTO_CTS is not set
+# CONFIG_CRYPTO_DEFLATE is not set
+# CONFIG_CRYPTO_DES is not set
+# CONFIG_CRYPTO_DEV_HIFN_795X is not set
+# CONFIG_CRYPTO_ECB is not set
+# CONFIG_CRYPTO_FCRYPT is not set
+# CONFIG_CRYPTO_FIPS is not set
+# CONFIG_CRYPTO_GCM is not set
+# CONFIG_CRYPTO_GF128MUL is not set
+# CONFIG_CRYPTO_HASH is not set
+# CONFIG_CRYPTO_HMAC is not set
+# CONFIG_CRYPTO_HW is not set
+# CONFIG_CRYPTO_KHAZAD is not set
+# CONFIG_CRYPTO_LRW is not set
+# CONFIG_CRYPTO_LZO is not set
+# CONFIG_CRYPTO_MANAGER is not set
+# CONFIG_CRYPTO_MANAGER2 is not set
+# CONFIG_CRYPTO_MD4 is not set
+# CONFIG_CRYPTO_MD5 is not set
+# CONFIG_CRYPTO_MICHAEL_MIC is not set
+# CONFIG_CRYPTO_NULL is not set
+# CONFIG_CRYPTO_PCBC is not set
+# CONFIG_CRYPTO_PCOMP is not set
+# CONFIG_CRYPTO_PCOMP2 is not set
+# CONFIG_CRYPTO_PRNG is not set
+# CONFIG_CRYPTO_RMD128 is not set
+# CONFIG_CRYPTO_RMD160 is not set
+# CONFIG_CRYPTO_RMD256 is not set
+# CONFIG_CRYPTO_RMD320 is not set
+# CONFIG_CRYPTO_RNG is not set
+# CONFIG_CRYPTO_SALSA20 is not set
+# CONFIG_CRYPTO_SALSA20_586 is not set
+# CONFIG_CRYPTO_SEED is not set
+# CONFIG_CRYPTO_SEQIV is not set
+# CONFIG_CRYPTO_SERPENT is not set
+# CONFIG_CRYPTO_SHA1 is not set
+# CONFIG_CRYPTO_SHA256 is not set
+# CONFIG_CRYPTO_SHA512 is not set
+# CONFIG_CRYPTO_TEA is not set
+# CONFIG_CRYPTO_TEST is not set
+# CONFIG_CRYPTO_TGR192 is not set
+# CONFIG_CRYPTO_TWOFISH is not set
+# CONFIG_CRYPTO_TWOFISH_586 is not set
+# CONFIG_CRYPTO_TWOFISH_COMMON is not set
+# CONFIG_CRYPTO_WP512 is not set
+# CONFIG_CRYPTO_XCBC is not set
+# CONFIG_CRYPTO_XTS is not set
+# CONFIG_CRYPTO_ZLIB is not set
+# CONFIG_CUSE is not set
+# CONFIG_DAB is not set
+# CONFIG_DAVICOM_PHY is not set
+# CONFIG_DCB is not set
+# CONFIG_DEBUG_BUGVERBOSE is not set
+CONFIG_DEBUG_FS=y
+# CONFIG_DEBUG_KERNEL is not set
+# CONFIG_DEBUG_LOCKDEP is not set
+# CONFIG_DEBUG_MEMORY_INIT is not set
+# CONFIG_DEBUG_PAGEALLOC is not set
+# CONFIG_DEBUG_RODATA is not set
+# CONFIG_DEBUG_STACKOVERFLOW is not set
+# CONFIG_DECNET is not set
+CONFIG_DECOMPRESS_LZMA_NEEDED=y
+# CONFIG_DEFAULT_AS is not set
+# CONFIG_DEFAULT_BIC is not set
+# CONFIG_DEFAULT_CFQ is not set
+# CONFIG_DEFAULT_CUBIC is not set
+CONFIG_DEFAULT_DEADLINE=y
+# CONFIG_DEFAULT_HTCP is not set
+CONFIG_DEFAULT_IOSCHED="deadline"
+CONFIG_DEFAULT_MMAP_MIN_ADDR=4096
+# CONFIG_DEFAULT_NOOP is not set
+# CONFIG_DEFAULT_RENO is not set
+CONFIG_DEFAULT_TCP_CONG="westwood"
+# CONFIG_DEFAULT_VEGAS is not set
+CONFIG_DEFAULT_WESTWOOD=y
+CONFIG_DEFCONFIG_LIST="/lib/modules/$UNAME_RELEASE/.config"
+# CONFIG_DEVKMEM is not set
+# CONFIG_DEVPTS_MULTIPLE_INSTANCES is not set
+# CONFIG_DGRS is not set
+# CONFIG_DISCONTIGMEM_MANUAL is not set
+# CONFIG_DISPLAY_SUPPORT is not set
+# CONFIG_DL2K is not set
+# CONFIG_DLM is not set
+# CONFIG_DMADEVICES is not set
+# CONFIG_DMASCC is not set
+# CONFIG_DMATEST is not set
+# CONFIG_DMA_ENGINE is not set
+# CONFIG_DNET is not set
+# CONFIG_DNOTIFY is not set
+# CONFIG_DRAGONRISE_FF is not set
+# CONFIG_DRM is not set
+# CONFIG_DS1682 is not set
+# CONFIG_DST is not set
+# CONFIG_DTLK is not set
+# CONFIG_DUMMY is not set
+# CONFIG_DVB is not set
+# CONFIG_DVB_CORE is not set
+# CONFIG_DYNAMIC_DEBUG is not set
+# CONFIG_DYNAMIC_PRINTK_DEBUG is not set
+# CONFIG_E100 is not set
+# CONFIG_E1000 is not set
+# CONFIG_E1000E is not set
+# CONFIG_ECHO is not set
+# CONFIG_ECONET is not set
+# CONFIG_EDAC is not set
+# CONFIG_EEPRO100 is not set
+# CONFIG_EEPROM_93CX6 is not set
+# CONFIG_EEPROM_AT24 is not set
+# CONFIG_EEPROM_AT25 is not set
+# CONFIG_EEPROM_LEGACY is not set
+# CONFIG_EEPROM_MAX6875 is not set
+CONFIG_EFI_PARTITION=y
+# CONFIG_EFS_FS is not set
+# CONFIG_ELF_CORE is not set
+CONFIG_EMBEDDED=y
+# CONFIG_ENABLE_MUST_CHECK is not set
+CONFIG_ENABLE_WARN_DEPRECATED=y
+# CONFIG_ENC28J60 is not set
+# CONFIG_ENCLOSURE_SERVICES is not set
+# CONFIG_EPIC100 is not set
+CONFIG_EPOLL=y
+# CONFIG_EQUALIZER is not set
+# CONFIG_ET131X is not set
+# CONFIG_ETHOC is not set
+CONFIG_EVENTFD=y
+# CONFIG_EVENT_TRACER is not set
+CONFIG_EXPERIMENTAL=y
+# CONFIG_EXPORTFS is not set
+# CONFIG_EXT2_FS is not set
+# CONFIG_EXT2_FS_XATTR is not set
+# CONFIG_EXT2_FS_XIP is not set
+# CONFIG_EXT3_DEFAULTS_TO_ORDERED is not set
+# CONFIG_EXT3_FS is not set
+# CONFIG_EXT3_FS_XATTR is not set
+# CONFIG_EXT4DEV_COMPAT is not set
+# CONFIG_EXT4DEV_FS is not set
+# CONFIG_EXT4_FS is not set
+# CONFIG_EXT4_FS_SECURITY is not set
+# CONFIG_EXT4_FS_XATTR is not set
+CONFIG_EXTRA_FIRMWARE=""
+CONFIG_EXTRA_TARGETS=""
+# CONFIG_EZX_PCAP is not set
+# CONFIG_FAIR_GROUP_SCHED is not set
+CONFIG_FAT_DEFAULT_CODEPAGE=437
+CONFIG_FAT_DEFAULT_IOCHARSET="iso8859-1"
+# CONFIG_FAT_FS is not set
+# CONFIG_FB is not set
+# CONFIG_FB_3DFX is not set
+# CONFIG_FB_ARC is not set
+# CONFIG_FB_ARK is not set
+# CONFIG_FB_ASILIANT is not set
+# CONFIG_FB_ATY is not set
+# CONFIG_FB_ATY128 is not set
+# CONFIG_FB_BACKLIGHT is not set
+# CONFIG_FB_BOOT_VESA_SUPPORT is not set
+# CONFIG_FB_BROADSHEET is not set
+# CONFIG_FB_CARMINE is not set
+# CONFIG_FB_CFB_COPYAREA is not set
+# CONFIG_FB_CFB_FILLRECT is not set
+# CONFIG_FB_CFB_IMAGEBLIT is not set
+# CONFIG_FB_CFB_REV_PIXELS_IN_BYTE is not set
+# CONFIG_FB_CIRRUS is not set
+# CONFIG_FB_CYBER2000 is not set
+# CONFIG_FB_DDC is not set
+# CONFIG_FB_EARLYSUSPEND is not set
+# CONFIG_FB_FOREIGN_ENDIAN is not set
+# CONFIG_FB_GEODE is not set
+# CONFIG_FB_GOLDFISH is not set
+# CONFIG_FB_HGA is not set
+# CONFIG_FB_IBM_GXT4500 is not set
+# CONFIG_FB_IMSTT is not set
+# CONFIG_FB_KYRO is not set
+# CONFIG_FB_LE80578 is not set
+# CONFIG_FB_MACMODES is not set
+# CONFIG_FB_MATROX is not set
+# CONFIG_FB_MB862XX is not set
+# CONFIG_FB_METRONOME is not set
+# CONFIG_FB_MODE_HELPERS is not set
+# CONFIG_FB_N411 is not set
+# CONFIG_FB_NEOMAGIC is not set
+# CONFIG_FB_NVIDIA is not set
+# CONFIG_FB_OF is not set
+# CONFIG_FB_PM2 is not set
+# CONFIG_FB_PM3 is not set
+# CONFIG_FB_PS3 is not set
+# CONFIG_FB_PXA is not set
+# CONFIG_FB_RADEON is not set
+# CONFIG_FB_RIVA is not set
+# CONFIG_FB_S1D13XXX is not set
+# CONFIG_FB_S3 is not set
+# CONFIG_FB_SAVAGE is not set
+# CONFIG_FB_SIS is not set
+# CONFIG_FB_SVGALIB is not set
+# CONFIG_FB_SYS_COPYAREA is not set
+# CONFIG_FB_SYS_FILLRECT is not set
+# CONFIG_FB_SYS_FOPS is not set
+# CONFIG_FB_SYS_IMAGEBLIT is not set
+# CONFIG_FB_TILEBLITTING is not set
+# CONFIG_FB_TRIDENT is not set
+# CONFIG_FB_VGA16 is not set
+# CONFIG_FB_VIA is not set
+# CONFIG_FB_VIRTUAL is not set
+# CONFIG_FB_VOODOO1 is not set
+# CONFIG_FB_VT8623 is not set
+# CONFIG_FCOE is not set
+# CONFIG_FCOE_FNIC is not set
+# CONFIG_FDDI is not set
+# CONFIG_FEALNX is not set
+CONFIG_FIB_RULES=y
+CONFIG_FILE_LOCKING=y
+# CONFIG_FIREWIRE is not set
+# CONFIG_FIRMWARE_IN_KERNEL is not set
+# CONFIG_FIXED_PHY is not set
+CONFIG_FLATMEM=y
+CONFIG_FLATMEM_MANUAL=y
+CONFIG_FLAT_NODE_MEM_MAP=y
+# CONFIG_FORCEDETH is not set
+# CONFIG_FRAMEBUFFER_CONSOLE is not set
+CONFIG_FRAME_WARN=1024
+# CONFIG_FREEZER is not set
+# CONFIG_FSCACHE is not set
+CONFIG_FSNOTIFY=y
+# CONFIG_FS_POSIX_ACL is not set
+# CONFIG_FTL is not set
+# CONFIG_FTRACE is not set
+# CONFIG_FTRACE_STARTUP_TEST is not set
+# CONFIG_FUNCTION_TRACER is not set
+# CONFIG_FUSE_FS is not set
+# CONFIG_FUSION is not set
+# CONFIG_FUSION_FC is not set
+# CONFIG_FUSION_SAS is not set
+# CONFIG_FUSION_SPI is not set
+CONFIG_FUTEX=y
+CONFIG_FW_LOADER=y
+CONFIG_GACT_PROB=y
+# CONFIG_GAMEPORT is not set
+# CONFIG_GCOV_KERNEL is not set
+CONFIG_GENERIC_CALIBRATE_DELAY=y
+CONFIG_GENERIC_HARDIRQS=y
+CONFIG_GENERIC_HWEIGHT=y
+CONFIG_GENERIC_IRQ_PROBE=y
+CONFIG_GENERIC_TIME=y
+# CONFIG_GFS2_FS is not set
+# CONFIG_GIGASET_DEBUG is not set
+# CONFIG_GPIOLIB is not set
+# CONFIG_GPIO_BT8XX is not set
+# CONFIG_GPIO_DEVICE is not set
+# CONFIG_GPIO_MAX7301 is not set
+# CONFIG_GPIO_MAX732X is not set
+# CONFIG_GPIO_MCP23S08 is not set
+# CONFIG_GPIO_PCA953X is not set
+# CONFIG_GPIO_PCF857X is not set
+# CONFIG_GPIO_SYSFS is not set
+# CONFIG_GPIO_XILINX is not set
+# CONFIG_GREENASIA_FF is not set
+# CONFIG_GROUP_SCHED is not set
+# CONFIG_HAMACHI is not set
+CONFIG_HAMRADIO=y
+# CONFIG_HAPPYMEAL is not set
+# CONFIG_HAVE_AOUT is not set
+CONFIG_HAVE_MLOCK=y
+CONFIG_HAVE_MLOCKED_PAGE_BIT=y
+# CONFIG_HCALL_STATS is not set
+# CONFIG_HDLC is not set
+# CONFIG_HDLC_CISCO is not set
+# CONFIG_HDLC_FR is not set
+# CONFIG_HDLC_PPP is not set
+# CONFIG_HDLC_RAW is not set
+# CONFIG_HDLC_RAW_ETH is not set
+# CONFIG_HEADERS_CHECK is not set
+# CONFIG_HECI is not set
+# CONFIG_HERMES is not set
+# CONFIG_HFSPLUS_FS is not set
+# CONFIG_HFS_FS is not set
+# CONFIG_HID is not set
+# CONFIG_HIDRAW is not set
+# CONFIG_HID_A4TECH is not set
+# CONFIG_HID_APPLE is not set
+# CONFIG_HID_BELKIN is not set
+# CONFIG_HID_BRIGHT is not set
+# CONFIG_HID_CHERRY is not set
+# CONFIG_HID_CHICONY is not set
+# CONFIG_HID_COMPAT is not set
+# CONFIG_HID_CYPRESS is not set
+# CONFIG_HID_DEBUG is not set
+# CONFIG_HID_DELL is not set
+# CONFIG_HID_DRAGONRISE is not set
+# CONFIG_HID_EZKEY is not set
+# CONFIG_HID_FF is not set
+# CONFIG_HID_GREENASIA is not set
+# CONFIG_HID_GYRATION is not set
+# CONFIG_HID_KENSINGTON is not set
+# CONFIG_HID_KYE is not set
+# CONFIG_HID_LOGITECH is not set
+# CONFIG_HID_MICROSOFT is not set
+# CONFIG_HID_MONTEREY is not set
+# CONFIG_HID_NTRIG is not set
+# CONFIG_HID_PANTHERLORD is not set
+# CONFIG_HID_PETALYNX is not set
+# CONFIG_HID_PID is not set
+# CONFIG_HID_SAMSUNG is not set
+# CONFIG_HID_SMARTJOYPLUS is not set
+# CONFIG_HID_SONY is not set
+# CONFIG_HID_SUNPLUS is not set
+# CONFIG_HID_SUPPORT is not set
+# CONFIG_HID_THRUSTMASTER is not set
+# CONFIG_HID_TOPSEED is not set
+# CONFIG_HID_WACOM is not set
+# CONFIG_HID_ZEROPLUS is not set
+# CONFIG_HIGHMEM is not set
+CONFIG_HIGH_RES_TIMERS=y
+# CONFIG_HIPPI is not set
+# CONFIG_HOSTAP is not set
+# CONFIG_HOSTAP_CS is not set
+# CONFIG_HOSTAP_PCI is not set
+# CONFIG_HOSTAP_PLX is not set
+CONFIG_HOTPLUG=y
+# CONFIG_HOTPLUG_CPU is not set
+# CONFIG_HOTPLUG_PCI is not set
+# CONFIG_HP100 is not set
+# CONFIG_HPFS_FS is not set
+# CONFIG_HP_ILO is not set
+# CONFIG_HTC_EGPIO is not set
+# CONFIG_HTC_PASIC3 is not set
+# CONFIG_HUGETLB_PAGE is not set
+# CONFIG_HVC_UDBG is not set
+# CONFIG_HWMON is not set
+# CONFIG_HWMON_VID is not set
+# CONFIG_HW_RANDOM_AMD is not set
+# CONFIG_HW_RANDOM_GEODE is not set
+# CONFIG_HW_RANDOM_INTEL is not set
+# CONFIG_HW_RANDOM_TIMERIOMEM is not set
+# CONFIG_HW_RANDOM_VIA is not set
+# CONFIG_HYSDN is not set
+CONFIG_HZ=100
+CONFIG_HZ_100=y
+# CONFIG_HZ_1000 is not set
+# CONFIG_HZ_1024 is not set
+# CONFIG_HZ_128 is not set
+# CONFIG_HZ_250 is not set
+# CONFIG_HZ_256 is not set
+# CONFIG_HZ_300 is not set
+# CONFIG_HZ_48 is not set
+# CONFIG_I2C is not set
+# CONFIG_I2C_ALGOBIT is not set
+# CONFIG_I2C_ALGOPCA is not set
+# CONFIG_I2C_ALGOPCF is not set
+# CONFIG_I2C_ALI1535 is not set
+# CONFIG_I2C_ALI1563 is not set
+# CONFIG_I2C_ALI15X3 is not set
+# CONFIG_I2C_AMD756 is not set
+# CONFIG_I2C_AMD8111 is not set
+# CONFIG_I2C_CHARDEV is not set
+# CONFIG_I2C_DEBUG_ALGO is not set
+# CONFIG_I2C_DEBUG_BUS is not set
+# CONFIG_I2C_DEBUG_CHIP is not set
+# CONFIG_I2C_DEBUG_CORE is not set
+# CONFIG_I2C_ELEKTOR is not set
+# CONFIG_I2C_GPIO is not set
+# CONFIG_I2C_HELPER_AUTO is not set
+# CONFIG_I2C_I801 is not set
+# CONFIG_I2C_I810 is not set
+# CONFIG_I2C_IBM_IIC is not set
+# CONFIG_I2C_ISCH is not set
+# CONFIG_I2C_MPC is not set
+# CONFIG_I2C_NFORCE2 is not set
+# CONFIG_I2C_OCORES is not set
+# CONFIG_I2C_PARPORT_LIGHT is not set
+# CONFIG_I2C_PCA_ISA is not set
+# CONFIG_I2C_PCA_PLATFORM is not set
+# CONFIG_I2C_PIIX4 is not set
+# CONFIG_I2C_PROSAVAGE is not set
+# CONFIG_I2C_SAVAGE4 is not set
+# CONFIG_I2C_SIMTEC is not set
+# CONFIG_I2C_SIS5595 is not set
+# CONFIG_I2C_SIS630 is not set
+# CONFIG_I2C_SIS96X is not set
+# CONFIG_I2C_STUB is not set
+# CONFIG_I2C_TAOS_EVM is not set
+# CONFIG_I2C_TINY_USB is not set
+# CONFIG_I2C_VIA is not set
+# CONFIG_I2C_VIAPRO is not set
+# CONFIG_I2C_VOODOO3 is not set
+# CONFIG_I2O is not set
+# CONFIG_I82092 is not set
+# CONFIG_I82365 is not set
+# CONFIG_IBM_ASM is not set
+# CONFIG_IBM_NEW_EMAC_EMAC4 is not set
+# CONFIG_IBM_NEW_EMAC_MAL_CLR_ICINTSTAT is not set
+# CONFIG_IBM_NEW_EMAC_MAL_COMMON_ERR is not set
+# CONFIG_IBM_NEW_EMAC_NO_FLOW_CTRL is not set
+# CONFIG_IBM_NEW_EMAC_RGMII is not set
+# CONFIG_IBM_NEW_EMAC_TAH is not set
+# CONFIG_IBM_NEW_EMAC_ZMII is not set
+# CONFIG_ICPLUS_PHY is not set
+# CONFIG_ICS932S401 is not set
+# CONFIG_IDE is not set
+# CONFIG_IDEDISK_MULTI_MODE is not set
+# CONFIG_IDEDMA_IVB is not set
+# CONFIG_IDEDMA_ONLYDISK is not set
+# CONFIG_IDEPCI_SHARE_IRQ is not set
+# CONFIG_IDE_GD is not set
+CONFIG_IDE_MAX_HWIFS=4
+# CONFIG_IDE_PHISON is not set
+# CONFIG_IDE_PROC_FS is not set
+# CONFIG_IDE_TASK_IOCTL is not set
+# CONFIG_IEEE1394 is not set
+# CONFIG_IEEE1394_DV1394 is not set
+# CONFIG_IEEE1394_ETH1394 is not set
+# CONFIG_IEEE1394_OHCI1394 is not set
+# CONFIG_IEEE1394_PCILYNX is not set
+# CONFIG_IEEE1394_RAWIO is not set
+# CONFIG_IEEE1394_VERBOSEDEBUG is not set
+# CONFIG_IEEE1394_VIDEO1394 is not set
+# CONFIG_IEEE80211 is not set
+# CONFIG_IEEE80211_CRYPT_CCMP is not set
+# CONFIG_IEEE80211_CRYPT_TKIP is not set
+# CONFIG_IEEE80211_CRYPT_WEP is not set
+# CONFIG_IEEE80211_DEBUG is not set
+# CONFIG_IEEE80211_SOFTMAC is not set
+# CONFIG_IEEE80211_SOFTMAC_DEBUG is not set
+# CONFIG_IEEE802154 is not set
+# CONFIG_IFB is not set
+# CONFIG_IGB is not set
+# CONFIG_IGBVF is not set
+# CONFIG_IKCONFIG is not set
+# CONFIG_IKCONFIG_PROC is not set
+# CONFIG_IMAGE_CMDLINE_HACK is not set
+CONFIG_INET=y
+# CONFIG_INET6_AH is not set
+# CONFIG_INET6_ESP is not set
+# CONFIG_INET6_IPCOMP is not set
+# CONFIG_INET6_TUNNEL is not set
+# CONFIG_INET6_XFRM_MODE_BEET is not set
+# CONFIG_INET6_XFRM_MODE_ROUTEOPTIMIZATION is not set
+# CONFIG_INET6_XFRM_MODE_TRANSPORT is not set
+# CONFIG_INET6_XFRM_MODE_TUNNEL is not set
+# CONFIG_INET6_XFRM_TUNNEL is not set
+# CONFIG_INET_AH is not set
+# CONFIG_INET_DIAG is not set
+# CONFIG_INET_ESP is not set
+# CONFIG_INET_IPCOMP is not set
+# CONFIG_INET_LRO is not set
+# CONFIG_INET_TCP_DIAG is not set
+# CONFIG_INET_TUNNEL is not set
+# CONFIG_INET_XFRM_MODE_BEET is not set
+# CONFIG_INET_XFRM_MODE_TRANSPORT is not set
+# CONFIG_INET_XFRM_MODE_TUNNEL is not set
+# CONFIG_INET_XFRM_TUNNEL is not set
+# CONFIG_INFINIBAND is not set
+# CONFIG_INFTL is not set
+# CONFIG_INITRAMFS_COMPRESSION_BZIP2 is not set
+# CONFIG_INITRAMFS_COMPRESSION_GZIP is not set
+# CONFIG_INITRAMFS_COMPRESSION_LZMA is not set
+CONFIG_INITRAMFS_COMPRESSION_NONE=y
+CONFIG_INIT_ENV_ARG_LIMIT=32
+CONFIG_INOTIFY=y
+CONFIG_INOTIFY_USER=y
+# CONFIG_INPUT is not set
+# CONFIG_INPUT_APANEL is not set
+# CONFIG_INPUT_ATI_REMOTE is not set
+# CONFIG_INPUT_ATI_REMOTE2 is not set
+# CONFIG_INPUT_ATLAS_BTNS is not set
+# CONFIG_INPUT_CM109 is not set
+# CONFIG_INPUT_EVBUG is not set
+# CONFIG_INPUT_EVDEV is not set
+# CONFIG_INPUT_FF_MEMLESS is not set
+# CONFIG_INPUT_GPIO_ROTARY_ENCODER is not set
+# CONFIG_INPUT_JOYDEV is not set
+# CONFIG_INPUT_JOYSTICK is not set
+# CONFIG_INPUT_KEYBOARD is not set
+# CONFIG_INPUT_KEYSPAN_REMOTE is not set
+# CONFIG_INPUT_MIMIO is not set
+CONFIG_INPUT_MISC=y
+# CONFIG_INPUT_MOUSE is not set
+# CONFIG_INPUT_MOUSEDEV is not set
+# CONFIG_INPUT_PCSPKR is not set
+# CONFIG_INPUT_POLLDEV is not set
+# CONFIG_INPUT_POWERMATE is not set
+# CONFIG_INPUT_TABLET is not set
+# CONFIG_INPUT_TOUCHSCREEN is not set
+# CONFIG_INPUT_TSDEV is not set
+# CONFIG_INPUT_UINPUT is not set
+# CONFIG_INPUT_WISTRON_BTNS is not set
+# CONFIG_INSTRUMENTATION is not set
+# CONFIG_IOSCHED_AS is not set
+# CONFIG_IOSCHED_CFQ is not set
+CONFIG_IOSCHED_DEADLINE=y
+CONFIG_IOSCHED_NOOP=y
+# CONFIG_IP1000 is not set
+# CONFIG_IP17XX_PHY is not set
+# CONFIG_IP6_NF_FILTER is not set
+# CONFIG_IP6_NF_IPTABLES is not set
+# CONFIG_IP6_NF_MANGLE is not set
+# CONFIG_IP6_NF_MATCH_AH is not set
+# CONFIG_IP6_NF_MATCH_EUI64 is not set
+# CONFIG_IP6_NF_MATCH_FRAG is not set
+# CONFIG_IP6_NF_MATCH_HL is not set
+# CONFIG_IP6_NF_MATCH_IPV6HEADER is not set
+# CONFIG_IP6_NF_MATCH_LIMIT is not set
+# CONFIG_IP6_NF_MATCH_MH is not set
+# CONFIG_IP6_NF_MATCH_OPTS is not set
+# CONFIG_IP6_NF_MATCH_OWNER is not set
+# CONFIG_IP6_NF_MATCH_RT is not set
+# CONFIG_IP6_NF_QUEUE is not set
+# CONFIG_IP6_NF_RAW is not set
+# CONFIG_IP6_NF_TARGET_HL is not set
+# CONFIG_IP6_NF_TARGET_IMQ is not set
+# CONFIG_IP6_NF_TARGET_LOG is not set
+# CONFIG_IP6_NF_TARGET_REJECT is not set
+# CONFIG_IP6_NF_TARGET_ROUTE is not set
+# CONFIG_IPC_NS is not set
+# CONFIG_IPMI_HANDLER is not set
+CONFIG_IPSEC_NAT_TRAVERSAL=y
+# CONFIG_IPV6 is not set
+# CONFIG_IPV6_MIP6 is not set
+# CONFIG_IPV6_MROUTE is not set
+# CONFIG_IPV6_MULTIPLE_TABLES is not set
+CONFIG_IPV6_NDISC_NODETYPE=y
+# CONFIG_IPV6_OPTIMISTIC_DAD is not set
+# CONFIG_IPV6_PRIVACY is not set
+# CONFIG_IPV6_ROUTER_PREF is not set
+# CONFIG_IPV6_ROUTE_INFO is not set
+# CONFIG_IPV6_SIT is not set
+# CONFIG_IPV6_TUNNEL is not set
+# CONFIG_IPW2100 is not set
+# CONFIG_IPW2100_DEBUG is not set
+CONFIG_IPW2100_MONITOR=y
+# CONFIG_IPW2200 is not set
+# CONFIG_IPW2200_DEBUG is not set
+CONFIG_IPW2200_MONITOR=y
+# CONFIG_IPW2200_PROMISCUOUS is not set
+# CONFIG_IPW2200_QOS is not set
+# CONFIG_IPW2200_RADIOTAP is not set
+# CONFIG_IPWIRELESS is not set
+# CONFIG_IPX is not set
+CONFIG_IP_ADVANCED_ROUTER=y
+# CONFIG_IP_DCCP is not set
+CONFIG_IP_FIB_HASH=y
+# CONFIG_IP_FIB_TRIE is not set
+CONFIG_IP_MROUTE=y
+CONFIG_IP_MULTICAST=y
+CONFIG_IP_MULTIPLE_TABLES=y
+# CONFIG_IP_NF_AMANDA is not set
+# CONFIG_IP_NF_ARPFILTER is not set
+# CONFIG_IP_NF_ARPTABLES is not set
+# CONFIG_IP_NF_ARP_MANGLE is not set
+CONFIG_IP_NF_CONNTRACK=y
+# CONFIG_IP_NF_CONNTRACK_EVENTS is not set
+CONFIG_IP_NF_CONNTRACK_MARK=y
+CONFIG_IP_NF_CT_ACCT=y
+# CONFIG_IP_NF_CT_PROTO_SCTP is not set
+# CONFIG_IP_NF_FILTER is not set
+# CONFIG_IP_NF_FTP is not set
+# CONFIG_IP_NF_H323 is not set
+# CONFIG_IP_NF_IPTABLES is not set
+# CONFIG_IP_NF_IRC is not set
+# CONFIG_IP_NF_MANGLE is not set
+# CONFIG_IP_NF_MATCH_ADDRTYPE is not set
+# CONFIG_IP_NF_MATCH_AH is not set
+# CONFIG_IP_NF_MATCH_ECN is not set
+# CONFIG_IP_NF_MATCH_HASHLIMIT is not set
+# CONFIG_IP_NF_MATCH_IPP2P is not set
+# CONFIG_IP_NF_MATCH_OWNER is not set
+# CONFIG_IP_NF_MATCH_RECENT is not set
+# CONFIG_IP_NF_MATCH_SET is not set
+# CONFIG_IP_NF_MATCH_TIME is not set
+# CONFIG_IP_NF_MATCH_TOS is not set
+# CONFIG_IP_NF_MATCH_TTL is not set
+CONFIG_IP_NF_NAT=y
+# CONFIG_IP_NF_NAT_AMANDA is not set
+# CONFIG_IP_NF_NAT_FTP is not set
+# CONFIG_IP_NF_NAT_H323 is not set
+# CONFIG_IP_NF_NAT_IRC is not set
+CONFIG_IP_NF_NAT_NEEDED=y
+# CONFIG_IP_NF_NAT_PPTP is not set
+# CONFIG_IP_NF_NAT_SIP is not set
+# CONFIG_IP_NF_NAT_SNMP_BASIC is not set
+# CONFIG_IP_NF_NAT_TFTP is not set
+# CONFIG_IP_NF_NETBIOS_NS is not set
+# CONFIG_IP_NF_PPTP is not set
+# CONFIG_IP_NF_QUEUE is not set
+# CONFIG_IP_NF_RAW is not set
+# CONFIG_IP_NF_SECURITY is not set
+# CONFIG_IP_NF_SET is not set
+CONFIG_IP_NF_SET_HASHSIZE=1024
+# CONFIG_IP_NF_SET_IPHASH is not set
+# CONFIG_IP_NF_SET_IPMAP is not set
+# CONFIG_IP_NF_SET_IPPORTHASH is not set
+# CONFIG_IP_NF_SET_IPTREE is not set
+# CONFIG_IP_NF_SET_IPTREEMAP is not set
+# CONFIG_IP_NF_SET_MACIPMAP is not set
+CONFIG_IP_NF_SET_MAX=256
+# CONFIG_IP_NF_SET_NETHASH is not set
+# CONFIG_IP_NF_SET_PORTMAP is not set
+# CONFIG_IP_NF_SIP is not set
+# CONFIG_IP_NF_TARGET_CLUSTERIP is not set
+# CONFIG_IP_NF_TARGET_ECN is not set
+# CONFIG_IP_NF_TARGET_IMQ is not set
+# CONFIG_IP_NF_TARGET_LOG is not set
+# CONFIG_IP_NF_TARGET_MASQUERADE is not set
+# CONFIG_IP_NF_TARGET_NETMAP is not set
+# CONFIG_IP_NF_TARGET_REDIRECT is not set
+# CONFIG_IP_NF_TARGET_REJECT is not set
+# CONFIG_IP_NF_TARGET_ROUTE is not set
+# CONFIG_IP_NF_TARGET_SAME is not set
+# CONFIG_IP_NF_TARGET_SET is not set
+# CONFIG_IP_NF_TARGET_TOS is not set
+# CONFIG_IP_NF_TARGET_TTL is not set
+# CONFIG_IP_NF_TARGET_ULOG is not set
+# CONFIG_IP_NF_TFTP is not set
+# CONFIG_IP_PIMSM_V1 is not set
+# CONFIG_IP_PIMSM_V2 is not set
+# CONFIG_IP_PNP is not set
+CONFIG_IP_ROUTE_FWMARK=y
+CONFIG_IP_ROUTE_MULTIPATH=y
+CONFIG_IP_ROUTE_MULTIPATH_CACHED=y
+# CONFIG_IP_ROUTE_MULTIPATH_DRR is not set
+# CONFIG_IP_ROUTE_MULTIPATH_RANDOM is not set
+# CONFIG_IP_ROUTE_MULTIPATH_RR is not set
+# CONFIG_IP_ROUTE_MULTIPATH_WRANDOM is not set
+CONFIG_IP_ROUTE_VERBOSE=y
+# CONFIG_IP_SCTP is not set
+# CONFIG_IP_VS is not set
+# CONFIG_IRDA is not set
+# CONFIG_IRQSOFF_TRACER is not set
+# CONFIG_ISCSI_TCP is not set
+CONFIG_ISDN=y
+# CONFIG_ISDN_AUDIO is not set
+# CONFIG_ISDN_CAPI_CAPIDRV is not set
+# CONFIG_ISDN_DIVERSION is not set
+# CONFIG_ISDN_DRV_ACT2000 is not set
+# CONFIG_ISDN_DRV_AVMB1_VERBOSE_REASON is not set
+# CONFIG_ISDN_DRV_EICON is not set
+# CONFIG_ISDN_DRV_HISAX is not set
+# CONFIG_ISDN_DRV_ICN is not set
+# CONFIG_ISDN_DRV_LOOP is not set
+# CONFIG_ISDN_DRV_PCBIT is not set
+# CONFIG_ISDN_DRV_SC is not set
+# CONFIG_ISDN_DRV_TPAM is not set
+# CONFIG_ISDN_WITH_ABC is not set
+# CONFIG_ISL29003 is not set
+# CONFIG_ISO9660_FS is not set
+# CONFIG_IWL3945 is not set
+# CONFIG_IWLAGN is not set
+# CONFIG_IWLCORE is not set
+# CONFIG_IWLWIFI is not set
+# CONFIG_IWLWIFI_LEDS is not set
+# CONFIG_IXGB is not set
+# CONFIG_JBD is not set
+# CONFIG_JBD2_DEBUG is not set
+# CONFIG_JBD_DEBUG is not set
+# CONFIG_JFFS2_CMODE_FAVOURLZO is not set
+# CONFIG_JFFS2_CMODE_NONE is not set
+CONFIG_JFFS2_CMODE_PRIORITY=y
+# CONFIG_JFFS2_CMODE_SIZE is not set
+CONFIG_JFFS2_COMPRESSION_OPTIONS=y
+CONFIG_JFFS2_FS=y
+CONFIG_JFFS2_FS_DEBUG=0
+# CONFIG_JFFS2_FS_WBUF_VERIFY is not set
+CONFIG_JFFS2_FS_WRITEBUFFER=y
+# CONFIG_JFFS2_FS_XATTR is not set
+# CONFIG_JFFS2_LZO is not set
+CONFIG_JFFS2_RTIME=y
+# CONFIG_JFFS2_RUBIN is not set
+CONFIG_JFFS2_SUMMARY=y
+CONFIG_JFFS2_ZLIB=y
+# CONFIG_JFFS_FS is not set
+# CONFIG_JFS_DEBUG is not set
+# CONFIG_JFS_FS is not set
+# CONFIG_JFS_POSIX_ACL is not set
+# CONFIG_JFS_SECURITY is not set
+# CONFIG_JFS_STATISTICS is not set
+# CONFIG_JME is not set
+CONFIG_JOLIET=y
+# CONFIG_KALLSYMS is not set
+# CONFIG_KALLSYMS_ALL is not set
+# CONFIG_KALLSYMS_EXTRA_PASS is not set
+# CONFIG_KARMA_PARTITION is not set
+# CONFIG_KERNEL_BZIP2 is not set
+# CONFIG_KERNEL_GZIP is not set
+CONFIG_KERNEL_LZMA=y
+# CONFIG_KERNEL_LZO is not set
+# CONFIG_KEXEC is not set
+# CONFIG_KEYBOARD_ADP5588 is not set
+# CONFIG_KEYBOARD_ATKBD is not set
+# CONFIG_KEYBOARD_LKKBD is not set
+# CONFIG_KEYBOARD_LM8323 is not set
+# CONFIG_KEYBOARD_MATRIX is not set
+# CONFIG_KEYBOARD_MAX7359 is not set
+# CONFIG_KEYBOARD_MCS is not set
+# CONFIG_KEYBOARD_NEWTON is not set
+# CONFIG_KEYBOARD_OPENCORES is not set
+# CONFIG_KEYBOARD_STOWAWAY is not set
+# CONFIG_KEYBOARD_SUNKBD is not set
+# CONFIG_KEYBOARD_XTKBD is not set
+# CONFIG_KEYS is not set
+# CONFIG_KMEMCHECK is not set
+# CONFIG_KMEMTRACE is not set
+CONFIG_KMOD=y
+# CONFIG_KPROBES is not set
+# CONFIG_KS8842 is not set
+# CONFIG_KS8851 is not set
+# CONFIG_LANMEDIA is not set
+# CONFIG_LAPB is not set
+# CONFIG_LASAT is not set
+# CONFIG_LATENCYTOP is not set
+CONFIG_LBDAF=y
+# CONFIG_LCD_LTV350QV is not set
+# CONFIG_LCD_TDO24M is not set
+# CONFIG_LCD_VGG2432A4 is not set
+# CONFIG_LDM_PARTITION is not set
+# CONFIG_LEDS_ALIX is not set
+# CONFIG_LEDS_BD2802 is not set
+CONFIG_LEDS_CLASS=y
+# CONFIG_LEDS_DAC124S085 is not set
+CONFIG_LEDS_GPIO_PLATFORM=y
+# CONFIG_LEDS_LP3944 is not set
+# CONFIG_LEDS_LP5521 is not set
+# CONFIG_LEDS_PCA9532 is not set
+# CONFIG_LEDS_PCA955X is not set
+CONFIG_LEDS_TRIGGERS=y
+# CONFIG_LEDS_TRIGGER_BACKLIGHT is not set
+CONFIG_LEDS_TRIGGER_DEFAULT_ON=y
+# CONFIG_LEDS_TRIGGER_GPIO is not set
+# CONFIG_LEDS_TRIGGER_HEARTBEAT is not set
+# CONFIG_LEDS_TRIGGER_IDE_DISK is not set
+# CONFIG_LEDS_TRIGGER_MORSE is not set
+CONFIG_LEDS_TRIGGER_NETDEV=y
+CONFIG_LEDS_TRIGGER_TIMER=y
+# CONFIG_LEGACY_PTYS is not set
+# CONFIG_LIB80211 is not set
+# CONFIG_LIB80211_CRYPT_CCMP is not set
+# CONFIG_LIB80211_CRYPT_TKIP is not set
+# CONFIG_LIB80211_CRYPT_WEP is not set
+# CONFIG_LIB80211_DEBUG is not set
+# CONFIG_LIBCRC32C is not set
+# CONFIG_LIBERTAS is not set
+# CONFIG_LIBERTAS_THINFIRM is not set
+# CONFIG_LIBERTAS_USB is not set
+# CONFIG_LIBFC is not set
+# CONFIG_LIBFCOE is not set
+# CONFIG_LIBIPW_DEBUG is not set
+# CONFIG_LINE6_USB is not set
+CONFIG_LLC=y
+# CONFIG_LLC2 is not set
+CONFIG_LOCALVERSION=""
+# CONFIG_LOCALVERSION_AUTO is not set
+# CONFIG_LOCKD is not set
+CONFIG_LOCKDEP_SUPPORT=y
+CONFIG_LOCKD_V4=y
+# CONFIG_LOGIRUMBLEPAD2_FF is not set
+# CONFIG_LOGITECH_FF is not set
+# CONFIG_LOGO is not set
+CONFIG_LOG_BUF_SHIFT=14
+# CONFIG_LSF is not set
+# CONFIG_LSI_ET1011C_PHY is not set
+# CONFIG_LTPC is not set
+# CONFIG_LXT_PHY is not set
+# CONFIG_MAC80211 is not set
+CONFIG_MAC80211_DEFAULT_PS=y
+CONFIG_MAC80211_DEFAULT_PS_VALUE=1
+# CONFIG_MACINTOSH_DRIVERS is not set
+# CONFIG_MACVLAN is not set
+# CONFIG_MAC_EMUMOUSEBTN is not set
+# CONFIG_MAC_PARTITION is not set
+CONFIG_MAGIC_SYSRQ=y
+# CONFIG_MARKEINS is not set
+# CONFIG_MARKERS is not set
+# CONFIG_MARVELL_PHY is not set
+# CONFIG_MD is not set
+# CONFIG_MDIO_BITBANG is not set
+# CONFIG_ME4000 is not set
+# CONFIG_MEDIA_ATTACH is not set
+# CONFIG_MEDIA_SUPPORT is not set
+# CONFIG_MEDIA_TUNER_CUSTOMISE is not set
+# CONFIG_MEGARAID_LEGACY is not set
+# CONFIG_MEGARAID_NEWGEN is not set
+# CONFIG_MEGARAID_SAS is not set
+# CONFIG_MEILHAUS is not set
+# CONFIG_MEMSTICK is not set
+# CONFIG_MFD_ASIC3 is not set
+# CONFIG_MFD_CORE is not set
+# CONFIG_MFD_PCF50633 is not set
+# CONFIG_MFD_SM501 is not set
+# CONFIG_MFD_TC6387XB is not set
+# CONFIG_MFD_TC6393XB is not set
+# CONFIG_MFD_TMIO is not set
+# CONFIG_MFD_WM8350_I2C is not set
+# CONFIG_MFD_WM8400 is not set
+# CONFIG_MG_DISK is not set
+# CONFIG_MIGRATION is not set
+CONFIG_MII=y
+# CONFIG_MINIX_FS is not set
+# CONFIG_MINIX_SUBPARTITION is not set
+CONFIG_MINI_FO=y
+# CONFIG_MIPS_FPU_EMU is not set
+CONFIG_MISC_DEVICES=y
+CONFIG_MISC_FILESYSTEMS=y
+# CONFIG_MISDN is not set
+# CONFIG_MISDN_HFCPCI is not set
+# CONFIG_MISDN_HFCUSB is not set
+# CONFIG_MKISS is not set
+# CONFIG_MMC is not set
+# CONFIG_MMC_ARMMMCI is not set
+# CONFIG_MMC_BLOCK is not set
+CONFIG_MMC_BLOCK_BOUNCE=y
+# CONFIG_MMC_CB710 is not set
+# CONFIG_MMC_DEBUG is not set
+# CONFIG_MMC_S3C is not set
+# CONFIG_MMC_SDHCI is not set
+# CONFIG_MMC_SDRICOH_CS is not set
+# CONFIG_MMC_SPI is not set
+# CONFIG_MMC_TEST is not set
+# CONFIG_MMC_UNSAFE_RESUME is not set
+# CONFIG_MMC_VIA_SDMMC is not set
+CONFIG_MMU=y
+CONFIG_MODULES=y
+# CONFIG_MODULE_FORCE_LOAD is not set
+# CONFIG_MODULE_FORCE_UNLOAD is not set
+# CONFIG_MODULE_SRCVERSION_ALL is not set
+CONFIG_MODULE_UNLOAD=y
+# CONFIG_MODVERSIONS is not set
+# CONFIG_MOUSE_APPLETOUCH is not set
+# CONFIG_MOUSE_GPIO is not set
+# CONFIG_MOUSE_INPORT is not set
+# CONFIG_MOUSE_LOGIBM is not set
+# CONFIG_MOUSE_PC110PAD is not set
+# CONFIG_MOUSE_SYNAPTICS_I2C is not set
+# CONFIG_MSDOS_FS is not set
+CONFIG_MSDOS_PARTITION=y
+CONFIG_MTD=y
+# CONFIG_MTD_ABSENT is not set
+# CONFIG_MTD_AFS_PARTS is not set
+# CONFIG_MTD_ALAUDA is not set
+# CONFIG_MTD_AR7_PARTS is not set
+# CONFIG_MTD_ARM_INTEGRATOR is not set
+CONFIG_MTD_BLKDEVS=y
+CONFIG_MTD_BLOCK=y
+# CONFIG_MTD_BLOCK2MTD is not set
+CONFIG_MTD_CFI=y
+# CONFIG_MTD_CFI_ADV_OPTIONS is not set
+CONFIG_MTD_CFI_AMDSTD=y
+# CONFIG_MTD_CFI_BE_BYTE_SWAP is not set
+CONFIG_MTD_CFI_I1=y
+CONFIG_MTD_CFI_I2=y
+# CONFIG_MTD_CFI_I4 is not set
+# CONFIG_MTD_CFI_I8 is not set
+CONFIG_MTD_CFI_INTELEXT=y
+# CONFIG_MTD_CFI_LE_BYTE_SWAP is not set
+CONFIG_MTD_CFI_NOSWAP=y
+# CONFIG_MTD_CFI_STAA is not set
+CONFIG_MTD_CFI_UTIL=y
+CONFIG_MTD_CHAR=y
+# CONFIG_MTD_CMDLINE_PARTS is not set
+CONFIG_MTD_COMPLEX_MAPPINGS=y
+# CONFIG_MTD_CONCAT is not set
+# CONFIG_MTD_DATAFLASH is not set
+# CONFIG_MTD_DEBUG is not set
+# CONFIG_MTD_DOC2000 is not set
+# CONFIG_MTD_DOC2001 is not set
+# CONFIG_MTD_DOC2001PLUS is not set
+CONFIG_MTD_GEN_PROBE=y
+# CONFIG_MTD_INTEL_VR_NOR is not set
+# CONFIG_MTD_JEDECPROBE is not set
+# CONFIG_MTD_LPDDR is not set
+# CONFIG_MTD_M25P80 is not set
+CONFIG_MTD_MAP_BANK_WIDTH_1=y
+# CONFIG_MTD_MAP_BANK_WIDTH_16 is not set
+CONFIG_MTD_MAP_BANK_WIDTH_2=y
+# CONFIG_MTD_MAP_BANK_WIDTH_32 is not set
+CONFIG_MTD_MAP_BANK_WIDTH_4=y
+# CONFIG_MTD_MAP_BANK_WIDTH_8 is not set
+# CONFIG_MTD_MTDRAM is not set
+# CONFIG_MTD_MYLOADER_PARTS is not set
+# CONFIG_MTD_NAND is not set
+# CONFIG_MTD_NAND_CAFE is not set
+# CONFIG_MTD_NAND_DISKONCHIP is not set
+# CONFIG_MTD_NAND_ECC_SMC is not set
+# CONFIG_MTD_NAND_GPIO is not set
+CONFIG_MTD_NAND_IDS=y
+# CONFIG_MTD_NAND_MUSEUM_IDS is not set
+# CONFIG_MTD_NAND_NANDSIM is not set
+# CONFIG_MTD_NAND_PLATFORM is not set
+# CONFIG_MTD_NAND_VERIFY_WRITE is not set
+# CONFIG_MTD_ONENAND is not set
+# CONFIG_MTD_OOPS is not set
+# CONFIG_MTD_OTP is not set
+CONFIG_MTD_PARTITIONS=y
+# CONFIG_MTD_PCI is not set
+# CONFIG_MTD_PHRAM is not set
+# CONFIG_MTD_PHYSMAP is not set
+# CONFIG_MTD_PHYSMAP_COMPAT is not set
+# CONFIG_MTD_PLATRAM is not set
+# CONFIG_MTD_PMC551 is not set
+# CONFIG_MTD_RAM is not set
+CONFIG_MTD_REDBOOT_DIRECTORY_BLOCK=-1
+# CONFIG_MTD_REDBOOT_PARTS is not set
+# CONFIG_MTD_REDBOOT_PARTS_READONLY is not set
+# CONFIG_MTD_REDBOOT_PARTS_UNALLOCATED is not set
+# CONFIG_MTD_ROM is not set
+CONFIG_MTD_ROOTFS_ROOT_DEV=y
+CONFIG_MTD_ROOTFS_SPLIT=y
+# CONFIG_MTD_SLRAM is not set
+# CONFIG_MTD_TESTS is not set
+# CONFIG_MTD_UBI is not set
+# CONFIG_MVSWITCH_PHY is not set
+# CONFIG_MWAVE is not set
+# CONFIG_MWL8K is not set
+# CONFIG_MYRI10GE is not set
+# CONFIG_NAMESPACES is not set
+# CONFIG_NATIONAL_PHY is not set
+# CONFIG_NATSEMI is not set
+# CONFIG_NCP_FS is not set
+# CONFIG_NE2K_PCI is not set
+# CONFIG_NEC_MARKEINS is not set
+CONFIG_NET=y
+# CONFIG_NETCONSOLE is not set
+# CONFIG_NETDEBUG is not set
+CONFIG_NETDEVICES=y
+CONFIG_NETDEVICES_MULTIQUEUE=y
+CONFIG_NETDEV_1000=y
+# CONFIG_NETDEV_10000 is not set
+CONFIG_NETFILTER=y
+CONFIG_NETFILTER_ADVANCED=y
+# CONFIG_NETFILTER_DEBUG is not set
+# CONFIG_NETFILTER_NETLINK is not set
+# CONFIG_NETFILTER_NETLINK_LOG is not set
+# CONFIG_NETFILTER_NETLINK_QUEUE is not set
+# CONFIG_NETFILTER_TPROXY is not set
+# CONFIG_NETFILTER_XTABLES is not set
+# CONFIG_NETFILTER_XT_MATCH_CLUSTER is not set
+# CONFIG_NETFILTER_XT_MATCH_COMMENT is not set
+# CONFIG_NETFILTER_XT_MATCH_CONNBYTES is not set
+# CONFIG_NETFILTER_XT_MATCH_CONNLIMIT is not set
+# CONFIG_NETFILTER_XT_MATCH_CONNMARK is not set
+# CONFIG_NETFILTER_XT_MATCH_CONNTRACK is not set
+# CONFIG_NETFILTER_XT_MATCH_DCCP is not set
+# CONFIG_NETFILTER_XT_MATCH_DSCP is not set
+# CONFIG_NETFILTER_XT_MATCH_ESP is not set
+# CONFIG_NETFILTER_XT_MATCH_HASHLIMIT is not set
+# CONFIG_NETFILTER_XT_MATCH_HELPER is not set
+# CONFIG_NETFILTER_XT_MATCH_HL is not set
+# CONFIG_NETFILTER_XT_MATCH_IPRANGE is not set
+# CONFIG_NETFILTER_XT_MATCH_LAYER7 is not set
+# CONFIG_NETFILTER_XT_MATCH_LAYER7_DEBUG is not set
+# CONFIG_NETFILTER_XT_MATCH_LENGTH is not set
+# CONFIG_NETFILTER_XT_MATCH_LIMIT is not set
+# CONFIG_NETFILTER_XT_MATCH_MAC is not set
+# CONFIG_NETFILTER_XT_MATCH_MARK is not set
+# CONFIG_NETFILTER_XT_MATCH_MULTIPORT is not set
+# CONFIG_NETFILTER_XT_MATCH_OSF is not set
+# CONFIG_NETFILTER_XT_MATCH_OWNER is not set
+# CONFIG_NETFILTER_XT_MATCH_PHYSDEV is not set
+# CONFIG_NETFILTER_XT_MATCH_PKTTYPE is not set
+# CONFIG_NETFILTER_XT_MATCH_POLICY is not set
+# CONFIG_NETFILTER_XT_MATCH_QUOTA is not set
+# CONFIG_NETFILTER_XT_MATCH_RATEEST is not set
+# CONFIG_NETFILTER_XT_MATCH_REALM is not set
+# CONFIG_NETFILTER_XT_MATCH_RECENT is not set
+# CONFIG_NETFILTER_XT_MATCH_RECENT_PROC_COMPAT is not set
+# CONFIG_NETFILTER_XT_MATCH_SCTP is not set
+# CONFIG_NETFILTER_XT_MATCH_SOCKET is not set
+# CONFIG_NETFILTER_XT_MATCH_STATE is not set
+# CONFIG_NETFILTER_XT_MATCH_STATISTIC is not set
+# CONFIG_NETFILTER_XT_MATCH_STRING is not set
+# CONFIG_NETFILTER_XT_MATCH_TCPMSS is not set
+# CONFIG_NETFILTER_XT_MATCH_TIME is not set
+# CONFIG_NETFILTER_XT_MATCH_U32 is not set
+# CONFIG_NETFILTER_XT_TARGET_CLASSIFY is not set
+# CONFIG_NETFILTER_XT_TARGET_CONNMARK is not set
+# CONFIG_NETFILTER_XT_TARGET_DSCP is not set
+# CONFIG_NETFILTER_XT_TARGET_HL is not set
+# CONFIG_NETFILTER_XT_TARGET_IMQ is not set
+# CONFIG_NETFILTER_XT_TARGET_LED is not set
+# CONFIG_NETFILTER_XT_TARGET_MARK is not set
+# CONFIG_NETFILTER_XT_TARGET_NFLOG is not set
+# CONFIG_NETFILTER_XT_TARGET_NFQUEUE is not set
+# CONFIG_NETFILTER_XT_TARGET_NOTRACK is not set
+# CONFIG_NETFILTER_XT_TARGET_RATEEST is not set
+# CONFIG_NETFILTER_XT_TARGET_TCPMSS is not set
+# CONFIG_NETFILTER_XT_TARGET_TCPOPTSTRIP is not set
+# CONFIG_NETFILTER_XT_TARGET_TPROXY is not set
+# CONFIG_NETFILTER_XT_TARGET_TRACE is not set
+# CONFIG_NETPOLL is not set
+# CONFIG_NETROM is not set
+CONFIG_NETWORK_FILESYSTEMS=y
+# CONFIG_NETWORK_SECMARK is not set
+# CONFIG_NETXEN_NIC is not set
+# CONFIG_NET_9P is not set
+# CONFIG_NET_ACT_GACT is not set
+# CONFIG_NET_ACT_IPT is not set
+# CONFIG_NET_ACT_MIRRED is not set
+# CONFIG_NET_ACT_NAT is not set
+# CONFIG_NET_ACT_PEDIT is not set
+# CONFIG_NET_ACT_POLICE is not set
+# CONFIG_NET_ACT_SIMP is not set
+# CONFIG_NET_ACT_SKBEDIT is not set
+CONFIG_NET_CLS=y
+# CONFIG_NET_CLS_ACT is not set
+# CONFIG_NET_CLS_BASIC is not set
+# CONFIG_NET_CLS_FLOW is not set
+# CONFIG_NET_CLS_FW is not set
+CONFIG_NET_CLS_IND=y
+# CONFIG_NET_CLS_ROUTE4 is not set
+# CONFIG_NET_CLS_RSVP is not set
+# CONFIG_NET_CLS_RSVP6 is not set
+# CONFIG_NET_CLS_TCINDEX is not set
+# CONFIG_NET_CLS_U32 is not set
+# CONFIG_NET_DROP_MONITOR is not set
+# CONFIG_NET_DSA is not set
+# CONFIG_NET_EMATCH is not set
+# CONFIG_NET_EMATCH_CMP is not set
+# CONFIG_NET_EMATCH_META is not set
+# CONFIG_NET_EMATCH_NBYTE is not set
+CONFIG_NET_EMATCH_STACK=32
+# CONFIG_NET_EMATCH_TEXT is not set
+# CONFIG_NET_EMATCH_U32 is not set
+CONFIG_NET_ESTIMATOR=y
+CONFIG_NET_ETHERNET=y
+# CONFIG_NET_FC is not set
+# CONFIG_NET_IPGRE is not set
+CONFIG_NET_IPGRE_BROADCAST=y
+# CONFIG_NET_IPIP is not set
+# CONFIG_NET_ISA is not set
+# CONFIG_NET_KEY is not set
+# CONFIG_NET_KEY_MIGRATE is not set
+CONFIG_NET_PCI=y
+# CONFIG_NET_PCMCIA is not set
+# CONFIG_NET_PKTGEN is not set
+# CONFIG_NET_POLL_CONTROLLER is not set
+CONFIG_NET_RADIO=y
+# CONFIG_NET_SB1000 is not set
+CONFIG_NET_SCHED=y
+# CONFIG_NET_SCH_ATM is not set
+# CONFIG_NET_SCH_CBQ is not set
+# CONFIG_NET_SCH_CLK_CPU is not set
+# CONFIG_NET_SCH_CLK_GETTIMEOFDAY is not set
+CONFIG_NET_SCH_CLK_JIFFIES=y
+# CONFIG_NET_SCH_DRR is not set
+# CONFIG_NET_SCH_DSMARK is not set
+# CONFIG_NET_SCH_ESFQ is not set
+CONFIG_NET_SCH_ESFQ_NFCT=y
+CONFIG_NET_SCH_FIFO=y
+# CONFIG_NET_SCH_GRED is not set
+# CONFIG_NET_SCH_HFSC is not set
+# CONFIG_NET_SCH_HTB is not set
+# CONFIG_NET_SCH_INGRESS is not set
+# CONFIG_NET_SCH_MULTIQ is not set
+# CONFIG_NET_SCH_NETEM is not set
+# CONFIG_NET_SCH_PRIO is not set
+# CONFIG_NET_SCH_RED is not set
+# CONFIG_NET_SCH_RR is not set
+# CONFIG_NET_SCH_SFQ is not set
+# CONFIG_NET_SCH_TBF is not set
+# CONFIG_NET_SCH_TEQL is not set
+# CONFIG_NET_TULIP is not set
+# CONFIG_NET_VENDOR_3COM is not set
+CONFIG_NET_WIRELESS=y
+CONFIG_NET_WIRELESS_RTNETLINK=y
+# CONFIG_NEW_GPIO is not set
+CONFIG_NEW_LEDS=y
+# CONFIG_NFSD is not set
+CONFIG_NFSD_TCP=y
+# CONFIG_NFSD_V2_ACL is not set
+CONFIG_NFSD_V3=y
+# CONFIG_NFSD_V3_ACL is not set
+# CONFIG_NFSD_V4 is not set
+# CONFIG_NFS_ACL_SUPPORT is not set
+CONFIG_NFS_COMMON=y
+# CONFIG_NFS_DIRECTIO is not set
+# CONFIG_NFS_FS is not set
+CONFIG_NFS_V3=y
+# CONFIG_NFS_V3_ACL is not set
+# CONFIG_NFS_V4 is not set
+# CONFIG_NFS_V4_1 is not set
+# CONFIG_NFTL is not set
+# CONFIG_NF_CONNTRACK is not set
+# CONFIG_NF_CONNTRACK_AMANDA is not set
+CONFIG_NF_CONNTRACK_ENABLED=y
+# CONFIG_NF_CONNTRACK_EVENTS is not set
+# CONFIG_NF_CONNTRACK_FTP is not set
+# CONFIG_NF_CONNTRACK_H323 is not set
+# CONFIG_NF_CONNTRACK_IPV4 is not set
+# CONFIG_NF_CONNTRACK_IPV6 is not set
+# CONFIG_NF_CONNTRACK_IRC is not set
+CONFIG_NF_CONNTRACK_MARK=y
+# CONFIG_NF_CONNTRACK_NETBIOS_NS is not set
+# CONFIG_NF_CONNTRACK_PPTP is not set
+CONFIG_NF_CONNTRACK_PROC_COMPAT=y
+# CONFIG_NF_CONNTRACK_RTSP is not set
+# CONFIG_NF_CONNTRACK_SANE is not set
+# CONFIG_NF_CONNTRACK_SIP is not set
+CONFIG_NF_CONNTRACK_SUPPORT=y
+# CONFIG_NF_CONNTRACK_TFTP is not set
+# CONFIG_NF_CONNTRACK_ZONES is not set
+# CONFIG_NF_CT_ACCT is not set
+# CONFIG_NF_CT_NETLINK is not set
+# CONFIG_NF_CT_PROTO_DCCP is not set
+# CONFIG_NF_CT_PROTO_GRE is not set
+# CONFIG_NF_CT_PROTO_SCTP is not set
+# CONFIG_NF_CT_PROTO_UDPLITE is not set
+# CONFIG_NF_DEFRAG_IPV4 is not set
+# CONFIG_NF_NAT is not set
+# CONFIG_NF_NAT_AMANDA is not set
+# CONFIG_NF_NAT_FTP is not set
+# CONFIG_NF_NAT_H323 is not set
+# CONFIG_NF_NAT_IRC is not set
+CONFIG_NF_NAT_NEEDED=y
+# CONFIG_NF_NAT_PPTP is not set
+# CONFIG_NF_NAT_PROTO_GRE is not set
+# CONFIG_NF_NAT_RTSP is not set
+# CONFIG_NF_NAT_SIP is not set
+# CONFIG_NF_NAT_SNMP_BASIC is not set
+# CONFIG_NF_NAT_TFTP is not set
+# CONFIG_NILFS2_FS is not set
+CONFIG_NL80211=y
+CONFIG_NLATTR=y
+# CONFIG_NLS is not set
+# CONFIG_NLS_ASCII is not set
+# CONFIG_NLS_CODEPAGE_1250 is not set
+# CONFIG_NLS_CODEPAGE_1251 is not set
+# CONFIG_NLS_CODEPAGE_437 is not set
+# CONFIG_NLS_CODEPAGE_737 is not set
+# CONFIG_NLS_CODEPAGE_775 is not set
+# CONFIG_NLS_CODEPAGE_850 is not set
+# CONFIG_NLS_CODEPAGE_852 is not set
+# CONFIG_NLS_CODEPAGE_855 is not set
+# CONFIG_NLS_CODEPAGE_857 is not set
+# CONFIG_NLS_CODEPAGE_860 is not set
+# CONFIG_NLS_CODEPAGE_861 is not set
+# CONFIG_NLS_CODEPAGE_862 is not set
+# CONFIG_NLS_CODEPAGE_863 is not set
+# CONFIG_NLS_CODEPAGE_864 is not set
+# CONFIG_NLS_CODEPAGE_865 is not set
+# CONFIG_NLS_CODEPAGE_866 is not set
+# CONFIG_NLS_CODEPAGE_869 is not set
+# CONFIG_NLS_CODEPAGE_874 is not set
+# CONFIG_NLS_CODEPAGE_932 is not set
+# CONFIG_NLS_CODEPAGE_936 is not set
+# CONFIG_NLS_CODEPAGE_949 is not set
+# CONFIG_NLS_CODEPAGE_950 is not set
+CONFIG_NLS_DEFAULT="iso8859-1"
+# CONFIG_NLS_ISO8859_1 is not set
+# CONFIG_NLS_ISO8859_13 is not set
+# CONFIG_NLS_ISO8859_14 is not set
+# CONFIG_NLS_ISO8859_15 is not set
+# CONFIG_NLS_ISO8859_2 is not set
+# CONFIG_NLS_ISO8859_3 is not set
+# CONFIG_NLS_ISO8859_4 is not set
+# CONFIG_NLS_ISO8859_5 is not set
+# CONFIG_NLS_ISO8859_6 is not set
+# CONFIG_NLS_ISO8859_7 is not set
+# CONFIG_NLS_ISO8859_8 is not set
+# CONFIG_NLS_ISO8859_9 is not set
+# CONFIG_NLS_KOI8_R is not set
+# CONFIG_NLS_KOI8_U is not set
+# CONFIG_NLS_UTF8 is not set
+# CONFIG_NOP_USB_XCEIV is not set
+# CONFIG_NORTEL_HERMES is not set
+# CONFIG_NOZOMI is not set
+# CONFIG_NO_HZ is not set
+# CONFIG_NS83820 is not set
+# CONFIG_NTFS_DEBUG is not set
+# CONFIG_NTFS_FS is not set
+# CONFIG_NTFS_RW is not set
+# CONFIG_NVRAM is not set
+# CONFIG_OABI_COMPAT is not set
+# CONFIG_OCFS2_FS is not set
+# CONFIG_OCF_BENCH is not set
+# CONFIG_OCF_C7108 is not set
+# CONFIG_OCF_CRYPTOCTEON is not set
+# CONFIG_OCF_EP80579 is not set
+# CONFIG_OCF_HIFN is not set
+# CONFIG_OCF_HIFNHIPP is not set
+# CONFIG_OCF_IXP4XX is not set
+# CONFIG_OCF_KIRKWOOD is not set
+# CONFIG_OCF_OCF is not set
+# CONFIG_OCF_OCFNULL is not set
+# CONFIG_OCF_SAFE is not set
+# CONFIG_OCF_TALITOS is not set
+# CONFIG_OCF_UBSEC_SSB is not set
+# CONFIG_OMFS_FS is not set
+# CONFIG_OPROFILE is not set
+# CONFIG_OSF_PARTITION is not set
+# CONFIG_P54_COMMON is not set
+CONFIG_PACKET=y
+CONFIG_PACKET_MMAP=y
+# CONFIG_PAGE_SIZE_16KB is not set
+# CONFIG_PAGE_SIZE_32KB is not set
+CONFIG_PAGE_SIZE_4KB=y
+# CONFIG_PAGE_SIZE_64KB is not set
+# CONFIG_PAGE_SIZE_8KB is not set
+# CONFIG_PANTHERLORD_FF is not set
+# CONFIG_PARPORT is not set
+# CONFIG_PARPORT_PC is not set
+CONFIG_PARTITION_ADVANCED=y
+# CONFIG_PATA_ALI is not set
+# CONFIG_PATA_AMD is not set
+# CONFIG_PATA_ARTOP is not set
+# CONFIG_PATA_ATIIXP is not set
+# CONFIG_PATA_CMD640_PCI is not set
+# CONFIG_PATA_CMD64X is not set
+# CONFIG_PATA_CS5520 is not set
+# CONFIG_PATA_CS5530 is not set
+# CONFIG_PATA_CS5535 is not set
+# CONFIG_PATA_CS5536 is not set
+# CONFIG_PATA_CYPRESS is not set
+# CONFIG_PATA_EFAR is not set
+# CONFIG_PATA_HPT366 is not set
+# CONFIG_PATA_HPT37X is not set
+# CONFIG_PATA_HPT3X2N is not set
+# CONFIG_PATA_HPT3X3 is not set
+# CONFIG_PATA_ISAPNP is not set
+# CONFIG_PATA_IT8213 is not set
+# CONFIG_PATA_IT821X is not set
+# CONFIG_PATA_JMICRON is not set
+# CONFIG_PATA_LEGACY is not set
+# CONFIG_PATA_MARVELL is not set
+# CONFIG_PATA_MPIIX is not set
+# CONFIG_PATA_NETCELL is not set
+# CONFIG_PATA_NINJA32 is not set
+# CONFIG_PATA_NS87410 is not set
+# CONFIG_PATA_NS87415 is not set
+# CONFIG_PATA_OLDPIIX is not set
+# CONFIG_PATA_OPTI is not set
+# CONFIG_PATA_OPTIDMA is not set
+# CONFIG_PATA_PCMCIA is not set
+# CONFIG_PATA_PDC2027X is not set
+# CONFIG_PATA_PDC_OLD is not set
+# CONFIG_PATA_PLATFORM is not set
+# CONFIG_PATA_QDI is not set
+# CONFIG_PATA_RADISYS is not set
+# CONFIG_PATA_RZ1000 is not set
+# CONFIG_PATA_SC1200 is not set
+# CONFIG_PATA_SCH is not set
+# CONFIG_PATA_SERVERWORKS is not set
+# CONFIG_PATA_SIL680 is not set
+# CONFIG_PATA_SIS is not set
+# CONFIG_PATA_TRIFLEX is not set
+# CONFIG_PATA_VIA is not set
+# CONFIG_PATA_WINBOND is not set
+# CONFIG_PATA_WINBOND_VLB is not set
+# CONFIG_PC300TOO is not set
+# CONFIG_PCCARD is not set
+# CONFIG_PCF8575 is not set
+# CONFIG_PCI is not set
+# CONFIG_PCI200SYN is not set
+# CONFIG_PCIEASPM is not set
+# CONFIG_PCIPCWATCHDOG is not set
+# CONFIG_PCI_ATMEL is not set
+# CONFIG_PCI_DISABLE_COMMON_QUIRKS is not set
+# CONFIG_PCI_HERMES is not set
+# CONFIG_PCI_IOV is not set
+# CONFIG_PCI_LEGACY is not set
+# CONFIG_PCI_MSI is not set
+CONFIG_PCI_QUIRKS=y
+# CONFIG_PCI_STUB is not set
+CONFIG_PCI_SYSCALL=y
+# CONFIG_PCMCIA is not set
+# CONFIG_PCMCIA_AHA152X is not set
+# CONFIG_PCMCIA_ATMEL is not set
+# CONFIG_PCMCIA_DEBUG is not set
+# CONFIG_PCMCIA_FDOMAIN is not set
+# CONFIG_PCMCIA_HERMES is not set
+# CONFIG_PCMCIA_IOCTL is not set
+# CONFIG_PCMCIA_LOAD_CIS is not set
+# CONFIG_PCMCIA_NETWAVE is not set
+# CONFIG_PCMCIA_NINJA_SCSI is not set
+# CONFIG_PCMCIA_QLOGIC is not set
+# CONFIG_PCMCIA_RAYCS is not set
+# CONFIG_PCMCIA_SPECTRUM is not set
+# CONFIG_PCMCIA_SYM53C500 is not set
+# CONFIG_PCMCIA_WAVELAN is not set
+# CONFIG_PCMCIA_WL3501 is not set
+# CONFIG_PCMCIA_XIRCOM is not set
+# CONFIG_PCNET32 is not set
+# CONFIG_PCSPKR_PLATFORM is not set
+# CONFIG_PD6729 is not set
+# CONFIG_PDC_ADMA is not set
+# CONFIG_PHANTOM is not set
+# CONFIG_PHONE is not set
+# CONFIG_PHONET is not set
+# CONFIG_PHYLIB is not set
+# CONFIG_PHYS_ADDR_T_64BIT is not set
+# CONFIG_PID_NS is not set
+# CONFIG_PLAN9AUTH is not set
+CONFIG_PLIST=y
+# CONFIG_PLX_HERMES is not set
+# CONFIG_PM is not set
+# CONFIG_PMIC_DA903X is not set
+# CONFIG_POHMELFS is not set
+# CONFIG_POSIX_MQUEUE is not set
+# CONFIG_POWER_SUPPLY is not set
+CONFIG_PPC4xx_GPIO=y
+# CONFIG_PPC_16K_PAGES is not set
+# CONFIG_PPC_256K_PAGES is not set
+CONFIG_PPC_4K_PAGES=y
+# CONFIG_PPC_64K_PAGES is not set
+# CONFIG_PPC_EMULATED_STATS is not set
+# CONFIG_PPP is not set
+# CONFIG_PPPOATM is not set
+# CONFIG_PPPOE is not set
+# CONFIG_PPPOL2TP is not set
+# CONFIG_PPP_ASYNC is not set
+# CONFIG_PPP_BSDCOMP is not set
+# CONFIG_PPP_DEFLATE is not set
+CONFIG_PPP_FILTER=y
+# CONFIG_PPP_MPPE is not set
+CONFIG_PPP_MULTILINK=y
+# CONFIG_PPP_SYNC_TTY is not set
+# CONFIG_PPS is not set
+# CONFIG_PREEMPT is not set
+CONFIG_PREEMPT_NONE=y
+# CONFIG_PREEMPT_RCU is not set
+# CONFIG_PREEMPT_RCU_TRACE is not set
+# CONFIG_PREEMPT_VOLUNTARY is not set
+CONFIG_PREVENT_FIRMWARE_BUILD=y
+CONFIG_PRINTK=y
+# CONFIG_PRINTK_TIME is not set
+# CONFIG_PRISM2_USB is not set
+# CONFIG_PRISM54 is not set
+CONFIG_PROC_FS=y
+# CONFIG_PROC_KCORE is not set
+# CONFIG_PROC_PAGE_MONITOR is not set
+CONFIG_PROC_SYSCTL=y
+# CONFIG_PROFILING is not set
+# CONFIG_PROVE_LOCKING is not set
+# CONFIG_PROVE_RCU is not set
+# CONFIG_QEMU is not set
+# CONFIG_QLA3XXX is not set
+# CONFIG_QNX4FS_FS is not set
+# CONFIG_QSEMI_PHY is not set
+# CONFIG_QUOTA is not set
+# CONFIG_R3964 is not set
+# CONFIG_R6040 is not set
+# CONFIG_R8169 is not set
+# CONFIG_RADIO_ADAPTERS is not set
+# CONFIG_RADIO_AZTECH is not set
+# CONFIG_RADIO_CADET is not set
+# CONFIG_RADIO_GEMTEK is not set
+# CONFIG_RADIO_GEMTEK_PCI is not set
+# CONFIG_RADIO_MAESTRO is not set
+# CONFIG_RADIO_MAXIRADIO is not set
+# CONFIG_RADIO_RTRACK is not set
+# CONFIG_RADIO_RTRACK2 is not set
+# CONFIG_RADIO_SF16FMI is not set
+# CONFIG_RADIO_SF16FMR2 is not set
+# CONFIG_RADIO_TERRATEC is not set
+# CONFIG_RADIO_TRUST is not set
+# CONFIG_RADIO_TYPHOON is not set
+# CONFIG_RADIO_ZOLTRIX is not set
+# CONFIG_RAID_ATTRS is not set
+CONFIG_RAMFS=y
+# CONFIG_RAW_DRIVER is not set
+# CONFIG_RCU_CPU_STALL_DETECTOR is not set
+# CONFIG_RDC_17F3101X is not set
+# CONFIG_RD_BZIP2 is not set
+# CONFIG_RD_GZIP is not set
+CONFIG_RD_LZMA=y
+# CONFIG_RD_LZO is not set
+# CONFIG_REALTEK_PHY is not set
+# CONFIG_REDWOOD is not set
+# CONFIG_REGULATOR is not set
+# CONFIG_REGULATOR_BQ24022 is not set
+# CONFIG_REGULATOR_FIXED_VOLTAGE is not set
+# CONFIG_REGULATOR_VIRTUAL_CONSUMER is not set
+# CONFIG_REISERFS_CHECK is not set
+# CONFIG_REISERFS_FS is not set
+# CONFIG_REISERFS_FS_XATTR is not set
+# CONFIG_REISERFS_PROC_INFO is not set
+# CONFIG_RELAY is not set
+# CONFIG_RESOURCES_64BIT is not set
+# CONFIG_RFD_FTL is not set
+# CONFIG_RFKILL is not set
+# CONFIG_RFKILL_INPUT is not set
+# CONFIG_ROMFS_FS is not set
+# CONFIG_ROSE is not set
+# CONFIG_RPCSEC_GSS_KRB5 is not set
+# CONFIG_RPCSEC_GSS_SPKM3 is not set
+# CONFIG_RT2860 is not set
+# CONFIG_RT2870 is not set
+# CONFIG_RT2X00 is not set
+# CONFIG_RT3070 is not set
+# CONFIG_RTC_CLASS is not set
+# CONFIG_RTC_DEBUG is not set
+# CONFIG_RTC_DRV_BQ4802 is not set
+CONFIG_RTC_DRV_CMOS=y
+# CONFIG_RTC_DRV_DS1286 is not set
+# CONFIG_RTC_DRV_DS1305 is not set
+# CONFIG_RTC_DRV_DS1307 is not set
+# CONFIG_RTC_DRV_DS1374 is not set
+# CONFIG_RTC_DRV_DS1390 is not set
+# CONFIG_RTC_DRV_DS1511 is not set
+# CONFIG_RTC_DRV_DS1553 is not set
+# CONFIG_RTC_DRV_DS1672 is not set
+# CONFIG_RTC_DRV_DS1742 is not set
+# CONFIG_RTC_DRV_DS3234 is not set
+# CONFIG_RTC_DRV_EP93XX is not set
+# CONFIG_RTC_DRV_FM3130 is not set
+# CONFIG_RTC_DRV_GENERIC is not set
+# CONFIG_RTC_DRV_ISL1208 is not set
+# CONFIG_RTC_DRV_M41T80 is not set
+# CONFIG_RTC_DRV_M41T94 is not set
+# CONFIG_RTC_DRV_M48T35 is not set
+# CONFIG_RTC_DRV_M48T59 is not set
+# CONFIG_RTC_DRV_M48T86 is not set
+# CONFIG_RTC_DRV_MAX6900 is not set
+# CONFIG_RTC_DRV_MAX6902 is not set
+# CONFIG_RTC_DRV_PCF50606 is not set
+# CONFIG_RTC_DRV_PCF8563 is not set
+# CONFIG_RTC_DRV_PCF8583 is not set
+# CONFIG_RTC_DRV_PL030 is not set
+# CONFIG_RTC_DRV_PL031 is not set
+# CONFIG_RTC_DRV_PS3 is not set
+# CONFIG_RTC_DRV_R9701 is not set
+# CONFIG_RTC_DRV_RS5C348 is not set
+# CONFIG_RTC_DRV_RS5C372 is not set
+# CONFIG_RTC_DRV_RTC7301 is not set
+# CONFIG_RTC_DRV_RX8025 is not set
+# CONFIG_RTC_DRV_RX8581 is not set
+# CONFIG_RTC_DRV_S35390A is not set
+# CONFIG_RTC_DRV_STK17TA8 is not set
+# CONFIG_RTC_DRV_TEST is not set
+# CONFIG_RTC_DRV_V3020 is not set
+# CONFIG_RTC_DRV_X1205 is not set
+CONFIG_RTC_HCTOSYS=y
+CONFIG_RTC_HCTOSYS_DEVICE="rtc0"
+CONFIG_RTC_INTF_DEV=y
+# CONFIG_RTC_INTF_DEV_UIE_EMUL is not set
+CONFIG_RTC_INTF_PROC=y
+CONFIG_RTC_INTF_SYSFS=y
+CONFIG_RTC_LIB=y
+# CONFIG_RTL8180 is not set
+# CONFIG_RTL8187 is not set
+# CONFIG_RTL8187SE is not set
+# CONFIG_RTL8192SU is not set
+# CONFIG_RTL8306_PHY is not set
+# CONFIG_RTL8366RB_PHY is not set
+# CONFIG_RTL8366S_PHY is not set
+# CONFIG_RTL8366S_PHY_DEBUG_FS is not set
+# CONFIG_RTL8366_SMI is not set
+CONFIG_RT_MUTEXES=y
+CONFIG_RWSEM_GENERIC_SPINLOCK=y
+# CONFIG_S2IO is not set
+# CONFIG_SAMPLES is not set
+# CONFIG_SATA_AHCI is not set
+# CONFIG_SATA_INIC162X is not set
+# CONFIG_SATA_MV is not set
+# CONFIG_SATA_NV is not set
+# CONFIG_SATA_PMP is not set
+# CONFIG_SATA_PROMISE is not set
+# CONFIG_SATA_QSTOR is not set
+# CONFIG_SATA_SIL is not set
+# CONFIG_SATA_SIL24 is not set
+# CONFIG_SATA_SIS is not set
+# CONFIG_SATA_SVW is not set
+# CONFIG_SATA_SX4 is not set
+# CONFIG_SATA_ULI is not set
+# CONFIG_SATA_VIA is not set
+# CONFIG_SATA_VITESSE is not set
+# CONFIG_SC92031 is not set
+# CONFIG_SCC is not set
+# CONFIG_SCHED_BFS is not set
+CONFIG_SCHED_CFS=y
+# CONFIG_SCHED_TRACER is not set
+# CONFIG_SCSI is not set
+# CONFIG_SCSI_3W_9XXX is not set
+# CONFIG_SCSI_7000FASST is not set
+# CONFIG_SCSI_AACRAID is not set
+# CONFIG_SCSI_ACARD is not set
+# CONFIG_SCSI_ADVANSYS is not set
+# CONFIG_SCSI_AHA152X is not set
+# CONFIG_SCSI_AHA1542 is not set
+# CONFIG_SCSI_AIC79XX is not set
+# CONFIG_SCSI_AIC7XXX is not set
+# CONFIG_SCSI_AIC7XXX_OLD is not set
+# CONFIG_SCSI_AIC94XX is not set
+# CONFIG_SCSI_ARCMSR is not set
+# CONFIG_SCSI_BNX2_ISCSI is not set
+# CONFIG_SCSI_BUSLOGIC is not set
+# CONFIG_SCSI_CONSTANTS is not set
+# CONFIG_SCSI_DC390T is not set
+# CONFIG_SCSI_DC395x is not set
+# CONFIG_SCSI_DEBUG is not set
+# CONFIG_SCSI_DH is not set
+CONFIG_SCSI_DMA=y
+# CONFIG_SCSI_DMX3191D is not set
+# CONFIG_SCSI_DPT_I2O is not set
+# CONFIG_SCSI_DTC3280 is not set
+# CONFIG_SCSI_EATA is not set
+# CONFIG_SCSI_ESP_CORE is not set
+# CONFIG_SCSI_FC_ATTRS is not set
+# CONFIG_SCSI_FUTURE_DOMAIN is not set
+# CONFIG_SCSI_GDTH is not set
+# CONFIG_SCSI_GENERIC_NCR5380 is not set
+# CONFIG_SCSI_GENERIC_NCR5380_MMIO is not set
+# CONFIG_SCSI_HPTIOP is not set
+# CONFIG_SCSI_IN2000 is not set
+# CONFIG_SCSI_INIA100 is not set
+# CONFIG_SCSI_INITIO is not set
+# CONFIG_SCSI_IPR is not set
+# CONFIG_SCSI_IPS is not set
+# CONFIG_SCSI_ISCSI_ATTRS is not set
+# CONFIG_SCSI_LOGGING is not set
+CONFIG_SCSI_LOWLEVEL=y
+# CONFIG_SCSI_LOWLEVEL_PCMCIA is not set
+# CONFIG_SCSI_LPFC is not set
+# CONFIG_SCSI_MPT2SAS is not set
+CONFIG_SCSI_MULTI_LUN=y
+# CONFIG_SCSI_MVSAS is not set
+# CONFIG_SCSI_MVSAS_DEBUG is not set
+# CONFIG_SCSI_NCR53C406A is not set
+# CONFIG_SCSI_NETLINK is not set
+# CONFIG_SCSI_NSP32 is not set
+# CONFIG_SCSI_OSD_INITIATOR is not set
+# CONFIG_SCSI_PAS16 is not set
+CONFIG_SCSI_PROC_FS=y
+# CONFIG_SCSI_PSI240I is not set
+# CONFIG_SCSI_QLA_FC is not set
+# CONFIG_SCSI_QLA_ISCSI is not set
+# CONFIG_SCSI_QLOGIC_1280 is not set
+# CONFIG_SCSI_QLOGIC_FAS is not set
+# CONFIG_SCSI_SAS_ATTRS is not set
+# CONFIG_SCSI_SAS_LIBSAS is not set
+# CONFIG_SCSI_SCAN_ASYNC is not set
+# CONFIG_SCSI_SEAGATE is not set
+# CONFIG_SCSI_SPI_ATTRS is not set
+# CONFIG_SCSI_SRP is not set
+# CONFIG_SCSI_SRP_ATTRS is not set
+# CONFIG_SCSI_STEX is not set
+# CONFIG_SCSI_SYM53C416 is not set
+# CONFIG_SCSI_SYM53C8XX_2 is not set
+# CONFIG_SCSI_T128 is not set
+# CONFIG_SCSI_TGT is not set
+# CONFIG_SCSI_U14_34F is not set
+# CONFIG_SCSI_ULTRASTOR is not set
+CONFIG_SCSI_WAIT_SCAN=m
+# CONFIG_SECCOMP is not set
+# CONFIG_SECURITY is not set
+# CONFIG_SECURITYFS is not set
+# CONFIG_SECURITY_FILE_CAPABILITIES is not set
+CONFIG_SELECT_MEMORY_MODEL=y
+# CONFIG_SENSORS_ABITUGURU is not set
+# CONFIG_SENSORS_ABITUGURU3 is not set
+# CONFIG_SENSORS_AD7414 is not set
+# CONFIG_SENSORS_AD7418 is not set
+# CONFIG_SENSORS_ADCXX is not set
+# CONFIG_SENSORS_ADM1021 is not set
+# CONFIG_SENSORS_ADM1025 is not set
+# CONFIG_SENSORS_ADM1026 is not set
+# CONFIG_SENSORS_ADM1029 is not set
+# CONFIG_SENSORS_ADM1031 is not set
+# CONFIG_SENSORS_ADM9240 is not set
+# CONFIG_SENSORS_ADS7828 is not set
+# CONFIG_SENSORS_ADT7462 is not set
+# CONFIG_SENSORS_ADT7470 is not set
+# CONFIG_SENSORS_ADT7473 is not set
+# CONFIG_SENSORS_ADT7475 is not set
+# CONFIG_SENSORS_APPLESMC is not set
+# CONFIG_SENSORS_ASB100 is not set
+# CONFIG_SENSORS_ATK0110 is not set
+# CONFIG_SENSORS_ATXP1 is not set
+# CONFIG_SENSORS_CORETEMP is not set
+# CONFIG_SENSORS_DME1737 is not set
+# CONFIG_SENSORS_DS1337 is not set
+# CONFIG_SENSORS_DS1374 is not set
+# CONFIG_SENSORS_DS1621 is not set
+# CONFIG_SENSORS_EEPROM is not set
+# CONFIG_SENSORS_F71805F is not set
+# CONFIG_SENSORS_F71882FG is not set
+# CONFIG_SENSORS_F75375S is not set
+# CONFIG_SENSORS_FSCHER is not set
+# CONFIG_SENSORS_FSCHMD is not set
+# CONFIG_SENSORS_FSCPOS is not set
+# CONFIG_SENSORS_G760A is not set
+# CONFIG_SENSORS_GL518SM is not set
+# CONFIG_SENSORS_GL520SM is not set
+# CONFIG_SENSORS_HDAPS is not set
+# CONFIG_SENSORS_I5K_AMB is not set
+# CONFIG_SENSORS_IT87 is not set
+# CONFIG_SENSORS_K8TEMP is not set
+# CONFIG_SENSORS_LIS3LV02D is not set
+# CONFIG_SENSORS_LIS3_SPI is not set
+# CONFIG_SENSORS_LM63 is not set
+# CONFIG_SENSORS_LM70 is not set
+# CONFIG_SENSORS_LM75 is not set
+# CONFIG_SENSORS_LM77 is not set
+# CONFIG_SENSORS_LM78 is not set
+# CONFIG_SENSORS_LM80 is not set
+# CONFIG_SENSORS_LM83 is not set
+# CONFIG_SENSORS_LM85 is not set
+# CONFIG_SENSORS_LM87 is not set
+# CONFIG_SENSORS_LM90 is not set
+# CONFIG_SENSORS_LM92 is not set
+# CONFIG_SENSORS_LM93 is not set
+# CONFIG_SENSORS_LM95241 is not set
+# CONFIG_SENSORS_LTC4215 is not set
+# CONFIG_SENSORS_LTC4245 is not set
+# CONFIG_SENSORS_M41T00 is not set
+# CONFIG_SENSORS_MAX1111 is not set
+# CONFIG_SENSORS_MAX1619 is not set
+# CONFIG_SENSORS_MAX6650 is not set
+# CONFIG_SENSORS_MAX6875 is not set
+# CONFIG_SENSORS_PC87360 is not set
+# CONFIG_SENSORS_PC87427 is not set
+# CONFIG_SENSORS_PCA9539 is not set
+# CONFIG_SENSORS_PCF8574 is not set
+# CONFIG_SENSORS_PCF8591 is not set
+# CONFIG_SENSORS_SHT15 is not set
+# CONFIG_SENSORS_SIS5595 is not set
+# CONFIG_SENSORS_SMSC47B397 is not set
+# CONFIG_SENSORS_SMSC47M1 is not set
+# CONFIG_SENSORS_SMSC47M192 is not set
+# CONFIG_SENSORS_THMC50 is not set
+# CONFIG_SENSORS_TMP401 is not set
+# CONFIG_SENSORS_TSL2550 is not set
+# CONFIG_SENSORS_VIA686A is not set
+# CONFIG_SENSORS_VT1211 is not set
+# CONFIG_SENSORS_VT8231 is not set
+# CONFIG_SENSORS_W83627EHF is not set
+# CONFIG_SENSORS_W83627HF is not set
+# CONFIG_SENSORS_W83781D is not set
+# CONFIG_SENSORS_W83791D is not set
+# CONFIG_SENSORS_W83792D is not set
+# CONFIG_SENSORS_W83793 is not set
+# CONFIG_SENSORS_W83L785TS is not set
+# CONFIG_SENSORS_W83L786NG is not set
+CONFIG_SERIAL_8250=y
+# CONFIG_SERIAL_8250_ACCENT is not set
+# CONFIG_SERIAL_8250_BOCA is not set
+CONFIG_SERIAL_8250_CONSOLE=y
+# CONFIG_SERIAL_8250_CS is not set
+# CONFIG_SERIAL_8250_EXAR_ST16C554 is not set
+# CONFIG_SERIAL_8250_FOURPORT is not set
+# CONFIG_SERIAL_8250_HUB6 is not set
+CONFIG_SERIAL_8250_NR_UARTS=2
+# CONFIG_SERIAL_8250_PCI is not set
+CONFIG_SERIAL_8250_RUNTIME_UARTS=2
+CONFIG_SERIAL_CORE=y
+CONFIG_SERIAL_CORE_CONSOLE=y
+# CONFIG_SERIAL_JSM is not set
+# CONFIG_SERIAL_MAX3100 is not set
+# CONFIG_SERIAL_NONSTANDARD is not set
+# CONFIG_SERIAL_OF_PLATFORM_NWPSERIAL is not set
+# CONFIG_SERIAL_UARTLITE is not set
+# CONFIG_SERIO is not set
+# CONFIG_SGI_IOC4 is not set
+# CONFIG_SGI_PARTITION is not set
+# CONFIG_SHAPER is not set
+CONFIG_SHMEM=y
+CONFIG_SIGNALFD=y
+# CONFIG_SIMPLE_GPIO is not set
+# CONFIG_SIS190 is not set
+# CONFIG_SIS900 is not set
+# CONFIG_SK98LIN is not set
+# CONFIG_SKGE is not set
+# CONFIG_SKY2 is not set
+# CONFIG_SKY2_DEBUG is not set
+CONFIG_SLAB=y
+CONFIG_SLABINFO=y
+# CONFIG_SLHC is not set
+# CONFIG_SLICOSS is not set
+# CONFIG_SLIP is not set
+# CONFIG_SLOB is not set
+# CONFIG_SLOW_WORK is not set
+# CONFIG_SLUB is not set
+# CONFIG_SLUB_DEBUG is not set
+# CONFIG_SMARTJOYPLUS_FF is not set
+# CONFIG_SMB_FS is not set
+# CONFIG_SMB_NLS_DEFAULT is not set
+# CONFIG_SMC911X is not set
+# CONFIG_SMC91X is not set
+# CONFIG_SMP is not set
+# CONFIG_SMSC911X is not set
+# CONFIG_SMSC9420 is not set
+# CONFIG_SMSC_PHY is not set
+# CONFIG_SND is not set
+# CONFIG_SND_AC97_POWER_SAVE is not set
+# CONFIG_SND_AD1816A is not set
+# CONFIG_SND_AD1848 is not set
+# CONFIG_SND_AD1889 is not set
+# CONFIG_SND_ADLIB is not set
+# CONFIG_SND_ALI5451 is not set
+# CONFIG_SND_ALS100 is not set
+# CONFIG_SND_ALS300 is not set
+# CONFIG_SND_ALS4000 is not set
+# CONFIG_SND_ARM is not set
+# CONFIG_SND_ATIIXP is not set
+# CONFIG_SND_ATIIXP_MODEM is not set
+# CONFIG_SND_AU8810 is not set
+# CONFIG_SND_AU8820 is not set
+# CONFIG_SND_AU8830 is not set
+# CONFIG_SND_AW2 is not set
+# CONFIG_SND_AZT2320 is not set
+# CONFIG_SND_AZT3328 is not set
+# CONFIG_SND_BT87X is not set
+# CONFIG_SND_CA0106 is not set
+# CONFIG_SND_CMI8330 is not set
+# CONFIG_SND_CMIPCI is not set
+# CONFIG_SND_CS4231 is not set
+# CONFIG_SND_CS4232 is not set
+# CONFIG_SND_CS4236 is not set
+# CONFIG_SND_CS4281 is not set
+# CONFIG_SND_CS46XX is not set
+# CONFIG_SND_CS5530 is not set
+# CONFIG_SND_CS5535AUDIO is not set
+# CONFIG_SND_CTXFI is not set
+# CONFIG_SND_DARLA20 is not set
+# CONFIG_SND_DARLA24 is not set
+# CONFIG_SND_DEBUG is not set
+CONFIG_SND_DRIVERS=y
+# CONFIG_SND_DT019X is not set
+# CONFIG_SND_DUMMY is not set
+# CONFIG_SND_DYNAMIC_MINORS is not set
+# CONFIG_SND_ECHO3G is not set
+# CONFIG_SND_EMU10K1 is not set
+# CONFIG_SND_EMU10K1X is not set
+# CONFIG_SND_ENS1370 is not set
+# CONFIG_SND_ENS1371 is not set
+# CONFIG_SND_ES1688 is not set
+# CONFIG_SND_ES18XX is not set
+# CONFIG_SND_ES1938 is not set
+# CONFIG_SND_ES1968 is not set
+# CONFIG_SND_ES968 is not set
+# CONFIG_SND_FM801 is not set
+# CONFIG_SND_GINA20 is not set
+# CONFIG_SND_GINA24 is not set
+# CONFIG_SND_GUSCLASSIC is not set
+# CONFIG_SND_GUSEXTREME is not set
+# CONFIG_SND_GUSMAX is not set
+# CONFIG_SND_HDA_INTEL is not set
+# CONFIG_SND_HDSP is not set
+# CONFIG_SND_HDSPM is not set
+# CONFIG_SND_HIFIER is not set
+# CONFIG_SND_HRTIMER is not set
+# CONFIG_SND_HWDEP is not set
+# CONFIG_SND_ICE1712 is not set
+# CONFIG_SND_ICE1724 is not set
+# CONFIG_SND_INDIGO is not set
+# CONFIG_SND_INDIGODJ is not set
+# CONFIG_SND_INDIGODJX is not set
+# CONFIG_SND_INDIGOIO is not set
+# CONFIG_SND_INDIGOIOX is not set
+# CONFIG_SND_INTEL8X0 is not set
+# CONFIG_SND_INTEL8X0M is not set
+# CONFIG_SND_INTERWAVE is not set
+# CONFIG_SND_INTERWAVE_STB is not set
+# CONFIG_SND_ISA is not set
+# CONFIG_SND_KORG1212 is not set
+# CONFIG_SND_LAYLA20 is not set
+# CONFIG_SND_LAYLA24 is not set
+# CONFIG_SND_LX6464ES is not set
+# CONFIG_SND_MAESTRO3 is not set
+# CONFIG_SND_MIA is not set
+# CONFIG_SND_MIPS is not set
+# CONFIG_SND_MIRO is not set
+# CONFIG_SND_MIXART is not set
+# CONFIG_SND_MIXER_OSS is not set
+# CONFIG_SND_MONA is not set
+# CONFIG_SND_MPU401 is not set
+# CONFIG_SND_MTPAV is not set
+# CONFIG_SND_NM256 is not set
+# CONFIG_SND_OPL3SA2 is not set
+# CONFIG_SND_OPTI92X_AD1848 is not set
+# CONFIG_SND_OPTI92X_CS4231 is not set
+# CONFIG_SND_OPTI93X is not set
+CONFIG_SND_OSSEMUL=y
+# CONFIG_SND_OXYGEN is not set
+CONFIG_SND_PCI=y
+# CONFIG_SND_PCM is not set
+# CONFIG_SND_PCMCIA is not set
+# CONFIG_SND_PCM_OSS is not set
+CONFIG_SND_PCM_OSS_PLUGINS=y
+# CONFIG_SND_PCXHR is not set
+# CONFIG_SND_PDAUDIOCF is not set
+# CONFIG_SND_RAWMIDI is not set
+# CONFIG_SND_RIPTIDE is not set
+# CONFIG_SND_RME32 is not set
+# CONFIG_SND_RME96 is not set
+# CONFIG_SND_RME9652 is not set
+# CONFIG_SND_RTCTIMER is not set
+# CONFIG_SND_SB16 is not set
+# CONFIG_SND_SB8 is not set
+# CONFIG_SND_SBAWE is not set
+# CONFIG_SND_SEQUENCER is not set
+# CONFIG_SND_SERIAL_U16550 is not set
+# CONFIG_SND_SGALAXY is not set
+# CONFIG_SND_SIS7019 is not set
+# CONFIG_SND_SOC is not set
+# CONFIG_SND_SONICVIBES is not set
+# CONFIG_SND_SPI is not set
+# CONFIG_SND_SSCAPE is not set
+# CONFIG_SND_SUPPORT_OLD_API is not set
+# CONFIG_SND_TIMER is not set
+# CONFIG_SND_TRIDENT is not set
+CONFIG_SND_USB=y
+# CONFIG_SND_USB_AUDIO is not set
+# CONFIG_SND_USB_CAIAQ is not set
+# CONFIG_SND_USB_US122L is not set
+# CONFIG_SND_USB_USX2Y is not set
+# CONFIG_SND_VERBOSE_PRINTK is not set
+CONFIG_SND_VERBOSE_PROCFS=y
+# CONFIG_SND_VIA82XX is not set
+# CONFIG_SND_VIA82XX_MODEM is not set
+# CONFIG_SND_VIRTUOSO is not set
+# CONFIG_SND_VX222 is not set
+# CONFIG_SND_VXPOCKET is not set
+# CONFIG_SND_WAVEFRONT is not set
+# CONFIG_SND_YMFPCI is not set
+# CONFIG_SNI_RM is not set
+# CONFIG_SOC_CAMERA is not set
+# CONFIG_SOFT_WATCHDOG is not set
+# CONFIG_SOLARIS_X86_PARTITION is not set
+# CONFIG_SONYPI is not set
+# CONFIG_SONY_LAPTOP is not set
+# CONFIG_SOUND is not set
+# CONFIG_SOUND_PRIME is not set
+# CONFIG_SPARSEMEM_MANUAL is not set
+# CONFIG_SPARSEMEM_STATIC is not set
+# CONFIG_SPARSEMEM_VMEMMAP_ENABLE is not set
+# CONFIG_SPI is not set
+# CONFIG_SPI_AT25 is not set
+# CONFIG_SPI_DEBUG is not set
+# CONFIG_SPI_GPIO_OLD is not set
+# CONFIG_SPI_MASTER is not set
+# CONFIG_SPI_ORION is not set
+# CONFIG_SPI_TLE62X0 is not set
+CONFIG_SPLIT_PTLOCK_CPUS=4
+CONFIG_SQUASHFS=y
+# CONFIG_SQUASHFS_EMBEDDED is not set
+CONFIG_SQUASHFS_FRAGMENT_CACHE_SIZE=3
+CONFIG_SQUASHFS_LZMA=y
+CONFIG_SQUASHFS_SUPPORT_ZLIB=y
+# CONFIG_SQUASHFS_VMALLOC is not set
+# CONFIG_SSB is not set
+# CONFIG_SSB_DEBUG is not set
+# CONFIG_SSB_PCMCIAHOST is not set
+CONFIG_SSB_POSSIBLE=y
+# CONFIG_SSB_SDIOHOST is not set
+# CONFIG_SSB_SILENT is not set
+# CONFIG_SSFDC is not set
+CONFIG_STACKTRACE_SUPPORT=y
+# CONFIG_STACK_TRACER is not set
+CONFIG_STAGING=y
+# CONFIG_STAGING_EXCLUDE_BUILD is not set
+CONFIG_STANDALONE=y
+CONFIG_STDBINUTILS=y
+# CONFIG_STE10XP is not set
+CONFIG_STP=y
+# CONFIG_STRIP is not set
+CONFIG_STRIP_ASM_SYMS=y
+# CONFIG_SUNDANCE is not set
+# CONFIG_SUNGEM is not set
+# CONFIG_SUNRPC is not set
+# CONFIG_SUNRPC_BIND34 is not set
+# CONFIG_SUNRPC_GSS is not set
+# CONFIG_SUNRPC_REGISTER_V4 is not set
+# CONFIG_SUN_PARTITION is not set
+CONFIG_SUSPEND_UP_POSSIBLE=y
+CONFIG_SWAP=y
+# CONFIG_SWCONFIG is not set
+# CONFIG_SYNCLINK_CS is not set
+CONFIG_SYN_COOKIES=y
+CONFIG_SYSCTL=y
+# CONFIG_SYSCTL_SYSCALL is not set
+# CONFIG_SYSCTL_SYSCALL_CHECK is not set
+CONFIG_SYSFS=y
+# CONFIG_SYSFS_DEPRECATED is not set
+# CONFIG_SYSFS_DEPRECATED_V2 is not set
+# CONFIG_SYSV68_PARTITION is not set
+CONFIG_SYSVIPC=y
+CONFIG_SYSVIPC_SYSCTL=y
+# CONFIG_SYSV_FS is not set
+# CONFIG_SYS_HYPERVISOR is not set
+# CONFIG_TASKSTATS is not set
+# CONFIG_TCG_TPM is not set
+# CONFIG_TCIC is not set
+CONFIG_TCP_CONG_ADVANCED=y
+# CONFIG_TCP_CONG_BIC is not set
+# CONFIG_TCP_CONG_CUBIC is not set
+# CONFIG_TCP_CONG_HSTCP is not set
+# CONFIG_TCP_CONG_HTCP is not set
+# CONFIG_TCP_CONG_HYBLA is not set
+# CONFIG_TCP_CONG_ILLINOIS is not set
+# CONFIG_TCP_CONG_LP is not set
+# CONFIG_TCP_CONG_SCALABLE is not set
+# CONFIG_TCP_CONG_VEGAS is not set
+# CONFIG_TCP_CONG_VENO is not set
+CONFIG_TCP_CONG_WESTWOOD=y
+# CONFIG_TCP_CONG_YEAH is not set
+# CONFIG_TCP_MD5SIG is not set
+CONFIG_TEXTSEARCH=y
+# CONFIG_TEXTSEARCH_BM is not set
+# CONFIG_TEXTSEARCH_FSM is not set
+# CONFIG_TEXTSEARCH_KMP is not set
+# CONFIG_THERMAL is not set
+# CONFIG_THERMAL_HWMON is not set
+# CONFIG_THRUSTMASTER_FF is not set
+CONFIG_TICK_ONESHOT=y
+# CONFIG_TIFM_CORE is not set
+# CONFIG_TIGON3 is not set
+CONFIG_TIMERFD=y
+# CONFIG_TIMER_STATS is not set
+# CONFIG_TINY_SHMEM is not set
+# CONFIG_TIPC is not set
+# CONFIG_TLAN is not set
+# CONFIG_TMD_HERMES is not set
+CONFIG_TMPFS=y
+# CONFIG_TMPFS_POSIX_ACL is not set
+# CONFIG_TOUCHSCREEN_AD7877 is not set
+# CONFIG_TOUCHSCREEN_AD7879 is not set
+# CONFIG_TOUCHSCREEN_AD7879_I2C is not set
+# CONFIG_TOUCHSCREEN_AD7879_SPI is not set
+# CONFIG_TOUCHSCREEN_ADS7846 is not set
+# CONFIG_TOUCHSCREEN_EETI is not set
+# CONFIG_TOUCHSCREEN_ELO is not set
+# CONFIG_TOUCHSCREEN_FILTER is not set
+# CONFIG_TOUCHSCREEN_FUJITSU is not set
+# CONFIG_TOUCHSCREEN_GUNZE is not set
+# CONFIG_TOUCHSCREEN_INEXIO is not set
+# CONFIG_TOUCHSCREEN_MK712 is not set
+# CONFIG_TOUCHSCREEN_MTOUCH is not set
+# CONFIG_TOUCHSCREEN_PENMOUNT is not set
+# CONFIG_TOUCHSCREEN_S3C2410 is not set
+# CONFIG_TOUCHSCREEN_TOUCHIT213 is not set
+# CONFIG_TOUCHSCREEN_TOUCHRIGHT is not set
+# CONFIG_TOUCHSCREEN_TOUCHWIN is not set
+# CONFIG_TOUCHSCREEN_TSC2007 is not set
+# CONFIG_TOUCHSCREEN_USB_COMPOSITE is not set
+# CONFIG_TOUCHSCREEN_W90X900 is not set
+# CONFIG_TOUCHSCREEN_WACOM_W8001 is not set
+# CONFIG_TPS65010 is not set
+# CONFIG_TR is not set
+# CONFIG_TRACE_BRANCH_PROFILING is not set
+CONFIG_TRACE_IRQFLAGS_SUPPORT=y
+CONFIG_TRACING_SUPPORT=y
+# CONFIG_TRANZPORT is not set
+# CONFIG_TREE_RCU is not set
+# CONFIG_TREE_RCU_TRACE is not set
+# CONFIG_TUN is not set
+# CONFIG_TUNER_3036 is not set
+# CONFIG_TUNER_TEA5761 is not set
+# CONFIG_TWL4030_CORE is not set
+# CONFIG_UACCESS_WITH_MEMCPY is not set
+# CONFIG_UCB1400_CORE is not set
+# CONFIG_UDF_FS is not set
+CONFIG_UDF_NLS=y
+CONFIG_UEVENT_HELPER_PATH="/sbin/hotplug"
+# CONFIG_UFS_FS is not set
+# CONFIG_UIO is not set
+# CONFIG_ULTRIX_PARTITION is not set
+# CONFIG_UNEVICTABLE_LRU is not set
+# CONFIG_UNION_MOUNT is not set
+CONFIG_UNIX=y
+CONFIG_UNIX98_PTYS=y
+# CONFIG_UNIXWARE_DISKLABEL is not set
+# CONFIG_UNUSED_SYMBOLS is not set
+# CONFIG_USB is not set
+# CONFIG_USBPCWATCHDOG is not set
+# CONFIG_USB_ACECAD is not set
+# CONFIG_USB_ACM is not set
+# CONFIG_USB_ADUTUX is not set
+# CONFIG_USB_AIPTEK is not set
+CONFIG_USB_ALI_M5632=y
+CONFIG_USB_AN2720=y
+# CONFIG_USB_ANNOUNCE_NEW_DEVICES is not set
+# CONFIG_USB_APPLEDISPLAY is not set
+# CONFIG_USB_APPLETOUCH is not set
+CONFIG_USB_ARCH_HAS_EHCI=y
+CONFIG_USB_ARCH_HAS_HCD=y
+CONFIG_USB_ARCH_HAS_OHCI=y
+CONFIG_USB_ARMLINUX=y
+# CONFIG_USB_ATI_REMOTE is not set
+# CONFIG_USB_ATI_REMOTE2 is not set
+# CONFIG_USB_ATM is not set
+# CONFIG_USB_ATMEL is not set
+# CONFIG_USB_AUERSWALD is not set
+# CONFIG_USB_BANDWIDTH is not set
+CONFIG_USB_BELKIN=y
+# CONFIG_USB_BERRY_CHARGE is not set
+# CONFIG_USB_C67X00_HCD is not set
+# CONFIG_USB_CATC is not set
+# CONFIG_USB_CPC is not set
+# CONFIG_USB_CXACRU is not set
+# CONFIG_USB_CYPRESS_CY7C63 is not set
+# CONFIG_USB_CYTHERM is not set
+# CONFIG_USB_DABUSB is not set
+# CONFIG_USB_DEBUG is not set
+CONFIG_USB_DEVICEFS=y
+# CONFIG_USB_DEVICE_CLASS is not set
+# CONFIG_USB_DSBR is not set
+# CONFIG_USB_DYNAMIC_MINORS is not set
+# CONFIG_USB_EHCI_HCD_PPC_OF is not set
+CONFIG_USB_EHCI_ROOT_HUB_TT=y
+# CONFIG_USB_EHCI_SPLIT_ISO is not set
+# CONFIG_USB_EHCI_TT_NEWSCHED is not set
+# CONFIG_USB_EMI26 is not set
+# CONFIG_USB_EMI62 is not set
+# CONFIG_USB_EPSON2888 is not set
+# CONFIG_USB_ET61X251 is not set
+CONFIG_USB_EZUSB=y
+# CONFIG_USB_FTDI_ELAN is not set
+# CONFIG_USB_GADGET is not set
+# CONFIG_USB_GPIO_VBUS is not set
+# CONFIG_USB_GSPCA is not set
+# CONFIG_USB_GSPCA_CONEX is not set
+# CONFIG_USB_GSPCA_ETOMS is not set
+# CONFIG_USB_GSPCA_FINEPIX is not set
+# CONFIG_USB_GSPCA_MARS is not set
+# CONFIG_USB_GSPCA_MR97310A is not set
+# CONFIG_USB_GSPCA_OV519 is not set
+# CONFIG_USB_GSPCA_OV534 is not set
+# CONFIG_USB_GSPCA_PAC207 is not set
+# CONFIG_USB_GSPCA_PAC7311 is not set
+# CONFIG_USB_GSPCA_SN9C20X is not set
+CONFIG_USB_GSPCA_SN9C20X_EVDEV=y
+# CONFIG_USB_GSPCA_SONIXB is not set
+# CONFIG_USB_GSPCA_SONIXJ is not set
+# CONFIG_USB_GSPCA_SPCA500 is not set
+# CONFIG_USB_GSPCA_SPCA501 is not set
+# CONFIG_USB_GSPCA_SPCA505 is not set
+# CONFIG_USB_GSPCA_SPCA506 is not set
+# CONFIG_USB_GSPCA_SPCA508 is not set
+# CONFIG_USB_GSPCA_SPCA561 is not set
+# CONFIG_USB_GSPCA_SQ905 is not set
+# CONFIG_USB_GSPCA_SQ905C is not set
+# CONFIG_USB_GSPCA_STK014 is not set
+# CONFIG_USB_GSPCA_SUNPLUS is not set
+# CONFIG_USB_GSPCA_T613 is not set
+# CONFIG_USB_GSPCA_TV8532 is not set
+# CONFIG_USB_GSPCA_VC032X is not set
+# CONFIG_USB_GSPCA_ZC3XX is not set
+# CONFIG_USB_HID is not set
+# CONFIG_USB_HIDDEV is not set
+CONFIG_USB_HIDINPUT=y
+# CONFIG_USB_HIDINPUT_POWERBOOK is not set
+# CONFIG_USB_HSO is not set
+# CONFIG_USB_HWA_HCD is not set
+# CONFIG_USB_IBMCAM is not set
+# CONFIG_USB_IDMOUSE is not set
+# CONFIG_USB_IOWARRIOR is not set
+# CONFIG_USB_IP_COMMON is not set
+# CONFIG_USB_ISIGHTFW is not set
+# CONFIG_USB_ISP116X_HCD is not set
+# CONFIG_USB_ISP1760_HCD is not set
+# CONFIG_USB_KAWETH is not set
+# CONFIG_USB_KBD is not set
+# CONFIG_USB_KBTAB is not set
+# CONFIG_USB_KC2190 is not set
+# CONFIG_USB_KEYSPAN_REMOTE is not set
+# CONFIG_USB_KONICAWC is not set
+# CONFIG_USB_LCD is not set
+# CONFIG_USB_LD is not set
+# CONFIG_USB_LED is not set
+# CONFIG_USB_LEGOTOWER is not set
+# CONFIG_USB_LIBUSUAL is not set
+# CONFIG_USB_M5602 is not set
+# CONFIG_USB_MDC800 is not set
+# CONFIG_USB_MICROTEK is not set
+# CONFIG_USB_MON is not set
+# CONFIG_USB_MOUSE is not set
+# CONFIG_USB_MUSB_HDRC is not set
+# CONFIG_USB_NET_AX8817X is not set
+# CONFIG_USB_NET_CDCETHER is not set
+# CONFIG_USB_NET_CDC_EEM is not set
+# CONFIG_USB_NET_CDC_SUBSET is not set
+# CONFIG_USB_NET_DM9601 is not set
+# CONFIG_USB_NET_GL620A is not set
+# CONFIG_USB_NET_INT51X1 is not set
+# CONFIG_USB_NET_MCS7830 is not set
+# CONFIG_USB_NET_NET1080 is not set
+# CONFIG_USB_NET_PLUSB is not set
+# CONFIG_USB_NET_RNDIS_HOST is not set
+# CONFIG_USB_NET_RNDIS_WLAN is not set
+# CONFIG_USB_NET_SMSC95XX is not set
+# CONFIG_USB_NET_ZAURUS is not set
+# CONFIG_USB_OHCI_BIG_ENDIAN is not set
+# CONFIG_USB_OHCI_HCD is not set
+# CONFIG_USB_OHCI_HCD_PCI is not set
+# CONFIG_USB_OHCI_HCD_PPC_OF is not set
+# CONFIG_USB_OHCI_HCD_PPC_SOC is not set
+# CONFIG_USB_OHCI_HCD_SSB is not set
+CONFIG_USB_OHCI_LITTLE_ENDIAN=y
+# CONFIG_USB_OTG is not set
+# CONFIG_USB_OTG_BLACKLIST_HUB is not set
+# CONFIG_USB_OTG_WHITELIST is not set
+# CONFIG_USB_OV511 is not set
+# CONFIG_USB_OXU210HP_HCD is not set
+# CONFIG_USB_PEGASUS is not set
+# CONFIG_USB_PHIDGET is not set
+# CONFIG_USB_POWERMATE is not set
+# CONFIG_USB_PRINTER is not set
+# CONFIG_USB_PWC_INPUT_EVDEV is not set
+# CONFIG_USB_QUICKCAM_MESSENGER is not set
+# CONFIG_USB_R8A66597_HCD is not set
+# CONFIG_USB_RIO500 is not set
+# CONFIG_USB_RTL8150 is not set
+# CONFIG_USB_S2255 is not set
+# CONFIG_USB_SE401 is not set
+# CONFIG_USB_SERIAL is not set
+# CONFIG_USB_SERIAL_AIRCABLE is not set
+# CONFIG_USB_SERIAL_AIRPRIME is not set
+# CONFIG_USB_SERIAL_ARK3116 is not set
+# CONFIG_USB_SERIAL_BELKIN is not set
+# CONFIG_USB_SERIAL_CH341 is not set
+# CONFIG_USB_SERIAL_CP2101 is not set
+# CONFIG_USB_SERIAL_CP210X is not set
+# CONFIG_USB_SERIAL_CYBERJACK is not set
+# CONFIG_USB_SERIAL_CYPRESS_M8 is not set
+# CONFIG_USB_SERIAL_DEBUG is not set
+# CONFIG_USB_SERIAL_DIGI_ACCELEPORT is not set
+# CONFIG_USB_SERIAL_EDGEPORT is not set
+# CONFIG_USB_SERIAL_EDGEPORT_TI is not set
+# CONFIG_USB_SERIAL_EMPEG is not set
+# CONFIG_USB_SERIAL_FTDI_SIO is not set
+# CONFIG_USB_SERIAL_FUNSOFT is not set
+# CONFIG_USB_SERIAL_GARMIN is not set
+CONFIG_USB_SERIAL_GENERIC=y
+# CONFIG_USB_SERIAL_HP4X is not set
+# CONFIG_USB_SERIAL_IPAQ is not set
+# CONFIG_USB_SERIAL_IPW is not set
+# CONFIG_USB_SERIAL_IR is not set
+# CONFIG_USB_SERIAL_IUU is not set
+# CONFIG_USB_SERIAL_KEYSPAN is not set
+CONFIG_USB_SERIAL_KEYSPAN_MPR=y
+# CONFIG_USB_SERIAL_KEYSPAN_PDA is not set
+CONFIG_USB_SERIAL_KEYSPAN_USA18X=y
+CONFIG_USB_SERIAL_KEYSPAN_USA19=y
+CONFIG_USB_SERIAL_KEYSPAN_USA19QI=y
+CONFIG_USB_SERIAL_KEYSPAN_USA19QW=y
+CONFIG_USB_SERIAL_KEYSPAN_USA19W=y
+CONFIG_USB_SERIAL_KEYSPAN_USA28=y
+CONFIG_USB_SERIAL_KEYSPAN_USA28X=y
+CONFIG_USB_SERIAL_KEYSPAN_USA28XA=y
+CONFIG_USB_SERIAL_KEYSPAN_USA28XB=y
+CONFIG_USB_SERIAL_KEYSPAN_USA49W=y
+CONFIG_USB_SERIAL_KEYSPAN_USA49WLC=y
+# CONFIG_USB_SERIAL_KLSI is not set
+# CONFIG_USB_SERIAL_KOBIL_SCT is not set
+# CONFIG_USB_SERIAL_MCT_U232 is not set
+# CONFIG_USB_SERIAL_MOS7720 is not set
+# CONFIG_USB_SERIAL_MOS7840 is not set
+# CONFIG_USB_SERIAL_MOTOROLA is not set
+# CONFIG_USB_SERIAL_NAVMAN is not set
+# CONFIG_USB_SERIAL_OMNINET is not set
+# CONFIG_USB_SERIAL_OPTICON is not set
+# CONFIG_USB_SERIAL_OPTION is not set
+# CONFIG_USB_SERIAL_OTI6858 is not set
+# CONFIG_USB_SERIAL_PL2303 is not set
+# CONFIG_USB_SERIAL_QUALCOMM is not set
+# CONFIG_USB_SERIAL_QUATECH2 is not set
+# CONFIG_USB_SERIAL_SAFE is not set
+CONFIG_USB_SERIAL_SAFE_PADDED=y
+# CONFIG_USB_SERIAL_SIEMENS_MPI is not set
+# CONFIG_USB_SERIAL_SIERRAWIRELESS is not set
+# CONFIG_USB_SERIAL_SPCP8X5 is not set
+# CONFIG_USB_SERIAL_SYMBOL is not set
+# CONFIG_USB_SERIAL_TI is not set
+# CONFIG_USB_SERIAL_VISOR is not set
+# CONFIG_USB_SERIAL_WHITEHEAT is not set
+# CONFIG_USB_SERIAL_XIRCOM is not set
+# CONFIG_USB_SEVSEG is not set
+# CONFIG_USB_SISUSBVGA is not set
+# CONFIG_USB_SL811_HCD is not set
+# CONFIG_USB_SN9C102 is not set
+# CONFIG_USB_SPEEDTOUCH is not set
+# CONFIG_USB_STKWEBCAM is not set
+# CONFIG_USB_STORAGE is not set
+# CONFIG_USB_STORAGE_ALAUDA is not set
+# CONFIG_USB_STORAGE_CYPRESS_ATACB is not set
+# CONFIG_USB_STORAGE_DATAFAB is not set
+# CONFIG_USB_STORAGE_DEBUG is not set
+# CONFIG_USB_STORAGE_FREECOM is not set
+# CONFIG_USB_STORAGE_ISD200 is not set
+# CONFIG_USB_STORAGE_JUMPSHOT is not set
+# CONFIG_USB_STORAGE_KARMA is not set
+# CONFIG_USB_STORAGE_ONETOUCH is not set
+# CONFIG_USB_STORAGE_SDDR09 is not set
+# CONFIG_USB_STORAGE_SDDR55 is not set
+# CONFIG_USB_STORAGE_USBAT is not set
+# CONFIG_USB_STV06XX is not set
+# CONFIG_USB_STV680 is not set
+# CONFIG_USB_SUPPORT is not set
+# CONFIG_USB_SUSPEND is not set
+# CONFIG_USB_TEST is not set
+# CONFIG_USB_TMC is not set
+# CONFIG_USB_TOUCHSCREEN is not set
+# CONFIG_USB_TRANCEVIBRATOR is not set
+# CONFIG_USB_UEAGLEATM is not set
+# CONFIG_USB_USBNET is not set
+# CONFIG_USB_USBNET_MII is not set
+# CONFIG_USB_VICAM is not set
+# CONFIG_USB_VIDEO_CLASS is not set
+CONFIG_USB_VIDEO_CLASS_INPUT_EVDEV=y
+# CONFIG_USB_VST is not set
+# CONFIG_USB_W9968CF is not set
+# CONFIG_USB_WACOM is not set
+# CONFIG_USB_WDM is not set
+# CONFIG_USB_WHCI_HCD is not set
+# CONFIG_USB_WUSB is not set
+# CONFIG_USB_WUSB_CBAF is not set
+# CONFIG_USB_XHCI_HCD is not set
+# CONFIG_USB_XPAD is not set
+# CONFIG_USB_XUSBATM is not set
+# CONFIG_USB_YEALINK is not set
+# CONFIG_USB_ZC0301 is not set
+# CONFIG_USB_ZD1201 is not set
+# CONFIG_USB_ZR364XX is not set
+# CONFIG_USE_GENERIC_SMP_HELPERS is not set
+# CONFIG_UTS_NS is not set
+# CONFIG_UWB is not set
+# CONFIG_VETH is not set
+# CONFIG_VFAT_FS is not set
+# CONFIG_VGASTATE is not set
+# CONFIG_VIA_RHINE is not set
+# CONFIG_VIA_VELOCITY is not set
+# CONFIG_VIDEO_ADV7170 is not set
+# CONFIG_VIDEO_ADV7175 is not set
+# CONFIG_VIDEO_ADV7343 is not set
+# CONFIG_VIDEO_ADV_DEBUG is not set
+# CONFIG_VIDEO_ALLOW_V4L1 is not set
+# CONFIG_VIDEO_BT819 is not set
+# CONFIG_VIDEO_BT848 is not set
+# CONFIG_VIDEO_BT856 is not set
+# CONFIG_VIDEO_BT866 is not set
+# CONFIG_VIDEO_CAFE_CCIC is not set
+# CONFIG_VIDEO_CAPTURE_DRIVERS is not set
+# CONFIG_VIDEO_CPIA is not set
+# CONFIG_VIDEO_CS5345 is not set
+# CONFIG_VIDEO_CS53L32A is not set
+# CONFIG_VIDEO_CX231XX is not set
+# CONFIG_VIDEO_CX2341X is not set
+# CONFIG_VIDEO_CX25840 is not set
+# CONFIG_VIDEO_CX88 is not set
+# CONFIG_VIDEO_DEV is not set
+# CONFIG_VIDEO_DPC is not set
+# CONFIG_VIDEO_EM28XX is not set
+# CONFIG_VIDEO_FIXED_MINOR_RANGES is not set
+# CONFIG_VIDEO_GO7007 is not set
+# CONFIG_VIDEO_HDPVR is not set
+# CONFIG_VIDEO_HELPER_CHIPS_AUTO is not set
+# CONFIG_VIDEO_HEXIUM_GEMINI is not set
+# CONFIG_VIDEO_HEXIUM_ORION is not set
+# CONFIG_VIDEO_IVTV is not set
+# CONFIG_VIDEO_KS0127 is not set
+# CONFIG_VIDEO_M52790 is not set
+# CONFIG_VIDEO_MEDIA is not set
+# CONFIG_VIDEO_MSP3400 is not set
+# CONFIG_VIDEO_MT9V011 is not set
+# CONFIG_VIDEO_MXB is not set
+# CONFIG_VIDEO_OUTPUT_CONTROL is not set
+# CONFIG_VIDEO_OV7670 is not set
+# CONFIG_VIDEO_OVCAMCHIP is not set
+# CONFIG_VIDEO_PMS is not set
+# CONFIG_VIDEO_PVRUSB2 is not set
+# CONFIG_VIDEO_SAA5246A is not set
+# CONFIG_VIDEO_SAA5249 is not set
+# CONFIG_VIDEO_SAA6588 is not set
+# CONFIG_VIDEO_SAA7110 is not set
+# CONFIG_VIDEO_SAA7111 is not set
+# CONFIG_VIDEO_SAA7114 is not set
+# CONFIG_VIDEO_SAA711X is not set
+# CONFIG_VIDEO_SAA7127 is not set
+# CONFIG_VIDEO_SAA7134 is not set
+# CONFIG_VIDEO_SAA717X is not set
+# CONFIG_VIDEO_SAA7185 is not set
+# CONFIG_VIDEO_SAA7191 is not set
+# CONFIG_VIDEO_SH_MOBILE_CEU is not set
+# CONFIG_VIDEO_STRADIS is not set
+# CONFIG_VIDEO_TCM825X is not set
+# CONFIG_VIDEO_TDA7432 is not set
+# CONFIG_VIDEO_TDA9840 is not set
+# CONFIG_VIDEO_TDA9875 is not set
+# CONFIG_VIDEO_TEA6415C is not set
+# CONFIG_VIDEO_TEA6420 is not set
+# CONFIG_VIDEO_THS7303 is not set
+# CONFIG_VIDEO_TLV320AIC23B is not set
+# CONFIG_VIDEO_TVAUDIO is not set
+# CONFIG_VIDEO_TVP514X is not set
+# CONFIG_VIDEO_TVP5150 is not set
+# CONFIG_VIDEO_UPD64031A is not set
+# CONFIG_VIDEO_UPD64083 is not set
+# CONFIG_VIDEO_USBVISION is not set
+# CONFIG_VIDEO_V4L1 is not set
+CONFIG_VIDEO_V4L1_COMPAT=y
+# CONFIG_VIDEO_V4L2 is not set
+# CONFIG_VIDEO_V4L2_COMMON is not set
+# CONFIG_VIDEO_VIVI is not set
+# CONFIG_VIDEO_VP27SMPX is not set
+# CONFIG_VIDEO_VPX3220 is not set
+# CONFIG_VIDEO_WM8739 is not set
+# CONFIG_VIDEO_WM8775 is not set
+# CONFIG_VIDEO_ZORAN is not set
+# CONFIG_VIRQ_DEBUG is not set
+# CONFIG_VIRTUALIZATION is not set
+CONFIG_VIRT_TO_BUS=y
+# CONFIG_VITESSE_PHY is not set
+CONFIG_VLAN_8021Q=y
+# CONFIG_VLAN_8021Q_GVRP is not set
+# CONFIG_VMSPLIT_1G is not set
+# CONFIG_VMSPLIT_2G is not set
+# CONFIG_VMSPLIT_2G_OPT is not set
+CONFIG_VMSPLIT_3G=y
+# CONFIG_VMSPLIT_3G_OPT is not set
+# CONFIG_VM_EVENT_COUNTERS is not set
+# CONFIG_VT is not set
+# CONFIG_VT6655 is not set
+# CONFIG_VXFS_FS is not set
+# CONFIG_W1 is not set
+# CONFIG_W1_CON is not set
+# CONFIG_W1_MASTER_DS1WM is not set
+# CONFIG_W1_MASTER_DS2482 is not set
+# CONFIG_W1_MASTER_DS2490 is not set
+# CONFIG_W1_MASTER_GPIO is not set
+# CONFIG_W1_MASTER_MATROX is not set
+# CONFIG_W1_SLAVE_BQ27000 is not set
+# CONFIG_W1_SLAVE_DS2431 is not set
+# CONFIG_W1_SLAVE_DS2433 is not set
+# CONFIG_W1_SLAVE_DS2760 is not set
+# CONFIG_W1_SLAVE_SMEM is not set
+# CONFIG_W1_SLAVE_THERM is not set
+# CONFIG_W83627HF_WDT is not set
+# CONFIG_W83697HF_WDT is not set
+# CONFIG_W83877F_WDT is not set
+# CONFIG_W83977F_WDT is not set
+# CONFIG_WAN is not set
+# CONFIG_WANXL is not set
+# CONFIG_WAN_ROUTER is not set
+CONFIG_WATCHDOG=y
+# CONFIG_WATCHDOG_NOWAYOUT is not set
+# CONFIG_WDTPCI is not set
+# CONFIG_WIMAX is not set
+CONFIG_WIRELESS=y
+CONFIG_WIRELESS_EXT=y
+# CONFIG_WIRELESS_EXT_SYSFS is not set
+CONFIG_WIRELESS_OLD_REGULATORY=y
+CONFIG_WLAN_80211=y
+# CONFIG_WLAN_PRE80211 is not set
+# CONFIG_WORKQUEUE_TRACER is not set
+# CONFIG_WR_PPMC is not set
+# CONFIG_X25 is not set
+CONFIG_XFRM=y
+# CONFIG_XFRM_IPCOMP is not set
+# CONFIG_XFRM_MIGRATE is not set
+# CONFIG_XFRM_STATISTICS is not set
+# CONFIG_XFRM_SUB_POLICY is not set
+# CONFIG_XFRM_USER is not set
+# CONFIG_XFS_DEBUG is not set
+# CONFIG_XFS_FS is not set
+# CONFIG_XFS_POSIX_ACL is not set
+# CONFIG_XFS_QUOTA is not set
+# CONFIG_XFS_RT is not set
+# CONFIG_XFS_SECURITY is not set
+# CONFIG_XIP_KERNEL is not set
+# CONFIG_YAFFS_FS is not set
+# CONFIG_YAM is not set
+# CONFIG_YELLOWFIN is not set
+# CONFIG_YENTA is not set
+# CONFIG_YENTA_O2 is not set
+# CONFIG_YENTA_RICOH is not set
+# CONFIG_YENTA_TI is not set
+# CONFIG_YENTA_TOSHIBA is not set
+# CONFIG_ZD1211RW is not set
+# CONFIG_ZD1211RW_DEBUG is not set
+# CONFIG_ZEROPLUS_FF is not set
+CONFIG_ZISOFS=y
+# CONFIG_ZISOFS_FS is not set
+CONFIG_ZLIB_DEFLATE=y
+CONFIG_ZLIB_INFLATE=y
+CONFIG_ZONE_DMA=y
+CONFIG_ZONE_DMA_FLAG=1
diff -Nru a/target/linux/generic/patches-2.6.31/001-squashfs_move_zlib_decomp.patch b/target/linux/generic/patches-2.6.31/001-squashfs_move_zlib_decomp.patch
--- a/target/linux/generic/patches-2.6.31/001-squashfs_move_zlib_decomp.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/001-squashfs_move_zlib_decomp.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,244 @@
+From 6c4419d997d4431bb62e73475cd6b084e83efbd1 Mon Sep 17 00:00:00 2001
+From: Phillip Lougher <phillip@lougher.demon.co.uk>
+Date: Tue, 22 Sep 2009 19:25:24 +0100
+Subject: [PATCH] Squashfs: move zlib decompression wrapper code into a separate file
+
+Signed-off-by: Phillip Lougher <phillip@lougher.demon.co.uk>
+---
+ fs/squashfs/Makefile       |    2 +-
+ fs/squashfs/block.c        |   74 ++----------------------------
+ fs/squashfs/squashfs.h     |    4 ++
+ fs/squashfs/zlib_wrapper.c |  109 ++++++++++++++++++++++++++++++++++++++++++++
+ 4 files changed, 118 insertions(+), 71 deletions(-)
+ create mode 100644 fs/squashfs/zlib_wrapper.c
+
+--- a/fs/squashfs/Makefile
++++ b/fs/squashfs/Makefile
+@@ -4,4 +4,4 @@
+ 
+ obj-$(CONFIG_SQUASHFS) += squashfs.o
+ squashfs-y += block.o cache.o dir.o export.o file.o fragment.o id.o inode.o
+-squashfs-y += namei.o super.o symlink.o
++squashfs-y += namei.o super.o symlink.o zlib_wrapper.o
+--- a/fs/squashfs/block.c
++++ b/fs/squashfs/block.c
+@@ -29,7 +29,6 @@
+ #include <linux/fs.h>
+ #include <linux/vfs.h>
+ #include <linux/slab.h>
+-#include <linux/mutex.h>
+ #include <linux/string.h>
+ #include <linux/buffer_head.h>
+ #include <linux/zlib.h>
+@@ -153,72 +152,10 @@ int squashfs_read_data(struct super_bloc
+ 	}
+ 
+ 	if (compressed) {
+-		int zlib_err = 0, zlib_init = 0;
+-
+-		/*
+-		 * Uncompress block.
+-		 */
+-
+-		mutex_lock(&msblk->read_data_mutex);
+-
+-		msblk->stream.avail_out = 0;
+-		msblk->stream.avail_in = 0;
+-
+-		bytes = length;
+-		do {
+-			if (msblk->stream.avail_in == 0 && k < b) {
+-				avail = min(bytes, msblk->devblksize - offset);
+-				bytes -= avail;
+-				wait_on_buffer(bh[k]);
+-				if (!buffer_uptodate(bh[k]))
+-					goto release_mutex;
+-
+-				if (avail == 0) {
+-					offset = 0;
+-					put_bh(bh[k++]);
+-					continue;
+-				}
+-
+-				msblk->stream.next_in = bh[k]->b_data + offset;
+-				msblk->stream.avail_in = avail;
+-				offset = 0;
+-			}
+-
+-			if (msblk->stream.avail_out == 0 && page < pages) {
+-				msblk->stream.next_out = buffer[page++];
+-				msblk->stream.avail_out = PAGE_CACHE_SIZE;
+-			}
+-
+-			if (!zlib_init) {
+-				zlib_err = zlib_inflateInit(&msblk->stream);
+-				if (zlib_err != Z_OK) {
+-					ERROR("zlib_inflateInit returned"
+-						" unexpected result 0x%x,"
+-						" srclength %d\n", zlib_err,
+-						srclength);
+-					goto release_mutex;
+-				}
+-				zlib_init = 1;
+-			}
+-
+-			zlib_err = zlib_inflate(&msblk->stream, Z_SYNC_FLUSH);
+-
+-			if (msblk->stream.avail_in == 0 && k < b)
+-				put_bh(bh[k++]);
+-		} while (zlib_err == Z_OK);
+-
+-		if (zlib_err != Z_STREAM_END) {
+-			ERROR("zlib_inflate error, data probably corrupt\n");
+-			goto release_mutex;
+-		}
+-
+-		zlib_err = zlib_inflateEnd(&msblk->stream);
+-		if (zlib_err != Z_OK) {
+-			ERROR("zlib_inflate error, data probably corrupt\n");
+-			goto release_mutex;
+-		}
+-		length = msblk->stream.total_out;
+-		mutex_unlock(&msblk->read_data_mutex);
++		length = zlib_uncompress(msblk, buffer, bh, b, offset, length,
++			srclength, pages);
++		if (length < 0)
++			goto read_failure;
+ 	} else {
+ 		/*
+ 		 * Block is uncompressed.
+@@ -255,9 +192,6 @@ int squashfs_read_data(struct super_bloc
+ 	kfree(bh);
+ 	return length;
+ 
+-release_mutex:
+-	mutex_unlock(&msblk->read_data_mutex);
+-
+ block_release:
+ 	for (; k < b; k++)
+ 		put_bh(bh[k]);
+--- a/fs/squashfs/squashfs.h
++++ b/fs/squashfs/squashfs.h
+@@ -70,6 +70,10 @@ extern struct inode *squashfs_iget(struc
+ 				unsigned int);
+ extern int squashfs_read_inode(struct inode *, long long);
+ 
++/* zlib_wrapper.c */
++extern int zlib_uncompress(struct squashfs_sb_info *, void **,
++				struct buffer_head **, int, int, int, int, int);
++
+ /*
+  * Inodes and files operations
+  */
+--- /dev/null
++++ b/fs/squashfs/zlib_wrapper.c
+@@ -0,0 +1,109 @@
++/*
++ * Squashfs - a compressed read only filesystem for Linux
++ *
++ * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009
++ * Phillip Lougher <phillip@lougher.demon.co.uk>
++ *
++ * This program is free software; you can redistribute it and/or
++ * modify it under the terms of the GNU General Public License
++ * as published by the Free Software Foundation; either version 2,
++ * or (at your option) any later version.
++ *
++ * This program is distributed in the hope that it will be useful,
++ * but WITHOUT ANY WARRANTY; without even the implied warranty of
++ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
++ * GNU General Public License for more details.
++ *
++ * You should have received a copy of the GNU General Public License
++ * along with this program; if not, write to the Free Software
++ * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
++ *
++ * zlib_wrapper.c
++ */
++
++
++#include <linux/mutex.h>
++#include <linux/buffer_head.h>
++#include <linux/zlib.h>
++
++#include "squashfs_fs.h"
++#include "squashfs_fs_sb.h"
++#include "squashfs_fs_i.h"
++#include "squashfs.h"
++
++int zlib_uncompress(struct squashfs_sb_info *msblk, void **buffer,
++	struct buffer_head **bh, int b, int offset, int length, int srclength,
++	int pages)
++{
++	int zlib_err = 0, zlib_init = 0;
++	int avail, bytes, k = 0, page = 0;
++
++	mutex_lock(&msblk->read_data_mutex);
++
++	msblk->stream.avail_out = 0;
++	msblk->stream.avail_in = 0;
++
++	bytes = length;
++	do {
++		if (msblk->stream.avail_in == 0 && k < b) {
++			avail = min(bytes, msblk->devblksize - offset);
++			bytes -= avail;
++			wait_on_buffer(bh[k]);
++			if (!buffer_uptodate(bh[k]))
++				goto release_mutex;
++
++			if (avail == 0) {
++				offset = 0;
++				put_bh(bh[k++]);
++				continue;
++			}
++
++			msblk->stream.next_in = bh[k]->b_data + offset;
++			msblk->stream.avail_in = avail;
++			offset = 0;
++		}
++
++		if (msblk->stream.avail_out == 0 && page < pages) {
++			msblk->stream.next_out = buffer[page++];
++			msblk->stream.avail_out = PAGE_CACHE_SIZE;
++		}
++
++		if (!zlib_init) {
++			zlib_err = zlib_inflateInit(&msblk->stream);
++			if (zlib_err != Z_OK) {
++				ERROR("zlib_inflateInit returned unexpected "
++					"result 0x%x, srclength %d\n",
++					zlib_err, srclength);
++				goto release_mutex;
++			}
++			zlib_init = 1;
++		}
++
++		zlib_err = zlib_inflate(&msblk->stream, Z_SYNC_FLUSH);
++
++		if (msblk->stream.avail_in == 0 && k < b)
++			put_bh(bh[k++]);
++	} while (zlib_err == Z_OK);
++
++	if (zlib_err != Z_STREAM_END) {
++		ERROR("zlib_inflate error, data probably corrupt\n");
++		goto release_mutex;
++	}
++
++	zlib_err = zlib_inflateEnd(&msblk->stream);
++	if (zlib_err != Z_OK) {
++		ERROR("zlib_inflate error, data probably corrupt\n");
++		goto release_mutex;
++	}
++
++	mutex_unlock(&msblk->read_data_mutex);
++	return msblk->stream.total_out;
++
++release_mutex:
++	mutex_unlock(&msblk->read_data_mutex);
++
++	for (; k < b; k++)
++		put_bh(bh[k]);
++
++	return -EIO;
++}
diff -Nru a/target/linux/generic/patches-2.6.31/002-squashfs_factor_out_remaining_zlib.patch b/target/linux/generic/patches-2.6.31/002-squashfs_factor_out_remaining_zlib.patch
--- a/target/linux/generic/patches-2.6.31/002-squashfs_factor_out_remaining_zlib.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/002-squashfs_factor_out_remaining_zlib.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,317 @@
+From 37c44e85fd49676ec15ccaeea065662c1fbcda7d Mon Sep 17 00:00:00 2001
+From: Phillip Lougher <phillip@lougher.demon.co.uk>
+Date: Wed, 23 Sep 2009 19:04:49 +0100
+Subject: [PATCH] Squashfs: Factor out remaining zlib dependencies into separate wrapper file
+
+Move zlib buffer init/destroy code into separate wrapper file.  Also
+make zlib z_stream field a void * removing the need to include zlib.h
+for most files.
+
+Signed-off-by: Phillip Lougher <phillip@lougher.demon.co.uk>
+---
+ fs/squashfs/block.c          |    1 -
+ fs/squashfs/cache.c          |    1 -
+ fs/squashfs/dir.c            |    1 -
+ fs/squashfs/export.c         |    1 -
+ fs/squashfs/file.c           |    1 -
+ fs/squashfs/fragment.c       |    1 -
+ fs/squashfs/id.c             |    1 -
+ fs/squashfs/inode.c          |    1 -
+ fs/squashfs/namei.c          |    1 -
+ fs/squashfs/squashfs.h       |    2 +
+ fs/squashfs/squashfs_fs_sb.h |    2 +-
+ fs/squashfs/super.c          |   14 +++------
+ fs/squashfs/symlink.c        |    1 -
+ fs/squashfs/zlib_wrapper.c   |   56 ++++++++++++++++++++++++++++++++---------
+ 14 files changed, 51 insertions(+), 33 deletions(-)
+
+--- a/fs/squashfs/block.c
++++ b/fs/squashfs/block.c
+@@ -31,7 +31,6 @@
+ #include <linux/slab.h>
+ #include <linux/string.h>
+ #include <linux/buffer_head.h>
+-#include <linux/zlib.h>
+ 
+ #include "squashfs_fs.h"
+ #include "squashfs_fs_sb.h"
+--- a/fs/squashfs/cache.c
++++ b/fs/squashfs/cache.c
+@@ -51,7 +51,6 @@
+ #include <linux/sched.h>
+ #include <linux/spinlock.h>
+ #include <linux/wait.h>
+-#include <linux/zlib.h>
+ #include <linux/pagemap.h>
+ 
+ #include "squashfs_fs.h"
+--- a/fs/squashfs/dir.c
++++ b/fs/squashfs/dir.c
+@@ -30,7 +30,6 @@
+ #include <linux/fs.h>
+ #include <linux/vfs.h>
+ #include <linux/slab.h>
+-#include <linux/zlib.h>
+ 
+ #include "squashfs_fs.h"
+ #include "squashfs_fs_sb.h"
+--- a/fs/squashfs/export.c
++++ b/fs/squashfs/export.c
+@@ -39,7 +39,6 @@
+ #include <linux/vfs.h>
+ #include <linux/dcache.h>
+ #include <linux/exportfs.h>
+-#include <linux/zlib.h>
+ #include <linux/slab.h>
+ 
+ #include "squashfs_fs.h"
+--- a/fs/squashfs/file.c
++++ b/fs/squashfs/file.c
+@@ -47,7 +47,6 @@
+ #include <linux/string.h>
+ #include <linux/pagemap.h>
+ #include <linux/mutex.h>
+-#include <linux/zlib.h>
+ 
+ #include "squashfs_fs.h"
+ #include "squashfs_fs_sb.h"
+--- a/fs/squashfs/fragment.c
++++ b/fs/squashfs/fragment.c
+@@ -36,7 +36,6 @@
+ #include <linux/fs.h>
+ #include <linux/vfs.h>
+ #include <linux/slab.h>
+-#include <linux/zlib.h>
+ 
+ #include "squashfs_fs.h"
+ #include "squashfs_fs_sb.h"
+--- a/fs/squashfs/id.c
++++ b/fs/squashfs/id.c
+@@ -34,7 +34,6 @@
+ #include <linux/fs.h>
+ #include <linux/vfs.h>
+ #include <linux/slab.h>
+-#include <linux/zlib.h>
+ 
+ #include "squashfs_fs.h"
+ #include "squashfs_fs_sb.h"
+--- a/fs/squashfs/inode.c
++++ b/fs/squashfs/inode.c
+@@ -40,7 +40,6 @@
+ 
+ #include <linux/fs.h>
+ #include <linux/vfs.h>
+-#include <linux/zlib.h>
+ 
+ #include "squashfs_fs.h"
+ #include "squashfs_fs_sb.h"
+--- a/fs/squashfs/namei.c
++++ b/fs/squashfs/namei.c
+@@ -57,7 +57,6 @@
+ #include <linux/slab.h>
+ #include <linux/string.h>
+ #include <linux/dcache.h>
+-#include <linux/zlib.h>
+ 
+ #include "squashfs_fs.h"
+ #include "squashfs_fs_sb.h"
+--- a/fs/squashfs/squashfs.h
++++ b/fs/squashfs/squashfs.h
+@@ -71,6 +71,8 @@ extern struct inode *squashfs_iget(struc
+ extern int squashfs_read_inode(struct inode *, long long);
+ 
+ /* zlib_wrapper.c */
++extern void *zlib_init(void);
++extern void zlib_free(void *);
+ extern int zlib_uncompress(struct squashfs_sb_info *, void **,
+ 				struct buffer_head **, int, int, int, int, int);
+ 
+--- a/fs/squashfs/squashfs_fs_sb.h
++++ b/fs/squashfs/squashfs_fs_sb.h
+@@ -64,7 +64,7 @@ struct squashfs_sb_info {
+ 	struct mutex		read_data_mutex;
+ 	struct mutex		meta_index_mutex;
+ 	struct meta_index	*meta_index;
+-	z_stream		stream;
++	void			*stream;
+ 	__le64			*inode_lookup_table;
+ 	u64			inode_table;
+ 	u64			directory_table;
+--- a/fs/squashfs/super.c
++++ b/fs/squashfs/super.c
+@@ -35,7 +35,6 @@
+ #include <linux/pagemap.h>
+ #include <linux/init.h>
+ #include <linux/module.h>
+-#include <linux/zlib.h>
+ #include <linux/magic.h>
+ 
+ #include "squashfs_fs.h"
+@@ -87,12 +86,9 @@ static int squashfs_fill_super(struct su
+ 	}
+ 	msblk = sb->s_fs_info;
+ 
+-	msblk->stream.workspace = kmalloc(zlib_inflate_workspacesize(),
+-		GFP_KERNEL);
+-	if (msblk->stream.workspace == NULL) {
+-		ERROR("Failed to allocate zlib workspace\n");
++	msblk->stream = zlib_init();
++	if (msblk->stream == NULL)
+ 		goto failure;
+-	}
+ 
+ 	sblk = kzalloc(sizeof(*sblk), GFP_KERNEL);
+ 	if (sblk == NULL) {
+@@ -292,17 +288,17 @@ failed_mount:
+ 	squashfs_cache_delete(msblk->block_cache);
+ 	squashfs_cache_delete(msblk->fragment_cache);
+ 	squashfs_cache_delete(msblk->read_page);
++	zlib_free(msblk->stream);
+ 	kfree(msblk->inode_lookup_table);
+ 	kfree(msblk->fragment_index);
+ 	kfree(msblk->id_table);
+-	kfree(msblk->stream.workspace);
+ 	kfree(sb->s_fs_info);
+ 	sb->s_fs_info = NULL;
+ 	kfree(sblk);
+ 	return err;
+ 
+ failure:
+-	kfree(msblk->stream.workspace);
++	zlib_free(msblk->stream);
+ 	kfree(sb->s_fs_info);
+ 	sb->s_fs_info = NULL;
+ 	return -ENOMEM;
+@@ -346,10 +342,10 @@ static void squashfs_put_super(struct su
+ 		squashfs_cache_delete(sbi->block_cache);
+ 		squashfs_cache_delete(sbi->fragment_cache);
+ 		squashfs_cache_delete(sbi->read_page);
++		zlib_free(sbi->stream);
+ 		kfree(sbi->id_table);
+ 		kfree(sbi->fragment_index);
+ 		kfree(sbi->meta_index);
+-		kfree(sbi->stream.workspace);
+ 		kfree(sb->s_fs_info);
+ 		sb->s_fs_info = NULL;
+ 	}
+--- a/fs/squashfs/symlink.c
++++ b/fs/squashfs/symlink.c
+@@ -36,7 +36,6 @@
+ #include <linux/slab.h>
+ #include <linux/string.h>
+ #include <linux/pagemap.h>
+-#include <linux/zlib.h>
+ 
+ #include "squashfs_fs.h"
+ #include "squashfs_fs_sb.h"
+--- a/fs/squashfs/zlib_wrapper.c
++++ b/fs/squashfs/zlib_wrapper.c
+@@ -31,21 +31,51 @@
+ #include "squashfs_fs_i.h"
+ #include "squashfs.h"
+ 
++void *zlib_init()
++{
++	z_stream *stream = kmalloc(sizeof(z_stream), GFP_KERNEL);
++	if (stream == NULL)
++		goto failed;
++	stream->workspace = kmalloc(zlib_inflate_workspacesize(),
++		GFP_KERNEL);
++	if (stream->workspace == NULL)
++		goto failed;
++
++	return stream;
++
++failed:
++	ERROR("Failed to allocate zlib workspace\n");
++	kfree(stream);
++	return NULL;
++}
++
++
++void zlib_free(void *strm)
++{
++	z_stream *stream = strm;
++
++	if (stream)
++		kfree(stream->workspace);
++	kfree(stream);
++}
++
++
+ int zlib_uncompress(struct squashfs_sb_info *msblk, void **buffer,
+ 	struct buffer_head **bh, int b, int offset, int length, int srclength,
+ 	int pages)
+ {
+ 	int zlib_err = 0, zlib_init = 0;
+ 	int avail, bytes, k = 0, page = 0;
++	z_stream *stream = msblk->stream;
+ 
+ 	mutex_lock(&msblk->read_data_mutex);
+ 
+-	msblk->stream.avail_out = 0;
+-	msblk->stream.avail_in = 0;
++	stream->avail_out = 0;
++	stream->avail_in = 0;
+ 
+ 	bytes = length;
+ 	do {
+-		if (msblk->stream.avail_in == 0 && k < b) {
++		if (stream->avail_in == 0 && k < b) {
+ 			avail = min(bytes, msblk->devblksize - offset);
+ 			bytes -= avail;
+ 			wait_on_buffer(bh[k]);
+@@ -58,18 +88,18 @@ int zlib_uncompress(struct squashfs_sb_i
+ 				continue;
+ 			}
+ 
+-			msblk->stream.next_in = bh[k]->b_data + offset;
+-			msblk->stream.avail_in = avail;
++			stream->next_in = bh[k]->b_data + offset;
++			stream->avail_in = avail;
+ 			offset = 0;
+ 		}
+ 
+-		if (msblk->stream.avail_out == 0 && page < pages) {
+-			msblk->stream.next_out = buffer[page++];
+-			msblk->stream.avail_out = PAGE_CACHE_SIZE;
++		if (stream->avail_out == 0 && page < pages) {
++			stream->next_out = buffer[page++];
++			stream->avail_out = PAGE_CACHE_SIZE;
+ 		}
+ 
+ 		if (!zlib_init) {
+-			zlib_err = zlib_inflateInit(&msblk->stream);
++			zlib_err = zlib_inflateInit(stream);
+ 			if (zlib_err != Z_OK) {
+ 				ERROR("zlib_inflateInit returned unexpected "
+ 					"result 0x%x, srclength %d\n",
+@@ -79,9 +109,9 @@ int zlib_uncompress(struct squashfs_sb_i
+ 			zlib_init = 1;
+ 		}
+ 
+-		zlib_err = zlib_inflate(&msblk->stream, Z_SYNC_FLUSH);
++		zlib_err = zlib_inflate(stream, Z_SYNC_FLUSH);
+ 
+-		if (msblk->stream.avail_in == 0 && k < b)
++		if (stream->avail_in == 0 && k < b)
+ 			put_bh(bh[k++]);
+ 	} while (zlib_err == Z_OK);
+ 
+@@ -90,14 +120,14 @@ int zlib_uncompress(struct squashfs_sb_i
+ 		goto release_mutex;
+ 	}
+ 
+-	zlib_err = zlib_inflateEnd(&msblk->stream);
++	zlib_err = zlib_inflateEnd(stream);
+ 	if (zlib_err != Z_OK) {
+ 		ERROR("zlib_inflate error, data probably corrupt\n");
+ 		goto release_mutex;
+ 	}
+ 
+ 	mutex_unlock(&msblk->read_data_mutex);
+-	return msblk->stream.total_out;
++	return stream->total_out;
+ 
+ release_mutex:
+ 	mutex_unlock(&msblk->read_data_mutex);
diff -Nru a/target/linux/generic/patches-2.6.31/003-squashfs_add_decompressor_framework.patch b/target/linux/generic/patches-2.6.31/003-squashfs_add_decompressor_framework.patch
--- a/target/linux/generic/patches-2.6.31/003-squashfs_add_decompressor_framework.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/003-squashfs_add_decompressor_framework.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,426 @@
+From 327fbf47a419befc6bff74f3ca42d2b6f0841903 Mon Sep 17 00:00:00 2001
+From: Phillip Lougher <phillip@lougher.demon.co.uk>
+Date: Tue, 6 Oct 2009 04:04:15 +0100
+Subject: [PATCH] Squashfs: add a decompressor framework
+
+This adds a decompressor framework which allows multiple compression
+algorithms to be cleanly supported.
+
+Also update zlib wrapper and other code to use the new framework.
+
+Signed-off-by: Phillip Lougher <phillip@lougher.demon.co.uk>
+---
+ fs/squashfs/Makefile         |    2 +-
+ fs/squashfs/block.c          |    6 ++--
+ fs/squashfs/decompressor.c   |   58 ++++++++++++++++++++++++++++++++++++++++++
+ fs/squashfs/decompressor.h   |   55 +++++++++++++++++++++++++++++++++++++++
+ fs/squashfs/squashfs.h       |   14 +++++-----
+ fs/squashfs/squashfs_fs_sb.h |   41 +++++++++++++++--------------
+ fs/squashfs/super.c          |   45 ++++++++++++++++++-------------
+ fs/squashfs/zlib_wrapper.c   |   17 ++++++++++--
+ 8 files changed, 185 insertions(+), 53 deletions(-)
+ create mode 100644 fs/squashfs/decompressor.c
+ create mode 100644 fs/squashfs/decompressor.h
+
+--- a/fs/squashfs/Makefile
++++ b/fs/squashfs/Makefile
+@@ -4,4 +4,4 @@
+ 
+ obj-$(CONFIG_SQUASHFS) += squashfs.o
+ squashfs-y += block.o cache.o dir.o export.o file.o fragment.o id.o inode.o
+-squashfs-y += namei.o super.o symlink.o zlib_wrapper.o
++squashfs-y += namei.o super.o symlink.o zlib_wrapper.o decompressor.o
+--- a/fs/squashfs/block.c
++++ b/fs/squashfs/block.c
+@@ -36,7 +36,7 @@
+ #include "squashfs_fs_sb.h"
+ #include "squashfs_fs_i.h"
+ #include "squashfs.h"
+-
++#include "decompressor.h"
+ /*
+  * Read the metadata block length, this is stored in the first two
+  * bytes of the metadata block.
+@@ -151,8 +151,8 @@ int squashfs_read_data(struct super_bloc
+ 	}
+ 
+ 	if (compressed) {
+-		length = zlib_uncompress(msblk, buffer, bh, b, offset, length,
+-			srclength, pages);
++		length = squashfs_decompress(msblk, buffer, bh, b, offset,
++			length, srclength, pages);
+ 		if (length < 0)
+ 			goto read_failure;
+ 	} else {
+--- /dev/null
++++ b/fs/squashfs/decompressor.c
+@@ -0,0 +1,58 @@
++/*
++ * Squashfs - a compressed read only filesystem for Linux
++ *
++ * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009
++ * Phillip Lougher <phillip@lougher.demon.co.uk>
++ *
++ * This program is free software; you can redistribute it and/or
++ * modify it under the terms of the GNU General Public License
++ * as published by the Free Software Foundation; either version 2,
++ * or (at your option) any later version.
++ *
++ * This program is distributed in the hope that it will be useful,
++ * but WITHOUT ANY WARRANTY; without even the implied warranty of
++ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
++ * GNU General Public License for more details.
++ *
++ * You should have received a copy of the GNU General Public License
++ * along with this program; if not, write to the Free Software
++ * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
++ *
++ * decompressor.c
++ */
++
++#include <linux/types.h>
++#include <linux/mutex.h>
++#include <linux/buffer_head.h>
++
++#include "squashfs_fs.h"
++#include "squashfs_fs_sb.h"
++#include "squashfs_fs_i.h"
++#include "decompressor.h"
++#include "squashfs.h"
++
++/*
++ * This file (and decompressor.h) implements a decompressor framework for
++ * Squashfs, allowing multiple decompressors to be easily supported
++ */
++
++static const struct squashfs_decompressor squashfs_unknown_comp_ops = {
++	NULL, NULL, NULL, 0, "unknown", 0
++};
++
++static const struct squashfs_decompressor *decompressor[] = {
++	&squashfs_zlib_comp_ops,
++	&squashfs_unknown_comp_ops
++};
++
++
++const struct squashfs_decompressor *squashfs_lookup_decompressor(int id)
++{
++	int i;
++
++	for (i = 0; decompressor[i]->id; i++)
++		if (id == decompressor[i]->id)
++			break;
++
++	return decompressor[i];
++}
+--- /dev/null
++++ b/fs/squashfs/decompressor.h
+@@ -0,0 +1,55 @@
++#ifndef DECOMPRESSOR_H
++#define DECOMPRESSOR_H
++/*
++ * Squashfs - a compressed read only filesystem for Linux
++ *
++ * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009
++ * Phillip Lougher <phillip@lougher.demon.co.uk>
++ *
++ * This program is free software; you can redistribute it and/or
++ * modify it under the terms of the GNU General Public License
++ * as published by the Free Software Foundation; either version 2,
++ * or (at your option) any later version.
++ *
++ * This program is distributed in the hope that it will be useful,
++ * but WITHOUT ANY WARRANTY; without even the implied warranty of
++ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
++ * GNU General Public License for more details.
++ *
++ * You should have received a copy of the GNU General Public License
++ * along with this program; if not, write to the Free Software
++ * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
++ *
++ * decompressor.h
++ */
++
++struct squashfs_decompressor {
++	void	*(*init)(void);
++	void	(*free)(void *);
++	int	(*decompress)(struct squashfs_sb_info *, void **,
++		struct buffer_head **, int, int, int, int, int);
++	int	id;
++	char	*name;
++	int	supported;
++};
++
++static inline void *squashfs_decompressor_init(struct squashfs_sb_info *msblk)
++{
++	return msblk->decompressor->init();
++}
++
++static inline void squashfs_decompressor_free(struct squashfs_sb_info *msblk,
++	void *s)
++{
++	if (msblk->decompressor)
++		msblk->decompressor->free(s);
++}
++
++static inline int squashfs_decompress(struct squashfs_sb_info *msblk,
++	void **buffer, struct buffer_head **bh, int b, int offset, int length,
++	int srclength, int pages)
++{
++	return msblk->decompressor->decompress(msblk, buffer, bh, b, offset,
++		length, srclength, pages);
++}
++#endif
+--- a/fs/squashfs/squashfs.h
++++ b/fs/squashfs/squashfs.h
+@@ -51,6 +51,9 @@ extern struct squashfs_cache_entry *squa
+ 				u64, int);
+ extern int squashfs_read_table(struct super_block *, void *, u64, int);
+ 
++/* decompressor.c */
++extern const struct squashfs_decompressor *squashfs_lookup_decompressor(int);
++
+ /* export.c */
+ extern __le64 *squashfs_read_inode_lookup_table(struct super_block *, u64,
+ 				unsigned int);
+@@ -70,14 +73,8 @@ extern struct inode *squashfs_iget(struc
+ 				unsigned int);
+ extern int squashfs_read_inode(struct inode *, long long);
+ 
+-/* zlib_wrapper.c */
+-extern void *zlib_init(void);
+-extern void zlib_free(void *);
+-extern int zlib_uncompress(struct squashfs_sb_info *, void **,
+-				struct buffer_head **, int, int, int, int, int);
+-
+ /*
+- * Inodes and files operations
++ * Inodes, files and decompressor operations
+  */
+ 
+ /* dir.c */
+@@ -94,3 +91,6 @@ extern const struct inode_operations squ
+ 
+ /* symlink.c */
+ extern const struct address_space_operations squashfs_symlink_aops;
++
++/* zlib_wrapper.c */
++extern const struct squashfs_decompressor squashfs_zlib_comp_ops;
+--- a/fs/squashfs/squashfs_fs_sb.h
++++ b/fs/squashfs/squashfs_fs_sb.h
+@@ -52,25 +52,26 @@ struct squashfs_cache_entry {
+ };
+ 
+ struct squashfs_sb_info {
+-	int			devblksize;
+-	int			devblksize_log2;
+-	struct squashfs_cache	*block_cache;
+-	struct squashfs_cache	*fragment_cache;
+-	struct squashfs_cache	*read_page;
+-	int			next_meta_index;
+-	__le64			*id_table;
+-	__le64			*fragment_index;
+-	unsigned int		*fragment_index_2;
+-	struct mutex		read_data_mutex;
+-	struct mutex		meta_index_mutex;
+-	struct meta_index	*meta_index;
+-	void			*stream;
+-	__le64			*inode_lookup_table;
+-	u64			inode_table;
+-	u64			directory_table;
+-	unsigned int		block_size;
+-	unsigned short		block_log;
+-	long long		bytes_used;
+-	unsigned int		inodes;
++	const struct squashfs_decompressor	*decompressor;
++	int					devblksize;
++	int					devblksize_log2;
++	struct squashfs_cache			*block_cache;
++	struct squashfs_cache			*fragment_cache;
++	struct squashfs_cache			*read_page;
++	int					next_meta_index;
++	__le64					*id_table;
++	__le64					*fragment_index;
++	unsigned int				*fragment_index_2;
++	struct mutex				read_data_mutex;
++	struct mutex				meta_index_mutex;
++	struct meta_index			*meta_index;
++	void					*stream;
++	__le64					*inode_lookup_table;
++	u64					inode_table;
++	u64					directory_table;
++	unsigned int				block_size;
++	unsigned short				block_log;
++	long long				bytes_used;
++	unsigned int				inodes;
+ };
+ #endif
+--- a/fs/squashfs/super.c
++++ b/fs/squashfs/super.c
+@@ -41,27 +41,35 @@
+ #include "squashfs_fs_sb.h"
+ #include "squashfs_fs_i.h"
+ #include "squashfs.h"
++#include "decompressor.h"
+ 
+ static struct file_system_type squashfs_fs_type;
+ static struct super_operations squashfs_super_ops;
+ 
+-static int supported_squashfs_filesystem(short major, short minor, short comp)
++static const struct squashfs_decompressor *supported_squashfs_filesystem(short
++	major, short minor, short id)
+ {
++	const struct squashfs_decompressor *decompressor;
++
+ 	if (major < SQUASHFS_MAJOR) {
+ 		ERROR("Major/Minor mismatch, older Squashfs %d.%d "
+ 			"filesystems are unsupported\n", major, minor);
+-		return -EINVAL;
++		return NULL;
+ 	} else if (major > SQUASHFS_MAJOR || minor > SQUASHFS_MINOR) {
+ 		ERROR("Major/Minor mismatch, trying to mount newer "
+ 			"%d.%d filesystem\n", major, minor);
+ 		ERROR("Please update your kernel\n");
+-		return -EINVAL;
++		return NULL;
+ 	}
+ 
+-	if (comp != ZLIB_COMPRESSION)
+-		return -EINVAL;
++	decompressor = squashfs_lookup_decompressor(id);
++	if (!decompressor->supported) {
++		ERROR("Filesystem uses \"%s\" compression. This is not "
++			"supported\n", decompressor->name);
++		return NULL;
++	}
+ 
+-	return 0;
++	return decompressor;
+ }
+ 
+ 
+@@ -86,10 +94,6 @@ static int squashfs_fill_super(struct su
+ 	}
+ 	msblk = sb->s_fs_info;
+ 
+-	msblk->stream = zlib_init();
+-	if (msblk->stream == NULL)
+-		goto failure;
+-
+ 	sblk = kzalloc(sizeof(*sblk), GFP_KERNEL);
+ 	if (sblk == NULL) {
+ 		ERROR("Failed to allocate squashfs_super_block\n");
+@@ -116,25 +120,25 @@ static int squashfs_fill_super(struct su
+ 		goto failed_mount;
+ 	}
+ 
++	err = -EINVAL;
++
+ 	/* Check it is a SQUASHFS superblock */
+ 	sb->s_magic = le32_to_cpu(sblk->s_magic);
+ 	if (sb->s_magic != SQUASHFS_MAGIC) {
+ 		if (!silent)
+ 			ERROR("Can't find a SQUASHFS superblock on %s\n",
+ 						bdevname(sb->s_bdev, b));
+-		err = -EINVAL;
+ 		goto failed_mount;
+ 	}
+ 
+-	/* Check the MAJOR & MINOR versions and compression type */
+-	err = supported_squashfs_filesystem(le16_to_cpu(sblk->s_major),
++	/* Check the MAJOR & MINOR versions and lookup compression type */
++	msblk->decompressor = supported_squashfs_filesystem(
++			le16_to_cpu(sblk->s_major),
+ 			le16_to_cpu(sblk->s_minor),
+ 			le16_to_cpu(sblk->compression));
+-	if (err < 0)
++	if (msblk->decompressor == NULL)
+ 		goto failed_mount;
+ 
+-	err = -EINVAL;
+-
+ 	/*
+ 	 * Check if there's xattrs in the filesystem.  These are not
+ 	 * supported in this version, so warn that they will be ignored.
+@@ -201,6 +205,10 @@ static int squashfs_fill_super(struct su
+ 
+ 	err = -ENOMEM;
+ 
++	msblk->stream = squashfs_decompressor_init(msblk);
++	if (msblk->stream == NULL)
++		goto failed_mount;
++
+ 	msblk->block_cache = squashfs_cache_init("metadata",
+ 			SQUASHFS_CACHED_BLKS, SQUASHFS_METADATA_SIZE);
+ 	if (msblk->block_cache == NULL)
+@@ -288,7 +296,7 @@ failed_mount:
+ 	squashfs_cache_delete(msblk->block_cache);
+ 	squashfs_cache_delete(msblk->fragment_cache);
+ 	squashfs_cache_delete(msblk->read_page);
+-	zlib_free(msblk->stream);
++	squashfs_decompressor_free(msblk, msblk->stream);
+ 	kfree(msblk->inode_lookup_table);
+ 	kfree(msblk->fragment_index);
+ 	kfree(msblk->id_table);
+@@ -298,7 +306,6 @@ failed_mount:
+ 	return err;
+ 
+ failure:
+-	zlib_free(msblk->stream);
+ 	kfree(sb->s_fs_info);
+ 	sb->s_fs_info = NULL;
+ 	return -ENOMEM;
+@@ -342,7 +349,7 @@ static void squashfs_put_super(struct su
+ 		squashfs_cache_delete(sbi->block_cache);
+ 		squashfs_cache_delete(sbi->fragment_cache);
+ 		squashfs_cache_delete(sbi->read_page);
+-		zlib_free(sbi->stream);
++		squashfs_decompressor_free(sbi, sbi->stream);
+ 		kfree(sbi->id_table);
+ 		kfree(sbi->fragment_index);
+ 		kfree(sbi->meta_index);
+--- a/fs/squashfs/zlib_wrapper.c
++++ b/fs/squashfs/zlib_wrapper.c
+@@ -30,8 +30,9 @@
+ #include "squashfs_fs_sb.h"
+ #include "squashfs_fs_i.h"
+ #include "squashfs.h"
++#include "decompressor.h"
+ 
+-void *zlib_init()
++static void *zlib_init(void)
+ {
+ 	z_stream *stream = kmalloc(sizeof(z_stream), GFP_KERNEL);
+ 	if (stream == NULL)
+@@ -50,7 +51,7 @@ failed:
+ }
+ 
+ 
+-void zlib_free(void *strm)
++static void zlib_free(void *strm)
+ {
+ 	z_stream *stream = strm;
+ 
+@@ -60,7 +61,7 @@ void zlib_free(void *strm)
+ }
+ 
+ 
+-int zlib_uncompress(struct squashfs_sb_info *msblk, void **buffer,
++static int zlib_uncompress(struct squashfs_sb_info *msblk, void **buffer,
+ 	struct buffer_head **bh, int b, int offset, int length, int srclength,
+ 	int pages)
+ {
+@@ -137,3 +138,13 @@ release_mutex:
+ 
+ 	return -EIO;
+ }
++
++const struct squashfs_decompressor squashfs_zlib_comp_ops = {
++	.init = zlib_init,
++	.free = zlib_free,
++	.decompress = zlib_uncompress,
++	.id = ZLIB_COMPRESSION,
++	.name = "zlib",
++	.supported = 1
++};
++
diff -Nru a/target/linux/generic/patches-2.6.31/004-squashfs_add_decompressor_lzma_lzo.patch b/target/linux/generic/patches-2.6.31/004-squashfs_add_decompressor_lzma_lzo.patch
--- a/target/linux/generic/patches-2.6.31/004-squashfs_add_decompressor_lzma_lzo.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/004-squashfs_add_decompressor_lzma_lzo.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,54 @@
+From 1885ca0a1973944684f252094a703b7c80dfc974 Mon Sep 17 00:00:00 2001
+From: Phillip Lougher <phillip@lougher.demon.co.uk>
+Date: Wed, 14 Oct 2009 03:58:11 +0100
+Subject: [PATCH] Squashfs: add decompressor entries for lzma and lzo
+
+Add knowledge of lzma/lzo compression formats to the decompressor
+framework.  For now these are added as unsupported.  Without
+these entries lzma/lzo compressed filesystems will be flagged as
+having unknown compression which is undesirable.
+
+Signed-off-by: Phillip Lougher <phillip@lougher.demon.co.uk>
+---
+ fs/squashfs/decompressor.c |   10 ++++++++++
+ fs/squashfs/squashfs_fs.h  |    4 +++-
+ 2 files changed, 13 insertions(+), 1 deletions(-)
+
+--- a/fs/squashfs/decompressor.c
++++ b/fs/squashfs/decompressor.c
+@@ -36,12 +36,22 @@
+  * Squashfs, allowing multiple decompressors to be easily supported
+  */
+ 
++static const struct squashfs_decompressor squashfs_lzma_unsupported_comp_ops = {
++	NULL, NULL, NULL, LZMA_COMPRESSION, "lzma", 0
++};
++
++static const struct squashfs_decompressor squashfs_lzo_unsupported_comp_ops = {
++	NULL, NULL, NULL, LZO_COMPRESSION, "lzo", 0
++};
++
+ static const struct squashfs_decompressor squashfs_unknown_comp_ops = {
+ 	NULL, NULL, NULL, 0, "unknown", 0
+ };
+ 
+ static const struct squashfs_decompressor *decompressor[] = {
+ 	&squashfs_zlib_comp_ops,
++	&squashfs_lzma_unsupported_comp_ops,
++	&squashfs_lzo_unsupported_comp_ops,
+ 	&squashfs_unknown_comp_ops
+ };
+ 
+--- a/fs/squashfs/squashfs_fs.h
++++ b/fs/squashfs/squashfs_fs.h
+@@ -211,7 +211,9 @@ struct meta_index {
+ /*
+  * definitions for structures on disk
+  */
+-#define ZLIB_COMPRESSION	 1
++#define ZLIB_COMPRESSION	1
++#define LZMA_COMPRESSION	2
++#define LZO_COMPRESSION		3
+ 
+ struct squashfs_super_block {
+ 	__le32			s_magic;
diff -Nru a/target/linux/generic/patches-2.6.31/005-squashfs_extra_parameter.patch b/target/linux/generic/patches-2.6.31/005-squashfs_extra_parameter.patch
--- a/target/linux/generic/patches-2.6.31/005-squashfs_extra_parameter.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/005-squashfs_extra_parameter.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,42 @@
+From 5f393ede3ddb5dd4cc2a9f243182fac45f1ce10b Mon Sep 17 00:00:00 2001
+From: Phillip Lougher <phillip@lougher.demon.co.uk>
+Date: Wed, 14 Oct 2009 04:07:54 +0100
+Subject: [PATCH] Squashfs: add an extra parameter to the decompressor init function
+
+Signed-off-by: Phillip Lougher <phillip@lougher.demon.co.uk>
+---
+ fs/squashfs/decompressor.h |    4 ++--
+ fs/squashfs/zlib_wrapper.c |    2 +-
+ 2 files changed, 3 insertions(+), 3 deletions(-)
+
+--- a/fs/squashfs/decompressor.h
++++ b/fs/squashfs/decompressor.h
+@@ -24,7 +24,7 @@
+  */
+ 
+ struct squashfs_decompressor {
+-	void	*(*init)(void);
++	void	*(*init)(struct squashfs_sb_info *);
+ 	void	(*free)(void *);
+ 	int	(*decompress)(struct squashfs_sb_info *, void **,
+ 		struct buffer_head **, int, int, int, int, int);
+@@ -35,7 +35,7 @@ struct squashfs_decompressor {
+ 
+ static inline void *squashfs_decompressor_init(struct squashfs_sb_info *msblk)
+ {
+-	return msblk->decompressor->init();
++	return msblk->decompressor->init(msblk);
+ }
+ 
+ static inline void squashfs_decompressor_free(struct squashfs_sb_info *msblk,
+--- a/fs/squashfs/zlib_wrapper.c
++++ b/fs/squashfs/zlib_wrapper.c
+@@ -32,7 +32,7 @@
+ #include "squashfs.h"
+ #include "decompressor.h"
+ 
+-static void *zlib_init(void)
++static void *zlib_init(struct squashfs_sb_info *dummy)
+ {
+ 	z_stream *stream = kmalloc(sizeof(z_stream), GFP_KERNEL);
+ 	if (stream == NULL)
diff -Nru a/target/linux/generic/patches-2.6.31/006-squashfs_add_lzma.patch b/target/linux/generic/patches-2.6.31/006-squashfs_add_lzma.patch
--- a/target/linux/generic/patches-2.6.31/006-squashfs_add_lzma.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/006-squashfs_add_lzma.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,216 @@
+From f49e1efdd179d54e814ff2a8e8f469496583062c Mon Sep 17 00:00:00 2001
+From: Phillip Lougher <phillip@lougher.demon.co.uk>
+Date: Tue, 20 Oct 2009 10:54:36 +0100
+Subject: [PATCH] Squashfs: add LZMA compression
+
+Add support for LZMA compressed filesystems.  This is an initial
+implementation.
+
+Signed-off-by: Phillip Lougher <phillip@lougher.demon.co.uk>
+---
+ fs/squashfs/Kconfig        |    5 ++
+ fs/squashfs/Makefile       |    1 +
+ fs/squashfs/decompressor.c |    4 +
+ fs/squashfs/lzma_wrapper.c |  151 ++++++++++++++++++++++++++++++++++++++++++++
+ fs/squashfs/squashfs.h     |    3 +
+ 5 files changed, 164 insertions(+), 0 deletions(-)
+ create mode 100644 fs/squashfs/lzma_wrapper.c
+
+--- a/fs/squashfs/Kconfig
++++ b/fs/squashfs/Kconfig
+@@ -26,6 +26,11 @@ config SQUASHFS
+ 
+ 	  If unsure, say N.
+ 
++config SQUASHFS_LZMA
++	bool "Include support for LZMA compressed file systems"
++	depends on SQUASHFS
++	select DECOMPRESS_LZMA
++
+ config SQUASHFS_EMBEDDED
+ 
+ 	bool "Additional option for memory-constrained systems" 
+--- a/fs/squashfs/Makefile
++++ b/fs/squashfs/Makefile
+@@ -5,3 +5,4 @@
+ obj-$(CONFIG_SQUASHFS) += squashfs.o
+ squashfs-y += block.o cache.o dir.o export.o file.o fragment.o id.o inode.o
+ squashfs-y += namei.o super.o symlink.o zlib_wrapper.o decompressor.o
++squashfs-$(CONFIG_SQUASHFS_LZMA) += lzma_wrapper.o
+--- a/fs/squashfs/decompressor.c
++++ b/fs/squashfs/decompressor.c
+@@ -50,7 +50,11 @@ static const struct squashfs_decompresso
+ 
+ static const struct squashfs_decompressor *decompressor[] = {
+ 	&squashfs_zlib_comp_ops,
++#ifdef CONFIG_SQUASHFS_LZMA
++	&squashfs_lzma_comp_ops,
++#else
+ 	&squashfs_lzma_unsupported_comp_ops,
++#endif
+ 	&squashfs_lzo_unsupported_comp_ops,
+ 	&squashfs_unknown_comp_ops
+ };
+--- /dev/null
++++ b/fs/squashfs/lzma_wrapper.c
+@@ -0,0 +1,151 @@
++/*
++ * Squashfs - a compressed read only filesystem for Linux
++ *
++ * Copyright (c) 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009
++ * Phillip Lougher <phillip@lougher.demon.co.uk>
++ *
++ * This program is free software; you can redistribute it and/or
++ * modify it under the terms of the GNU General Public License
++ * as published by the Free Software Foundation; either version 2,
++ * or (at your option) any later version.
++ *
++ * This program is distributed in the hope that it will be useful,
++ * but WITHOUT ANY WARRANTY; without even the implied warranty of
++ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
++ * GNU General Public License for more details.
++ *
++ * You should have received a copy of the GNU General Public License
++ * along with this program; if not, write to the Free Software
++ * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
++ *
++ * lzma_wrapper.c
++ */
++
++#include <asm/unaligned.h>
++#include <linux/buffer_head.h>
++#include <linux/mutex.h>
++#include <linux/vmalloc.h>
++#include <linux/decompress/unlzma.h>
++
++#include "squashfs_fs.h"
++#include "squashfs_fs_sb.h"
++#include "squashfs_fs_i.h"
++#include "squashfs.h"
++#include "decompressor.h"
++
++struct squashfs_lzma {
++	void	*input;
++	void	*output;
++};
++
++/* decompress_unlzma.c is currently non re-entrant... */
++DEFINE_MUTEX(lzma_mutex);
++
++/* decompress_unlzma.c doesn't provide any context in its callbacks... */
++static int lzma_error;
++
++static void error(char *m)
++{
++	ERROR("unlzma error: %s\n", m);
++	lzma_error = 1;
++}
++
++	
++static void *lzma_init(struct squashfs_sb_info *msblk)
++{
++	struct squashfs_lzma *stream = kzalloc(sizeof(*stream), GFP_KERNEL);
++	if (stream == NULL)
++		goto failed;
++	stream->input = vmalloc(msblk->block_size);
++	if (stream->input == NULL)
++		goto failed;
++	stream->output = vmalloc(msblk->block_size);
++	if (stream->output == NULL)
++		goto failed2;
++
++	return stream;
++
++failed2:
++	vfree(stream->input);
++failed:
++	ERROR("failed to allocate lzma workspace\n");
++	kfree(stream);
++	return NULL;
++}
++
++
++static void lzma_free(void *strm)
++{
++	struct squashfs_lzma *stream = strm;
++
++	if (stream) {
++		vfree(stream->input);
++		vfree(stream->output);
++	}
++	kfree(stream);
++}
++
++
++static int lzma_uncompress(struct squashfs_sb_info *msblk, void **buffer,
++	struct buffer_head **bh, int b, int offset, int length, int srclength,
++	int pages)
++{
++	struct squashfs_lzma *stream = msblk->stream;
++	void *buff = stream->input;
++	int avail, i, bytes = length, res;
++
++	mutex_lock(&lzma_mutex);
++
++	for (i = 0; i < b; i++) {
++		wait_on_buffer(bh[i]);
++		if (!buffer_uptodate(bh[i]))
++			goto block_release;
++
++		avail = min(bytes, msblk->devblksize - offset);
++		memcpy(buff, bh[i]->b_data + offset, avail);
++		buff += avail;
++		bytes -= avail;
++		offset = 0;
++		put_bh(bh[i]);
++	}
++
++	lzma_error = 0;
++	res = unlzma(stream->input, length, NULL, NULL, stream->output, NULL,
++							error);
++	if (res || lzma_error)
++		goto failed;
++
++	/* uncompressed size is stored in the LZMA header (5 byte offset) */
++	res = bytes = get_unaligned_le32(stream->input + 5);
++	for (i = 0, buff = stream->output; bytes && i < pages; i++) {
++		avail = min_t(int, bytes, PAGE_CACHE_SIZE);
++		memcpy(buffer[i], buff, avail);
++		buff += avail;
++		bytes -= avail;
++	}
++	if (bytes)
++		goto failed;
++
++	mutex_unlock(&lzma_mutex);
++	return res;
++
++block_release:
++	for (; i < b; i++)
++		put_bh(bh[i]);
++
++failed:
++	mutex_unlock(&lzma_mutex);
++
++	ERROR("lzma decompression failed, data probably corrupt\n");
++	return -EIO;
++}
++
++const struct squashfs_decompressor squashfs_lzma_comp_ops = {
++	.init = lzma_init,
++	.free = lzma_free,
++	.decompress = lzma_uncompress,
++	.id = LZMA_COMPRESSION,
++	.name = "lzma",
++	.supported = 1
++};
++
+--- a/fs/squashfs/squashfs.h
++++ b/fs/squashfs/squashfs.h
+@@ -94,3 +94,6 @@ extern const struct address_space_operat
+ 
+ /* zlib_wrapper.c */
+ extern const struct squashfs_decompressor squashfs_zlib_comp_ops;
++
++/* lzma wrapper.c */
++extern const struct squashfs_decompressor squashfs_lzma_comp_ops;
diff -Nru a/target/linux/generic/patches-2.6.31/007-squashfs_make_lzma_available.patch b/target/linux/generic/patches-2.6.31/007-squashfs_make_lzma_available.patch
--- a/target/linux/generic/patches-2.6.31/007-squashfs_make_lzma_available.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/007-squashfs_make_lzma_available.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,165 @@
+From fdf23ed283bc6ef5c25076ce2065f892120ff556 Mon Sep 17 00:00:00 2001
+From: Phillip Lougher <phillip@lougher.demon.co.uk>
+Date: Thu, 22 Oct 2009 04:57:38 +0100
+Subject: [PATCH] Squashfs: Make unlzma available to non initramfs/initrd code
+
+Add a config option DECOMPRESS_LZMA_NEEDED which allows subsystems to
+specify they need the unlzma code.  Normally decompress_unlzma.c is
+compiled with __init and unlzma is not exported to modules.
+
+Signed-off-by: Phillip Lougher <phillip@lougher.demon.co.uk>
+---
+ fs/squashfs/Kconfig                   |    1 +
+ include/linux/decompress/bunzip2_mm.h |   12 ++++++++++++
+ include/linux/decompress/inflate_mm.h |   12 ++++++++++++
+ include/linux/decompress/mm.h         |    3 ---
+ include/linux/decompress/unlzma_mm.h  |   20 ++++++++++++++++++++
+ lib/Kconfig                           |    3 +++
+ lib/decompress_bunzip2.c              |    1 +
+ lib/decompress_inflate.c              |    1 +
+ lib/decompress_unlzma.c               |    5 ++++-
+ 9 files changed, 54 insertions(+), 4 deletions(-)
+ create mode 100644 include/linux/decompress/bunzip2_mm.h
+ create mode 100644 include/linux/decompress/inflate_mm.h
+ create mode 100644 include/linux/decompress/unlzma_mm.h
+
+--- a/fs/squashfs/Kconfig
++++ b/fs/squashfs/Kconfig
+@@ -30,6 +30,7 @@ config SQUASHFS_LZMA
+ 	bool "Include support for LZMA compressed file systems"
+ 	depends on SQUASHFS
+ 	select DECOMPRESS_LZMA
++	select DECOMPRESS_LZMA_NEEDED
+ 
+ config SQUASHFS_EMBEDDED
+ 
+--- /dev/null
++++ b/include/linux/decompress/bunzip2_mm.h
+@@ -0,0 +1,12 @@
++#ifndef BUNZIP2_MM_H
++#define BUNZIP2_MM_H
++
++#ifdef STATIC
++/* Code active when included from pre-boot environment: */
++#define INIT
++#else
++/* Compile for initramfs/initrd code only */
++#define INIT __init
++#endif
++
++#endif
+--- /dev/null
++++ b/include/linux/decompress/inflate_mm.h
+@@ -0,0 +1,12 @@
++#ifndef INFLATE_MM_H
++#define INFLATE_MM_H
++
++#ifdef STATIC
++/* Code active when included from pre-boot environment: */
++#define INIT
++#else
++/* Compile for initramfs/initrd code only */
++#define INIT __init
++#endif
++
++#endif
+--- a/include/linux/decompress/mm.h
++++ b/include/linux/decompress/mm.h
+@@ -53,8 +53,6 @@ static void free(void *where)
+ 
+ #define set_error_fn(x)
+ 
+-#define INIT
+-
+ #else /* STATIC */
+ 
+ /* Code active when compiled standalone for use when loading ramdisk: */
+@@ -77,7 +75,6 @@ static void free(void *where)
+ static void(*error)(char *m);
+ #define set_error_fn(x) error = x;
+ 
+-#define INIT __init
+ #define STATIC
+ 
+ #include <linux/init.h>
+--- /dev/null
++++ b/include/linux/decompress/unlzma_mm.h
+@@ -0,0 +1,20 @@
++#ifndef UNLZMA_MM_H
++#define UNLZMA_MM_H
++
++#ifdef STATIC
++
++/* Code active when included from pre-boot environment: */
++#define INIT
++
++#elif defined(CONFIG_DECOMPRESS_LZMA_NEEDED)
++
++/* Make it available to non initramfs/initrd code */
++#define INIT
++#include <linux/module.h>
++#else
++
++/* Compile for initramfs/initrd code only */
++#define INIT __init
++#endif
++
++#endif
+--- a/lib/Kconfig
++++ b/lib/Kconfig
+@@ -117,6 +117,9 @@ config DECOMPRESS_BZIP2
+ config DECOMPRESS_LZMA
+ 	tristate
+ 
++config DECOMPRESS_LZMA_NEEDED
++	 boolean
++
+ #
+ # Generic allocator support is selected if needed
+ #
+--- a/lib/decompress_bunzip2.c
++++ b/lib/decompress_bunzip2.c
+@@ -52,6 +52,7 @@
+ #include <linux/slab.h>
+ #endif /* STATIC */
+ 
++#include <linux/decompress/bunzip2_mm.h>
+ #include <linux/decompress/mm.h>
+ 
+ #ifndef INT_MAX
+--- a/lib/decompress_inflate.c
++++ b/lib/decompress_inflate.c
+@@ -23,6 +23,7 @@
+ 
+ #endif /* STATIC */
+ 
++#include <linux/decompress/inflate_mm.h>
+ #include <linux/decompress/mm.h>
+ 
+ #define GZIP_IOBUF_SIZE (16*1024)
+--- a/lib/decompress_unlzma.c
++++ b/lib/decompress_unlzma.c
+@@ -36,6 +36,7 @@
+ #include <linux/slab.h>
+ #endif /* STATIC */
+ 
++#include <linux/decompress/unlzma_mm.h>
+ #include <linux/decompress/mm.h>
+ 
+ #define	MIN(a, b) (((a) < (b)) ? (a) : (b))
+@@ -523,7 +524,7 @@ static inline void INIT process_bit1(str
+ 
+ 
+ 
+-STATIC inline int INIT unlzma(unsigned char *buf, int in_len,
++STATIC int INIT unlzma(unsigned char *buf, int in_len,
+ 			      int(*fill)(void*, unsigned int),
+ 			      int(*flush)(void*, unsigned int),
+ 			      unsigned char *output,
+@@ -656,4 +657,6 @@ STATIC int INIT decompress(unsigned char
+ {
+ 	return unlzma(buf, in_len - 4, fill, flush, output, posp, error_fn);
+ }
++#elif defined(CONFIG_DECOMPRESS_LZMA_NEEDED)
++EXPORT_SYMBOL(unlzma);
+ #endif
diff -Nru a/target/linux/generic/patches-2.6.31/011-mips_boot.patch b/target/linux/generic/patches-2.6.31/011-mips_boot.patch
--- a/target/linux/generic/patches-2.6.31/011-mips_boot.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/011-mips_boot.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,11 @@
+--- a/arch/mips/kernel/head.S
++++ b/arch/mips/kernel/head.S
+@@ -121,6 +121,8 @@
+ #endif
+ 	.endm
+ 
++	j kernel_entry
++	nop
+ #ifndef CONFIG_NO_EXCEPT_FILL
+ 	/*
+ 	 * Reserved space for exception handlers.
diff -Nru a/target/linux/generic/patches-2.6.31/012-extra_optimization.patch b/target/linux/generic/patches-2.6.31/012-extra_optimization.patch
--- a/target/linux/generic/patches-2.6.31/012-extra_optimization.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/012-extra_optimization.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,21 @@
+--- a/Makefile
++++ b/Makefile
+@@ -521,7 +521,7 @@ all: vmlinux
+ ifdef CONFIG_CC_OPTIMIZE_FOR_SIZE
+ KBUILD_CFLAGS	+= -Os
+ else
+-KBUILD_CFLAGS	+= -O2
++KBUILD_CFLAGS	+= -O2 -fno-reorder-blocks -fno-tree-ch
+ endif
+ 
+ include $(srctree)/arch/$(SRCARCH)/Makefile
+@@ -559,6 +559,9 @@ endif
+ NOSTDINC_FLAGS += -nostdinc -isystem $(shell $(CC) -print-file-name=include)
+ CHECKFLAGS     += $(NOSTDINC_FLAGS)
+ 
++# improve gcc optimization
++CFLAGS += $(call cc-option,-funit-at-a-time,)
++
+ # warn about C99 declaration after statement
+ KBUILD_CFLAGS += $(call cc-option,-Wdeclaration-after-statement,)
+ 
diff -Nru a/target/linux/generic/patches-2.6.31/013-gcc4_inline_fix.patch b/target/linux/generic/patches-2.6.31/013-gcc4_inline_fix.patch
--- a/target/linux/generic/patches-2.6.31/013-gcc4_inline_fix.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/013-gcc4_inline_fix.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,11 @@
+--- a/arch/mips/include/asm/system.h
++++ b/arch/mips/include/asm/system.h
+@@ -187,7 +187,7 @@ extern __u64 __xchg_u64_unsupported_on_3
+    if something tries to do an invalid xchg().  */
+ extern void __xchg_called_with_bad_pointer(void);
+ 
+-static inline unsigned long __xchg(unsigned long x, volatile void * ptr, int size)
++static __always_inline unsigned long __xchg(unsigned long x, volatile void * ptr, int size)
+ {
+ 	switch (size) {
+ 	case 4:
diff -Nru a/target/linux/generic/patches-2.6.31/014-cfi_fix_amd_extended_table_check.patch b/target/linux/generic/patches-2.6.31/014-cfi_fix_amd_extended_table_check.patch
--- a/target/linux/generic/patches-2.6.31/014-cfi_fix_amd_extended_table_check.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/014-cfi_fix_amd_extended_table_check.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,36 @@
+--- a/drivers/mtd/chips/cfi_cmdset_0002.c
++++ b/drivers/mtd/chips/cfi_cmdset_0002.c
+@@ -51,6 +51,7 @@
+ #define SST49LF040B	        0x0050
+ #define SST49LF008A		0x005a
+ #define AT49BV6416		0x00d6
++#define MANUFACTURER_SAMSUNG	0x00ec
+ 
+ static int cfi_amdstd_read (struct mtd_info *, loff_t, size_t, size_t *, u_char *);
+ static int cfi_amdstd_write_words(struct mtd_info *, loff_t, size_t, size_t *, const u_char *);
+@@ -375,12 +376,19 @@ struct mtd_info *cfi_cmdset_0002(struct
+ 
+ 		if (extp->MajorVersion != '1' ||
+ 		    (extp->MinorVersion < '0' || extp->MinorVersion > '4')) {
+-			printk(KERN_ERR "  Unknown Amd/Fujitsu Extended Query "
+-			       "version %c.%c.\n",  extp->MajorVersion,
+-			       extp->MinorVersion);
+-			kfree(extp);
+-			kfree(mtd);
+-			return NULL;
++		        if (cfi->mfr == MANUFACTURER_SAMSUNG &&
++			    (extp->MajorVersion == '3' && extp->MinorVersion == '3')) {
++			    printk(KERN_NOTICE "  Newer Samsung flash detected, "
++			           "should be compatibile with Amd/Fujitsu.\n");
++		        }
++		        else {
++			    printk(KERN_ERR "  Unknown Amd/Fujitsu Extended Query "
++			           "version %c.%c.\n",  extp->MajorVersion,
++			           extp->MinorVersion);
++			    kfree(extp);
++			    kfree(mtd);
++			    return NULL;
++		        }
+ 		}
+ 
+ 		/* Install our own private info structure */
diff -Nru a/target/linux/generic/patches-2.6.31/020-mips_multi_machine_support.patch b/target/linux/generic/patches-2.6.31/020-mips_multi_machine_support.patch
--- a/target/linux/generic/patches-2.6.31/020-mips_multi_machine_support.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/020-mips_multi_machine_support.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,173 @@
+--- /dev/null
++++ b/arch/mips/include/asm/mips_machine.h
+@@ -0,0 +1,47 @@
++/*
++ *  Copyright (C) 2008-2009 Gabor Juhos <juhosg@openwrt.org>
++ *
++ *  This program is free software; you can redistribute it and/or modify it
++ *  under the terms of the GNU General Public License version 2 as published
++ *  by the Free Software Foundation.
++ *
++ */
++
++#ifndef __ASM_MIPS_MACHINE_H
++#define __ASM_MIPS_MACHINE_H
++
++#include <linux/init.h>
++#include <linux/list.h>
++
++struct mips_machine {
++	unsigned long		mach_type;
++	void			(*mach_setup)(void);
++	char			*mach_name;
++	struct list_head	list;
++};
++
++void mips_machine_register(struct mips_machine *) __init;
++void mips_machine_setup(unsigned long machtype) __init;
++void mips_machine_set_name(char *name) __init;
++
++extern char *mips_machine_name;
++
++#define MIPS_MACHINE(_type, _name, _setup) 			\
++static char machine_name_##_type[] __initdata = _name;		\
++static struct mips_machine machine_##_type __initdata =		\
++{								\
++	.mach_type	= _type,				\
++	.mach_name	= machine_name_##_type,			\
++	.mach_setup	= _setup,				\
++};								\
++								\
++static int __init register_machine_##_type(void)		\
++{								\
++	mips_machine_register(&machine_##_type);		\
++	return 0;						\
++}								\
++								\
++pure_initcall(register_machine_##_type)
++
++#endif /* __ASM_MIPS_MACHINE_H */
++
+--- /dev/null
++++ b/arch/mips/kernel/mips_machine.c
+@@ -0,0 +1,74 @@
++/*
++ *  Copyright (C) 2008-2009 Gabor Juhos <juhosg@openwrt.org>
++ *
++ *  This program is free software; you can redistribute it and/or modify it
++ *  under the terms of the GNU General Public License version 2 as published
++ *  by the Free Software Foundation.
++ *
++ */
++#include <linux/mm.h>
++
++#include <asm/mips_machine.h>
++#include <asm/bootinfo.h>
++
++static struct list_head mips_machines __initdata =
++		LIST_HEAD_INIT(mips_machines);
++
++char *mips_machine_name = "Unknown";
++
++static struct mips_machine * __init mips_machine_find(unsigned long machtype)
++{
++	struct list_head *this;
++
++	list_for_each(this, &mips_machines) {
++		struct mips_machine *mach;
++
++		mach = list_entry(this, struct mips_machine, list);
++		if (mach->mach_type == machtype)
++			return mach;
++	}
++
++	return NULL;
++}
++
++void __init mips_machine_register(struct mips_machine *mach)
++{
++	list_add_tail(&mach->list, &mips_machines);
++}
++
++void __init mips_machine_set_name(char *name)
++{
++	unsigned int len;
++	char *p;
++
++	if (name == NULL)
++		return;
++
++	len = strlen(name);
++	p = kmalloc(len + 1, GFP_KERNEL);
++	if (p) {
++		strncpy(p, name, len);
++		p[len] = '\0';
++		mips_machine_name = p;
++	} else {
++		printk(KERN_WARNING "MIPS: no memory for machine_name\n");
++	}
++}
++
++void __init mips_machine_setup(unsigned long machtype)
++{
++	struct mips_machine *mach;
++
++	mach = mips_machine_find(machtype);
++	if (!mach) {
++		printk(KERN_ALERT "MIPS: no machine registered for "
++			"machtype %lu\n", machtype);
++		return;
++	}
++
++	mips_machine_set_name(mach->mach_name);
++	printk(KERN_INFO "MIPS: machine is %s\n", mips_machine_name);
++
++	if (mach->mach_setup)
++		mach->mach_setup();
++}
+--- a/arch/mips/kernel/Makefile
++++ b/arch/mips/kernel/Makefile
+@@ -87,6 +87,7 @@ obj-$(CONFIG_GPIO_TXX9)		+= gpio_txx9.o
+ 
+ obj-$(CONFIG_KEXEC)		+= machine_kexec.o relocate_kernel.o
+ obj-$(CONFIG_EARLY_PRINTK)	+= early_printk.o
++obj-$(CONFIG_MIPS_MACHINE)	+= mips_machine.o
+ 
+ CFLAGS_cpu-bugs64.o	= $(shell if $(CC) $(KBUILD_CFLAGS) -Wa,-mdaddi -c -o /dev/null -xc /dev/null >/dev/null 2>&1; then echo "-DHAVE_AS_SET_DADDI"; fi)
+ 
+--- a/arch/mips/Kconfig
++++ b/arch/mips/Kconfig
+@@ -837,6 +837,9 @@ config MIPS_DISABLE_OBSOLETE_IDE
+ config SYNC_R4K
+ 	bool
+ 
++config MIPS_MACHINE
++	def_bool n
++
+ config NO_IOPORT
+ 	def_bool n
+ 
+--- a/arch/mips/kernel/proc.c
++++ b/arch/mips/kernel/proc.c
+@@ -12,6 +12,7 @@
+ #include <asm/cpu-features.h>
+ #include <asm/mipsregs.h>
+ #include <asm/processor.h>
++#include <asm/mips_machine.h>
+ 
+ unsigned int vced_count, vcei_count;
+ 
+@@ -31,8 +32,12 @@ static int show_cpuinfo(struct seq_file
+ 	/*
+ 	 * For the first processor also print the system type
+ 	 */
+-	if (n == 0)
++	if (n == 0) {
+ 		seq_printf(m, "system type\t\t: %s\n", get_system_type());
++#ifdef CONFIG_MIPS_MACHINE
++		seq_printf(m, "machine\t\t\t: %s\n", mips_machine_name);
++#endif
++	}
+ 
+ 	seq_printf(m, "processor\t\t: %ld\n", n);
+ 	sprintf(fmt, "cpu model\t\t: %%s V%%d.%%d%s\n",
diff -Nru a/target/linux/generic/patches-2.6.31/021-mips_image_cmdline_hack.patch b/target/linux/generic/patches-2.6.31/021-mips_image_cmdline_hack.patch
--- a/target/linux/generic/patches-2.6.31/021-mips_image_cmdline_hack.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/021-mips_image_cmdline_hack.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,28 @@
+--- a/arch/mips/Kconfig
++++ b/arch/mips/Kconfig
+@@ -840,6 +840,10 @@ config SYNC_R4K
+ config MIPS_MACHINE
+ 	def_bool n
+ 
++config IMAGE_CMDLINE_HACK
++	bool "OpenWrt specific image command line hack"
++	default n
++
+ config NO_IOPORT
+ 	def_bool n
+ 
+--- a/arch/mips/kernel/head.S
++++ b/arch/mips/kernel/head.S
+@@ -143,6 +143,12 @@ FEXPORT(__kernel_entry)
+ 	j	kernel_entry
+ #endif
+ 
++#ifdef CONFIG_IMAGE_CMDLINE_HACK
++	.ascii	"CMDLINE:"
++EXPORT(__image_cmdline)
++	.fill	0x400
++#endif /* CONFIG_IMAGE_CMDLINE_HACK */
++
+ 	__REF
+ 
+ NESTED(kernel_entry, 16, sp)			# kernel entry point
diff -Nru a/target/linux/generic/patches-2.6.31/022-mips_use_generic_thread_info_allocator.patch b/target/linux/generic/patches-2.6.31/022-mips_use_generic_thread_info_allocator.patch
--- a/target/linux/generic/patches-2.6.31/022-mips_use_generic_thread_info_allocator.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/022-mips_use_generic_thread_info_allocator.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,18 @@
+--- a/arch/mips/include/asm/thread_info.h
++++ b/arch/mips/include/asm/thread_info.h
+@@ -83,6 +83,7 @@ register struct thread_info *__current_t
+ #define THREAD_SIZE (PAGE_SIZE << THREAD_SIZE_ORDER)
+ #define THREAD_MASK (THREAD_SIZE - 1UL)
+ 
++#if 0
+ #define __HAVE_ARCH_THREAD_INFO_ALLOCATOR
+ 
+ #ifdef CONFIG_DEBUG_STACK_USAGE
+@@ -99,6 +100,7 @@ register struct thread_info *__current_t
+ #endif
+ 
+ #define free_thread_info(info) kfree(info)
++#endif
+ 
+ #endif /* !__ASSEMBLY__ */
+ 
diff -Nru a/target/linux/generic/patches-2.6.31/023-mips-fix-kexec.patch b/target/linux/generic/patches-2.6.31/023-mips-fix-kexec.patch
--- a/target/linux/generic/patches-2.6.31/023-mips-fix-kexec.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/023-mips-fix-kexec.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,11 @@
+--- a/arch/mips/kernel/machine_kexec.c
++++ b/arch/mips/kernel/machine_kexec.c
+@@ -52,7 +52,7 @@ machine_kexec(struct kimage *image)
+ 	reboot_code_buffer =
+ 	  (unsigned long)page_address(image->control_code_page);
+ 
+-	kexec_start_address = image->start;
++	kexec_start_address = (unsigned long) phys_to_virt(image->start);
+ 	kexec_indirection_page =
+ 		(unsigned long) phys_to_virt(image->head & PAGE_MASK);
+ 
diff -Nru a/target/linux/generic/patches-2.6.31/025-bcma_backport.patch b/target/linux/generic/patches-2.6.31/025-bcma_backport.patch
--- a/target/linux/generic/patches-2.6.31/025-bcma_backport.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/025-bcma_backport.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,4978 @@
+--- /dev/null
++++ b/Documentation/ABI/testing/sysfs-bus-bcma
+@@ -0,0 +1,31 @@
++What:		/sys/bus/bcma/devices/.../manuf
++Date:		May 2011
++KernelVersion:	2.6.40
++Contact:	Rafa≈Ç Mi≈Çecki <zajec5@gmail.com>
++Description:
++		Each BCMA core has it's manufacturer id. See
++		include/linux/bcma/bcma.h for possible values.
++
++What:		/sys/bus/bcma/devices/.../id
++Date:		May 2011
++KernelVersion:	2.6.40
++Contact:	Rafa≈Ç Mi≈Çecki <zajec5@gmail.com>
++Description:
++		There are a few types of BCMA cores, they can be identified by
++		id field.
++
++What:		/sys/bus/bcma/devices/.../rev
++Date:		May 2011
++KernelVersion:	2.6.40
++Contact:	Rafa≈Ç Mi≈Çecki <zajec5@gmail.com>
++Description:
++		BCMA cores of the same type can still slightly differ depending
++		on their revision. Use it for detailed programming.
++
++What:		/sys/bus/bcma/devices/.../class
++Date:		May 2011
++KernelVersion:	2.6.40
++Contact:	Rafa≈Ç Mi≈Çecki <zajec5@gmail.com>
++Description:
++		Each BCMA core is identified by few fields, including class it
++		belongs to. See include/linux/bcma/bcma.h for possible values.
+--- a/MAINTAINERS
++++ b/MAINTAINERS
+@@ -4716,6 +4716,13 @@ S:	Maintained
+ F:	drivers/ssb/
+ F:	include/linux/ssb/
+ 
++BROADCOM SPECIFIC AMBA DRIVER (BCMA)
++M:	Rafa≈Ç Mi≈Çecki <zajec5@gmail.com>
++L:	linux-wireless@vger.kernel.org
++S:	Maintained
++F:	drivers/bcma/
++F:	include/linux/bcma/
++
+ SONY VAIO CONTROL DEVICE DRIVER
+ M:	Mattia Dongili <malattia@linux.it>
+ L:	linux-acpi@vger.kernel.org
+--- a/drivers/Kconfig
++++ b/drivers/Kconfig
+@@ -68,6 +68,8 @@ source "drivers/watchdog/Kconfig"
+ 
+ source "drivers/ssb/Kconfig"
+ 
++source "drivers/bcma/Kconfig"
++
+ source "drivers/mfd/Kconfig"
+ 
+ source "drivers/regulator/Kconfig"
+--- a/drivers/Makefile
++++ b/drivers/Makefile
+@@ -105,6 +105,7 @@ obj-$(CONFIG_HID)		+= hid/
+ obj-$(CONFIG_PPC_PS3)		+= ps3/
+ obj-$(CONFIG_OF)		+= of/
+ obj-$(CONFIG_SSB)		+= ssb/
++obj-$(CONFIG_BCMA)		+= bcma/
+ obj-$(CONFIG_VIRTIO)		+= virtio/
+ obj-$(CONFIG_VLYNQ)		+= vlynq/
+ obj-$(CONFIG_STAGING)		+= staging/
+--- /dev/null
++++ b/drivers/bcma/Kconfig
+@@ -0,0 +1,57 @@
++config BCMA_POSSIBLE
++	bool
++	depends on HAS_IOMEM && HAS_DMA
++	default y
++
++menu "Broadcom specific AMBA"
++	depends on BCMA_POSSIBLE
++
++config BCMA
++	tristate "BCMA support"
++	depends on BCMA_POSSIBLE
++	help
++	  Bus driver for Broadcom specific Advanced Microcontroller Bus
++	  Architecture.
++
++# Support for Block-I/O. SELECT this from the driver that needs it.
++config BCMA_BLOCKIO
++	bool
++	depends on BCMA
++
++config BCMA_HOST_PCI_POSSIBLE
++	bool
++	depends on BCMA && PCI = y
++	default y
++
++config BCMA_HOST_PCI
++	bool "Support for BCMA on PCI-host bus"
++	depends on BCMA_HOST_PCI_POSSIBLE
++
++config BCMA_DRIVER_PCI_HOSTMODE
++	bool "Driver for PCI core working in hostmode"
++	depends on BCMA && MIPS && BCMA_HOST_PCI
++	help
++	  PCI core hostmode operation (external PCI bus).
++
++config BCMA_HOST_SOC
++	bool
++	depends on BCMA_DRIVER_MIPS
++
++config BCMA_DRIVER_MIPS
++	bool "BCMA Broadcom MIPS core driver"
++	depends on BCMA && MIPS
++	help
++	  Driver for the Broadcom MIPS core attached to Broadcom specific
++	  Advanced Microcontroller Bus.
++
++	  If unsure, say N
++
++config BCMA_DEBUG
++	bool "BCMA debugging"
++	depends on BCMA
++	help
++	  This turns on additional debugging messages.
++
++	  If unsure, say N
++
++endmenu
+--- /dev/null
++++ b/drivers/bcma/Makefile
+@@ -0,0 +1,10 @@
++bcma-y					+= main.o scan.o core.o sprom.o
++bcma-y					+= driver_chipcommon.o driver_chipcommon_pmu.o
++bcma-y					+= driver_pci.o
++bcma-$(CONFIG_BCMA_DRIVER_PCI_HOSTMODE)	+= driver_pci_host.o
++bcma-$(CONFIG_BCMA_DRIVER_MIPS)		+= driver_mips.o
++bcma-$(CONFIG_BCMA_HOST_PCI)		+= host_pci.o
++bcma-$(CONFIG_BCMA_HOST_SOC)		+= host_soc.o
++obj-$(CONFIG_BCMA)			+= bcma.o
++
++ccflags-$(CONFIG_BCMA_DEBUG)		:= -DDEBUG
+--- /dev/null
++++ b/drivers/bcma/README
+@@ -0,0 +1,19 @@
++Broadcom introduced new bus as replacement for older SSB. It is based on AMBA,
++however from programming point of view there is nothing AMBA specific we use.
++
++Standard AMBA drivers are platform specific, have hardcoded addresses and use
++AMBA standard fields like CID and PID.
++
++In case of Broadcom's cards every device consists of:
++1) Broadcom specific AMBA device. It is put on AMBA bus, but can not be treated
++   as standard AMBA device. Reading it's CID or PID can cause machine lockup.
++2) AMBA standard devices called ports or wrappers. They have CIDs (AMBA_CID)
++   and PIDs (0x103BB369), but we do not use that info for anything. One of that
++   devices is used for managing Broadcom specific core.
++
++Addresses of AMBA devices are not hardcoded in driver and have to be read from
++EPROM.
++
++In this situation we decided to introduce separated bus. It can contain up to
++16 devices identified by Broadcom specific fields: manufacturer, id, revision
++and class.
+--- /dev/null
++++ b/drivers/bcma/TODO
+@@ -0,0 +1,3 @@
++- Interrupts
++- Defines for PCI core driver
++- Create kernel Documentation (use info from README)
+--- /dev/null
++++ b/drivers/bcma/bcma_private.h
+@@ -0,0 +1,59 @@
++#ifndef LINUX_BCMA_PRIVATE_H_
++#define LINUX_BCMA_PRIVATE_H_
++
++#ifndef pr_fmt
++#define pr_fmt(fmt)		KBUILD_MODNAME ": " fmt
++#endif
++
++#include <linux/bcma/bcma.h>
++#include <linux/delay.h>
++
++#define BCMA_CORE_SIZE		0x1000
++
++struct bcma_bus;
++
++/* main.c */
++int __devinit bcma_bus_register(struct bcma_bus *bus);
++void bcma_bus_unregister(struct bcma_bus *bus);
++int __init bcma_bus_early_register(struct bcma_bus *bus,
++				   struct bcma_device *core_cc,
++				   struct bcma_device *core_mips);
++#ifdef CONFIG_PM
++int bcma_bus_suspend(struct bcma_bus *bus);
++int bcma_bus_resume(struct bcma_bus *bus);
++#endif
++
++/* scan.c */
++int bcma_bus_scan(struct bcma_bus *bus);
++int __init bcma_bus_scan_early(struct bcma_bus *bus,
++			       struct bcma_device_id *match,
++			       struct bcma_device *core);
++void bcma_init_bus(struct bcma_bus *bus);
++
++/* sprom.c */
++int bcma_sprom_get(struct bcma_bus *bus);
++
++/* driver_chipcommon.c */
++#ifdef CONFIG_BCMA_DRIVER_MIPS
++void bcma_chipco_serial_init(struct bcma_drv_cc *cc);
++#endif /* CONFIG_BCMA_DRIVER_MIPS */
++
++/* driver_chipcommon_pmu.c */
++u32 bcma_pmu_alp_clock(struct bcma_drv_cc *cc);
++u32 bcma_pmu_get_clockcpu(struct bcma_drv_cc *cc);
++
++#ifdef CONFIG_BCMA_HOST_PCI
++/* host_pci.c */
++extern int __init bcma_host_pci_init(void);
++extern void __exit bcma_host_pci_exit(void);
++#endif /* CONFIG_BCMA_HOST_PCI */
++
++/* driver_pci.c */
++u32 bcma_pcie_read(struct bcma_drv_pci *pc, u32 address);
++
++#ifdef CONFIG_BCMA_DRIVER_PCI_HOSTMODE
++bool __devinit bcma_core_pci_is_in_hostmode(struct bcma_drv_pci *pc);
++void __devinit bcma_core_pci_hostmode_init(struct bcma_drv_pci *pc);
++#endif /* CONFIG_BCMA_DRIVER_PCI_HOSTMODE */
++
++#endif
+--- /dev/null
++++ b/drivers/bcma/core.c
+@@ -0,0 +1,126 @@
++/*
++ * Broadcom specific AMBA
++ * Core ops
++ *
++ * Licensed under the GNU/GPL. See COPYING for details.
++ */
++
++#include "bcma_private.h"
++#include <linux/bcma/bcma.h>
++
++bool bcma_core_is_enabled(struct bcma_device *core)
++{
++	if ((bcma_aread32(core, BCMA_IOCTL) & (BCMA_IOCTL_CLK | BCMA_IOCTL_FGC))
++	    != BCMA_IOCTL_CLK)
++		return false;
++	if (bcma_aread32(core, BCMA_RESET_CTL) & BCMA_RESET_CTL_RESET)
++		return false;
++	return true;
++}
++EXPORT_SYMBOL_GPL(bcma_core_is_enabled);
++
++void bcma_core_disable(struct bcma_device *core, u32 flags)
++{
++	if (bcma_aread32(core, BCMA_RESET_CTL) & BCMA_RESET_CTL_RESET)
++		return;
++
++	bcma_awrite32(core, BCMA_IOCTL, flags);
++	bcma_aread32(core, BCMA_IOCTL);
++	udelay(10);
++
++	bcma_awrite32(core, BCMA_RESET_CTL, BCMA_RESET_CTL_RESET);
++	udelay(1);
++}
++EXPORT_SYMBOL_GPL(bcma_core_disable);
++
++int bcma_core_enable(struct bcma_device *core, u32 flags)
++{
++	bcma_core_disable(core, flags);
++
++	bcma_awrite32(core, BCMA_IOCTL, (BCMA_IOCTL_CLK | BCMA_IOCTL_FGC | flags));
++	bcma_aread32(core, BCMA_IOCTL);
++
++	bcma_awrite32(core, BCMA_RESET_CTL, 0);
++	udelay(1);
++
++	bcma_awrite32(core, BCMA_IOCTL, (BCMA_IOCTL_CLK | flags));
++	bcma_aread32(core, BCMA_IOCTL);
++	udelay(1);
++
++	return 0;
++}
++EXPORT_SYMBOL_GPL(bcma_core_enable);
++
++void bcma_core_set_clockmode(struct bcma_device *core,
++			     enum bcma_clkmode clkmode)
++{
++	u16 i;
++
++	WARN_ON(core->id.id != BCMA_CORE_CHIPCOMMON &&
++		core->id.id != BCMA_CORE_PCIE &&
++		core->id.id != BCMA_CORE_80211);
++
++	switch (clkmode) {
++	case BCMA_CLKMODE_FAST:
++		bcma_set32(core, BCMA_CLKCTLST, BCMA_CLKCTLST_FORCEHT);
++		udelay(64);
++		for (i = 0; i < 1500; i++) {
++			if (bcma_read32(core, BCMA_CLKCTLST) &
++			    BCMA_CLKCTLST_HAVEHT) {
++				i = 0;
++				break;
++			}
++			udelay(10);
++		}
++		if (i)
++			pr_err("HT force timeout\n");
++		break;
++	case BCMA_CLKMODE_DYNAMIC:
++		pr_warning("Dynamic clockmode not supported yet!\n");
++		break;
++	}
++}
++EXPORT_SYMBOL_GPL(bcma_core_set_clockmode);
++
++void bcma_core_pll_ctl(struct bcma_device *core, u32 req, u32 status, bool on)
++{
++	u16 i;
++
++	WARN_ON(req & ~BCMA_CLKCTLST_EXTRESREQ);
++	WARN_ON(status & ~BCMA_CLKCTLST_EXTRESST);
++
++	if (on) {
++		bcma_set32(core, BCMA_CLKCTLST, req);
++		for (i = 0; i < 10000; i++) {
++			if ((bcma_read32(core, BCMA_CLKCTLST) & status) ==
++			    status) {
++				i = 0;
++				break;
++			}
++			udelay(10);
++		}
++		if (i)
++			pr_err("PLL enable timeout\n");
++	} else {
++		pr_warning("Disabling PLL not supported yet!\n");
++	}
++}
++EXPORT_SYMBOL_GPL(bcma_core_pll_ctl);
++
++u32 bcma_core_dma_translation(struct bcma_device *core)
++{
++	switch (core->bus->hosttype) {
++	case BCMA_HOSTTYPE_SOC:
++		return 0;
++	case BCMA_HOSTTYPE_PCI:
++		if (bcma_aread32(core, BCMA_IOST) & BCMA_IOST_DMA64)
++			return BCMA_DMA_TRANSLATION_DMA64_CMT;
++		else
++			return BCMA_DMA_TRANSLATION_DMA32_CMT;
++	default:
++		pr_err("DMA translation unknown for host %d\n",
++		       core->bus->hosttype);
++	}
++	return BCMA_DMA_TRANSLATION_NONE;
++}
++EXPORT_SYMBOL(bcma_core_dma_translation);
+--- /dev/null
++++ b/drivers/bcma/driver_chipcommon.c
+@@ -0,0 +1,156 @@
++/*
++ * Broadcom specific AMBA
++ * ChipCommon core driver
++ *
++ * Copyright 2005, Broadcom Corporation
++ * Copyright 2006, 2007, Michael Buesch <m@bues.ch>
++ *
++ * Licensed under the GNU/GPL. See COPYING for details.
++ */
++
++#include "bcma_private.h"
++#include <linux/bcma/bcma.h>
++
++static inline u32 bcma_cc_write32_masked(struct bcma_drv_cc *cc, u16 offset,
++					 u32 mask, u32 value)
++{
++	value &= mask;
++	value |= bcma_cc_read32(cc, offset) & ~mask;
++	bcma_cc_write32(cc, offset, value);
++
++	return value;
++}
++
++void bcma_core_chipcommon_init(struct bcma_drv_cc *cc)
++{
++	u32 leddc_on = 10;
++	u32 leddc_off = 90;
++
++	if (cc->setup_done)
++		return;
++
++	if (cc->core->id.rev >= 11)
++		cc->status = bcma_cc_read32(cc, BCMA_CC_CHIPSTAT);
++	cc->capabilities = bcma_cc_read32(cc, BCMA_CC_CAP);
++	if (cc->core->id.rev >= 35)
++		cc->capabilities_ext = bcma_cc_read32(cc, BCMA_CC_CAP_EXT);
++
++	if (cc->core->id.rev >= 20) {
++		bcma_cc_write32(cc, BCMA_CC_GPIOPULLUP, 0);
++		bcma_cc_write32(cc, BCMA_CC_GPIOPULLDOWN, 0);
++	}
++
++	if (cc->capabilities & BCMA_CC_CAP_PMU)
++		bcma_pmu_init(cc);
++	if (cc->capabilities & BCMA_CC_CAP_PCTL)
++		pr_err("Power control not implemented!\n");
++
++	if (cc->core->id.rev >= 16) {
++		if (cc->core->bus->sprom.leddc_on_time &&
++		    cc->core->bus->sprom.leddc_off_time) {
++			leddc_on = cc->core->bus->sprom.leddc_on_time;
++			leddc_off = cc->core->bus->sprom.leddc_off_time;
++		}
++		bcma_cc_write32(cc, BCMA_CC_GPIOTIMER,
++			((leddc_on << BCMA_CC_GPIOTIMER_ONTIME_SHIFT) |
++			 (leddc_off << BCMA_CC_GPIOTIMER_OFFTIME_SHIFT)));
++	}
++
++	cc->setup_done = true;
++}
++
++/* Set chip watchdog reset timer to fire in 'ticks' backplane cycles */
++void bcma_chipco_watchdog_timer_set(struct bcma_drv_cc *cc, u32 ticks)
++{
++	/* instant NMI */
++	bcma_cc_write32(cc, BCMA_CC_WATCHDOG, ticks);
++}
++
++void bcma_chipco_irq_mask(struct bcma_drv_cc *cc, u32 mask, u32 value)
++{
++	bcma_cc_write32_masked(cc, BCMA_CC_IRQMASK, mask, value);
++}
++
++u32 bcma_chipco_irq_status(struct bcma_drv_cc *cc, u32 mask)
++{
++	return bcma_cc_read32(cc, BCMA_CC_IRQSTAT) & mask;
++}
++
++u32 bcma_chipco_gpio_in(struct bcma_drv_cc *cc, u32 mask)
++{
++	return bcma_cc_read32(cc, BCMA_CC_GPIOIN) & mask;
++}
++
++u32 bcma_chipco_gpio_out(struct bcma_drv_cc *cc, u32 mask, u32 value)
++{
++	return bcma_cc_write32_masked(cc, BCMA_CC_GPIOOUT, mask, value);
++}
++
++u32 bcma_chipco_gpio_outen(struct bcma_drv_cc *cc, u32 mask, u32 value)
++{
++	return bcma_cc_write32_masked(cc, BCMA_CC_GPIOOUTEN, mask, value);
++}
++
++u32 bcma_chipco_gpio_control(struct bcma_drv_cc *cc, u32 mask, u32 value)
++{
++	return bcma_cc_write32_masked(cc, BCMA_CC_GPIOCTL, mask, value);
++}
++EXPORT_SYMBOL_GPL(bcma_chipco_gpio_control);
++
++u32 bcma_chipco_gpio_intmask(struct bcma_drv_cc *cc, u32 mask, u32 value)
++{
++	return bcma_cc_write32_masked(cc, BCMA_CC_GPIOIRQ, mask, value);
++}
++
++u32 bcma_chipco_gpio_polarity(struct bcma_drv_cc *cc, u32 mask, u32 value)
++{
++	return bcma_cc_write32_masked(cc, BCMA_CC_GPIOPOL, mask, value);
++}
++
++#ifdef CONFIG_BCMA_DRIVER_MIPS
++void bcma_chipco_serial_init(struct bcma_drv_cc *cc)
++{
++	unsigned int irq;
++	u32 baud_base;
++	u32 i;
++	unsigned int ccrev = cc->core->id.rev;
++	struct bcma_serial_port *ports = cc->serial_ports;
++
++	if (ccrev >= 11 && ccrev != 15) {
++		/* Fixed ALP clock */
++		baud_base = bcma_pmu_alp_clock(cc);
++		if (ccrev >= 21) {
++			/* Turn off UART clock before switching clocksource. */
++			bcma_cc_write32(cc, BCMA_CC_CORECTL,
++				       bcma_cc_read32(cc, BCMA_CC_CORECTL)
++				       & ~BCMA_CC_CORECTL_UARTCLKEN);
++		}
++		/* Set the override bit so we don't divide it */
++		bcma_cc_write32(cc, BCMA_CC_CORECTL,
++			       bcma_cc_read32(cc, BCMA_CC_CORECTL)
++			       | BCMA_CC_CORECTL_UARTCLK0);
++		if (ccrev >= 21) {
++			/* Re-enable the UART clock. */
++			bcma_cc_write32(cc, BCMA_CC_CORECTL,
++				       bcma_cc_read32(cc, BCMA_CC_CORECTL)
++				       | BCMA_CC_CORECTL_UARTCLKEN);
++		}
++	} else {
++		pr_err("serial not supported on this device ccrev: 0x%x\n",
++		       ccrev);
++		return;
++	}
++
++	irq = bcma_core_mips_irq(cc->core);
++
++	/* Determine the registers of the UARTs */
++	cc->nr_serial_ports = (cc->capabilities & BCMA_CC_CAP_NRUART);
++	for (i = 0; i < cc->nr_serial_ports; i++) {
++		ports[i].regs = cc->core->io_addr + BCMA_CC_UART0_DATA +
++				(i * 256);
++		ports[i].irq = irq;
++		ports[i].baud_base = baud_base;
++		ports[i].reg_shift = 0;
++	}
++}
++#endif /* CONFIG_BCMA_DRIVER_MIPS */
+--- /dev/null
++++ b/drivers/bcma/driver_chipcommon_pmu.c
+@@ -0,0 +1,310 @@
++/*
++ * Broadcom specific AMBA
++ * ChipCommon Power Management Unit driver
++ *
++ * Copyright 2009, Michael Buesch <m@bues.ch>
++ * Copyright 2007, Broadcom Corporation
++ *
++ * Licensed under the GNU/GPL. See COPYING for details.
++ */
++
++#include "bcma_private.h"
++#include <linux/bcma/bcma.h>
++
++static u32 bcma_chipco_pll_read(struct bcma_drv_cc *cc, u32 offset)
++{
++	bcma_cc_write32(cc, BCMA_CC_PLLCTL_ADDR, offset);
++	bcma_cc_read32(cc, BCMA_CC_PLLCTL_ADDR);
++	return bcma_cc_read32(cc, BCMA_CC_PLLCTL_DATA);
++}
++
++void bcma_chipco_pll_write(struct bcma_drv_cc *cc, u32 offset, u32 value)
++{
++	bcma_cc_write32(cc, BCMA_CC_PLLCTL_ADDR, offset);
++	bcma_cc_read32(cc, BCMA_CC_PLLCTL_ADDR);
++	bcma_cc_write32(cc, BCMA_CC_PLLCTL_DATA, value);
++}
++EXPORT_SYMBOL_GPL(bcma_chipco_pll_write);
++
++void bcma_chipco_pll_maskset(struct bcma_drv_cc *cc, u32 offset, u32 mask,
++			     u32 set)
++{
++	bcma_cc_write32(cc, BCMA_CC_PLLCTL_ADDR, offset);
++	bcma_cc_read32(cc, BCMA_CC_PLLCTL_ADDR);
++	bcma_cc_maskset32(cc, BCMA_CC_PLLCTL_DATA, mask, set);
++}
++EXPORT_SYMBOL_GPL(bcma_chipco_pll_maskset);
++
++void bcma_chipco_chipctl_maskset(struct bcma_drv_cc *cc,
++				 u32 offset, u32 mask, u32 set)
++{
++	bcma_cc_write32(cc, BCMA_CC_CHIPCTL_ADDR, offset);
++	bcma_cc_read32(cc, BCMA_CC_CHIPCTL_ADDR);
++	bcma_cc_maskset32(cc, BCMA_CC_CHIPCTL_DATA, mask, set);
++}
++EXPORT_SYMBOL_GPL(bcma_chipco_chipctl_maskset);
++
++void bcma_chipco_regctl_maskset(struct bcma_drv_cc *cc, u32 offset, u32 mask,
++				u32 set)
++{
++	bcma_cc_write32(cc, BCMA_CC_REGCTL_ADDR, offset);
++	bcma_cc_read32(cc, BCMA_CC_REGCTL_ADDR);
++	bcma_cc_maskset32(cc, BCMA_CC_REGCTL_DATA, mask, set);
++}
++EXPORT_SYMBOL_GPL(bcma_chipco_regctl_maskset);
++
++static void bcma_pmu_pll_init(struct bcma_drv_cc *cc)
++{
++	struct bcma_bus *bus = cc->core->bus;
++
++	switch (bus->chipinfo.id) {
++	case 0x4313:
++	case 0x4331:
++	case 43224:
++	case 43225:
++		break;
++	default:
++		pr_err("PLL init unknown for device 0x%04X\n",
++			bus->chipinfo.id);
++	}
++}
++
++static void bcma_pmu_resources_init(struct bcma_drv_cc *cc)
++{
++	struct bcma_bus *bus = cc->core->bus;
++	u32 min_msk = 0, max_msk = 0;
++
++	switch (bus->chipinfo.id) {
++	case 0x4313:
++		min_msk = 0x200D;
++		max_msk = 0xFFFF;
++		break;
++	case 0x4331:
++	case 43224:
++	case 43225:
++		break;
++	default:
++		pr_err("PMU resource config unknown for device 0x%04X\n",
++			bus->chipinfo.id);
++	}
++
++	/* Set the resource masks. */
++	if (min_msk)
++		bcma_cc_write32(cc, BCMA_CC_PMU_MINRES_MSK, min_msk);
++	if (max_msk)
++		bcma_cc_write32(cc, BCMA_CC_PMU_MAXRES_MSK, max_msk);
++}
++
++void bcma_pmu_swreg_init(struct bcma_drv_cc *cc)
++{
++	struct bcma_bus *bus = cc->core->bus;
++
++	switch (bus->chipinfo.id) {
++	case 0x4313:
++	case 0x4331:
++	case 43224:
++	case 43225:
++		break;
++	default:
++		pr_err("PMU switch/regulators init unknown for device "
++			"0x%04X\n", bus->chipinfo.id);
++	}
++}
++
++/* Disable to allow reading SPROM. Don't know the adventages of enabling it. */
++void bcma_chipco_bcm4331_ext_pa_lines_ctl(struct bcma_drv_cc *cc, bool enable)
++{
++	struct bcma_bus *bus = cc->core->bus;
++	u32 val;
++
++	val = bcma_cc_read32(cc, BCMA_CC_CHIPCTL);
++	if (enable) {
++		val |= BCMA_CHIPCTL_4331_EXTPA_EN;
++		if (bus->chipinfo.pkg == 9 || bus->chipinfo.pkg == 11)
++			val |= BCMA_CHIPCTL_4331_EXTPA_ON_GPIO2_5;
++	} else {
++		val &= ~BCMA_CHIPCTL_4331_EXTPA_EN;
++		val &= ~BCMA_CHIPCTL_4331_EXTPA_ON_GPIO2_5;
++	}
++	bcma_cc_write32(cc, BCMA_CC_CHIPCTL, val);
++}
++
++void bcma_pmu_workarounds(struct bcma_drv_cc *cc)
++{
++	struct bcma_bus *bus = cc->core->bus;
++
++	switch (bus->chipinfo.id) {
++	case 0x4313:
++		bcma_chipco_chipctl_maskset(cc, 0, ~0, 0x7);
++		break;
++	case 0x4331:
++		/* BCM4331 workaround is SPROM-related, we put it in sprom.c */
++		break;
++	case 43224:
++		if (bus->chipinfo.rev == 0) {
++			pr_err("Workarounds for 43224 rev 0 not fully "
++				"implemented\n");
++			bcma_chipco_chipctl_maskset(cc, 0, ~0, 0x00F000F0);
++		} else {
++			bcma_chipco_chipctl_maskset(cc, 0, ~0, 0xF0);
++		}
++		break;
++	case 43225:
++		break;
++	default:
++		pr_err("Workarounds unknown for device 0x%04X\n",
++			bus->chipinfo.id);
++	}
++}
++
++void bcma_pmu_init(struct bcma_drv_cc *cc)
++{
++	u32 pmucap;
++
++	pmucap = bcma_cc_read32(cc, BCMA_CC_PMU_CAP);
++	cc->pmu.rev = (pmucap & BCMA_CC_PMU_CAP_REVISION);
++
++	pr_debug("Found rev %u PMU (capabilities 0x%08X)\n", cc->pmu.rev,
++		 pmucap);
++
++	if (cc->pmu.rev == 1)
++		bcma_cc_mask32(cc, BCMA_CC_PMU_CTL,
++			      ~BCMA_CC_PMU_CTL_NOILPONW);
++	else
++		bcma_cc_set32(cc, BCMA_CC_PMU_CTL,
++			     BCMA_CC_PMU_CTL_NOILPONW);
++
++	if (cc->core->id.id == 0x4329 && cc->core->id.rev == 2)
++		pr_err("Fix for 4329b0 bad LPOM state not implemented!\n");
++
++	bcma_pmu_pll_init(cc);
++	bcma_pmu_resources_init(cc);
++	bcma_pmu_swreg_init(cc);
++	bcma_pmu_workarounds(cc);
++}
++
++u32 bcma_pmu_alp_clock(struct bcma_drv_cc *cc)
++{
++	struct bcma_bus *bus = cc->core->bus;
++
++	switch (bus->chipinfo.id) {
++	case 0x4716:
++	case 0x4748:
++	case 47162:
++	case 0x4313:
++	case 0x5357:
++	case 0x4749:
++	case 53572:
++		/* always 20Mhz */
++		return 20000 * 1000;
++	case 0x5356:
++	case 0x5300:
++		/* always 25Mhz */
++		return 25000 * 1000;
++	default:
++		pr_warning("No ALP clock specified for %04X device, "
++			"pmu rev. %d, using default %d Hz\n",
++			bus->chipinfo.id, cc->pmu.rev, BCMA_CC_PMU_ALP_CLOCK);
++	}
++	return BCMA_CC_PMU_ALP_CLOCK;
++}
++
++/* Find the output of the "m" pll divider given pll controls that start with
++ * pllreg "pll0" i.e. 12 for main 6 for phy, 0 for misc.
++ */
++static u32 bcma_pmu_clock(struct bcma_drv_cc *cc, u32 pll0, u32 m)
++{
++	u32 tmp, div, ndiv, p1, p2, fc;
++	struct bcma_bus *bus = cc->core->bus;
++
++	BUG_ON((pll0 & 3) || (pll0 > BCMA_CC_PMU4716_MAINPLL_PLL0));
++
++	BUG_ON(!m || m > 4);
++
++	if (bus->chipinfo.id == 0x5357 || bus->chipinfo.id == 0x4749) {
++		/* Detect failure in clock setting */
++		tmp = bcma_cc_read32(cc, BCMA_CC_CHIPSTAT);
++		if (tmp & 0x40000)
++			return 133 * 1000000;
++	}
++
++	tmp = bcma_chipco_pll_read(cc, pll0 + BCMA_CC_PPL_P1P2_OFF);
++	p1 = (tmp & BCMA_CC_PPL_P1_MASK) >> BCMA_CC_PPL_P1_SHIFT;
++	p2 = (tmp & BCMA_CC_PPL_P2_MASK) >> BCMA_CC_PPL_P2_SHIFT;
++
++	tmp = bcma_chipco_pll_read(cc, pll0 + BCMA_CC_PPL_M14_OFF);
++	div = (tmp >> ((m - 1) * BCMA_CC_PPL_MDIV_WIDTH)) &
++		BCMA_CC_PPL_MDIV_MASK;
++
++	tmp = bcma_chipco_pll_read(cc, pll0 + BCMA_CC_PPL_NM5_OFF);
++	ndiv = (tmp & BCMA_CC_PPL_NDIV_MASK) >> BCMA_CC_PPL_NDIV_SHIFT;
++
++	/* Do calculation in Mhz */
++	fc = bcma_pmu_alp_clock(cc) / 1000000;
++	fc = (p1 * ndiv * fc) / p2;
++
++	/* Return clock in Hertz */
++	return (fc / div) * 1000000;
++}
++
++/* query bus clock frequency for PMU-enabled chipcommon */
++u32 bcma_pmu_get_clockcontrol(struct bcma_drv_cc *cc)
++{
++	struct bcma_bus *bus = cc->core->bus;
++
++	switch (bus->chipinfo.id) {
++	case 0x4716:
++	case 0x4748:
++	case 47162:
++		return bcma_pmu_clock(cc, BCMA_CC_PMU4716_MAINPLL_PLL0,
++				      BCMA_CC_PMU5_MAINPLL_SSB);
++	case 0x5356:
++		return bcma_pmu_clock(cc, BCMA_CC_PMU5356_MAINPLL_PLL0,
++				      BCMA_CC_PMU5_MAINPLL_SSB);
++	case 0x5357:
++	case 0x4749:
++		return bcma_pmu_clock(cc, BCMA_CC_PMU5357_MAINPLL_PLL0,
++				      BCMA_CC_PMU5_MAINPLL_SSB);
++	case 0x5300:
++		return bcma_pmu_clock(cc, BCMA_CC_PMU4706_MAINPLL_PLL0,
++				      BCMA_CC_PMU5_MAINPLL_SSB);
++	case 53572:
++		return 75000000;
++	default:
++		pr_warning("No backplane clock specified for %04X device, "
++			"pmu rev. %d, using default %d Hz\n",
++			bus->chipinfo.id, cc->pmu.rev, BCMA_CC_PMU_HT_CLOCK);
++	}
++	return BCMA_CC_PMU_HT_CLOCK;
++}
++
++/* query cpu clock frequency for PMU-enabled chipcommon */
++u32 bcma_pmu_get_clockcpu(struct bcma_drv_cc *cc)
++{
++	struct bcma_bus *bus = cc->core->bus;
++
++	if (bus->chipinfo.id == 53572)
++		return 300000000;
++
++	if (cc->pmu.rev >= 5) {
++		u32 pll;
++		switch (bus->chipinfo.id) {
++		case 0x5356:
++			pll = BCMA_CC_PMU5356_MAINPLL_PLL0;
++			break;
++		case 0x5357:
++		case 0x4749:
++			pll = BCMA_CC_PMU5357_MAINPLL_PLL0;
++			break;
++		default:
++			pll = BCMA_CC_PMU4716_MAINPLL_PLL0;
++			break;
++		}
++
++		/* TODO: if (bus->chipinfo.id == 0x5300)
++		  return si_4706_pmu_clock(sih, osh, cc, PMU4706_MAINPLL_PLL0, PMU5_MAINPLL_CPU); */
++		return bcma_pmu_clock(cc, pll, BCMA_CC_PMU5_MAINPLL_CPU);
++	}
++
++	return bcma_pmu_get_clockcontrol(cc);
++}
+--- /dev/null
++++ b/drivers/bcma/driver_pci.c
+@@ -0,0 +1,225 @@
++/*
++ * Broadcom specific AMBA
++ * PCI Core
++ *
++ * Copyright 2005, 2011, Broadcom Corporation
++ * Copyright 2006, 2007, Michael Buesch <m@bues.ch>
++ * Copyright 2011, 2012, Hauke Mehrtens <hauke@hauke-m.de>
++ *
++ * Licensed under the GNU/GPL. See COPYING for details.
++ */
++
++#include "bcma_private.h"
++#include <linux/bcma/bcma.h>
++
++/**************************************************
++ * R/W ops.
++ **************************************************/
++
++u32 bcma_pcie_read(struct bcma_drv_pci *pc, u32 address)
++{
++	pcicore_write32(pc, BCMA_CORE_PCI_PCIEIND_ADDR, address);
++	pcicore_read32(pc, BCMA_CORE_PCI_PCIEIND_ADDR);
++	return pcicore_read32(pc, BCMA_CORE_PCI_PCIEIND_DATA);
++}
++
++#if 0
++static void bcma_pcie_write(struct bcma_drv_pci *pc, u32 address, u32 data)
++{
++	pcicore_write32(pc, BCMA_CORE_PCI_PCIEIND_ADDR, address);
++	pcicore_read32(pc, BCMA_CORE_PCI_PCIEIND_ADDR);
++	pcicore_write32(pc, BCMA_CORE_PCI_PCIEIND_DATA, data);
++}
++#endif
++
++static void bcma_pcie_mdio_set_phy(struct bcma_drv_pci *pc, u8 phy)
++{
++	u32 v;
++	int i;
++
++	v = BCMA_CORE_PCI_MDIODATA_START;
++	v |= BCMA_CORE_PCI_MDIODATA_WRITE;
++	v |= (BCMA_CORE_PCI_MDIODATA_DEV_ADDR <<
++	      BCMA_CORE_PCI_MDIODATA_DEVADDR_SHF);
++	v |= (BCMA_CORE_PCI_MDIODATA_BLK_ADDR <<
++	      BCMA_CORE_PCI_MDIODATA_REGADDR_SHF);
++	v |= BCMA_CORE_PCI_MDIODATA_TA;
++	v |= (phy << 4);
++	pcicore_write32(pc, BCMA_CORE_PCI_MDIO_DATA, v);
++
++	udelay(10);
++	for (i = 0; i < 200; i++) {
++		v = pcicore_read32(pc, BCMA_CORE_PCI_MDIO_CONTROL);
++		if (v & BCMA_CORE_PCI_MDIOCTL_ACCESS_DONE)
++			break;
++		msleep(1);
++	}
++}
++
++static u16 bcma_pcie_mdio_read(struct bcma_drv_pci *pc, u8 device, u8 address)
++{
++	int max_retries = 10;
++	u16 ret = 0;
++	u32 v;
++	int i;
++
++	/* enable mdio access to SERDES */
++	v = BCMA_CORE_PCI_MDIOCTL_PREAM_EN;
++	v |= BCMA_CORE_PCI_MDIOCTL_DIVISOR_VAL;
++	pcicore_write32(pc, BCMA_CORE_PCI_MDIO_CONTROL, v);
++
++	if (pc->core->id.rev >= 10) {
++		max_retries = 200;
++		bcma_pcie_mdio_set_phy(pc, device);
++		v = (BCMA_CORE_PCI_MDIODATA_DEV_ADDR <<
++		     BCMA_CORE_PCI_MDIODATA_DEVADDR_SHF);
++		v |= (address << BCMA_CORE_PCI_MDIODATA_REGADDR_SHF);
++	} else {
++		v = (device << BCMA_CORE_PCI_MDIODATA_DEVADDR_SHF_OLD);
++		v |= (address << BCMA_CORE_PCI_MDIODATA_REGADDR_SHF_OLD);
++	}
++
++	v = BCMA_CORE_PCI_MDIODATA_START;
++	v |= BCMA_CORE_PCI_MDIODATA_READ;
++	v |= BCMA_CORE_PCI_MDIODATA_TA;
++
++	pcicore_write32(pc, BCMA_CORE_PCI_MDIO_DATA, v);
++	/* Wait for the device to complete the transaction */
++	udelay(10);
++	for (i = 0; i < max_retries; i++) {
++		v = pcicore_read32(pc, BCMA_CORE_PCI_MDIO_CONTROL);
++		if (v & BCMA_CORE_PCI_MDIOCTL_ACCESS_DONE) {
++			udelay(10);
++			ret = pcicore_read32(pc, BCMA_CORE_PCI_MDIO_DATA);
++			break;
++		}
++		msleep(1);
++	}
++	pcicore_write32(pc, BCMA_CORE_PCI_MDIO_CONTROL, 0);
++	return ret;
++}
++
++static void bcma_pcie_mdio_write(struct bcma_drv_pci *pc, u8 device,
++				u8 address, u16 data)
++{
++	int max_retries = 10;
++	u32 v;
++	int i;
++
++	/* enable mdio access to SERDES */
++	v = BCMA_CORE_PCI_MDIOCTL_PREAM_EN;
++	v |= BCMA_CORE_PCI_MDIOCTL_DIVISOR_VAL;
++	pcicore_write32(pc, BCMA_CORE_PCI_MDIO_CONTROL, v);
++
++	if (pc->core->id.rev >= 10) {
++		max_retries = 200;
++		bcma_pcie_mdio_set_phy(pc, device);
++		v = (BCMA_CORE_PCI_MDIODATA_DEV_ADDR <<
++		     BCMA_CORE_PCI_MDIODATA_DEVADDR_SHF);
++		v |= (address << BCMA_CORE_PCI_MDIODATA_REGADDR_SHF);
++	} else {
++		v = (device << BCMA_CORE_PCI_MDIODATA_DEVADDR_SHF_OLD);
++		v |= (address << BCMA_CORE_PCI_MDIODATA_REGADDR_SHF_OLD);
++	}
++
++	v = BCMA_CORE_PCI_MDIODATA_START;
++	v |= BCMA_CORE_PCI_MDIODATA_WRITE;
++	v |= BCMA_CORE_PCI_MDIODATA_TA;
++	v |= data;
++	pcicore_write32(pc, BCMA_CORE_PCI_MDIO_DATA, v);
++	/* Wait for the device to complete the transaction */
++	udelay(10);
++	for (i = 0; i < max_retries; i++) {
++		v = pcicore_read32(pc, BCMA_CORE_PCI_MDIO_CONTROL);
++		if (v & BCMA_CORE_PCI_MDIOCTL_ACCESS_DONE)
++			break;
++		msleep(1);
++	}
++	pcicore_write32(pc, BCMA_CORE_PCI_MDIO_CONTROL, 0);
++}
++
++/**************************************************
++ * Workarounds.
++ **************************************************/
++
++static u8 bcma_pcicore_polarity_workaround(struct bcma_drv_pci *pc)
++{
++	u32 tmp;
++
++	tmp = bcma_pcie_read(pc, BCMA_CORE_PCI_PLP_STATUSREG);
++	if (tmp & BCMA_CORE_PCI_PLP_POLARITYINV_STAT)
++		return BCMA_CORE_PCI_SERDES_RX_CTRL_FORCE |
++		       BCMA_CORE_PCI_SERDES_RX_CTRL_POLARITY;
++	else
++		return BCMA_CORE_PCI_SERDES_RX_CTRL_FORCE;
++}
++
++static void bcma_pcicore_serdes_workaround(struct bcma_drv_pci *pc)
++{
++	u16 tmp;
++
++	bcma_pcie_mdio_write(pc, BCMA_CORE_PCI_MDIODATA_DEV_RX,
++	                     BCMA_CORE_PCI_SERDES_RX_CTRL,
++			     bcma_pcicore_polarity_workaround(pc));
++	tmp = bcma_pcie_mdio_read(pc, BCMA_CORE_PCI_MDIODATA_DEV_PLL,
++	                          BCMA_CORE_PCI_SERDES_PLL_CTRL);
++	if (tmp & BCMA_CORE_PCI_PLL_CTRL_FREQDET_EN)
++		bcma_pcie_mdio_write(pc, BCMA_CORE_PCI_MDIODATA_DEV_PLL,
++		                     BCMA_CORE_PCI_SERDES_PLL_CTRL,
++		                     tmp & ~BCMA_CORE_PCI_PLL_CTRL_FREQDET_EN);
++}
++
++/**************************************************
++ * Init.
++ **************************************************/
++
++static void __devinit bcma_core_pci_clientmode_init(struct bcma_drv_pci *pc)
++{
++	bcma_pcicore_serdes_workaround(pc);
++}
++
++void __devinit bcma_core_pci_init(struct bcma_drv_pci *pc)
++{
++	if (pc->setup_done)
++		return;
++
++#ifdef CONFIG_BCMA_DRIVER_PCI_HOSTMODE
++	pc->hostmode = bcma_core_pci_is_in_hostmode(pc);
++	if (pc->hostmode)
++		bcma_core_pci_hostmode_init(pc);
++#endif /* CONFIG_BCMA_DRIVER_PCI_HOSTMODE */
++
++	if (!pc->hostmode)
++		bcma_core_pci_clientmode_init(pc);
++}
++
++int bcma_core_pci_irq_ctl(struct bcma_drv_pci *pc, struct bcma_device *core,
++			  bool enable)
++{
++	struct pci_dev *pdev = pc->core->bus->host_pci;
++	u32 coremask, tmp;
++	int err = 0;
++
++	if (core->bus->hosttype != BCMA_HOSTTYPE_PCI) {
++		/* This bcma device is not on a PCI host-bus. So the IRQs are
++		 * not routed through the PCI core.
++		 * So we must not enable routing through the PCI core. */
++		goto out;
++	}
++
++	err = pci_read_config_dword(pdev, BCMA_PCI_IRQMASK, &tmp);
++	if (err)
++		goto out;
++
++	coremask = BIT(core->core_index) << 8;
++	if (enable)
++		tmp |= coremask;
++	else
++		tmp &= ~coremask;
++
++	err = pci_write_config_dword(pdev, BCMA_PCI_IRQMASK, tmp);
++
++out:
++	return err;
++}
++EXPORT_SYMBOL_GPL(bcma_core_pci_irq_ctl);
+--- /dev/null
++++ b/drivers/bcma/host_pci.c
+@@ -0,0 +1,292 @@
++/*
++ * Broadcom specific AMBA
++ * PCI Host
++ *
++ * Licensed under the GNU/GPL. See COPYING for details.
++ */
++
++#include "bcma_private.h"
++#include <linux/slab.h>
++#include <linux/bcma/bcma.h>
++#include <linux/pci.h>
++#include <linux/module.h>
++
++static void bcma_host_pci_switch_core(struct bcma_device *core)
++{
++	pci_write_config_dword(core->bus->host_pci, BCMA_PCI_BAR0_WIN,
++			       core->addr);
++	pci_write_config_dword(core->bus->host_pci, BCMA_PCI_BAR0_WIN2,
++			       core->wrap);
++	core->bus->mapped_core = core;
++	pr_debug("Switched to core: 0x%X\n", core->id.id);
++}
++
++/* Provides access to the requested core. Returns base offset that has to be
++ * used. It makes use of fixed windows when possible. */
++static u16 bcma_host_pci_provide_access_to_core(struct bcma_device *core)
++{
++	switch (core->id.id) {
++	case BCMA_CORE_CHIPCOMMON:
++		return 3 * BCMA_CORE_SIZE;
++	case BCMA_CORE_PCIE:
++		return 2 * BCMA_CORE_SIZE;
++	}
++
++	if (core->bus->mapped_core != core)
++		bcma_host_pci_switch_core(core);
++	return 0;
++}
++
++static u8 bcma_host_pci_read8(struct bcma_device *core, u16 offset)
++{
++	offset += bcma_host_pci_provide_access_to_core(core);
++	return ioread8(core->bus->mmio + offset);
++}
++
++static u16 bcma_host_pci_read16(struct bcma_device *core, u16 offset)
++{
++	offset += bcma_host_pci_provide_access_to_core(core);
++	return ioread16(core->bus->mmio + offset);
++}
++
++static u32 bcma_host_pci_read32(struct bcma_device *core, u16 offset)
++{
++	offset += bcma_host_pci_provide_access_to_core(core);
++	return ioread32(core->bus->mmio + offset);
++}
++
++static void bcma_host_pci_write8(struct bcma_device *core, u16 offset,
++				 u8 value)
++{
++	offset += bcma_host_pci_provide_access_to_core(core);
++	iowrite8(value, core->bus->mmio + offset);
++}
++
++static void bcma_host_pci_write16(struct bcma_device *core, u16 offset,
++				 u16 value)
++{
++	offset += bcma_host_pci_provide_access_to_core(core);
++	iowrite16(value, core->bus->mmio + offset);
++}
++
++static void bcma_host_pci_write32(struct bcma_device *core, u16 offset,
++				 u32 value)
++{
++	offset += bcma_host_pci_provide_access_to_core(core);
++	iowrite32(value, core->bus->mmio + offset);
++}
++
++#ifdef CONFIG_BCMA_BLOCKIO
++void bcma_host_pci_block_read(struct bcma_device *core, void *buffer,
++			      size_t count, u16 offset, u8 reg_width)
++{
++	void __iomem *addr = core->bus->mmio + offset;
++	if (core->bus->mapped_core != core)
++		bcma_host_pci_switch_core(core);
++	switch (reg_width) {
++	case sizeof(u8):
++		ioread8_rep(addr, buffer, count);
++		break;
++	case sizeof(u16):
++		WARN_ON(count & 1);
++		ioread16_rep(addr, buffer, count >> 1);
++		break;
++	case sizeof(u32):
++		WARN_ON(count & 3);
++		ioread32_rep(addr, buffer, count >> 2);
++		break;
++	default:
++		WARN_ON(1);
++	}
++}
++
++void bcma_host_pci_block_write(struct bcma_device *core, const void *buffer,
++			       size_t count, u16 offset, u8 reg_width)
++{
++	void __iomem *addr = core->bus->mmio + offset;
++	if (core->bus->mapped_core != core)
++		bcma_host_pci_switch_core(core);
++	switch (reg_width) {
++	case sizeof(u8):
++		iowrite8_rep(addr, buffer, count);
++		break;
++	case sizeof(u16):
++		WARN_ON(count & 1);
++		iowrite16_rep(addr, buffer, count >> 1);
++		break;
++	case sizeof(u32):
++		WARN_ON(count & 3);
++		iowrite32_rep(addr, buffer, count >> 2);
++		break;
++	default:
++		WARN_ON(1);
++	}
++}
++#endif
++
++static u32 bcma_host_pci_aread32(struct bcma_device *core, u16 offset)
++{
++	if (core->bus->mapped_core != core)
++		bcma_host_pci_switch_core(core);
++	return ioread32(core->bus->mmio + (1 * BCMA_CORE_SIZE) + offset);
++}
++
++static void bcma_host_pci_awrite32(struct bcma_device *core, u16 offset,
++				  u32 value)
++{
++	if (core->bus->mapped_core != core)
++		bcma_host_pci_switch_core(core);
++	iowrite32(value, core->bus->mmio + (1 * BCMA_CORE_SIZE) + offset);
++}
++
++const struct bcma_host_ops bcma_host_pci_ops = {
++	.read8		= bcma_host_pci_read8,
++	.read16		= bcma_host_pci_read16,
++	.read32		= bcma_host_pci_read32,
++	.write8		= bcma_host_pci_write8,
++	.write16	= bcma_host_pci_write16,
++	.write32	= bcma_host_pci_write32,
++#ifdef CONFIG_BCMA_BLOCKIO
++	.block_read	= bcma_host_pci_block_read,
++	.block_write	= bcma_host_pci_block_write,
++#endif
++	.aread32	= bcma_host_pci_aread32,
++	.awrite32	= bcma_host_pci_awrite32,
++};
++
++static int __devinit bcma_host_pci_probe(struct pci_dev *dev,
++					 const struct pci_device_id *id)
++{
++	struct bcma_bus *bus;
++	int err = -ENOMEM;
++	const char *name;
++	u32 val;
++
++	/* Alloc */
++	bus = kzalloc(sizeof(*bus), GFP_KERNEL);
++	if (!bus)
++		goto out;
++
++	/* Basic PCI configuration */
++	err = pci_enable_device(dev);
++	if (err)
++		goto err_kfree_bus;
++
++	name = dev_name(&dev->dev);
++	if (dev->driver && dev->driver->name)
++		name = dev->driver->name;
++	err = pci_request_regions(dev, name);
++	if (err)
++		goto err_pci_disable;
++	pci_set_master(dev);
++
++	/* Disable the RETRY_TIMEOUT register (0x41) to keep
++	 * PCI Tx retries from interfering with C3 CPU state */
++	pci_read_config_dword(dev, 0x40, &val);
++	if ((val & 0x0000ff00) != 0)
++		pci_write_config_dword(dev, 0x40, val & 0xffff00ff);
++
++	/* SSB needed additional powering up, do we have any AMBA PCI cards? */
++	if (!dev->is_pcie)
++		pr_err("PCI card detected, report problems.\n");
++
++	/* Map MMIO */
++	err = -ENOMEM;
++	bus->mmio = pci_iomap(dev, 0, ~0UL);
++	if (!bus->mmio)
++		goto err_pci_release_regions;
++
++	/* Host specific */
++	bus->host_pci = dev;
++	bus->hosttype = BCMA_HOSTTYPE_PCI;
++	bus->ops = &bcma_host_pci_ops;
++
++	/* Register */
++	err = bcma_bus_register(bus);
++	if (err)
++		goto err_pci_unmap_mmio;
++
++	pci_set_drvdata(dev, bus);
++
++out:
++	return err;
++
++err_pci_unmap_mmio:
++	pci_iounmap(dev, bus->mmio);
++err_pci_release_regions:
++	pci_release_regions(dev);
++err_pci_disable:
++	pci_disable_device(dev);
++err_kfree_bus:
++	kfree(bus);
++	return err;
++}
++
++static void bcma_host_pci_remove(struct pci_dev *dev)
++{
++	struct bcma_bus *bus = pci_get_drvdata(dev);
++
++	bcma_bus_unregister(bus);
++	pci_iounmap(dev, bus->mmio);
++	pci_release_regions(dev);
++	pci_disable_device(dev);
++	kfree(bus);
++	pci_set_drvdata(dev, NULL);
++}
++
++#ifdef CONFIG_PM
++static int bcma_host_pci_suspend(struct device *dev)
++{
++	struct pci_dev *pdev = to_pci_dev(dev);
++	struct bcma_bus *bus = pci_get_drvdata(pdev);
++
++	bus->mapped_core = NULL;
++
++	return bcma_bus_suspend(bus);
++}
++
++static int bcma_host_pci_resume(struct device *dev)
++{
++	struct pci_dev *pdev = to_pci_dev(dev);
++	struct bcma_bus *bus = pci_get_drvdata(pdev);
++
++	return bcma_bus_resume(bus);
++}
++
++static SIMPLE_DEV_PM_OPS(bcma_pm_ops, bcma_host_pci_suspend,
++			 bcma_host_pci_resume);
++#define BCMA_PM_OPS	(&bcma_pm_ops)
++
++#else /* CONFIG_PM */
++
++#define BCMA_PM_OPS     NULL
++
++#endif /* CONFIG_PM */
++
++static DEFINE_PCI_DEVICE_TABLE(bcma_pci_bridge_tbl) = {
++	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x0576) },
++	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4331) },
++	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4353) },
++	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4357) },
++	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4727) },
++	{ 0, },
++};
++MODULE_DEVICE_TABLE(pci, bcma_pci_bridge_tbl);
++
++static struct pci_driver bcma_pci_bridge_driver = {
++	.name = "bcma-pci-bridge",
++	.id_table = bcma_pci_bridge_tbl,
++	.probe = bcma_host_pci_probe,
++	.remove = bcma_host_pci_remove,
++	.driver.pm = BCMA_PM_OPS,
++};
++
++int __init bcma_host_pci_init(void)
++{
++	return pci_register_driver(&bcma_pci_bridge_driver);
++}
++
++void __exit bcma_host_pci_exit(void)
++{
++	pci_unregister_driver(&bcma_pci_bridge_driver);
++}
+--- /dev/null
++++ b/drivers/bcma/main.c
+@@ -0,0 +1,387 @@
++/*
++ * Broadcom specific AMBA
++ * Bus subsystem
++ *
++ * Licensed under the GNU/GPL. See COPYING for details.
++ */
++
++#include "bcma_private.h"
++#include <linux/module.h>
++#include <linux/bcma/bcma.h>
++#include <linux/slab.h>
++
++MODULE_DESCRIPTION("Broadcom's specific AMBA driver");
++MODULE_LICENSE("GPL");
++
++/* contains the number the next bus should get. */
++static unsigned int bcma_bus_next_num = 0;
++
++/* bcma_buses_mutex locks the bcma_bus_next_num */
++static DEFINE_MUTEX(bcma_buses_mutex);
++
++static int bcma_bus_match(struct device *dev, struct device_driver *drv);
++static int bcma_device_probe(struct device *dev);
++static int bcma_device_remove(struct device *dev);
++static int bcma_device_uevent(struct device *dev, struct kobj_uevent_env *env);
++
++static ssize_t manuf_show(struct device *dev, struct device_attribute *attr, char *buf)
++{
++	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
++	return sprintf(buf, "0x%03X\n", core->id.manuf);
++}
++static ssize_t id_show(struct device *dev, struct device_attribute *attr, char *buf)
++{
++	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
++	return sprintf(buf, "0x%03X\n", core->id.id);
++}
++static ssize_t rev_show(struct device *dev, struct device_attribute *attr, char *buf)
++{
++	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
++	return sprintf(buf, "0x%02X\n", core->id.rev);
++}
++static ssize_t class_show(struct device *dev, struct device_attribute *attr, char *buf)
++{
++	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
++	return sprintf(buf, "0x%X\n", core->id.class);
++}
++static struct device_attribute bcma_device_attrs[] = {
++	__ATTR_RO(manuf),
++	__ATTR_RO(id),
++	__ATTR_RO(rev),
++	__ATTR_RO(class),
++	__ATTR_NULL,
++};
++
++static struct bus_type bcma_bus_type = {
++	.name		= "bcma",
++	.match		= bcma_bus_match,
++	.probe		= bcma_device_probe,
++	.remove		= bcma_device_remove,
++	.uevent		= bcma_device_uevent,
++	.dev_attrs	= bcma_device_attrs,
++};
++
++struct bcma_device *bcma_find_core(struct bcma_bus *bus, u16 coreid)
++{
++	struct bcma_device *core;
++
++	list_for_each_entry(core, &bus->cores, list) {
++		if (core->id.id == coreid)
++			return core;
++	}
++	return NULL;
++}
++EXPORT_SYMBOL_GPL(bcma_find_core);
++
++static void bcma_release_core_dev(struct device *dev)
++{
++	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
++	if (core->io_addr)
++		iounmap(core->io_addr);
++	if (core->io_wrap)
++		iounmap(core->io_wrap);
++	kfree(core);
++}
++
++static int bcma_register_cores(struct bcma_bus *bus)
++{
++	struct bcma_device *core;
++	int err, dev_id = 0;
++
++	list_for_each_entry(core, &bus->cores, list) {
++		/* We support that cores ourself */
++		switch (core->id.id) {
++		case BCMA_CORE_CHIPCOMMON:
++		case BCMA_CORE_PCI:
++		case BCMA_CORE_PCIE:
++		case BCMA_CORE_MIPS_74K:
++			continue;
++		}
++
++		core->dev.release = bcma_release_core_dev;
++		core->dev.bus = &bcma_bus_type;
++		dev_set_name(&core->dev, "bcma%d:%d", bus->num, dev_id);
++
++		switch (bus->hosttype) {
++		case BCMA_HOSTTYPE_PCI:
++			core->dev.parent = &bus->host_pci->dev;
++			core->dma_dev = &bus->host_pci->dev;
++			core->irq = bus->host_pci->irq;
++			break;
++		case BCMA_HOSTTYPE_SOC:
++			core->dev.dma_mask = &core->dev.coherent_dma_mask;
++			core->dma_dev = &core->dev;
++			break;
++		case BCMA_HOSTTYPE_SDIO:
++			break;
++		}
++
++		err = device_register(&core->dev);
++		if (err) {
++			pr_err("Could not register dev for core 0x%03X\n",
++			       core->id.id);
++			continue;
++		}
++		core->dev_registered = true;
++		dev_id++;
++	}
++
++	return 0;
++}
++
++static void bcma_unregister_cores(struct bcma_bus *bus)
++{
++	struct bcma_device *core;
++
++	list_for_each_entry(core, &bus->cores, list) {
++		if (core->dev_registered)
++			device_unregister(&core->dev);
++	}
++}
++
++int __devinit bcma_bus_register(struct bcma_bus *bus)
++{
++	int err;
++	struct bcma_device *core;
++
++	mutex_lock(&bcma_buses_mutex);
++	bus->num = bcma_bus_next_num++;
++	mutex_unlock(&bcma_buses_mutex);
++
++	/* Scan for devices (cores) */
++	err = bcma_bus_scan(bus);
++	if (err) {
++		pr_err("Failed to scan: %d\n", err);
++		return -1;
++	}
++
++	/* Init CC core */
++	core = bcma_find_core(bus, BCMA_CORE_CHIPCOMMON);
++	if (core) {
++		bus->drv_cc.core = core;
++		bcma_core_chipcommon_init(&bus->drv_cc);
++	}
++
++	/* Init MIPS core */
++	core = bcma_find_core(bus, BCMA_CORE_MIPS_74K);
++	if (core) {
++		bus->drv_mips.core = core;
++		bcma_core_mips_init(&bus->drv_mips);
++	}
++
++	/* Init PCIE core */
++	core = bcma_find_core(bus, BCMA_CORE_PCIE);
++	if (core) {
++		bus->drv_pci.core = core;
++		bcma_core_pci_init(&bus->drv_pci);
++	}
++
++	/* Try to get SPROM */
++	err = bcma_sprom_get(bus);
++	if (err == -ENOENT) {
++		pr_err("No SPROM available\n");
++	} else if (err)
++		pr_err("Failed to get SPROM: %d\n", err);
++
++	/* Register found cores */
++	bcma_register_cores(bus);
++
++	pr_info("Bus registered\n");
++
++	return 0;
++}
++
++void bcma_bus_unregister(struct bcma_bus *bus)
++{
++	bcma_unregister_cores(bus);
++}
++
++int __init bcma_bus_early_register(struct bcma_bus *bus,
++				   struct bcma_device *core_cc,
++				   struct bcma_device *core_mips)
++{
++	int err;
++	struct bcma_device *core;
++	struct bcma_device_id match;
++
++	bcma_init_bus(bus);
++
++	match.manuf = BCMA_MANUF_BCM;
++	match.id = BCMA_CORE_CHIPCOMMON;
++	match.class = BCMA_CL_SIM;
++	match.rev = BCMA_ANY_REV;
++
++	/* Scan for chip common core */
++	err = bcma_bus_scan_early(bus, &match, core_cc);
++	if (err) {
++		pr_err("Failed to scan for common core: %d\n", err);
++		return -1;
++	}
++
++	match.manuf = BCMA_MANUF_MIPS;
++	match.id = BCMA_CORE_MIPS_74K;
++	match.class = BCMA_CL_SIM;
++	match.rev = BCMA_ANY_REV;
++
++	/* Scan for mips core */
++	err = bcma_bus_scan_early(bus, &match, core_mips);
++	if (err) {
++		pr_err("Failed to scan for mips core: %d\n", err);
++		return -1;
++	}
++
++	/* Init CC core */
++	core = bcma_find_core(bus, BCMA_CORE_CHIPCOMMON);
++	if (core) {
++		bus->drv_cc.core = core;
++		bcma_core_chipcommon_init(&bus->drv_cc);
++	}
++
++	/* Init MIPS core */
++	core = bcma_find_core(bus, BCMA_CORE_MIPS_74K);
++	if (core) {
++		bus->drv_mips.core = core;
++		bcma_core_mips_init(&bus->drv_mips);
++	}
++
++	pr_info("Early bus registered\n");
++
++	return 0;
++}
++
++#ifdef CONFIG_PM
++int bcma_bus_suspend(struct bcma_bus *bus)
++{
++	struct bcma_device *core;
++
++	list_for_each_entry(core, &bus->cores, list) {
++		struct device_driver *drv = core->dev.driver;
++		if (drv) {
++			struct bcma_driver *adrv = container_of(drv, struct bcma_driver, drv);
++			if (adrv->suspend)
++				adrv->suspend(core);
++		}
++	}
++	return 0;
++}
++
++int bcma_bus_resume(struct bcma_bus *bus)
++{
++	struct bcma_device *core;
++
++	/* Init CC core */
++	core = bcma_find_core(bus, BCMA_CORE_CHIPCOMMON);
++	if (core) {
++		bus->drv_cc.setup_done = false;
++		bcma_core_chipcommon_init(&bus->drv_cc);
++	}
++
++	list_for_each_entry(core, &bus->cores, list) {
++		struct device_driver *drv = core->dev.driver;
++		if (drv) {
++			struct bcma_driver *adrv = container_of(drv, struct bcma_driver, drv);
++			if (adrv->resume)
++				adrv->resume(core);
++		}
++	}
++
++	return 0;
++}
++#endif
++
++int __bcma_driver_register(struct bcma_driver *drv, struct module *owner)
++{
++	drv->drv.name = drv->name;
++	drv->drv.bus = &bcma_bus_type;
++	drv->drv.owner = owner;
++
++	return driver_register(&drv->drv);
++}
++EXPORT_SYMBOL_GPL(__bcma_driver_register);
++
++void bcma_driver_unregister(struct bcma_driver *drv)
++{
++	driver_unregister(&drv->drv);
++}
++EXPORT_SYMBOL_GPL(bcma_driver_unregister);
++
++static int bcma_bus_match(struct device *dev, struct device_driver *drv)
++{
++	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
++	struct bcma_driver *adrv = container_of(drv, struct bcma_driver, drv);
++	const struct bcma_device_id *cid = &core->id;
++	const struct bcma_device_id *did;
++
++	for (did = adrv->id_table; did->manuf || did->id || did->rev; did++) {
++	    if ((did->manuf == cid->manuf || did->manuf == BCMA_ANY_MANUF) &&
++		(did->id == cid->id || did->id == BCMA_ANY_ID) &&
++		(did->rev == cid->rev || did->rev == BCMA_ANY_REV) &&
++		(did->class == cid->class || did->class == BCMA_ANY_CLASS))
++			return 1;
++	}
++	return 0;
++}
++
++static int bcma_device_probe(struct device *dev)
++{
++	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
++	struct bcma_driver *adrv = container_of(dev->driver, struct bcma_driver,
++					       drv);
++	int err = 0;
++
++	if (adrv->probe)
++		err = adrv->probe(core);
++
++	return err;
++}
++
++static int bcma_device_remove(struct device *dev)
++{
++	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
++	struct bcma_driver *adrv = container_of(dev->driver, struct bcma_driver,
++					       drv);
++
++	if (adrv->remove)
++		adrv->remove(core);
++
++	return 0;
++}
++
++static int bcma_device_uevent(struct device *dev, struct kobj_uevent_env *env)
++{
++	struct bcma_device *core = container_of(dev, struct bcma_device, dev);
++
++	return add_uevent_var(env,
++			      "MODALIAS=bcma:m%04Xid%04Xrev%02Xcl%02X",
++			      core->id.manuf, core->id.id,
++			      core->id.rev, core->id.class);
++}
++
++static int __init bcma_modinit(void)
++{
++	int err;
++
++	err = bus_register(&bcma_bus_type);
++	if (err)
++		return err;
++
++#ifdef CONFIG_BCMA_HOST_PCI
++	err = bcma_host_pci_init();
++	if (err) {
++		pr_err("PCI host initialization failed\n");
++		err = 0;
++	}
++#endif
++
++	return err;
++}
++fs_initcall(bcma_modinit);
++
++static void __exit bcma_modexit(void)
++{
++#ifdef CONFIG_BCMA_HOST_PCI
++	bcma_host_pci_exit();
++#endif
++	bus_unregister(&bcma_bus_type);
++}
++module_exit(bcma_modexit)
+--- /dev/null
++++ b/drivers/bcma/scan.c
+@@ -0,0 +1,507 @@
++/*
++ * Broadcom specific AMBA
++ * Bus scanning
++ *
++ * Licensed under the GNU/GPL. See COPYING for details.
++ */
++
++#include "scan.h"
++#include "bcma_private.h"
++
++#include <linux/bcma/bcma.h>
++#include <linux/bcma/bcma_regs.h>
++#include <linux/pci.h>
++#include <linux/io.h>
++#include <linux/dma-mapping.h>
++#include <linux/slab.h>
++
++struct bcma_device_id_name {
++	u16 id;
++	const char *name;
++};
++struct bcma_device_id_name bcma_device_names[] = {
++	{ BCMA_CORE_OOB_ROUTER, "OOB Router" },
++	{ BCMA_CORE_INVALID, "Invalid" },
++	{ BCMA_CORE_CHIPCOMMON, "ChipCommon" },
++	{ BCMA_CORE_ILINE20, "ILine 20" },
++	{ BCMA_CORE_SRAM, "SRAM" },
++	{ BCMA_CORE_SDRAM, "SDRAM" },
++	{ BCMA_CORE_PCI, "PCI" },
++	{ BCMA_CORE_MIPS, "MIPS" },
++	{ BCMA_CORE_ETHERNET, "Fast Ethernet" },
++	{ BCMA_CORE_V90, "V90" },
++	{ BCMA_CORE_USB11_HOSTDEV, "USB 1.1 Hostdev" },
++	{ BCMA_CORE_ADSL, "ADSL" },
++	{ BCMA_CORE_ILINE100, "ILine 100" },
++	{ BCMA_CORE_IPSEC, "IPSEC" },
++	{ BCMA_CORE_UTOPIA, "UTOPIA" },
++	{ BCMA_CORE_PCMCIA, "PCMCIA" },
++	{ BCMA_CORE_INTERNAL_MEM, "Internal Memory" },
++	{ BCMA_CORE_MEMC_SDRAM, "MEMC SDRAM" },
++	{ BCMA_CORE_OFDM, "OFDM" },
++	{ BCMA_CORE_EXTIF, "EXTIF" },
++	{ BCMA_CORE_80211, "IEEE 802.11" },
++	{ BCMA_CORE_PHY_A, "PHY A" },
++	{ BCMA_CORE_PHY_B, "PHY B" },
++	{ BCMA_CORE_PHY_G, "PHY G" },
++	{ BCMA_CORE_MIPS_3302, "MIPS 3302" },
++	{ BCMA_CORE_USB11_HOST, "USB 1.1 Host" },
++	{ BCMA_CORE_USB11_DEV, "USB 1.1 Device" },
++	{ BCMA_CORE_USB20_HOST, "USB 2.0 Host" },
++	{ BCMA_CORE_USB20_DEV, "USB 2.0 Device" },
++	{ BCMA_CORE_SDIO_HOST, "SDIO Host" },
++	{ BCMA_CORE_ROBOSWITCH, "Roboswitch" },
++	{ BCMA_CORE_PARA_ATA, "PATA" },
++	{ BCMA_CORE_SATA_XORDMA, "SATA XOR-DMA" },
++	{ BCMA_CORE_ETHERNET_GBIT, "GBit Ethernet" },
++	{ BCMA_CORE_PCIE, "PCIe" },
++	{ BCMA_CORE_PHY_N, "PHY N" },
++	{ BCMA_CORE_SRAM_CTL, "SRAM Controller" },
++	{ BCMA_CORE_MINI_MACPHY, "Mini MACPHY" },
++	{ BCMA_CORE_ARM_1176, "ARM 1176" },
++	{ BCMA_CORE_ARM_7TDMI, "ARM 7TDMI" },
++	{ BCMA_CORE_PHY_LP, "PHY LP" },
++	{ BCMA_CORE_PMU, "PMU" },
++	{ BCMA_CORE_PHY_SSN, "PHY SSN" },
++	{ BCMA_CORE_SDIO_DEV, "SDIO Device" },
++	{ BCMA_CORE_ARM_CM3, "ARM CM3" },
++	{ BCMA_CORE_PHY_HT, "PHY HT" },
++	{ BCMA_CORE_MIPS_74K, "MIPS 74K" },
++	{ BCMA_CORE_MAC_GBIT, "GBit MAC" },
++	{ BCMA_CORE_DDR12_MEM_CTL, "DDR1/DDR2 Memory Controller" },
++	{ BCMA_CORE_PCIE_RC, "PCIe Root Complex" },
++	{ BCMA_CORE_OCP_OCP_BRIDGE, "OCP to OCP Bridge" },
++	{ BCMA_CORE_SHARED_COMMON, "Common Shared" },
++	{ BCMA_CORE_OCP_AHB_BRIDGE, "OCP to AHB Bridge" },
++	{ BCMA_CORE_SPI_HOST, "SPI Host" },
++	{ BCMA_CORE_I2S, "I2S" },
++	{ BCMA_CORE_SDR_DDR1_MEM_CTL, "SDR/DDR1 Memory Controller" },
++	{ BCMA_CORE_SHIM, "SHIM" },
++	{ BCMA_CORE_DEFAULT, "Default" },
++};
++const char *bcma_device_name(struct bcma_device_id *id)
++{
++	int i;
++
++	if (id->manuf == BCMA_MANUF_BCM) {
++		for (i = 0; i < ARRAY_SIZE(bcma_device_names); i++) {
++			if (bcma_device_names[i].id == id->id)
++				return bcma_device_names[i].name;
++		}
++	}
++	return "UNKNOWN";
++}
++
++static u32 bcma_scan_read32(struct bcma_bus *bus, u8 current_coreidx,
++		       u16 offset)
++{
++	return readl(bus->mmio + offset);
++}
++
++static void bcma_scan_switch_core(struct bcma_bus *bus, u32 addr)
++{
++	if (bus->hosttype == BCMA_HOSTTYPE_PCI)
++		pci_write_config_dword(bus->host_pci, BCMA_PCI_BAR0_WIN,
++				       addr);
++}
++
++static u32 bcma_erom_get_ent(struct bcma_bus *bus, u32 **eromptr)
++{
++	u32 ent = readl(*eromptr);
++	(*eromptr)++;
++	return ent;
++}
++
++static void bcma_erom_push_ent(u32 **eromptr)
++{
++	(*eromptr)--;
++}
++
++static s32 bcma_erom_get_ci(struct bcma_bus *bus, u32 **eromptr)
++{
++	u32 ent = bcma_erom_get_ent(bus, eromptr);
++	if (!(ent & SCAN_ER_VALID))
++		return -ENOENT;
++	if ((ent & SCAN_ER_TAG) != SCAN_ER_TAG_CI)
++		return -ENOENT;
++	return ent;
++}
++
++static bool bcma_erom_is_end(struct bcma_bus *bus, u32 **eromptr)
++{
++	u32 ent = bcma_erom_get_ent(bus, eromptr);
++	bcma_erom_push_ent(eromptr);
++	return (ent == (SCAN_ER_TAG_END | SCAN_ER_VALID));
++}
++
++static bool bcma_erom_is_bridge(struct bcma_bus *bus, u32 **eromptr)
++{
++	u32 ent = bcma_erom_get_ent(bus, eromptr);
++	bcma_erom_push_ent(eromptr);
++	return (((ent & SCAN_ER_VALID)) &&
++		((ent & SCAN_ER_TAGX) == SCAN_ER_TAG_ADDR) &&
++		((ent & SCAN_ADDR_TYPE) == SCAN_ADDR_TYPE_BRIDGE));
++}
++
++static void bcma_erom_skip_component(struct bcma_bus *bus, u32 **eromptr)
++{
++	u32 ent;
++	while (1) {
++		ent = bcma_erom_get_ent(bus, eromptr);
++		if ((ent & SCAN_ER_VALID) &&
++		    ((ent & SCAN_ER_TAG) == SCAN_ER_TAG_CI))
++			break;
++		if (ent == (SCAN_ER_TAG_END | SCAN_ER_VALID))
++			break;
++	}
++	bcma_erom_push_ent(eromptr);
++}
++
++static s32 bcma_erom_get_mst_port(struct bcma_bus *bus, u32 **eromptr)
++{
++	u32 ent = bcma_erom_get_ent(bus, eromptr);
++	if (!(ent & SCAN_ER_VALID))
++		return -ENOENT;
++	if ((ent & SCAN_ER_TAG) != SCAN_ER_TAG_MP)
++		return -ENOENT;
++	return ent;
++}
++
++static s32 bcma_erom_get_addr_desc(struct bcma_bus *bus, u32 **eromptr,
++				  u32 type, u8 port)
++{
++	u32 addrl, addrh, sizel, sizeh = 0;
++	u32 size;
++
++	u32 ent = bcma_erom_get_ent(bus, eromptr);
++	if ((!(ent & SCAN_ER_VALID)) ||
++	    ((ent & SCAN_ER_TAGX) != SCAN_ER_TAG_ADDR) ||
++	    ((ent & SCAN_ADDR_TYPE) != type) ||
++	    (((ent & SCAN_ADDR_PORT) >> SCAN_ADDR_PORT_SHIFT) != port)) {
++		bcma_erom_push_ent(eromptr);
++		return -EINVAL;
++	}
++
++	addrl = ent & SCAN_ADDR_ADDR;
++	if (ent & SCAN_ADDR_AG32)
++		addrh = bcma_erom_get_ent(bus, eromptr);
++	else
++		addrh = 0;
++
++	if ((ent & SCAN_ADDR_SZ) == SCAN_ADDR_SZ_SZD) {
++		size = bcma_erom_get_ent(bus, eromptr);
++		sizel = size & SCAN_SIZE_SZ;
++		if (size & SCAN_SIZE_SG32)
++			sizeh = bcma_erom_get_ent(bus, eromptr);
++	} else
++		sizel = SCAN_ADDR_SZ_BASE <<
++				((ent & SCAN_ADDR_SZ) >> SCAN_ADDR_SZ_SHIFT);
++
++	return addrl;
++}
++
++static struct bcma_device *bcma_find_core_by_index(struct bcma_bus *bus,
++						   u16 index)
++{
++	struct bcma_device *core;
++
++	list_for_each_entry(core, &bus->cores, list) {
++		if (core->core_index == index)
++			return core;
++	}
++	return NULL;
++}
++
++static struct bcma_device *bcma_find_core_reverse(struct bcma_bus *bus, u16 coreid)
++{
++	struct bcma_device *core;
++
++	list_for_each_entry_reverse(core, &bus->cores, list) {
++		if (core->id.id == coreid)
++			return core;
++	}
++	return NULL;
++}
++
++static int bcma_get_next_core(struct bcma_bus *bus, u32 __iomem **eromptr,
++			      struct bcma_device_id *match, int core_num,
++			      struct bcma_device *core)
++{
++	s32 tmp;
++	u8 i, j;
++	s32 cia, cib;
++	u8 ports[2], wrappers[2];
++
++	/* get CIs */
++	cia = bcma_erom_get_ci(bus, eromptr);
++	if (cia < 0) {
++		bcma_erom_push_ent(eromptr);
++		if (bcma_erom_is_end(bus, eromptr))
++			return -ESPIPE;
++		return -EILSEQ;
++	}
++	cib = bcma_erom_get_ci(bus, eromptr);
++	if (cib < 0)
++		return -EILSEQ;
++
++	/* parse CIs */
++	core->id.class = (cia & SCAN_CIA_CLASS) >> SCAN_CIA_CLASS_SHIFT;
++	core->id.id = (cia & SCAN_CIA_ID) >> SCAN_CIA_ID_SHIFT;
++	core->id.manuf = (cia & SCAN_CIA_MANUF) >> SCAN_CIA_MANUF_SHIFT;
++	ports[0] = (cib & SCAN_CIB_NMP) >> SCAN_CIB_NMP_SHIFT;
++	ports[1] = (cib & SCAN_CIB_NSP) >> SCAN_CIB_NSP_SHIFT;
++	wrappers[0] = (cib & SCAN_CIB_NMW) >> SCAN_CIB_NMW_SHIFT;
++	wrappers[1] = (cib & SCAN_CIB_NSW) >> SCAN_CIB_NSW_SHIFT;
++	core->id.rev = (cib & SCAN_CIB_REV) >> SCAN_CIB_REV_SHIFT;
++
++	if (((core->id.manuf == BCMA_MANUF_ARM) &&
++	     (core->id.id == 0xFFF)) ||
++	    (ports[1] == 0)) {
++		bcma_erom_skip_component(bus, eromptr);
++		return -ENXIO;
++	}
++
++	/* check if component is a core at all */
++	if (wrappers[0] + wrappers[1] == 0) {
++		/* we could save addrl of the router
++		if (cid == BCMA_CORE_OOB_ROUTER)
++		 */
++		bcma_erom_skip_component(bus, eromptr);
++		return -ENXIO;
++	}
++
++	if (bcma_erom_is_bridge(bus, eromptr)) {
++		bcma_erom_skip_component(bus, eromptr);
++		return -ENXIO;
++	}
++
++	if (bcma_find_core_by_index(bus, core_num)) {
++		bcma_erom_skip_component(bus, eromptr);
++		return -ENODEV;
++	}
++
++	if (match && ((match->manuf != BCMA_ANY_MANUF &&
++	      match->manuf != core->id.manuf) ||
++	     (match->id != BCMA_ANY_ID && match->id != core->id.id) ||
++	     (match->rev != BCMA_ANY_REV && match->rev != core->id.rev) ||
++	     (match->class != BCMA_ANY_CLASS && match->class != core->id.class)
++	    )) {
++		bcma_erom_skip_component(bus, eromptr);
++		return -ENODEV;
++	}
++
++	/* get & parse master ports */
++	for (i = 0; i < ports[0]; i++) {
++		s32 mst_port_d = bcma_erom_get_mst_port(bus, eromptr);
++		if (mst_port_d < 0)
++			return -EILSEQ;
++	}
++
++	/* get & parse slave ports */
++	for (i = 0; i < ports[1]; i++) {
++		for (j = 0; ; j++) {
++			tmp = bcma_erom_get_addr_desc(bus, eromptr,
++				SCAN_ADDR_TYPE_SLAVE, i);
++			if (tmp < 0) {
++				/* no more entries for port _i_ */
++				/* pr_debug("erom: slave port %d "
++				 * "has %d descriptors\n", i, j); */
++				break;
++			} else {
++				if (i == 0 && j == 0)
++					core->addr = tmp;
++			}
++		}
++	}
++
++	/* get & parse master wrappers */
++	for (i = 0; i < wrappers[0]; i++) {
++		for (j = 0; ; j++) {
++			tmp = bcma_erom_get_addr_desc(bus, eromptr,
++				SCAN_ADDR_TYPE_MWRAP, i);
++			if (tmp < 0) {
++				/* no more entries for port _i_ */
++				/* pr_debug("erom: master wrapper %d "
++				 * "has %d descriptors\n", i, j); */
++				break;
++			} else {
++				if (i == 0 && j == 0)
++					core->wrap = tmp;
++			}
++		}
++	}
++
++	/* get & parse slave wrappers */
++	for (i = 0; i < wrappers[1]; i++) {
++		u8 hack = (ports[1] == 1) ? 0 : 1;
++		for (j = 0; ; j++) {
++			tmp = bcma_erom_get_addr_desc(bus, eromptr,
++				SCAN_ADDR_TYPE_SWRAP, i + hack);
++			if (tmp < 0) {
++				/* no more entries for port _i_ */
++				/* pr_debug("erom: master wrapper %d "
++				 * has %d descriptors\n", i, j); */
++				break;
++			} else {
++				if (wrappers[0] == 0 && !i && !j)
++					core->wrap = tmp;
++			}
++		}
++	}
++	if (bus->hosttype == BCMA_HOSTTYPE_SOC) {
++		core->io_addr = ioremap_nocache(core->addr, BCMA_CORE_SIZE);
++		if (!core->io_addr)
++			return -ENOMEM;
++		core->io_wrap = ioremap_nocache(core->wrap, BCMA_CORE_SIZE);
++		if (!core->io_wrap) {
++			iounmap(core->io_addr);
++			return -ENOMEM;
++		}
++	}
++	return 0;
++}
++
++void bcma_init_bus(struct bcma_bus *bus)
++{
++	s32 tmp;
++	struct bcma_chipinfo *chipinfo = &(bus->chipinfo);
++
++	if (bus->init_done)
++		return;
++
++	INIT_LIST_HEAD(&bus->cores);
++	bus->nr_cores = 0;
++
++	bcma_scan_switch_core(bus, BCMA_ADDR_BASE);
++
++	tmp = bcma_scan_read32(bus, 0, BCMA_CC_ID);
++	chipinfo->id = (tmp & BCMA_CC_ID_ID) >> BCMA_CC_ID_ID_SHIFT;
++	chipinfo->rev = (tmp & BCMA_CC_ID_REV) >> BCMA_CC_ID_REV_SHIFT;
++	chipinfo->pkg = (tmp & BCMA_CC_ID_PKG) >> BCMA_CC_ID_PKG_SHIFT;
++	pr_info("Found chip with id 0x%04X, rev 0x%02X and package 0x%02X\n",
++		chipinfo->id, chipinfo->rev, chipinfo->pkg);
++
++	bus->init_done = true;
++}
++
++int bcma_bus_scan(struct bcma_bus *bus)
++{
++	u32 erombase;
++	u32 __iomem *eromptr, *eromend;
++
++	int err, core_num = 0;
++
++	bcma_init_bus(bus);
++
++	erombase = bcma_scan_read32(bus, 0, BCMA_CC_EROM);
++	if (bus->hosttype == BCMA_HOSTTYPE_SOC) {
++		eromptr = ioremap_nocache(erombase, BCMA_CORE_SIZE);
++		if (!eromptr)
++			return -ENOMEM;
++	} else {
++		eromptr = bus->mmio;
++	}
++
++	eromend = eromptr + BCMA_CORE_SIZE / sizeof(u32);
++
++	bcma_scan_switch_core(bus, erombase);
++
++	while (eromptr < eromend) {
++		struct bcma_device *other_core;
++		struct bcma_device *core = kzalloc(sizeof(*core), GFP_KERNEL);
++		if (!core)
++			return -ENOMEM;
++		INIT_LIST_HEAD(&core->list);
++		core->bus = bus;
++
++		err = bcma_get_next_core(bus, &eromptr, NULL, core_num, core);
++		if (err < 0) {
++			kfree(core);
++			if (err == -ENODEV) {
++				core_num++;
++				continue;
++			} else if (err == -ENXIO) {
++				continue;
++			} else if (err == -ESPIPE) {
++				break;
++			}
++			return err;
++		}
++
++		core->core_index = core_num++;
++		bus->nr_cores++;
++		other_core = bcma_find_core_reverse(bus, core->id.id);
++		core->core_unit = (other_core == NULL) ? 0 : other_core->core_unit + 1;
++
++		pr_info("Core %d found: %s "
++			"(manuf 0x%03X, id 0x%03X, rev 0x%02X, class 0x%X)\n",
++			core->core_index, bcma_device_name(&core->id),
++			core->id.manuf, core->id.id, core->id.rev,
++			core->id.class);
++
++		list_add(&core->list, &bus->cores);
++	}
++
++	if (bus->hosttype == BCMA_HOSTTYPE_SOC)
++		iounmap(eromptr);
++
++	return 0;
++}
++
++int __init bcma_bus_scan_early(struct bcma_bus *bus,
++			       struct bcma_device_id *match,
++			       struct bcma_device *core)
++{
++	u32 erombase;
++	u32 __iomem *eromptr, *eromend;
++
++	int err = -ENODEV;
++	int core_num = 0;
++
++	erombase = bcma_scan_read32(bus, 0, BCMA_CC_EROM);
++	if (bus->hosttype == BCMA_HOSTTYPE_SOC) {
++		eromptr = ioremap_nocache(erombase, BCMA_CORE_SIZE);
++		if (!eromptr)
++			return -ENOMEM;
++	} else {
++		eromptr = bus->mmio;
++	}
++
++	eromend = eromptr + BCMA_CORE_SIZE / sizeof(u32);
++
++	bcma_scan_switch_core(bus, erombase);
++
++	while (eromptr < eromend) {
++		memset(core, 0, sizeof(*core));
++		INIT_LIST_HEAD(&core->list);
++		core->bus = bus;
++
++		err = bcma_get_next_core(bus, &eromptr, match, core_num, core);
++		if (err == -ENODEV) {
++			core_num++;
++			continue;
++		} else if (err == -ENXIO)
++			continue;
++		else if (err == -ESPIPE)
++			break;
++		else if (err < 0)
++			return err;
++
++		core->core_index = core_num++;
++		bus->nr_cores++;
++		pr_info("Core %d found: %s "
++			"(manuf 0x%03X, id 0x%03X, rev 0x%02X, class 0x%X)\n",
++			core->core_index, bcma_device_name(&core->id),
++			core->id.manuf, core->id.id, core->id.rev,
++			core->id.class);
++
++		list_add(&core->list, &bus->cores);
++		err = 0;
++		break;
++	}
++
++	if (bus->hosttype == BCMA_HOSTTYPE_SOC)
++		iounmap(eromptr);
++
++	return err;
++}
+--- /dev/null
++++ b/drivers/bcma/scan.h
+@@ -0,0 +1,56 @@
++#ifndef BCMA_SCAN_H_
++#define BCMA_SCAN_H_
++
++#define BCMA_ADDR_BASE		0x18000000
++#define BCMA_WRAP_BASE		0x18100000
++
++#define SCAN_ER_VALID		0x00000001
++#define SCAN_ER_TAGX		0x00000006 /* we have to ignore 0x8 bit when checking tag for SCAN_ER_TAG_ADDR */
++#define SCAN_ER_TAG		0x0000000E
++#define  SCAN_ER_TAG_CI		0x00000000
++#define  SCAN_ER_TAG_MP		0x00000002
++#define  SCAN_ER_TAG_ADDR	0x00000004
++#define  SCAN_ER_TAG_END	0x0000000E
++#define SCAN_ER_BAD		0xFFFFFFFF
++
++#define SCAN_CIA_CLASS		0x000000F0
++#define SCAN_CIA_CLASS_SHIFT	4
++#define SCAN_CIA_ID		0x000FFF00
++#define SCAN_CIA_ID_SHIFT	8
++#define SCAN_CIA_MANUF		0xFFF00000
++#define SCAN_CIA_MANUF_SHIFT	20
++
++#define SCAN_CIB_NMP		0x000001F0
++#define SCAN_CIB_NMP_SHIFT	4
++#define SCAN_CIB_NSP		0x00003E00
++#define SCAN_CIB_NSP_SHIFT	9
++#define SCAN_CIB_NMW		0x0007C000
++#define SCAN_CIB_NMW_SHIFT	14
++#define SCAN_CIB_NSW		0x00F80000
++#define SCAN_CIB_NSW_SHIFT	17
++#define SCAN_CIB_REV		0xFF000000
++#define SCAN_CIB_REV_SHIFT	24
++
++#define SCAN_ADDR_AG32		0x00000008
++#define SCAN_ADDR_SZ		0x00000030
++#define SCAN_ADDR_SZ_SHIFT	4
++#define  SCAN_ADDR_SZ_4K	0x00000000
++#define  SCAN_ADDR_SZ_8K	0x00000010
++#define  SCAN_ADDR_SZ_16K	0x00000020
++#define  SCAN_ADDR_SZ_SZD	0x00000030
++#define SCAN_ADDR_TYPE		0x000000C0
++#define  SCAN_ADDR_TYPE_SLAVE	0x00000000
++#define  SCAN_ADDR_TYPE_BRIDGE	0x00000040
++#define  SCAN_ADDR_TYPE_SWRAP	0x00000080
++#define  SCAN_ADDR_TYPE_MWRAP	0x000000C0
++#define SCAN_ADDR_PORT		0x00000F00
++#define SCAN_ADDR_PORT_SHIFT	8
++#define SCAN_ADDR_ADDR		0xFFFFF000
++
++#define SCAN_ADDR_SZ_BASE	0x00001000	/* 4KB */
++
++#define SCAN_SIZE_SZ_ALIGN	0x00000FFF
++#define SCAN_SIZE_SZ		0xFFFFF000
++#define SCAN_SIZE_SG32		0x00000008
++
++#endif /* BCMA_SCAN_H_ */
+--- /dev/null
++++ b/include/linux/bcma/bcma.h
+@@ -0,0 +1,307 @@
++#ifndef LINUX_BCMA_H_
++#define LINUX_BCMA_H_
++
++#include <linux/pci.h>
++#include <linux/mod_devicetable.h>
++
++#include <linux/bcma/bcma_driver_chipcommon.h>
++#include <linux/bcma/bcma_driver_pci.h>
++#include <linux/bcma/bcma_driver_mips.h>
++#include <linux/ssb/ssb.h> /* SPROM sharing */
++
++#include "bcma_regs.h"
++
++struct bcma_device;
++struct bcma_bus;
++
++enum bcma_hosttype {
++	BCMA_HOSTTYPE_PCI,
++	BCMA_HOSTTYPE_SDIO,
++	BCMA_HOSTTYPE_SOC,
++};
++
++struct bcma_chipinfo {
++	u16 id;
++	u8 rev;
++	u8 pkg;
++};
++
++enum bcma_clkmode {
++	BCMA_CLKMODE_FAST,
++	BCMA_CLKMODE_DYNAMIC,
++};
++
++struct bcma_host_ops {
++	u8 (*read8)(struct bcma_device *core, u16 offset);
++	u16 (*read16)(struct bcma_device *core, u16 offset);
++	u32 (*read32)(struct bcma_device *core, u16 offset);
++	void (*write8)(struct bcma_device *core, u16 offset, u8 value);
++	void (*write16)(struct bcma_device *core, u16 offset, u16 value);
++	void (*write32)(struct bcma_device *core, u16 offset, u32 value);
++#ifdef CONFIG_BCMA_BLOCKIO
++	void (*block_read)(struct bcma_device *core, void *buffer,
++			   size_t count, u16 offset, u8 reg_width);
++	void (*block_write)(struct bcma_device *core, const void *buffer,
++			    size_t count, u16 offset, u8 reg_width);
++#endif
++	/* Agent ops */
++	u32 (*aread32)(struct bcma_device *core, u16 offset);
++	void (*awrite32)(struct bcma_device *core, u16 offset, u32 value);
++};
++
++/* Core manufacturers */
++#define BCMA_MANUF_ARM			0x43B
++#define BCMA_MANUF_MIPS			0x4A7
++#define BCMA_MANUF_BCM			0x4BF
++
++/* Core class values. */
++#define BCMA_CL_SIM			0x0
++#define BCMA_CL_EROM			0x1
++#define BCMA_CL_CORESIGHT		0x9
++#define BCMA_CL_VERIF			0xB
++#define BCMA_CL_OPTIMO			0xD
++#define BCMA_CL_GEN			0xE
++#define BCMA_CL_PRIMECELL		0xF
++
++/* Core-ID values. */
++#define BCMA_CORE_OOB_ROUTER		0x367	/* Out of band */
++#define BCMA_CORE_INVALID		0x700
++#define BCMA_CORE_CHIPCOMMON		0x800
++#define BCMA_CORE_ILINE20		0x801
++#define BCMA_CORE_SRAM			0x802
++#define BCMA_CORE_SDRAM			0x803
++#define BCMA_CORE_PCI			0x804
++#define BCMA_CORE_MIPS			0x805
++#define BCMA_CORE_ETHERNET		0x806
++#define BCMA_CORE_V90			0x807
++#define BCMA_CORE_USB11_HOSTDEV		0x808
++#define BCMA_CORE_ADSL			0x809
++#define BCMA_CORE_ILINE100		0x80A
++#define BCMA_CORE_IPSEC			0x80B
++#define BCMA_CORE_UTOPIA		0x80C
++#define BCMA_CORE_PCMCIA		0x80D
++#define BCMA_CORE_INTERNAL_MEM		0x80E
++#define BCMA_CORE_MEMC_SDRAM		0x80F
++#define BCMA_CORE_OFDM			0x810
++#define BCMA_CORE_EXTIF			0x811
++#define BCMA_CORE_80211			0x812
++#define BCMA_CORE_PHY_A			0x813
++#define BCMA_CORE_PHY_B			0x814
++#define BCMA_CORE_PHY_G			0x815
++#define BCMA_CORE_MIPS_3302		0x816
++#define BCMA_CORE_USB11_HOST		0x817
++#define BCMA_CORE_USB11_DEV		0x818
++#define BCMA_CORE_USB20_HOST		0x819
++#define BCMA_CORE_USB20_DEV		0x81A
++#define BCMA_CORE_SDIO_HOST		0x81B
++#define BCMA_CORE_ROBOSWITCH		0x81C
++#define BCMA_CORE_PARA_ATA		0x81D
++#define BCMA_CORE_SATA_XORDMA		0x81E
++#define BCMA_CORE_ETHERNET_GBIT		0x81F
++#define BCMA_CORE_PCIE			0x820
++#define BCMA_CORE_PHY_N			0x821
++#define BCMA_CORE_SRAM_CTL		0x822
++#define BCMA_CORE_MINI_MACPHY		0x823
++#define BCMA_CORE_ARM_1176		0x824
++#define BCMA_CORE_ARM_7TDMI		0x825
++#define BCMA_CORE_PHY_LP		0x826
++#define BCMA_CORE_PMU			0x827
++#define BCMA_CORE_PHY_SSN		0x828
++#define BCMA_CORE_SDIO_DEV		0x829
++#define BCMA_CORE_ARM_CM3		0x82A
++#define BCMA_CORE_PHY_HT		0x82B
++#define BCMA_CORE_MIPS_74K		0x82C
++#define BCMA_CORE_MAC_GBIT		0x82D
++#define BCMA_CORE_DDR12_MEM_CTL		0x82E
++#define BCMA_CORE_PCIE_RC		0x82F	/* PCIe Root Complex */
++#define BCMA_CORE_OCP_OCP_BRIDGE	0x830
++#define BCMA_CORE_SHARED_COMMON		0x831
++#define BCMA_CORE_OCP_AHB_BRIDGE	0x832
++#define BCMA_CORE_SPI_HOST		0x833
++#define BCMA_CORE_I2S			0x834
++#define BCMA_CORE_SDR_DDR1_MEM_CTL	0x835	/* SDR/DDR1 memory controller core */
++#define BCMA_CORE_SHIM			0x837	/* SHIM component in ubus/6362 */
++#define BCMA_CORE_DEFAULT		0xFFF
++
++#define BCMA_MAX_NR_CORES		16
++
++struct bcma_device {
++	struct bcma_bus *bus;
++	struct bcma_device_id id;
++
++	struct device dev;
++	struct device *dma_dev;
++
++	unsigned int irq;
++	bool dev_registered;
++
++	u8 core_index;
++	u8 core_unit;
++
++	u32 addr;
++	u32 wrap;
++
++	void __iomem *io_addr;
++	void __iomem *io_wrap;
++
++	void *drvdata;
++	struct list_head list;
++};
++
++static inline void *bcma_get_drvdata(struct bcma_device *core)
++{
++	return core->drvdata;
++}
++static inline void bcma_set_drvdata(struct bcma_device *core, void *drvdata)
++{
++	core->drvdata = drvdata;
++}
++
++struct bcma_driver {
++	const char *name;
++	const struct bcma_device_id *id_table;
++
++	int (*probe)(struct bcma_device *dev);
++	void (*remove)(struct bcma_device *dev);
++	int (*suspend)(struct bcma_device *dev);
++	int (*resume)(struct bcma_device *dev);
++	void (*shutdown)(struct bcma_device *dev);
++
++	struct device_driver drv;
++};
++extern
++int __bcma_driver_register(struct bcma_driver *drv, struct module *owner);
++#define bcma_driver_register(drv) \
++	__bcma_driver_register(drv, THIS_MODULE)
++
++extern void bcma_driver_unregister(struct bcma_driver *drv);
++
++/* Set a fallback SPROM.
++ * See kdoc at the function definition for complete documentation. */
++extern int bcma_arch_register_fallback_sprom(
++		int (*sprom_callback)(struct bcma_bus *bus,
++		struct ssb_sprom *out));
++
++struct bcma_bus {
++	/* The MMIO area. */
++	void __iomem *mmio;
++
++	const struct bcma_host_ops *ops;
++
++	enum bcma_hosttype hosttype;
++	union {
++		/* Pointer to the PCI bus (only for BCMA_HOSTTYPE_PCI) */
++		struct pci_dev *host_pci;
++		/* Pointer to the SDIO device (only for BCMA_HOSTTYPE_SDIO) */
++		struct sdio_func *host_sdio;
++	};
++
++	struct bcma_chipinfo chipinfo;
++
++	struct bcma_device *mapped_core;
++	struct list_head cores;
++	u8 nr_cores;
++	u8 init_done:1;
++	u8 num;
++
++	struct bcma_drv_cc drv_cc;
++	struct bcma_drv_pci drv_pci;
++	struct bcma_drv_mips drv_mips;
++
++	/* We decided to share SPROM struct with SSB as long as we do not need
++	 * any hacks for BCMA. This simplifies drivers code. */
++	struct ssb_sprom sprom;
++};
++
++static inline u32 bcma_read8(struct bcma_device *core, u16 offset)
++{
++	return core->bus->ops->read8(core, offset);
++}
++static inline u32 bcma_read16(struct bcma_device *core, u16 offset)
++{
++	return core->bus->ops->read16(core, offset);
++}
++static inline u32 bcma_read32(struct bcma_device *core, u16 offset)
++{
++	return core->bus->ops->read32(core, offset);
++}
++static inline
++void bcma_write8(struct bcma_device *core, u16 offset, u32 value)
++{
++	core->bus->ops->write8(core, offset, value);
++}
++static inline
++void bcma_write16(struct bcma_device *core, u16 offset, u32 value)
++{
++	core->bus->ops->write16(core, offset, value);
++}
++static inline
++void bcma_write32(struct bcma_device *core, u16 offset, u32 value)
++{
++	core->bus->ops->write32(core, offset, value);
++}
++#ifdef CONFIG_BCMA_BLOCKIO
++static inline void bcma_block_read(struct bcma_device *core, void *buffer,
++				   size_t count, u16 offset, u8 reg_width)
++{
++	core->bus->ops->block_read(core, buffer, count, offset, reg_width);
++}
++static inline void bcma_block_write(struct bcma_device *core,
++				    const void *buffer, size_t count,
++				    u16 offset, u8 reg_width)
++{
++	core->bus->ops->block_write(core, buffer, count, offset, reg_width);
++}
++#endif
++static inline u32 bcma_aread32(struct bcma_device *core, u16 offset)
++{
++	return core->bus->ops->aread32(core, offset);
++}
++static inline
++void bcma_awrite32(struct bcma_device *core, u16 offset, u32 value)
++{
++	core->bus->ops->awrite32(core, offset, value);
++}
++
++static inline void bcma_mask32(struct bcma_device *cc, u16 offset, u32 mask)
++{
++	bcma_write32(cc, offset, bcma_read32(cc, offset) & mask);
++}
++static inline void bcma_set32(struct bcma_device *cc, u16 offset, u32 set)
++{
++	bcma_write32(cc, offset, bcma_read32(cc, offset) | set);
++}
++static inline void bcma_maskset32(struct bcma_device *cc,
++				  u16 offset, u32 mask, u32 set)
++{
++	bcma_write32(cc, offset, (bcma_read32(cc, offset) & mask) | set);
++}
++static inline void bcma_mask16(struct bcma_device *cc, u16 offset, u16 mask)
++{
++	bcma_write16(cc, offset, bcma_read16(cc, offset) & mask);
++}
++static inline void bcma_set16(struct bcma_device *cc, u16 offset, u16 set)
++{
++	bcma_write16(cc, offset, bcma_read16(cc, offset) | set);
++}
++static inline void bcma_maskset16(struct bcma_device *cc,
++				  u16 offset, u16 mask, u16 set)
++{
++	bcma_write16(cc, offset, (bcma_read16(cc, offset) & mask) | set);
++}
++
++extern struct bcma_device *bcma_find_core(struct bcma_bus *bus, u16 coreid);
++extern bool bcma_core_is_enabled(struct bcma_device *core);
++extern void bcma_core_disable(struct bcma_device *core, u32 flags);
++extern int bcma_core_enable(struct bcma_device *core, u32 flags);
++extern void bcma_core_set_clockmode(struct bcma_device *core,
++				    enum bcma_clkmode clkmode);
++extern void bcma_core_pll_ctl(struct bcma_device *core, u32 req, u32 status,
++			      bool on);
++#define BCMA_DMA_TRANSLATION_MASK	0xC0000000
++#define  BCMA_DMA_TRANSLATION_NONE	0x00000000
++#define  BCMA_DMA_TRANSLATION_DMA32_CMT	0x40000000 /* Client Mode Translation for 32-bit DMA */
++#define  BCMA_DMA_TRANSLATION_DMA64_CMT	0x80000000 /* Client Mode Translation for 64-bit DMA */
++extern u32 bcma_core_dma_translation(struct bcma_device *core);
++
++#endif /* LINUX_BCMA_H_ */
+--- /dev/null
++++ b/include/linux/bcma/bcma_driver_chipcommon.h
+@@ -0,0 +1,415 @@
++#ifndef LINUX_BCMA_DRIVER_CC_H_
++#define LINUX_BCMA_DRIVER_CC_H_
++
++/** ChipCommon core registers. **/
++#define BCMA_CC_ID			0x0000
++#define  BCMA_CC_ID_ID			0x0000FFFF
++#define  BCMA_CC_ID_ID_SHIFT		0
++#define  BCMA_CC_ID_REV			0x000F0000
++#define  BCMA_CC_ID_REV_SHIFT		16
++#define  BCMA_CC_ID_PKG			0x00F00000
++#define  BCMA_CC_ID_PKG_SHIFT		20
++#define  BCMA_CC_ID_NRCORES		0x0F000000
++#define  BCMA_CC_ID_NRCORES_SHIFT	24
++#define  BCMA_CC_ID_TYPE		0xF0000000
++#define  BCMA_CC_ID_TYPE_SHIFT		28
++#define BCMA_CC_CAP			0x0004		/* Capabilities */
++#define  BCMA_CC_CAP_NRUART		0x00000003	/* # of UARTs */
++#define  BCMA_CC_CAP_MIPSEB		0x00000004	/* MIPS in BigEndian Mode */
++#define  BCMA_CC_CAP_UARTCLK		0x00000018	/* UART clock select */
++#define   BCMA_CC_CAP_UARTCLK_INT	0x00000008	/* UARTs are driven by internal divided clock */
++#define  BCMA_CC_CAP_UARTGPIO		0x00000020	/* UARTs on GPIO 15-12 */
++#define  BCMA_CC_CAP_EXTBUS		0x000000C0	/* External buses present */
++#define  BCMA_CC_CAP_FLASHT		0x00000700	/* Flash Type */
++#define   BCMA_CC_FLASHT_NONE		0x00000000	/* No flash */
++#define   BCMA_CC_FLASHT_STSER		0x00000100	/* ST serial flash */
++#define   BCMA_CC_FLASHT_ATSER		0x00000200	/* Atmel serial flash */
++#define   BCMA_CC_FLASHT_NFLASH		0x00000200
++#define	  BCMA_CC_FLASHT_PARA		0x00000700	/* Parallel flash */
++#define  BCMA_CC_CAP_PLLT		0x00038000	/* PLL Type */
++#define   BCMA_PLLTYPE_NONE		0x00000000
++#define   BCMA_PLLTYPE_1		0x00010000	/* 48Mhz base, 3 dividers */
++#define   BCMA_PLLTYPE_2		0x00020000	/* 48Mhz, 4 dividers */
++#define   BCMA_PLLTYPE_3		0x00030000	/* 25Mhz, 2 dividers */
++#define   BCMA_PLLTYPE_4		0x00008000	/* 48Mhz, 4 dividers */
++#define   BCMA_PLLTYPE_5		0x00018000	/* 25Mhz, 4 dividers */
++#define   BCMA_PLLTYPE_6		0x00028000	/* 100/200 or 120/240 only */
++#define   BCMA_PLLTYPE_7		0x00038000	/* 25Mhz, 4 dividers */
++#define  BCMA_CC_CAP_PCTL		0x00040000	/* Power Control */
++#define  BCMA_CC_CAP_OTPS		0x00380000	/* OTP size */
++#define  BCMA_CC_CAP_OTPS_SHIFT		19
++#define  BCMA_CC_CAP_OTPS_BASE		5
++#define  BCMA_CC_CAP_JTAGM		0x00400000	/* JTAG master present */
++#define  BCMA_CC_CAP_BROM		0x00800000	/* Internal boot ROM active */
++#define  BCMA_CC_CAP_64BIT		0x08000000	/* 64-bit Backplane */
++#define  BCMA_CC_CAP_PMU		0x10000000	/* PMU available (rev >= 20) */
++#define  BCMA_CC_CAP_ECI		0x20000000	/* ECI available (rev >= 20) */
++#define  BCMA_CC_CAP_SPROM		0x40000000	/* SPROM present */
++#define BCMA_CC_CORECTL			0x0008
++#define  BCMA_CC_CORECTL_UARTCLK0	0x00000001	/* Drive UART with internal clock */
++#define	 BCMA_CC_CORECTL_SE		0x00000002	/* sync clk out enable (corerev >= 3) */
++#define  BCMA_CC_CORECTL_UARTCLKEN	0x00000008	/* UART clock enable (rev >= 21) */
++#define BCMA_CC_BIST			0x000C
++#define BCMA_CC_OTPS			0x0010		/* OTP status */
++#define	 BCMA_CC_OTPS_PROGFAIL		0x80000000
++#define	 BCMA_CC_OTPS_PROTECT		0x00000007
++#define	 BCMA_CC_OTPS_HW_PROTECT	0x00000001
++#define	 BCMA_CC_OTPS_SW_PROTECT	0x00000002
++#define	 BCMA_CC_OTPS_CID_PROTECT	0x00000004
++#define  BCMA_CC_OTPS_GU_PROG_IND	0x00000F00	/* General Use programmed indication */
++#define  BCMA_CC_OTPS_GU_PROG_IND_SHIFT	8
++#define  BCMA_CC_OTPS_GU_PROG_HW	0x00000100	/* HW region programmed */
++#define BCMA_CC_OTPC			0x0014		/* OTP control */
++#define	 BCMA_CC_OTPC_RECWAIT		0xFF000000
++#define	 BCMA_CC_OTPC_PROGWAIT		0x00FFFF00
++#define	 BCMA_CC_OTPC_PRW_SHIFT		8
++#define	 BCMA_CC_OTPC_MAXFAIL		0x00000038
++#define	 BCMA_CC_OTPC_VSEL		0x00000006
++#define	 BCMA_CC_OTPC_SELVL		0x00000001
++#define BCMA_CC_OTPP			0x0018		/* OTP prog */
++#define	 BCMA_CC_OTPP_COL		0x000000FF
++#define	 BCMA_CC_OTPP_ROW		0x0000FF00
++#define	 BCMA_CC_OTPP_ROW_SHIFT		8
++#define	 BCMA_CC_OTPP_READERR		0x10000000
++#define	 BCMA_CC_OTPP_VALUE		0x20000000
++#define	 BCMA_CC_OTPP_READ		0x40000000
++#define	 BCMA_CC_OTPP_START		0x80000000
++#define	 BCMA_CC_OTPP_BUSY		0x80000000
++#define BCMA_CC_OTPL			0x001C		/* OTP layout */
++#define  BCMA_CC_OTPL_GURGN_OFFSET	0x00000FFF	/* offset of general use region */
++#define BCMA_CC_IRQSTAT			0x0020
++#define BCMA_CC_IRQMASK			0x0024
++#define	 BCMA_CC_IRQ_GPIO		0x00000001	/* gpio intr */
++#define	 BCMA_CC_IRQ_EXT		0x00000002	/* ro: ext intr pin (corerev >= 3) */
++#define	 BCMA_CC_IRQ_WDRESET		0x80000000	/* watchdog reset occurred */
++#define BCMA_CC_CHIPCTL			0x0028		/* Rev >= 11 only */
++#define BCMA_CC_CHIPSTAT		0x002C		/* Rev >= 11 only */
++#define  BCMA_CC_CHIPST_4313_SPROM_PRESENT	1
++#define  BCMA_CC_CHIPST_4313_OTP_PRESENT	2
++#define  BCMA_CC_CHIPST_4331_SPROM_PRESENT	2
++#define  BCMA_CC_CHIPST_4331_OTP_PRESENT	4
++#define BCMA_CC_JCMD			0x0030		/* Rev >= 10 only */
++#define  BCMA_CC_JCMD_START		0x80000000
++#define  BCMA_CC_JCMD_BUSY		0x80000000
++#define  BCMA_CC_JCMD_PAUSE		0x40000000
++#define  BCMA_CC_JCMD0_ACC_MASK		0x0000F000
++#define  BCMA_CC_JCMD0_ACC_IRDR		0x00000000
++#define  BCMA_CC_JCMD0_ACC_DR		0x00001000
++#define  BCMA_CC_JCMD0_ACC_IR		0x00002000
++#define  BCMA_CC_JCMD0_ACC_RESET	0x00003000
++#define  BCMA_CC_JCMD0_ACC_IRPDR	0x00004000
++#define  BCMA_CC_JCMD0_ACC_PDR		0x00005000
++#define  BCMA_CC_JCMD0_IRW_MASK		0x00000F00
++#define  BCMA_CC_JCMD_ACC_MASK		0x000F0000	/* Changes for corerev 11 */
++#define  BCMA_CC_JCMD_ACC_IRDR		0x00000000
++#define  BCMA_CC_JCMD_ACC_DR		0x00010000
++#define  BCMA_CC_JCMD_ACC_IR		0x00020000
++#define  BCMA_CC_JCMD_ACC_RESET		0x00030000
++#define  BCMA_CC_JCMD_ACC_IRPDR		0x00040000
++#define  BCMA_CC_JCMD_ACC_PDR		0x00050000
++#define  BCMA_CC_JCMD_IRW_MASK		0x00001F00
++#define  BCMA_CC_JCMD_IRW_SHIFT		8
++#define  BCMA_CC_JCMD_DRW_MASK		0x0000003F
++#define BCMA_CC_JIR			0x0034		/* Rev >= 10 only */
++#define BCMA_CC_JDR			0x0038		/* Rev >= 10 only */
++#define BCMA_CC_JCTL			0x003C		/* Rev >= 10 only */
++#define  BCMA_CC_JCTL_FORCE_CLK		4		/* Force clock */
++#define  BCMA_CC_JCTL_EXT_EN		2		/* Enable external targets */
++#define  BCMA_CC_JCTL_EN		1		/* Enable Jtag master */
++#define BCMA_CC_FLASHCTL		0x0040
++#define  BCMA_CC_FLASHCTL_START		0x80000000
++#define  BCMA_CC_FLASHCTL_BUSY		BCMA_CC_FLASHCTL_START
++#define BCMA_CC_FLASHADDR		0x0044
++#define BCMA_CC_FLASHDATA		0x0048
++#define BCMA_CC_BCAST_ADDR		0x0050
++#define BCMA_CC_BCAST_DATA		0x0054
++#define BCMA_CC_GPIOPULLUP		0x0058		/* Rev >= 20 only */
++#define BCMA_CC_GPIOPULLDOWN		0x005C		/* Rev >= 20 only */
++#define BCMA_CC_GPIOIN			0x0060
++#define BCMA_CC_GPIOOUT			0x0064
++#define BCMA_CC_GPIOOUTEN		0x0068
++#define BCMA_CC_GPIOCTL			0x006C
++#define BCMA_CC_GPIOPOL			0x0070
++#define BCMA_CC_GPIOIRQ			0x0074
++#define BCMA_CC_WATCHDOG		0x0080
++#define BCMA_CC_GPIOTIMER		0x0088		/* LED powersave (corerev >= 16) */
++#define  BCMA_CC_GPIOTIMER_OFFTIME	0x0000FFFF
++#define  BCMA_CC_GPIOTIMER_OFFTIME_SHIFT	0
++#define  BCMA_CC_GPIOTIMER_ONTIME	0xFFFF0000
++#define  BCMA_CC_GPIOTIMER_ONTIME_SHIFT	16
++#define BCMA_CC_GPIOTOUTM		0x008C		/* LED powersave (corerev >= 16) */
++#define BCMA_CC_CLOCK_N			0x0090
++#define BCMA_CC_CLOCK_SB		0x0094
++#define BCMA_CC_CLOCK_PCI		0x0098
++#define BCMA_CC_CLOCK_M2		0x009C
++#define BCMA_CC_CLOCK_MIPS		0x00A0
++#define BCMA_CC_CLKDIV			0x00A4		/* Rev >= 3 only */
++#define	 BCMA_CC_CLKDIV_SFLASH		0x0F000000
++#define	 BCMA_CC_CLKDIV_SFLASH_SHIFT	24
++#define	 BCMA_CC_CLKDIV_OTP		0x000F0000
++#define	 BCMA_CC_CLKDIV_OTP_SHIFT	16
++#define	 BCMA_CC_CLKDIV_JTAG		0x00000F00
++#define	 BCMA_CC_CLKDIV_JTAG_SHIFT	8
++#define	 BCMA_CC_CLKDIV_UART		0x000000FF
++#define BCMA_CC_CAP_EXT			0x00AC		/* Capabilities */
++#define BCMA_CC_PLLONDELAY		0x00B0		/* Rev >= 4 only */
++#define BCMA_CC_FREFSELDELAY		0x00B4		/* Rev >= 4 only */
++#define BCMA_CC_SLOWCLKCTL		0x00B8		/* 6 <= Rev <= 9 only */
++#define  BCMA_CC_SLOWCLKCTL_SRC		0x00000007	/* slow clock source mask */
++#define	  BCMA_CC_SLOWCLKCTL_SRC_LPO	0x00000000	/* source of slow clock is LPO */
++#define   BCMA_CC_SLOWCLKCTL_SRC_XTAL	0x00000001	/* source of slow clock is crystal */
++#define	  BCMA_CC_SLOECLKCTL_SRC_PCI	0x00000002	/* source of slow clock is PCI */
++#define  BCMA_CC_SLOWCLKCTL_LPOFREQ	0x00000200	/* LPOFreqSel, 1: 160Khz, 0: 32KHz */
++#define  BCMA_CC_SLOWCLKCTL_LPOPD	0x00000400	/* LPOPowerDown, 1: LPO is disabled, 0: LPO is enabled */
++#define  BCMA_CC_SLOWCLKCTL_FSLOW	0x00000800	/* ForceSlowClk, 1: sb/cores running on slow clock, 0: power logic control */
++#define  BCMA_CC_SLOWCLKCTL_IPLL	0x00001000	/* IgnorePllOffReq, 1/0: power logic ignores/honors PLL clock disable requests from core */
++#define  BCMA_CC_SLOWCLKCTL_ENXTAL	0x00002000	/* XtalControlEn, 1/0: power logic does/doesn't disable crystal when appropriate */
++#define  BCMA_CC_SLOWCLKCTL_XTALPU	0x00004000	/* XtalPU (RO), 1/0: crystal running/disabled */
++#define  BCMA_CC_SLOWCLKCTL_CLKDIV	0xFFFF0000	/* ClockDivider (SlowClk = 1/(4+divisor)) */
++#define  BCMA_CC_SLOWCLKCTL_CLKDIV_SHIFT	16
++#define BCMA_CC_SYSCLKCTL		0x00C0		/* Rev >= 3 only */
++#define	 BCMA_CC_SYSCLKCTL_IDLPEN	0x00000001	/* ILPen: Enable Idle Low Power */
++#define	 BCMA_CC_SYSCLKCTL_ALPEN	0x00000002	/* ALPen: Enable Active Low Power */
++#define	 BCMA_CC_SYSCLKCTL_PLLEN	0x00000004	/* ForcePLLOn */
++#define	 BCMA_CC_SYSCLKCTL_FORCEALP	0x00000008	/* Force ALP (or HT if ALPen is not set */
++#define	 BCMA_CC_SYSCLKCTL_FORCEHT	0x00000010	/* Force HT */
++#define  BCMA_CC_SYSCLKCTL_CLKDIV	0xFFFF0000	/* ClkDiv  (ILP = 1/(4+divisor)) */
++#define  BCMA_CC_SYSCLKCTL_CLKDIV_SHIFT	16
++#define BCMA_CC_CLKSTSTR		0x00C4		/* Rev >= 3 only */
++#define BCMA_CC_EROM			0x00FC
++#define BCMA_CC_PCMCIA_CFG		0x0100
++#define BCMA_CC_PCMCIA_MEMWAIT		0x0104
++#define BCMA_CC_PCMCIA_ATTRWAIT		0x0108
++#define BCMA_CC_PCMCIA_IOWAIT		0x010C
++#define BCMA_CC_IDE_CFG			0x0110
++#define BCMA_CC_IDE_MEMWAIT		0x0114
++#define BCMA_CC_IDE_ATTRWAIT		0x0118
++#define BCMA_CC_IDE_IOWAIT		0x011C
++#define BCMA_CC_PROG_CFG		0x0120
++#define BCMA_CC_PROG_WAITCNT		0x0124
++#define BCMA_CC_FLASH_CFG		0x0128
++#define  BCMA_CC_FLASH_CFG_DS		0x0010	/* Data size, 0=8bit, 1=16bit */
++#define BCMA_CC_FLASH_WAITCNT		0x012C
++#define BCMA_CC_SROM_CONTROL		0x0190
++#define  BCMA_CC_SROM_CONTROL_START	0x80000000
++#define  BCMA_CC_SROM_CONTROL_BUSY	0x80000000
++#define  BCMA_CC_SROM_CONTROL_OPCODE	0x60000000
++#define  BCMA_CC_SROM_CONTROL_OP_READ	0x00000000
++#define  BCMA_CC_SROM_CONTROL_OP_WRITE	0x20000000
++#define  BCMA_CC_SROM_CONTROL_OP_WRDIS	0x40000000
++#define  BCMA_CC_SROM_CONTROL_OP_WREN	0x60000000
++#define  BCMA_CC_SROM_CONTROL_OTPSEL	0x00000010
++#define  BCMA_CC_SROM_CONTROL_LOCK	0x00000008
++#define  BCMA_CC_SROM_CONTROL_SIZE_MASK	0x00000006
++#define  BCMA_CC_SROM_CONTROL_SIZE_1K	0x00000000
++#define  BCMA_CC_SROM_CONTROL_SIZE_4K	0x00000002
++#define  BCMA_CC_SROM_CONTROL_SIZE_16K	0x00000004
++#define  BCMA_CC_SROM_CONTROL_SIZE_SHIFT	1
++#define  BCMA_CC_SROM_CONTROL_PRESENT	0x00000001
++/* 0x1E0 is defined as shared BCMA_CLKCTLST */
++#define BCMA_CC_HW_WORKAROUND		0x01E4 /* Hardware workaround (rev >= 20) */
++#define BCMA_CC_UART0_DATA		0x0300
++#define BCMA_CC_UART0_IMR		0x0304
++#define BCMA_CC_UART0_FCR		0x0308
++#define BCMA_CC_UART0_LCR		0x030C
++#define BCMA_CC_UART0_MCR		0x0310
++#define BCMA_CC_UART0_LSR		0x0314
++#define BCMA_CC_UART0_MSR		0x0318
++#define BCMA_CC_UART0_SCRATCH		0x031C
++#define BCMA_CC_UART1_DATA		0x0400
++#define BCMA_CC_UART1_IMR		0x0404
++#define BCMA_CC_UART1_FCR		0x0408
++#define BCMA_CC_UART1_LCR		0x040C
++#define BCMA_CC_UART1_MCR		0x0410
++#define BCMA_CC_UART1_LSR		0x0414
++#define BCMA_CC_UART1_MSR		0x0418
++#define BCMA_CC_UART1_SCRATCH		0x041C
++/* PMU registers (rev >= 20) */
++#define BCMA_CC_PMU_CTL			0x0600 /* PMU control */
++#define  BCMA_CC_PMU_CTL_ILP_DIV	0xFFFF0000 /* ILP div mask */
++#define  BCMA_CC_PMU_CTL_ILP_DIV_SHIFT	16
++#define  BCMA_CC_PMU_CTL_PLL_UPD	0x00000400
++#define  BCMA_CC_PMU_CTL_NOILPONW	0x00000200 /* No ILP on wait */
++#define  BCMA_CC_PMU_CTL_HTREQEN	0x00000100 /* HT req enable */
++#define  BCMA_CC_PMU_CTL_ALPREQEN	0x00000080 /* ALP req enable */
++#define  BCMA_CC_PMU_CTL_XTALFREQ	0x0000007C /* Crystal freq */
++#define  BCMA_CC_PMU_CTL_XTALFREQ_SHIFT	2
++#define  BCMA_CC_PMU_CTL_ILPDIVEN	0x00000002 /* ILP div enable */
++#define  BCMA_CC_PMU_CTL_LPOSEL		0x00000001 /* LPO sel */
++#define BCMA_CC_PMU_CAP			0x0604 /* PMU capabilities */
++#define  BCMA_CC_PMU_CAP_REVISION	0x000000FF /* Revision mask */
++#define BCMA_CC_PMU_STAT		0x0608 /* PMU status */
++#define  BCMA_CC_PMU_STAT_INTPEND	0x00000040 /* Interrupt pending */
++#define  BCMA_CC_PMU_STAT_SBCLKST	0x00000030 /* Backplane clock status? */
++#define  BCMA_CC_PMU_STAT_HAVEALP	0x00000008 /* ALP available */
++#define  BCMA_CC_PMU_STAT_HAVEHT	0x00000004 /* HT available */
++#define  BCMA_CC_PMU_STAT_RESINIT	0x00000003 /* Res init */
++#define BCMA_CC_PMU_RES_STAT		0x060C /* PMU res status */
++#define BCMA_CC_PMU_RES_PEND		0x0610 /* PMU res pending */
++#define BCMA_CC_PMU_TIMER		0x0614 /* PMU timer */
++#define BCMA_CC_PMU_MINRES_MSK		0x0618 /* PMU min res mask */
++#define BCMA_CC_PMU_MAXRES_MSK		0x061C /* PMU max res mask */
++#define BCMA_CC_PMU_RES_TABSEL		0x0620 /* PMU res table sel */
++#define BCMA_CC_PMU_RES_DEPMSK		0x0624 /* PMU res dep mask */
++#define BCMA_CC_PMU_RES_UPDNTM		0x0628 /* PMU res updown timer */
++#define BCMA_CC_PMU_RES_TIMER		0x062C /* PMU res timer */
++#define BCMA_CC_PMU_CLKSTRETCH		0x0630 /* PMU clockstretch */
++#define BCMA_CC_PMU_WATCHDOG		0x0634 /* PMU watchdog */
++#define BCMA_CC_PMU_RES_REQTS		0x0640 /* PMU res req timer sel */
++#define BCMA_CC_PMU_RES_REQT		0x0644 /* PMU res req timer */
++#define BCMA_CC_PMU_RES_REQM		0x0648 /* PMU res req mask */
++#define BCMA_CC_CHIPCTL_ADDR		0x0650
++#define BCMA_CC_CHIPCTL_DATA		0x0654
++#define BCMA_CC_REGCTL_ADDR		0x0658
++#define BCMA_CC_REGCTL_DATA		0x065C
++#define BCMA_CC_PLLCTL_ADDR		0x0660
++#define BCMA_CC_PLLCTL_DATA		0x0664
++#define BCMA_CC_SPROM			0x0800 /* SPROM beginning */
++
++/* Divider allocation in 4716/47162/5356 */
++#define BCMA_CC_PMU5_MAINPLL_CPU	1
++#define BCMA_CC_PMU5_MAINPLL_MEM	2
++#define BCMA_CC_PMU5_MAINPLL_SSB	3
++
++/* PLL usage in 4716/47162 */
++#define BCMA_CC_PMU4716_MAINPLL_PLL0	12
++
++/* PLL usage in 5356/5357 */
++#define BCMA_CC_PMU5356_MAINPLL_PLL0	0
++#define BCMA_CC_PMU5357_MAINPLL_PLL0	0
++
++/* 4706 PMU */
++#define BCMA_CC_PMU4706_MAINPLL_PLL0	0
++
++/* ALP clock on pre-PMU chips */
++#define BCMA_CC_PMU_ALP_CLOCK		20000000
++/* HT clock for systems with PMU-enabled chipcommon */
++#define BCMA_CC_PMU_HT_CLOCK		80000000
++
++/* PMU rev 5 (& 6) */
++#define BCMA_CC_PPL_P1P2_OFF		0
++#define BCMA_CC_PPL_P1_MASK		0x0f000000
++#define BCMA_CC_PPL_P1_SHIFT		24
++#define BCMA_CC_PPL_P2_MASK		0x00f00000
++#define BCMA_CC_PPL_P2_SHIFT		20
++#define BCMA_CC_PPL_M14_OFF		1
++#define BCMA_CC_PPL_MDIV_MASK		0x000000ff
++#define BCMA_CC_PPL_MDIV_WIDTH		8
++#define BCMA_CC_PPL_NM5_OFF		2
++#define BCMA_CC_PPL_NDIV_MASK		0xfff00000
++#define BCMA_CC_PPL_NDIV_SHIFT		20
++#define BCMA_CC_PPL_FMAB_OFF		3
++#define BCMA_CC_PPL_MRAT_MASK		0xf0000000
++#define BCMA_CC_PPL_MRAT_SHIFT		28
++#define BCMA_CC_PPL_ABRAT_MASK		0x08000000
++#define BCMA_CC_PPL_ABRAT_SHIFT		27
++#define BCMA_CC_PPL_FDIV_MASK		0x07ffffff
++#define BCMA_CC_PPL_PLLCTL_OFF		4
++#define BCMA_CC_PPL_PCHI_OFF		5
++#define BCMA_CC_PPL_PCHI_MASK		0x0000003f
++
++/* BCM4331 ChipControl numbers. */
++#define BCMA_CHIPCTL_4331_BT_COEXIST		BIT(0)	/* 0 disable */
++#define BCMA_CHIPCTL_4331_SECI			BIT(1)	/* 0 SECI is disabled (JATG functional) */
++#define BCMA_CHIPCTL_4331_EXT_LNA		BIT(2)	/* 0 disable */
++#define BCMA_CHIPCTL_4331_SPROM_GPIO13_15	BIT(3)	/* sprom/gpio13-15 mux */
++#define BCMA_CHIPCTL_4331_EXTPA_EN		BIT(4)	/* 0 ext pa disable, 1 ext pa enabled */
++#define BCMA_CHIPCTL_4331_GPIOCLK_ON_SPROMCS	BIT(5)	/* set drive out GPIO_CLK on sprom_cs pin */
++#define BCMA_CHIPCTL_4331_PCIE_MDIO_ON_SPROMCS	BIT(6)	/* use sprom_cs pin as PCIE mdio interface */
++#define BCMA_CHIPCTL_4331_EXTPA_ON_GPIO2_5	BIT(7)	/* aband extpa will be at gpio2/5 and sprom_dout */
++#define BCMA_CHIPCTL_4331_OVR_PIPEAUXCLKEN	BIT(8)	/* override core control on pipe_AuxClkEnable */
++#define BCMA_CHIPCTL_4331_OVR_PIPEAUXPWRDOWN	BIT(9)	/* override core control on pipe_AuxPowerDown */
++#define BCMA_CHIPCTL_4331_PCIE_AUXCLKEN		BIT(10)	/* pcie_auxclkenable */
++#define BCMA_CHIPCTL_4331_PCIE_PIPE_PLLDOWN	BIT(11)	/* pcie_pipe_pllpowerdown */
++#define BCMA_CHIPCTL_4331_BT_SHD0_ON_GPIO4	BIT(16)	/* enable bt_shd0 at gpio4 */
++#define BCMA_CHIPCTL_4331_BT_SHD1_ON_GPIO5	BIT(17)	/* enable bt_shd1 at gpio5 */
++
++/* Data for the PMU, if available.
++ * Check availability with ((struct bcma_chipcommon)->capabilities & BCMA_CC_CAP_PMU)
++ */
++struct bcma_chipcommon_pmu {
++	u8 rev;			/* PMU revision */
++	u32 crystalfreq;	/* The active crystal frequency (in kHz) */
++};
++
++#ifdef CONFIG_BCMA_DRIVER_MIPS
++struct bcma_pflash {
++	u8 buswidth;
++	u32 window;
++	u32 window_size;
++};
++
++struct bcma_serial_port {
++	void *regs;
++	unsigned long clockspeed;
++	unsigned int irq;
++	unsigned int baud_base;
++	unsigned int reg_shift;
++};
++#endif /* CONFIG_BCMA_DRIVER_MIPS */
++
++struct bcma_drv_cc {
++	struct bcma_device *core;
++	u32 status;
++	u32 capabilities;
++	u32 capabilities_ext;
++	u8 setup_done:1;
++	/* Fast Powerup Delay constant */
++	u16 fast_pwrup_delay;
++	struct bcma_chipcommon_pmu pmu;
++#ifdef CONFIG_BCMA_DRIVER_MIPS
++	struct bcma_pflash pflash;
++
++	int nr_serial_ports;
++	struct bcma_serial_port serial_ports[4];
++#endif /* CONFIG_BCMA_DRIVER_MIPS */
++};
++
++/* Register access */
++#define bcma_cc_read32(cc, offset) \
++	bcma_read32((cc)->core, offset)
++#define bcma_cc_write32(cc, offset, val) \
++	bcma_write32((cc)->core, offset, val)
++
++#define bcma_cc_mask32(cc, offset, mask) \
++	bcma_cc_write32(cc, offset, bcma_cc_read32(cc, offset) & (mask))
++#define bcma_cc_set32(cc, offset, set) \
++	bcma_cc_write32(cc, offset, bcma_cc_read32(cc, offset) | (set))
++#define bcma_cc_maskset32(cc, offset, mask, set) \
++	bcma_cc_write32(cc, offset, (bcma_cc_read32(cc, offset) & (mask)) | (set))
++
++extern void bcma_core_chipcommon_init(struct bcma_drv_cc *cc);
++
++extern void bcma_chipco_suspend(struct bcma_drv_cc *cc);
++extern void bcma_chipco_resume(struct bcma_drv_cc *cc);
++
++void bcma_chipco_bcm4331_ext_pa_lines_ctl(struct bcma_drv_cc *cc, bool enable);
++
++extern void bcma_chipco_watchdog_timer_set(struct bcma_drv_cc *cc,
++					  u32 ticks);
++
++void bcma_chipco_irq_mask(struct bcma_drv_cc *cc, u32 mask, u32 value);
++
++u32 bcma_chipco_irq_status(struct bcma_drv_cc *cc, u32 mask);
++
++/* Chipcommon GPIO pin access. */
++u32 bcma_chipco_gpio_in(struct bcma_drv_cc *cc, u32 mask);
++u32 bcma_chipco_gpio_out(struct bcma_drv_cc *cc, u32 mask, u32 value);
++u32 bcma_chipco_gpio_outen(struct bcma_drv_cc *cc, u32 mask, u32 value);
++u32 bcma_chipco_gpio_control(struct bcma_drv_cc *cc, u32 mask, u32 value);
++u32 bcma_chipco_gpio_intmask(struct bcma_drv_cc *cc, u32 mask, u32 value);
++u32 bcma_chipco_gpio_polarity(struct bcma_drv_cc *cc, u32 mask, u32 value);
++
++/* PMU support */
++extern void bcma_pmu_init(struct bcma_drv_cc *cc);
++
++extern void bcma_chipco_pll_write(struct bcma_drv_cc *cc, u32 offset,
++				  u32 value);
++extern void bcma_chipco_pll_maskset(struct bcma_drv_cc *cc, u32 offset,
++				    u32 mask, u32 set);
++extern void bcma_chipco_chipctl_maskset(struct bcma_drv_cc *cc,
++					u32 offset, u32 mask, u32 set);
++extern void bcma_chipco_regctl_maskset(struct bcma_drv_cc *cc,
++				       u32 offset, u32 mask, u32 set);
++
++#endif /* LINUX_BCMA_DRIVER_CC_H_ */
+--- /dev/null
++++ b/include/linux/bcma/bcma_driver_pci.h
+@@ -0,0 +1,214 @@
++#ifndef LINUX_BCMA_DRIVER_PCI_H_
++#define LINUX_BCMA_DRIVER_PCI_H_
++
++#include <linux/types.h>
++
++struct pci_dev;
++
++/** PCI core registers. **/
++#define BCMA_CORE_PCI_CTL			0x0000	/* PCI Control */
++#define  BCMA_CORE_PCI_CTL_RST_OE		0x00000001 /* PCI_RESET Output Enable */
++#define  BCMA_CORE_PCI_CTL_RST			0x00000002 /* PCI_RESET driven out to pin */
++#define  BCMA_CORE_PCI_CTL_CLK_OE		0x00000004 /* Clock gate Output Enable */
++#define  BCMA_CORE_PCI_CTL_CLK			0x00000008 /* Gate for clock driven out to pin */
++#define BCMA_CORE_PCI_ARBCTL			0x0010	/* PCI Arbiter Control */
++#define  BCMA_CORE_PCI_ARBCTL_INTERN		0x00000001 /* Use internal arbiter */
++#define  BCMA_CORE_PCI_ARBCTL_EXTERN		0x00000002 /* Use external arbiter */
++#define  BCMA_CORE_PCI_ARBCTL_PARKID		0x00000006 /* Mask, selects which agent is parked on an idle bus */
++#define   BCMA_CORE_PCI_ARBCTL_PARKID_LAST	0x00000000 /* Last requestor */
++#define   BCMA_CORE_PCI_ARBCTL_PARKID_4710	0x00000002 /* 4710 */
++#define   BCMA_CORE_PCI_ARBCTL_PARKID_EXT0	0x00000004 /* External requestor 0 */
++#define   BCMA_CORE_PCI_ARBCTL_PARKID_EXT1	0x00000006 /* External requestor 1 */
++#define BCMA_CORE_PCI_ISTAT			0x0020	/* Interrupt status */
++#define  BCMA_CORE_PCI_ISTAT_INTA		0x00000001 /* PCI INTA# */
++#define  BCMA_CORE_PCI_ISTAT_INTB		0x00000002 /* PCI INTB# */
++#define  BCMA_CORE_PCI_ISTAT_SERR		0x00000004 /* PCI SERR# (write to clear) */
++#define  BCMA_CORE_PCI_ISTAT_PERR		0x00000008 /* PCI PERR# (write to clear) */
++#define  BCMA_CORE_PCI_ISTAT_PME		0x00000010 /* PCI PME# */
++#define BCMA_CORE_PCI_IMASK			0x0024	/* Interrupt mask */
++#define  BCMA_CORE_PCI_IMASK_INTA		0x00000001 /* PCI INTA# */
++#define  BCMA_CORE_PCI_IMASK_INTB		0x00000002 /* PCI INTB# */
++#define  BCMA_CORE_PCI_IMASK_SERR		0x00000004 /* PCI SERR# */
++#define  BCMA_CORE_PCI_IMASK_PERR		0x00000008 /* PCI PERR# */
++#define  BCMA_CORE_PCI_IMASK_PME		0x00000010 /* PCI PME# */
++#define BCMA_CORE_PCI_MBOX			0x0028	/* Backplane to PCI Mailbox */
++#define  BCMA_CORE_PCI_MBOX_F0_0		0x00000100 /* PCI function 0, INT 0 */
++#define  BCMA_CORE_PCI_MBOX_F0_1		0x00000200 /* PCI function 0, INT 1 */
++#define  BCMA_CORE_PCI_MBOX_F1_0		0x00000400 /* PCI function 1, INT 0 */
++#define  BCMA_CORE_PCI_MBOX_F1_1		0x00000800 /* PCI function 1, INT 1 */
++#define  BCMA_CORE_PCI_MBOX_F2_0		0x00001000 /* PCI function 2, INT 0 */
++#define  BCMA_CORE_PCI_MBOX_F2_1		0x00002000 /* PCI function 2, INT 1 */
++#define  BCMA_CORE_PCI_MBOX_F3_0		0x00004000 /* PCI function 3, INT 0 */
++#define  BCMA_CORE_PCI_MBOX_F3_1		0x00008000 /* PCI function 3, INT 1 */
++#define BCMA_CORE_PCI_BCAST_ADDR		0x0050	/* Backplane Broadcast Address */
++#define  BCMA_CORE_PCI_BCAST_ADDR_MASK		0x000000FF
++#define BCMA_CORE_PCI_BCAST_DATA		0x0054	/* Backplane Broadcast Data */
++#define BCMA_CORE_PCI_GPIO_IN			0x0060	/* rev >= 2 only */
++#define BCMA_CORE_PCI_GPIO_OUT			0x0064	/* rev >= 2 only */
++#define BCMA_CORE_PCI_GPIO_ENABLE		0x0068	/* rev >= 2 only */
++#define BCMA_CORE_PCI_GPIO_CTL			0x006C	/* rev >= 2 only */
++#define BCMA_CORE_PCI_SBTOPCI0			0x0100	/* Backplane to PCI translation 0 (sbtopci0) */
++#define  BCMA_CORE_PCI_SBTOPCI0_MASK		0xFC000000
++#define BCMA_CORE_PCI_SBTOPCI1			0x0104	/* Backplane to PCI translation 1 (sbtopci1) */
++#define  BCMA_CORE_PCI_SBTOPCI1_MASK		0xFC000000
++#define BCMA_CORE_PCI_SBTOPCI2			0x0108	/* Backplane to PCI translation 2 (sbtopci2) */
++#define  BCMA_CORE_PCI_SBTOPCI2_MASK		0xC0000000
++#define BCMA_CORE_PCI_CONFIG_ADDR		0x0120	/* pcie config space access */
++#define BCMA_CORE_PCI_CONFIG_DATA		0x0124	/* pcie config space access */
++#define BCMA_CORE_PCI_MDIO_CONTROL		0x0128	/* controls the mdio access */
++#define  BCMA_CORE_PCI_MDIOCTL_DIVISOR_MASK	0x7f	/* clock to be used on MDIO */
++#define  BCMA_CORE_PCI_MDIOCTL_DIVISOR_VAL	0x2
++#define  BCMA_CORE_PCI_MDIOCTL_PREAM_EN		0x80	/* Enable preamble sequnce */
++#define  BCMA_CORE_PCI_MDIOCTL_ACCESS_DONE	0x100	/* Tranaction complete */
++#define BCMA_CORE_PCI_MDIO_DATA			0x012c	/* Data to the mdio access */
++#define  BCMA_CORE_PCI_MDIODATA_MASK		0x0000ffff /* data 2 bytes */
++#define  BCMA_CORE_PCI_MDIODATA_TA		0x00020000 /* Turnaround */
++#define  BCMA_CORE_PCI_MDIODATA_REGADDR_SHF_OLD	18	/* Regaddr shift (rev < 10) */
++#define  BCMA_CORE_PCI_MDIODATA_REGADDR_MASK_OLD	0x003c0000 /* Regaddr Mask (rev < 10) */
++#define  BCMA_CORE_PCI_MDIODATA_DEVADDR_SHF_OLD	22	/* Physmedia devaddr shift (rev < 10) */
++#define  BCMA_CORE_PCI_MDIODATA_DEVADDR_MASK_OLD	0x0fc00000 /* Physmedia devaddr Mask (rev < 10) */
++#define  BCMA_CORE_PCI_MDIODATA_REGADDR_SHF	18	/* Regaddr shift */
++#define  BCMA_CORE_PCI_MDIODATA_REGADDR_MASK	0x007c0000 /* Regaddr Mask */
++#define  BCMA_CORE_PCI_MDIODATA_DEVADDR_SHF	23	/* Physmedia devaddr shift */
++#define  BCMA_CORE_PCI_MDIODATA_DEVADDR_MASK	0x0f800000 /* Physmedia devaddr Mask */
++#define  BCMA_CORE_PCI_MDIODATA_WRITE		0x10000000 /* write Transaction */
++#define  BCMA_CORE_PCI_MDIODATA_READ		0x20000000 /* Read Transaction */
++#define  BCMA_CORE_PCI_MDIODATA_START		0x40000000 /* start of Transaction */
++#define  BCMA_CORE_PCI_MDIODATA_DEV_ADDR	0x0	/* dev address for serdes */
++#define  BCMA_CORE_PCI_MDIODATA_BLK_ADDR	0x1F	/* blk address for serdes */
++#define  BCMA_CORE_PCI_MDIODATA_DEV_PLL		0x1d	/* SERDES PLL Dev */
++#define  BCMA_CORE_PCI_MDIODATA_DEV_TX		0x1e	/* SERDES TX Dev */
++#define  BCMA_CORE_PCI_MDIODATA_DEV_RX		0x1f	/* SERDES RX Dev */
++#define BCMA_CORE_PCI_PCIEIND_ADDR		0x0130	/* indirect access to the internal register */
++#define BCMA_CORE_PCI_PCIEIND_DATA		0x0134	/* Data to/from the internal regsiter */
++#define BCMA_CORE_PCI_CLKREQENCTRL		0x0138	/*  >= rev 6, Clkreq rdma control */
++#define BCMA_CORE_PCI_PCICFG0			0x0400	/* PCI config space 0 (rev >= 8) */
++#define BCMA_CORE_PCI_PCICFG1			0x0500	/* PCI config space 1 (rev >= 8) */
++#define BCMA_CORE_PCI_PCICFG2			0x0600	/* PCI config space 2 (rev >= 8) */
++#define BCMA_CORE_PCI_PCICFG3			0x0700	/* PCI config space 3 (rev >= 8) */
++#define BCMA_CORE_PCI_SPROM(wordoffset)		(0x0800 + ((wordoffset) * 2)) /* SPROM shadow area (72 bytes) */
++
++/* SBtoPCIx */
++#define BCMA_CORE_PCI_SBTOPCI_MEM		0x00000000
++#define BCMA_CORE_PCI_SBTOPCI_IO		0x00000001
++#define BCMA_CORE_PCI_SBTOPCI_CFG0		0x00000002
++#define BCMA_CORE_PCI_SBTOPCI_CFG1		0x00000003
++#define BCMA_CORE_PCI_SBTOPCI_PREF		0x00000004 /* Prefetch enable */
++#define BCMA_CORE_PCI_SBTOPCI_BURST		0x00000008 /* Burst enable */
++#define BCMA_CORE_PCI_SBTOPCI_MRM		0x00000020 /* Memory Read Multiple */
++#define BCMA_CORE_PCI_SBTOPCI_RC		0x00000030 /* Read Command mask (rev >= 11) */
++#define  BCMA_CORE_PCI_SBTOPCI_RC_READ		0x00000000 /* Memory read */
++#define  BCMA_CORE_PCI_SBTOPCI_RC_READL		0x00000010 /* Memory read line */
++#define  BCMA_CORE_PCI_SBTOPCI_RC_READM		0x00000020 /* Memory read multiple */
++
++/* PCIE protocol PHY diagnostic registers */
++#define BCMA_CORE_PCI_PLP_MODEREG		0x200	/* Mode */
++#define BCMA_CORE_PCI_PLP_STATUSREG		0x204	/* Status */
++#define  BCMA_CORE_PCI_PLP_POLARITYINV_STAT	0x10	/* Status reg PCIE_PLP_STATUSREG */
++#define BCMA_CORE_PCI_PLP_LTSSMCTRLREG		0x208	/* LTSSM control */
++#define BCMA_CORE_PCI_PLP_LTLINKNUMREG		0x20c	/* Link Training Link number */
++#define BCMA_CORE_PCI_PLP_LTLANENUMREG		0x210	/* Link Training Lane number */
++#define BCMA_CORE_PCI_PLP_LTNFTSREG		0x214	/* Link Training N_FTS */
++#define BCMA_CORE_PCI_PLP_ATTNREG		0x218	/* Attention */
++#define BCMA_CORE_PCI_PLP_ATTNMASKREG		0x21C	/* Attention Mask */
++#define BCMA_CORE_PCI_PLP_RXERRCTR		0x220	/* Rx Error */
++#define BCMA_CORE_PCI_PLP_RXFRMERRCTR		0x224	/* Rx Framing Error */
++#define BCMA_CORE_PCI_PLP_RXERRTHRESHREG	0x228	/* Rx Error threshold */
++#define BCMA_CORE_PCI_PLP_TESTCTRLREG		0x22C	/* Test Control reg */
++#define BCMA_CORE_PCI_PLP_SERDESCTRLOVRDREG	0x230	/* SERDES Control Override */
++#define BCMA_CORE_PCI_PLP_TIMINGOVRDREG		0x234	/* Timing param override */
++#define BCMA_CORE_PCI_PLP_RXTXSMDIAGREG		0x238	/* RXTX State Machine Diag */
++#define BCMA_CORE_PCI_PLP_LTSSMDIAGREG		0x23C	/* LTSSM State Machine Diag */
++
++/* PCIE protocol DLLP diagnostic registers */
++#define BCMA_CORE_PCI_DLLP_LCREG		0x100	/* Link Control */
++#define BCMA_CORE_PCI_DLLP_LSREG		0x104	/* Link Status */
++#define BCMA_CORE_PCI_DLLP_LAREG		0x108	/* Link Attention */
++#define  BCMA_CORE_PCI_DLLP_LSREG_LINKUP	(1 << 16)
++#define BCMA_CORE_PCI_DLLP_LAMASKREG		0x10C	/* Link Attention Mask */
++#define BCMA_CORE_PCI_DLLP_NEXTTXSEQNUMREG	0x110	/* Next Tx Seq Num */
++#define BCMA_CORE_PCI_DLLP_ACKEDTXSEQNUMREG	0x114	/* Acked Tx Seq Num */
++#define BCMA_CORE_PCI_DLLP_PURGEDTXSEQNUMREG	0x118	/* Purged Tx Seq Num */
++#define BCMA_CORE_PCI_DLLP_RXSEQNUMREG		0x11C	/* Rx Sequence Number */
++#define BCMA_CORE_PCI_DLLP_LRREG		0x120	/* Link Replay */
++#define BCMA_CORE_PCI_DLLP_LACKTOREG		0x124	/* Link Ack Timeout */
++#define BCMA_CORE_PCI_DLLP_PMTHRESHREG		0x128	/* Power Management Threshold */
++#define BCMA_CORE_PCI_DLLP_RTRYWPREG		0x12C	/* Retry buffer write ptr */
++#define BCMA_CORE_PCI_DLLP_RTRYRPREG		0x130	/* Retry buffer Read ptr */
++#define BCMA_CORE_PCI_DLLP_RTRYPPREG		0x134	/* Retry buffer Purged ptr */
++#define BCMA_CORE_PCI_DLLP_RTRRWREG		0x138	/* Retry buffer Read/Write */
++#define BCMA_CORE_PCI_DLLP_ECTHRESHREG		0x13C	/* Error Count Threshold */
++#define BCMA_CORE_PCI_DLLP_TLPERRCTRREG		0x140	/* TLP Error Counter */
++#define BCMA_CORE_PCI_DLLP_ERRCTRREG		0x144	/* Error Counter */
++#define BCMA_CORE_PCI_DLLP_NAKRXCTRREG		0x148	/* NAK Received Counter */
++#define BCMA_CORE_PCI_DLLP_TESTREG		0x14C	/* Test */
++#define BCMA_CORE_PCI_DLLP_PKTBIST		0x150	/* Packet BIST */
++#define BCMA_CORE_PCI_DLLP_PCIE11		0x154	/* DLLP PCIE 1.1 reg */
++
++/* SERDES RX registers */
++#define BCMA_CORE_PCI_SERDES_RX_CTRL		1	/* Rx cntrl */
++#define  BCMA_CORE_PCI_SERDES_RX_CTRL_FORCE	0x80	/* rxpolarity_force */
++#define  BCMA_CORE_PCI_SERDES_RX_CTRL_POLARITY	0x40	/* rxpolarity_value */
++#define BCMA_CORE_PCI_SERDES_RX_TIMER1		2	/* Rx Timer1 */
++#define BCMA_CORE_PCI_SERDES_RX_CDR		6	/* CDR */
++#define BCMA_CORE_PCI_SERDES_RX_CDRBW		7	/* CDR BW */
++
++/* SERDES PLL registers */
++#define BCMA_CORE_PCI_SERDES_PLL_CTRL		1	/* PLL control reg */
++#define BCMA_CORE_PCI_PLL_CTRL_FREQDET_EN	0x4000	/* bit 14 is FREQDET on */
++
++/* PCIcore specific boardflags */
++#define BCMA_CORE_PCI_BFL_NOPCI			0x00000400 /* Board leaves PCI floating */
++
++/* PCIE Config space accessing MACROS */
++#define BCMA_CORE_PCI_CFG_BUS_SHIFT		24	/* Bus shift */
++#define BCMA_CORE_PCI_CFG_SLOT_SHIFT		19	/* Slot/Device shift */
++#define BCMA_CORE_PCI_CFG_FUN_SHIFT		16	/* Function shift */
++#define BCMA_CORE_PCI_CFG_OFF_SHIFT		0	/* Register shift */
++
++#define BCMA_CORE_PCI_CFG_BUS_MASK		0xff	/* Bus mask */
++#define BCMA_CORE_PCI_CFG_SLOT_MASK		0x1f	/* Slot/Device mask */
++#define BCMA_CORE_PCI_CFG_FUN_MASK		7	/* Function mask */
++#define BCMA_CORE_PCI_CFG_OFF_MASK		0xfff	/* Register mask */
++
++/* PCIE Root Capability Register bits (Host mode only) */
++#define BCMA_CORE_PCI_RC_CRS_VISIBILITY		0x0001
++
++struct bcma_drv_pci;
++
++#ifdef CONFIG_BCMA_DRIVER_PCI_HOSTMODE
++struct bcma_drv_pci_host {
++	struct bcma_drv_pci *pdev;
++
++	u32 host_cfg_addr;
++	spinlock_t cfgspace_lock;
++
++	struct pci_controller pci_controller;
++	struct pci_ops pci_ops;
++	struct resource mem_resource;
++	struct resource io_resource;
++};
++#endif
++
++struct bcma_drv_pci {
++	struct bcma_device *core;
++	u8 setup_done:1;
++	u8 hostmode:1;
++
++#ifdef CONFIG_BCMA_DRIVER_PCI_HOSTMODE
++	struct bcma_drv_pci_host *host_controller;
++#endif
++};
++
++/* Register access */
++#define pcicore_read32(pc, offset)		bcma_read32((pc)->core, offset)
++#define pcicore_write32(pc, offset, val)	bcma_write32((pc)->core, offset, val)
++
++extern void __devinit bcma_core_pci_init(struct bcma_drv_pci *pc);
++extern int bcma_core_pci_irq_ctl(struct bcma_drv_pci *pc,
++				 struct bcma_device *core, bool enable);
++
++extern int bcma_core_pci_pcibios_map_irq(const struct pci_dev *dev);
++extern int bcma_core_pci_plat_dev_init(struct pci_dev *dev);
++
++#endif /* LINUX_BCMA_DRIVER_PCI_H_ */
+--- /dev/null
++++ b/include/linux/bcma/bcma_regs.h
+@@ -0,0 +1,86 @@
++#ifndef LINUX_BCMA_REGS_H_
++#define LINUX_BCMA_REGS_H_
++
++/* Some single registers are shared between many cores */
++/* BCMA_CLKCTLST: ChipCommon (rev >= 20), PCIe, 80211 */
++#define BCMA_CLKCTLST			0x01E0 /* Clock control and status */
++#define  BCMA_CLKCTLST_FORCEALP		0x00000001 /* Force ALP request */
++#define  BCMA_CLKCTLST_FORCEHT		0x00000002 /* Force HT request */
++#define  BCMA_CLKCTLST_FORCEILP		0x00000004 /* Force ILP request */
++#define  BCMA_CLKCTLST_HAVEALPREQ	0x00000008 /* ALP available request */
++#define  BCMA_CLKCTLST_HAVEHTREQ	0x00000010 /* HT available request */
++#define  BCMA_CLKCTLST_HWCROFF		0x00000020 /* Force HW clock request off */
++#define  BCMA_CLKCTLST_EXTRESREQ	0x00000700 /* Mask of external resource requests */
++#define  BCMA_CLKCTLST_HAVEALP		0x00010000 /* ALP available */
++#define  BCMA_CLKCTLST_HAVEHT		0x00020000 /* HT available */
++#define  BCMA_CLKCTLST_BP_ON_ALP	0x00040000 /* RO: running on ALP clock */
++#define  BCMA_CLKCTLST_BP_ON_HT		0x00080000 /* RO: running on HT clock */
++#define  BCMA_CLKCTLST_EXTRESST		0x07000000 /* Mask of external resource status */
++/* Is there any BCM4328 on BCMA bus? */
++#define  BCMA_CLKCTLST_4328A0_HAVEHT	0x00010000 /* 4328a0 has reversed bits */
++#define  BCMA_CLKCTLST_4328A0_HAVEALP	0x00020000 /* 4328a0 has reversed bits */
++
++/* Agent registers (common for every core) */
++#define BCMA_IOCTL			0x0408 /* IO control */
++#define  BCMA_IOCTL_CLK			0x0001
++#define  BCMA_IOCTL_FGC			0x0002
++#define  BCMA_IOCTL_CORE_BITS		0x3FFC
++#define  BCMA_IOCTL_PME_EN		0x4000
++#define  BCMA_IOCTL_BIST_EN		0x8000
++#define BCMA_IOST			0x0500 /* IO status */
++#define  BCMA_IOST_CORE_BITS		0x0FFF
++#define  BCMA_IOST_DMA64		0x1000
++#define  BCMA_IOST_GATED_CLK		0x2000
++#define  BCMA_IOST_BIST_ERROR		0x4000
++#define  BCMA_IOST_BIST_DONE		0x8000
++#define BCMA_RESET_CTL			0x0800
++#define  BCMA_RESET_CTL_RESET		0x0001
++
++/* BCMA PCI config space registers. */
++#define BCMA_PCI_PMCSR			0x44
++#define  BCMA_PCI_PE			0x100
++#define BCMA_PCI_BAR0_WIN		0x80	/* Backplane address space 0 */
++#define BCMA_PCI_BAR1_WIN		0x84	/* Backplane address space 1 */
++#define BCMA_PCI_SPROMCTL		0x88	/* SPROM control */
++#define  BCMA_PCI_SPROMCTL_WE		0x10	/* SPROM write enable */
++#define BCMA_PCI_BAR1_CONTROL		0x8c	/* Address space 1 burst control */
++#define BCMA_PCI_IRQS			0x90	/* PCI interrupts */
++#define BCMA_PCI_IRQMASK		0x94	/* PCI IRQ control and mask (pcirev >= 6 only) */
++#define BCMA_PCI_BACKPLANE_IRQS		0x98	/* Backplane Interrupts */
++#define BCMA_PCI_BAR0_WIN2		0xAC
++#define BCMA_PCI_GPIO_IN		0xB0	/* GPIO Input (pcirev >= 3 only) */
++#define BCMA_PCI_GPIO_OUT		0xB4	/* GPIO Output (pcirev >= 3 only) */
++#define BCMA_PCI_GPIO_OUT_ENABLE	0xB8	/* GPIO Output Enable/Disable (pcirev >= 3 only) */
++#define  BCMA_PCI_GPIO_SCS		0x10	/* PCI config space bit 4 for 4306c0 slow clock source */
++#define  BCMA_PCI_GPIO_HWRAD		0x20	/* PCI config space GPIO 13 for hw radio disable */
++#define  BCMA_PCI_GPIO_XTAL		0x40	/* PCI config space GPIO 14 for Xtal powerup */
++#define  BCMA_PCI_GPIO_PLL		0x80	/* PCI config space GPIO 15 for PLL powerdown */
++
++/* SiliconBackplane Address Map.
++ * All regions may not exist on all chips.
++ */
++#define BCMA_SOC_SDRAM_BASE		0x00000000U	/* Physical SDRAM */
++#define BCMA_SOC_PCI_MEM		0x08000000U	/* Host Mode sb2pcitranslation0 (64 MB) */
++#define BCMA_SOC_PCI_MEM_SZ		(64 * 1024 * 1024)
++#define BCMA_SOC_PCI_CFG		0x0c000000U	/* Host Mode sb2pcitranslation1 (64 MB) */
++#define BCMA_SOC_SDRAM_SWAPPED		0x10000000U	/* Byteswapped Physical SDRAM */
++#define BCMA_SOC_SDRAM_R2		0x80000000U	/* Region 2 for sdram (512 MB) */
++
++
++#define BCMA_SOC_PCI_DMA		0x40000000U	/* Client Mode sb2pcitranslation2 (1 GB) */
++#define BCMA_SOC_PCI_DMA2		0x80000000U	/* Client Mode sb2pcitranslation2 (1 GB) */
++#define BCMA_SOC_PCI_DMA_SZ		0x40000000U	/* Client Mode sb2pcitranslation2 size in bytes */
++#define BCMA_SOC_PCIE_DMA_L32		0x00000000U	/* PCIE Client Mode sb2pcitranslation2
++							 * (2 ZettaBytes), low 32 bits
++							 */
++#define BCMA_SOC_PCIE_DMA_H32		0x80000000U	/* PCIE Client Mode sb2pcitranslation2
++							 * (2 ZettaBytes), high 32 bits
++							 */
++
++#define BCMA_SOC_PCI1_MEM		0x40000000U	/* Host Mode sb2pcitranslation0 (64 MB) */
++#define BCMA_SOC_PCI1_CFG		0x44000000U	/* Host Mode sb2pcitranslation1 (64 MB) */
++#define BCMA_SOC_PCIE1_DMA_H32		0xc0000000U	/* PCIE Client Mode sb2pcitranslation2
++							 * (2 ZettaBytes), high 32 bits
++							 */
++
++#endif /* LINUX_BCMA_REGS_H_ */
+--- a/include/linux/mod_devicetable.h
++++ b/include/linux/mod_devicetable.h
+@@ -382,6 +382,23 @@ struct ssb_device_id {
+ #define SSB_ANY_ID		0xFFFF
+ #define SSB_ANY_REV		0xFF
+ 
++/* Broadcom's specific AMBA core, see drivers/bcma/ */
++struct bcma_device_id {
++	__u16	manuf;
++	__u16	id;
++	__u8	rev;
++	__u8	class;
++};
++#define BCMA_CORE(_manuf, _id, _rev, _class)  \
++	{ .manuf = _manuf, .id = _id, .rev = _rev, .class = _class, }
++#define BCMA_CORETABLE_END  \
++	{ 0, },
++
++#define BCMA_ANY_MANUF		0xFFFF
++#define BCMA_ANY_ID		0xFFFF
++#define BCMA_ANY_REV		0xFF
++#define BCMA_ANY_CLASS		0xFF
++
+ struct virtio_device_id {
+ 	__u32 device;
+ 	__u32 vendor;
+--- a/scripts/mod/file2alias.c
++++ b/scripts/mod/file2alias.c
+@@ -633,6 +633,24 @@ static int do_ssb_entry(const char *file
+ 	return 1;
+ }
+ 
++/* Looks like: bcma:mNidNrevNclN. */
++static int do_bcma_entry(const char *filename,
++			 struct bcma_device_id *id, char *alias)
++{
++	id->manuf = TO_NATIVE(id->manuf);
++	id->id = TO_NATIVE(id->id);
++	id->rev = TO_NATIVE(id->rev);
++	id->class = TO_NATIVE(id->class);
++
++	strcpy(alias, "bcma:");
++	ADD(alias, "m", id->manuf != BCMA_ANY_MANUF, id->manuf);
++	ADD(alias, "id", id->id != BCMA_ANY_ID, id->id);
++	ADD(alias, "rev", id->rev != BCMA_ANY_REV, id->rev);
++	ADD(alias, "cl", id->class != BCMA_ANY_CLASS, id->class);
++	add_wildcard(alias);
++	return 1;
++}
++
+ /* Looks like: virtio:dNvN */
+ static int do_virtio_entry(const char *filename, struct virtio_device_id *id,
+ 			   char *alias)
+@@ -845,6 +863,10 @@ void handle_moddevtable(struct module *m
+ 		do_table(symval, sym->st_size,
+ 			 sizeof(struct ssb_device_id), "ssb",
+ 			 do_ssb_entry, mod);
++	else if (sym_is(symname, "__mod_bcma_device_table"))
++		do_table(symval, sym->st_size,
++			 sizeof(struct bcma_device_id), "bcma",
++			 do_bcma_entry, mod);
+ 	else if (sym_is(symname, "__mod_virtio_device_table"))
+ 		do_table(symval, sym->st_size,
+ 			 sizeof(struct virtio_device_id), "virtio",
+--- /dev/null
++++ b/drivers/bcma/sprom.c
+@@ -0,0 +1,450 @@
++/*
++ * Broadcom specific AMBA
++ * SPROM reading
++ *
++ * Copyright 2011, 2012, Hauke Mehrtens <hauke@hauke-m.de>
++ *
++ * Licensed under the GNU/GPL. See COPYING for details.
++ */
++
++#include "bcma_private.h"
++
++#include <linux/bcma/bcma.h>
++#include <linux/bcma/bcma_regs.h>
++#include <linux/pci.h>
++#include <linux/io.h>
++#include <linux/dma-mapping.h>
++#include <linux/slab.h>
++
++static int(*get_fallback_sprom)(struct bcma_bus *dev, struct ssb_sprom *out);
++
++/**
++ * bcma_arch_register_fallback_sprom - Registers a method providing a
++ * fallback SPROM if no SPROM is found.
++ *
++ * @sprom_callback: The callback function.
++ *
++ * With this function the architecture implementation may register a
++ * callback handler which fills the SPROM data structure. The fallback is
++ * used for PCI based BCMA devices, where no valid SPROM can be found
++ * in the shadow registers and to provide the SPROM for SoCs where BCMA is
++ * to controll the system bus.
++ *
++ * This function is useful for weird architectures that have a half-assed
++ * BCMA device hardwired to their PCI bus.
++ *
++ * This function is available for architecture code, only. So it is not
++ * exported.
++ */
++int bcma_arch_register_fallback_sprom(int (*sprom_callback)(struct bcma_bus *bus,
++				     struct ssb_sprom *out))
++{
++	if (get_fallback_sprom)
++		return -EEXIST;
++	get_fallback_sprom = sprom_callback;
++
++	return 0;
++}
++
++static int bcma_fill_sprom_with_fallback(struct bcma_bus *bus,
++					 struct ssb_sprom *out)
++{
++	int err;
++
++	if (!get_fallback_sprom) {
++		err = -ENOENT;
++		goto fail;
++	}
++
++	err = get_fallback_sprom(bus, out);
++	if (err)
++		goto fail;
++
++	pr_debug("Using SPROM revision %d provided by"
++		 " platform.\n", bus->sprom.revision);
++	return 0;
++fail:
++	pr_warning("Using fallback SPROM failed (err %d)\n", err);
++	return err;
++}
++
++/**************************************************
++ * R/W ops.
++ **************************************************/
++
++static void bcma_sprom_read(struct bcma_bus *bus, u16 offset, u16 *sprom)
++{
++	int i;
++	for (i = 0; i < SSB_SPROMSIZE_WORDS_R4; i++)
++		sprom[i] = bcma_read16(bus->drv_cc.core,
++				       offset + (i * 2));
++}
++
++/**************************************************
++ * Validation.
++ **************************************************/
++
++static inline u8 bcma_crc8(u8 crc, u8 data)
++{
++	/* Polynomial:   x^8 + x^7 + x^6 + x^4 + x^2 + 1   */
++	static const u8 t[] = {
++		0x00, 0xF7, 0xB9, 0x4E, 0x25, 0xD2, 0x9C, 0x6B,
++		0x4A, 0xBD, 0xF3, 0x04, 0x6F, 0x98, 0xD6, 0x21,
++		0x94, 0x63, 0x2D, 0xDA, 0xB1, 0x46, 0x08, 0xFF,
++		0xDE, 0x29, 0x67, 0x90, 0xFB, 0x0C, 0x42, 0xB5,
++		0x7F, 0x88, 0xC6, 0x31, 0x5A, 0xAD, 0xE3, 0x14,
++		0x35, 0xC2, 0x8C, 0x7B, 0x10, 0xE7, 0xA9, 0x5E,
++		0xEB, 0x1C, 0x52, 0xA5, 0xCE, 0x39, 0x77, 0x80,
++		0xA1, 0x56, 0x18, 0xEF, 0x84, 0x73, 0x3D, 0xCA,
++		0xFE, 0x09, 0x47, 0xB0, 0xDB, 0x2C, 0x62, 0x95,
++		0xB4, 0x43, 0x0D, 0xFA, 0x91, 0x66, 0x28, 0xDF,
++		0x6A, 0x9D, 0xD3, 0x24, 0x4F, 0xB8, 0xF6, 0x01,
++		0x20, 0xD7, 0x99, 0x6E, 0x05, 0xF2, 0xBC, 0x4B,
++		0x81, 0x76, 0x38, 0xCF, 0xA4, 0x53, 0x1D, 0xEA,
++		0xCB, 0x3C, 0x72, 0x85, 0xEE, 0x19, 0x57, 0xA0,
++		0x15, 0xE2, 0xAC, 0x5B, 0x30, 0xC7, 0x89, 0x7E,
++		0x5F, 0xA8, 0xE6, 0x11, 0x7A, 0x8D, 0xC3, 0x34,
++		0xAB, 0x5C, 0x12, 0xE5, 0x8E, 0x79, 0x37, 0xC0,
++		0xE1, 0x16, 0x58, 0xAF, 0xC4, 0x33, 0x7D, 0x8A,
++		0x3F, 0xC8, 0x86, 0x71, 0x1A, 0xED, 0xA3, 0x54,
++		0x75, 0x82, 0xCC, 0x3B, 0x50, 0xA7, 0xE9, 0x1E,
++		0xD4, 0x23, 0x6D, 0x9A, 0xF1, 0x06, 0x48, 0xBF,
++		0x9E, 0x69, 0x27, 0xD0, 0xBB, 0x4C, 0x02, 0xF5,
++		0x40, 0xB7, 0xF9, 0x0E, 0x65, 0x92, 0xDC, 0x2B,
++		0x0A, 0xFD, 0xB3, 0x44, 0x2F, 0xD8, 0x96, 0x61,
++		0x55, 0xA2, 0xEC, 0x1B, 0x70, 0x87, 0xC9, 0x3E,
++		0x1F, 0xE8, 0xA6, 0x51, 0x3A, 0xCD, 0x83, 0x74,
++		0xC1, 0x36, 0x78, 0x8F, 0xE4, 0x13, 0x5D, 0xAA,
++		0x8B, 0x7C, 0x32, 0xC5, 0xAE, 0x59, 0x17, 0xE0,
++		0x2A, 0xDD, 0x93, 0x64, 0x0F, 0xF8, 0xB6, 0x41,
++		0x60, 0x97, 0xD9, 0x2E, 0x45, 0xB2, 0xFC, 0x0B,
++		0xBE, 0x49, 0x07, 0xF0, 0x9B, 0x6C, 0x22, 0xD5,
++		0xF4, 0x03, 0x4D, 0xBA, 0xD1, 0x26, 0x68, 0x9F,
++	};
++	return t[crc ^ data];
++}
++
++static u8 bcma_sprom_crc(const u16 *sprom)
++{
++	int word;
++	u8 crc = 0xFF;
++
++	for (word = 0; word < SSB_SPROMSIZE_WORDS_R4 - 1; word++) {
++		crc = bcma_crc8(crc, sprom[word] & 0x00FF);
++		crc = bcma_crc8(crc, (sprom[word] & 0xFF00) >> 8);
++	}
++	crc = bcma_crc8(crc, sprom[SSB_SPROMSIZE_WORDS_R4 - 1] & 0x00FF);
++	crc ^= 0xFF;
++
++	return crc;
++}
++
++static int bcma_sprom_check_crc(const u16 *sprom)
++{
++	u8 crc;
++	u8 expected_crc;
++	u16 tmp;
++
++	crc = bcma_sprom_crc(sprom);
++	tmp = sprom[SSB_SPROMSIZE_WORDS_R4 - 1] & SSB_SPROM_REVISION_CRC;
++	expected_crc = tmp >> SSB_SPROM_REVISION_CRC_SHIFT;
++	if (crc != expected_crc)
++		return -EPROTO;
++
++	return 0;
++}
++
++static int bcma_sprom_valid(const u16 *sprom)
++{
++	u16 revision;
++	int err;
++
++	err = bcma_sprom_check_crc(sprom);
++	if (err)
++		return err;
++
++	revision = sprom[SSB_SPROMSIZE_WORDS_R4 - 1] & SSB_SPROM_REVISION_REV;
++	if (revision != 8 && revision != 9) {
++		pr_err("Unsupported SPROM revision: %d\n", revision);
++		return -ENOENT;
++	}
++
++	return 0;
++}
++
++/**************************************************
++ * SPROM extraction.
++ **************************************************/
++
++#define SPOFF(offset)	((offset) / sizeof(u16))
++
++#define SPEX(_field, _offset, _mask, _shift)	\
++	bus->sprom._field = ((sprom[SPOFF(_offset)] & (_mask)) >> (_shift))
++
++static void bcma_sprom_extract_r8(struct bcma_bus *bus, const u16 *sprom)
++{
++	u16 v, o;
++	int i;
++	u16 pwr_info_offset[] = {
++		SSB_SROM8_PWR_INFO_CORE0, SSB_SROM8_PWR_INFO_CORE1,
++		SSB_SROM8_PWR_INFO_CORE2, SSB_SROM8_PWR_INFO_CORE3
++	};
++	BUILD_BUG_ON(ARRAY_SIZE(pwr_info_offset) !=
++			ARRAY_SIZE(bus->sprom.core_pwr_info));
++
++	bus->sprom.revision = sprom[SSB_SPROMSIZE_WORDS_R4 - 1] &
++		SSB_SPROM_REVISION_REV;
++
++	for (i = 0; i < 3; i++) {
++		v = sprom[SPOFF(SSB_SPROM8_IL0MAC) + i];
++		*(((__be16 *)bus->sprom.il0mac) + i) = cpu_to_be16(v);
++	}
++
++	SPEX(board_rev, SSB_SPROM8_BOARDREV, ~0, 0);
++
++	SPEX(txpid2g[0], SSB_SPROM4_TXPID2G01, SSB_SPROM4_TXPID2G0,
++	     SSB_SPROM4_TXPID2G0_SHIFT);
++	SPEX(txpid2g[1], SSB_SPROM4_TXPID2G01, SSB_SPROM4_TXPID2G1,
++	     SSB_SPROM4_TXPID2G1_SHIFT);
++	SPEX(txpid2g[2], SSB_SPROM4_TXPID2G23, SSB_SPROM4_TXPID2G2,
++	     SSB_SPROM4_TXPID2G2_SHIFT);
++	SPEX(txpid2g[3], SSB_SPROM4_TXPID2G23, SSB_SPROM4_TXPID2G3,
++	     SSB_SPROM4_TXPID2G3_SHIFT);
++
++	SPEX(txpid5gl[0], SSB_SPROM4_TXPID5GL01, SSB_SPROM4_TXPID5GL0,
++	     SSB_SPROM4_TXPID5GL0_SHIFT);
++	SPEX(txpid5gl[1], SSB_SPROM4_TXPID5GL01, SSB_SPROM4_TXPID5GL1,
++	     SSB_SPROM4_TXPID5GL1_SHIFT);
++	SPEX(txpid5gl[2], SSB_SPROM4_TXPID5GL23, SSB_SPROM4_TXPID5GL2,
++	     SSB_SPROM4_TXPID5GL2_SHIFT);
++	SPEX(txpid5gl[3], SSB_SPROM4_TXPID5GL23, SSB_SPROM4_TXPID5GL3,
++	     SSB_SPROM4_TXPID5GL3_SHIFT);
++
++	SPEX(txpid5g[0], SSB_SPROM4_TXPID5G01, SSB_SPROM4_TXPID5G0,
++	     SSB_SPROM4_TXPID5G0_SHIFT);
++	SPEX(txpid5g[1], SSB_SPROM4_TXPID5G01, SSB_SPROM4_TXPID5G1,
++	     SSB_SPROM4_TXPID5G1_SHIFT);
++	SPEX(txpid5g[2], SSB_SPROM4_TXPID5G23, SSB_SPROM4_TXPID5G2,
++	     SSB_SPROM4_TXPID5G2_SHIFT);
++	SPEX(txpid5g[3], SSB_SPROM4_TXPID5G23, SSB_SPROM4_TXPID5G3,
++	     SSB_SPROM4_TXPID5G3_SHIFT);
++
++	SPEX(txpid5gh[0], SSB_SPROM4_TXPID5GH01, SSB_SPROM4_TXPID5GH0,
++	     SSB_SPROM4_TXPID5GH0_SHIFT);
++	SPEX(txpid5gh[1], SSB_SPROM4_TXPID5GH01, SSB_SPROM4_TXPID5GH1,
++	     SSB_SPROM4_TXPID5GH1_SHIFT);
++	SPEX(txpid5gh[2], SSB_SPROM4_TXPID5GH23, SSB_SPROM4_TXPID5GH2,
++	     SSB_SPROM4_TXPID5GH2_SHIFT);
++	SPEX(txpid5gh[3], SSB_SPROM4_TXPID5GH23, SSB_SPROM4_TXPID5GH3,
++	     SSB_SPROM4_TXPID5GH3_SHIFT);
++
++	SPEX(boardflags_lo, SSB_SPROM8_BFLLO, ~0, 0);
++	SPEX(boardflags_hi, SSB_SPROM8_BFLHI, ~0, 0);
++	SPEX(boardflags2_lo, SSB_SPROM8_BFL2LO, ~0, 0);
++	SPEX(boardflags2_hi, SSB_SPROM8_BFL2HI, ~0, 0);
++
++	SPEX(country_code, SSB_SPROM8_CCODE, ~0, 0);
++
++	/* Extract cores power info info */
++	for (i = 0; i < ARRAY_SIZE(pwr_info_offset); i++) {
++		o = pwr_info_offset[i];
++		SPEX(core_pwr_info[i].itssi_2g, o + SSB_SROM8_2G_MAXP_ITSSI,
++			SSB_SPROM8_2G_ITSSI, SSB_SPROM8_2G_ITSSI_SHIFT);
++		SPEX(core_pwr_info[i].maxpwr_2g, o + SSB_SROM8_2G_MAXP_ITSSI,
++			SSB_SPROM8_2G_MAXP, 0);
++
++		SPEX(core_pwr_info[i].pa_2g[0], o + SSB_SROM8_2G_PA_0, ~0, 0);
++		SPEX(core_pwr_info[i].pa_2g[1], o + SSB_SROM8_2G_PA_1, ~0, 0);
++		SPEX(core_pwr_info[i].pa_2g[2], o + SSB_SROM8_2G_PA_2, ~0, 0);
++
++		SPEX(core_pwr_info[i].itssi_5g, o + SSB_SROM8_5G_MAXP_ITSSI,
++			SSB_SPROM8_5G_ITSSI, SSB_SPROM8_5G_ITSSI_SHIFT);
++		SPEX(core_pwr_info[i].maxpwr_5g, o + SSB_SROM8_5G_MAXP_ITSSI,
++			SSB_SPROM8_5G_MAXP, 0);
++		SPEX(core_pwr_info[i].maxpwr_5gh, o + SSB_SPROM8_5GHL_MAXP,
++			SSB_SPROM8_5GH_MAXP, 0);
++		SPEX(core_pwr_info[i].maxpwr_5gl, o + SSB_SPROM8_5GHL_MAXP,
++			SSB_SPROM8_5GL_MAXP, SSB_SPROM8_5GL_MAXP_SHIFT);
++
++		SPEX(core_pwr_info[i].pa_5gl[0], o + SSB_SROM8_5GL_PA_0, ~0, 0);
++		SPEX(core_pwr_info[i].pa_5gl[1], o + SSB_SROM8_5GL_PA_1, ~0, 0);
++		SPEX(core_pwr_info[i].pa_5gl[2], o + SSB_SROM8_5GL_PA_2, ~0, 0);
++		SPEX(core_pwr_info[i].pa_5g[0], o + SSB_SROM8_5G_PA_0, ~0, 0);
++		SPEX(core_pwr_info[i].pa_5g[1], o + SSB_SROM8_5G_PA_1, ~0, 0);
++		SPEX(core_pwr_info[i].pa_5g[2], o + SSB_SROM8_5G_PA_2, ~0, 0);
++		SPEX(core_pwr_info[i].pa_5gh[0], o + SSB_SROM8_5GH_PA_0, ~0, 0);
++		SPEX(core_pwr_info[i].pa_5gh[1], o + SSB_SROM8_5GH_PA_1, ~0, 0);
++		SPEX(core_pwr_info[i].pa_5gh[2], o + SSB_SROM8_5GH_PA_2, ~0, 0);
++	}
++
++	SPEX(fem.ghz2.tssipos, SSB_SPROM8_FEM2G, SSB_SROM8_FEM_TSSIPOS,
++	     SSB_SROM8_FEM_TSSIPOS_SHIFT);
++	SPEX(fem.ghz2.extpa_gain, SSB_SPROM8_FEM2G, SSB_SROM8_FEM_EXTPA_GAIN,
++	     SSB_SROM8_FEM_EXTPA_GAIN_SHIFT);
++	SPEX(fem.ghz2.pdet_range, SSB_SPROM8_FEM2G, SSB_SROM8_FEM_PDET_RANGE,
++	     SSB_SROM8_FEM_PDET_RANGE_SHIFT);
++	SPEX(fem.ghz2.tr_iso, SSB_SPROM8_FEM2G, SSB_SROM8_FEM_TR_ISO,
++	     SSB_SROM8_FEM_TR_ISO_SHIFT);
++	SPEX(fem.ghz2.antswlut, SSB_SPROM8_FEM2G, SSB_SROM8_FEM_ANTSWLUT,
++	     SSB_SROM8_FEM_ANTSWLUT_SHIFT);
++
++	SPEX(fem.ghz5.tssipos, SSB_SPROM8_FEM5G, SSB_SROM8_FEM_TSSIPOS,
++	     SSB_SROM8_FEM_TSSIPOS_SHIFT);
++	SPEX(fem.ghz5.extpa_gain, SSB_SPROM8_FEM5G, SSB_SROM8_FEM_EXTPA_GAIN,
++	     SSB_SROM8_FEM_EXTPA_GAIN_SHIFT);
++	SPEX(fem.ghz5.pdet_range, SSB_SPROM8_FEM5G, SSB_SROM8_FEM_PDET_RANGE,
++	     SSB_SROM8_FEM_PDET_RANGE_SHIFT);
++	SPEX(fem.ghz5.tr_iso, SSB_SPROM8_FEM5G, SSB_SROM8_FEM_TR_ISO,
++	     SSB_SROM8_FEM_TR_ISO_SHIFT);
++	SPEX(fem.ghz5.antswlut, SSB_SPROM8_FEM5G, SSB_SROM8_FEM_ANTSWLUT,
++	     SSB_SROM8_FEM_ANTSWLUT_SHIFT);
++}
++
++/*
++ * Indicates the presence of external SPROM.
++ */
++static bool bcma_sprom_ext_available(struct bcma_bus *bus)
++{
++	u32 chip_status;
++	u32 srom_control;
++	u32 present_mask;
++
++	if (bus->drv_cc.core->id.rev >= 31) {
++		if (!(bus->drv_cc.capabilities & BCMA_CC_CAP_SPROM))
++			return false;
++
++		srom_control = bcma_read32(bus->drv_cc.core,
++					   BCMA_CC_SROM_CONTROL);
++		return srom_control & BCMA_CC_SROM_CONTROL_PRESENT;
++	}
++
++	/* older chipcommon revisions use chip status register */
++	chip_status = bcma_read32(bus->drv_cc.core, BCMA_CC_CHIPSTAT);
++	switch (bus->chipinfo.id) {
++	case 0x4313:
++		present_mask = BCMA_CC_CHIPST_4313_SPROM_PRESENT;
++		break;
++
++	case 0x4331:
++		present_mask = BCMA_CC_CHIPST_4331_SPROM_PRESENT;
++		break;
++
++	default:
++		return true;
++	}
++
++	return chip_status & present_mask;
++}
++
++/*
++ * Indicates that on-chip OTP memory is present and enabled.
++ */
++static bool bcma_sprom_onchip_available(struct bcma_bus *bus)
++{
++	u32 chip_status;
++	u32 otpsize = 0;
++	bool present;
++
++	chip_status = bcma_read32(bus->drv_cc.core, BCMA_CC_CHIPSTAT);
++	switch (bus->chipinfo.id) {
++	case 0x4313:
++		present = chip_status & BCMA_CC_CHIPST_4313_OTP_PRESENT;
++		break;
++
++	case 0x4331:
++		present = chip_status & BCMA_CC_CHIPST_4331_OTP_PRESENT;
++		break;
++
++	case 43224:
++	case 43225:
++		/* for these chips OTP is always available */
++		present = true;
++		break;
++
++	default:
++		present = false;
++		break;
++	}
++
++	if (present) {
++		otpsize = bus->drv_cc.capabilities & BCMA_CC_CAP_OTPS;
++		otpsize >>= BCMA_CC_CAP_OTPS_SHIFT;
++	}
++
++	return otpsize != 0;
++}
++
++/*
++ * Verify OTP is filled and determine the byte
++ * offset where SPROM data is located.
++ *
++ * On error, returns 0; byte offset otherwise.
++ */
++static int bcma_sprom_onchip_offset(struct bcma_bus *bus)
++{
++	struct bcma_device *cc = bus->drv_cc.core;
++	u32 offset;
++
++	/* verify OTP status */
++	if ((bcma_read32(cc, BCMA_CC_OTPS) & BCMA_CC_OTPS_GU_PROG_HW) == 0)
++		return 0;
++
++	/* obtain bit offset from otplayout register */
++	offset = (bcma_read32(cc, BCMA_CC_OTPL) & BCMA_CC_OTPL_GURGN_OFFSET);
++	return BCMA_CC_SPROM + (offset >> 3);
++}
++
++int bcma_sprom_get(struct bcma_bus *bus)
++{
++	u16 offset = BCMA_CC_SPROM;
++	u16 *sprom;
++	int err = 0;
++
++	if (!bus->drv_cc.core)
++		return -EOPNOTSUPP;
++
++	if (!bcma_sprom_ext_available(bus)) {
++		/*
++		 * External SPROM takes precedence so check
++		 * on-chip OTP only when no external SPROM
++		 * is present.
++		 */
++		if (bcma_sprom_onchip_available(bus)) {
++			/* determine offset */
++			offset = bcma_sprom_onchip_offset(bus);
++		}
++		if (!offset) {
++			/*
++			 * Maybe there is no SPROM on the device?
++			 * Now we ask the arch code if there is some sprom
++			 * available for this device in some other storage.
++			 */
++			err = bcma_fill_sprom_with_fallback(bus, &bus->sprom);
++			return err;
++		}
++	}
++
++	sprom = kcalloc(SSB_SPROMSIZE_WORDS_R4, sizeof(u16),
++			GFP_KERNEL);
++	if (!sprom)
++		return -ENOMEM;
++
++	if (bus->chipinfo.id == 0x4331)
++		bcma_chipco_bcm4331_ext_pa_lines_ctl(&bus->drv_cc, false);
++
++	pr_debug("SPROM offset 0x%x\n", offset);
++	bcma_sprom_read(bus, offset, sprom);
++
++	if (bus->chipinfo.id == 0x4331)
++		bcma_chipco_bcm4331_ext_pa_lines_ctl(&bus->drv_cc, true);
++
++	err = bcma_sprom_valid(sprom);
++	if (err)
++		goto out;
++
++	bcma_sprom_extract_r8(bus, sprom);
++
++out:
++	kfree(sprom);
++	return err;
++}
+--- /dev/null
++++ b/drivers/bcma/driver_pci_host.c
+@@ -0,0 +1,589 @@
++/*
++ * Broadcom specific AMBA
++ * PCI Core in hostmode
++ *
++ * Copyright 2005 - 2011, Broadcom Corporation
++ * Copyright 2006, 2007, Michael Buesch <m@bues.ch>
++ * Copyright 2011, 2012, Hauke Mehrtens <hauke@hauke-m.de>
++ *
++ * Licensed under the GNU/GPL. See COPYING for details.
++ */
++
++#include "bcma_private.h"
++#include <linux/pci.h>
++#include <linux/export.h>
++#include <linux/bcma/bcma.h>
++#include <asm/paccess.h>
++
++/* Probe a 32bit value on the bus and catch bus exceptions.
++ * Returns nonzero on a bus exception.
++ * This is MIPS specific */
++#define mips_busprobe32(val, addr)	get_dbe((val), ((u32 *)(addr)))
++
++/* Assume one-hot slot wiring */
++#define BCMA_PCI_SLOT_MAX	16
++#define	PCI_CONFIG_SPACE_SIZE	256
++
++bool __devinit bcma_core_pci_is_in_hostmode(struct bcma_drv_pci *pc)
++{
++	struct bcma_bus *bus = pc->core->bus;
++	u16 chipid_top;
++	u32 tmp;
++
++	chipid_top = (bus->chipinfo.id & 0xFF00);
++	if (chipid_top != 0x4700 &&
++	    chipid_top != 0x5300)
++		return false;
++
++	if (bus->sprom.boardflags_lo & BCMA_CORE_PCI_BFL_NOPCI) {
++		pr_info("This PCI core is disabled and not working\n");
++		return false;
++	}
++
++	bcma_core_enable(pc->core, 0);
++
++	return !mips_busprobe32(tmp, pc->core->io_addr);
++}
++
++static u32 bcma_pcie_read_config(struct bcma_drv_pci *pc, u32 address)
++{
++	pcicore_write32(pc, BCMA_CORE_PCI_CONFIG_ADDR, address);
++	pcicore_read32(pc, BCMA_CORE_PCI_CONFIG_ADDR);
++	return pcicore_read32(pc, BCMA_CORE_PCI_CONFIG_DATA);
++}
++
++static void bcma_pcie_write_config(struct bcma_drv_pci *pc, u32 address,
++				   u32 data)
++{
++	pcicore_write32(pc, BCMA_CORE_PCI_CONFIG_ADDR, address);
++	pcicore_read32(pc, BCMA_CORE_PCI_CONFIG_ADDR);
++	pcicore_write32(pc, BCMA_CORE_PCI_CONFIG_DATA, data);
++}
++
++static u32 bcma_get_cfgspace_addr(struct bcma_drv_pci *pc, unsigned int dev,
++			     unsigned int func, unsigned int off)
++{
++	u32 addr = 0;
++
++	/* Issue config commands only when the data link is up (atleast
++	 * one external pcie device is present).
++	 */
++	if (dev >= 2 || !(bcma_pcie_read(pc, BCMA_CORE_PCI_DLLP_LSREG)
++			  & BCMA_CORE_PCI_DLLP_LSREG_LINKUP))
++		goto out;
++
++	/* Type 0 transaction */
++	/* Slide the PCI window to the appropriate slot */
++	pcicore_write32(pc, BCMA_CORE_PCI_SBTOPCI1, BCMA_CORE_PCI_SBTOPCI_CFG0);
++	/* Calculate the address */
++	addr = pc->host_controller->host_cfg_addr;
++	addr |= (dev << BCMA_CORE_PCI_CFG_SLOT_SHIFT);
++	addr |= (func << BCMA_CORE_PCI_CFG_FUN_SHIFT);
++	addr |= (off & ~3);
++
++out:
++	return addr;
++}
++
++static int bcma_extpci_read_config(struct bcma_drv_pci *pc, unsigned int dev,
++				  unsigned int func, unsigned int off,
++				  void *buf, int len)
++{
++	int err = -EINVAL;
++	u32 addr, val;
++	void __iomem *mmio = 0;
++
++	WARN_ON(!pc->hostmode);
++	if (unlikely(len != 1 && len != 2 && len != 4))
++		goto out;
++	if (dev == 0) {
++		/* we support only two functions on device 0 */
++		if (func > 1)
++			return -EINVAL;
++
++		/* accesses to config registers with offsets >= 256
++		 * requires indirect access.
++		 */
++		if (off >= PCI_CONFIG_SPACE_SIZE) {
++			addr = (func << 12);
++			addr |= (off & 0x0FFF);
++			val = bcma_pcie_read_config(pc, addr);
++		} else {
++			addr = BCMA_CORE_PCI_PCICFG0;
++			addr |= (func << 8);
++			addr |= (off & 0xfc);
++			val = pcicore_read32(pc, addr);
++		}
++	} else {
++		addr = bcma_get_cfgspace_addr(pc, dev, func, off);
++		if (unlikely(!addr))
++			goto out;
++		err = -ENOMEM;
++		mmio = ioremap_nocache(addr, len);
++		if (!mmio)
++			goto out;
++
++		if (mips_busprobe32(val, mmio)) {
++			val = 0xffffffff;
++			goto unmap;
++		}
++
++		val = readl(mmio);
++	}
++	val >>= (8 * (off & 3));
++
++	switch (len) {
++	case 1:
++		*((u8 *)buf) = (u8)val;
++		break;
++	case 2:
++		*((u16 *)buf) = (u16)val;
++		break;
++	case 4:
++		*((u32 *)buf) = (u32)val;
++		break;
++	}
++	err = 0;
++unmap:
++	if (mmio)
++		iounmap(mmio);
++out:
++	return err;
++}
++
++static int bcma_extpci_write_config(struct bcma_drv_pci *pc, unsigned int dev,
++				   unsigned int func, unsigned int off,
++				   const void *buf, int len)
++{
++	int err = -EINVAL;
++	u32 addr = 0, val = 0;
++	void __iomem *mmio = 0;
++	u16 chipid = pc->core->bus->chipinfo.id;
++
++	WARN_ON(!pc->hostmode);
++	if (unlikely(len != 1 && len != 2 && len != 4))
++		goto out;
++	if (dev == 0) {
++		/* accesses to config registers with offsets >= 256
++		 * requires indirect access.
++		 */
++		if (off < PCI_CONFIG_SPACE_SIZE) {
++			addr = pc->core->addr + BCMA_CORE_PCI_PCICFG0;
++			addr |= (func << 8);
++			addr |= (off & 0xfc);
++			mmio = ioremap_nocache(addr, len);
++			if (!mmio)
++				goto out;
++		}
++	} else {
++		addr = bcma_get_cfgspace_addr(pc, dev, func, off);
++		if (unlikely(!addr))
++			goto out;
++		err = -ENOMEM;
++		mmio = ioremap_nocache(addr, len);
++		if (!mmio)
++			goto out;
++
++		if (mips_busprobe32(val, mmio)) {
++			val = 0xffffffff;
++			goto unmap;
++		}
++	}
++
++	switch (len) {
++	case 1:
++		val = readl(mmio);
++		val &= ~(0xFF << (8 * (off & 3)));
++		val |= *((const u8 *)buf) << (8 * (off & 3));
++		break;
++	case 2:
++		val = readl(mmio);
++		val &= ~(0xFFFF << (8 * (off & 3)));
++		val |= *((const u16 *)buf) << (8 * (off & 3));
++		break;
++	case 4:
++		val = *((const u32 *)buf);
++		break;
++	}
++	if (dev == 0 && !addr) {
++		/* accesses to config registers with offsets >= 256
++		 * requires indirect access.
++		 */
++		addr = (func << 12);
++		addr |= (off & 0x0FFF);
++		bcma_pcie_write_config(pc, addr, val);
++	} else {
++		writel(val, mmio);
++
++		if (chipid == 0x4716 || chipid == 0x4748)
++			readl(mmio);
++	}
++
++	err = 0;
++unmap:
++	if (mmio)
++		iounmap(mmio);
++out:
++	return err;
++}
++
++static int bcma_core_pci_hostmode_read_config(struct pci_bus *bus,
++					      unsigned int devfn,
++					      int reg, int size, u32 *val)
++{
++	unsigned long flags;
++	int err;
++	struct bcma_drv_pci *pc;
++	struct bcma_drv_pci_host *pc_host;
++
++	pc_host = container_of(bus->ops, struct bcma_drv_pci_host, pci_ops);
++	pc = pc_host->pdev;
++
++	spin_lock_irqsave(&pc_host->cfgspace_lock, flags);
++	err = bcma_extpci_read_config(pc, PCI_SLOT(devfn),
++				     PCI_FUNC(devfn), reg, val, size);
++	spin_unlock_irqrestore(&pc_host->cfgspace_lock, flags);
++
++	return err ? PCIBIOS_DEVICE_NOT_FOUND : PCIBIOS_SUCCESSFUL;
++}
++
++static int bcma_core_pci_hostmode_write_config(struct pci_bus *bus,
++					       unsigned int devfn,
++					       int reg, int size, u32 val)
++{
++	unsigned long flags;
++	int err;
++	struct bcma_drv_pci *pc;
++	struct bcma_drv_pci_host *pc_host;
++
++	pc_host = container_of(bus->ops, struct bcma_drv_pci_host, pci_ops);
++	pc = pc_host->pdev;
++
++	spin_lock_irqsave(&pc_host->cfgspace_lock, flags);
++	err = bcma_extpci_write_config(pc, PCI_SLOT(devfn),
++				      PCI_FUNC(devfn), reg, &val, size);
++	spin_unlock_irqrestore(&pc_host->cfgspace_lock, flags);
++
++	return err ? PCIBIOS_DEVICE_NOT_FOUND : PCIBIOS_SUCCESSFUL;
++}
++
++/* return cap_offset if requested capability exists in the PCI config space */
++static u8 __devinit bcma_find_pci_capability(struct bcma_drv_pci *pc,
++					     unsigned int dev,
++					     unsigned int func, u8 req_cap_id,
++					     unsigned char *buf, u32 *buflen)
++{
++	u8 cap_id;
++	u8 cap_ptr = 0;
++	u32 bufsize;
++	u8 byte_val;
++
++	/* check for Header type 0 */
++	bcma_extpci_read_config(pc, dev, func, PCI_HEADER_TYPE, &byte_val,
++				sizeof(u8));
++	if ((byte_val & 0x7f) != PCI_HEADER_TYPE_NORMAL)
++		return cap_ptr;
++
++	/* check if the capability pointer field exists */
++	bcma_extpci_read_config(pc, dev, func, PCI_STATUS, &byte_val,
++				sizeof(u8));
++	if (!(byte_val & PCI_STATUS_CAP_LIST))
++		return cap_ptr;
++
++	/* check if the capability pointer is 0x00 */
++	bcma_extpci_read_config(pc, dev, func, PCI_CAPABILITY_LIST, &cap_ptr,
++				sizeof(u8));
++	if (cap_ptr == 0x00)
++		return cap_ptr;
++
++	/* loop thr'u the capability list and see if the requested capabilty
++	 * exists */
++	bcma_extpci_read_config(pc, dev, func, cap_ptr, &cap_id, sizeof(u8));
++	while (cap_id != req_cap_id) {
++		bcma_extpci_read_config(pc, dev, func, cap_ptr + 1, &cap_ptr,
++					sizeof(u8));
++		if (cap_ptr == 0x00)
++			return cap_ptr;
++		bcma_extpci_read_config(pc, dev, func, cap_ptr, &cap_id,
++					sizeof(u8));
++	}
++
++	/* found the caller requested capability */
++	if ((buf != NULL) && (buflen != NULL)) {
++		u8 cap_data;
++
++		bufsize = *buflen;
++		if (!bufsize)
++			return cap_ptr;
++
++		*buflen = 0;
++
++		/* copy the cpability data excluding cap ID and next ptr */
++		cap_data = cap_ptr + 2;
++		if ((bufsize + cap_data)  > PCI_CONFIG_SPACE_SIZE)
++			bufsize = PCI_CONFIG_SPACE_SIZE - cap_data;
++		*buflen = bufsize;
++		while (bufsize--) {
++			bcma_extpci_read_config(pc, dev, func, cap_data, buf,
++						sizeof(u8));
++			cap_data++;
++			buf++;
++		}
++	}
++
++	return cap_ptr;
++}
++
++/* If the root port is capable of returning Config Request
++ * Retry Status (CRS) Completion Status to software then
++ * enable the feature.
++ */
++static void __devinit bcma_core_pci_enable_crs(struct bcma_drv_pci *pc)
++{
++	u8 cap_ptr, root_ctrl, root_cap, dev;
++	u16 val16;
++	int i;
++
++	cap_ptr = bcma_find_pci_capability(pc, 0, 0, PCI_CAP_ID_EXP, NULL,
++					   NULL);
++	root_cap = cap_ptr + PCI_EXP_RTCAP;
++	bcma_extpci_read_config(pc, 0, 0, root_cap, &val16, sizeof(u16));
++	if (val16 & BCMA_CORE_PCI_RC_CRS_VISIBILITY) {
++		/* Enable CRS software visibility */
++		root_ctrl = cap_ptr + PCI_EXP_RTCTL;
++		val16 = PCI_EXP_RTCTL_CRSSVE;
++		bcma_extpci_read_config(pc, 0, 0, root_ctrl, &val16,
++					sizeof(u16));
++
++		/* Initiate a configuration request to read the vendor id
++		 * field of the device function's config space header after
++		 * 100 ms wait time from the end of Reset. If the device is
++		 * not done with its internal initialization, it must at
++		 * least return a completion TLP, with a completion status
++		 * of "Configuration Request Retry Status (CRS)". The root
++		 * complex must complete the request to the host by returning
++		 * a read-data value of 0001h for the Vendor ID field and
++		 * all 1s for any additional bytes included in the request.
++		 * Poll using the config reads for max wait time of 1 sec or
++		 * until we receive the successful completion status. Repeat
++		 * the procedure for all the devices.
++		 */
++		for (dev = 1; dev < BCMA_PCI_SLOT_MAX; dev++) {
++			for (i = 0; i < 100000; i++) {
++				bcma_extpci_read_config(pc, dev, 0,
++							PCI_VENDOR_ID, &val16,
++							sizeof(val16));
++				if (val16 != 0x1)
++					break;
++				udelay(10);
++			}
++			if (val16 == 0x1)
++				pr_err("PCI: Broken device in slot %d\n", dev);
++		}
++	}
++}
++
++void __devinit bcma_core_pci_hostmode_init(struct bcma_drv_pci *pc)
++{
++	struct bcma_bus *bus = pc->core->bus;
++	struct bcma_drv_pci_host *pc_host;
++	u32 tmp;
++	u32 pci_membase_1G;
++	unsigned long io_map_base;
++
++	pr_info("PCIEcore in host mode found\n");
++
++	pc_host = kzalloc(sizeof(*pc_host), GFP_KERNEL);
++	if (!pc_host)  {
++		pr_err("can not allocate memory");
++		return;
++	}
++
++	pc->host_controller = pc_host;
++	pc_host->pci_controller.io_resource = &pc_host->io_resource;
++	pc_host->pci_controller.mem_resource = &pc_host->mem_resource;
++	pc_host->pci_controller.pci_ops = &pc_host->pci_ops;
++	pc_host->pdev = pc;
++
++	pci_membase_1G = BCMA_SOC_PCI_DMA;
++	pc_host->host_cfg_addr = BCMA_SOC_PCI_CFG;
++
++	pc_host->pci_ops.read = bcma_core_pci_hostmode_read_config;
++	pc_host->pci_ops.write = bcma_core_pci_hostmode_write_config;
++
++	pc_host->mem_resource.name = "BCMA PCIcore external memory",
++	pc_host->mem_resource.start = BCMA_SOC_PCI_DMA;
++	pc_host->mem_resource.end = BCMA_SOC_PCI_DMA + BCMA_SOC_PCI_DMA_SZ - 1;
++	pc_host->mem_resource.flags = IORESOURCE_MEM | IORESOURCE_PCI_FIXED;
++
++	pc_host->io_resource.name = "BCMA PCIcore external I/O",
++	pc_host->io_resource.start = 0x100;
++	pc_host->io_resource.end = 0x7FF;
++	pc_host->io_resource.flags = IORESOURCE_IO | IORESOURCE_PCI_FIXED;
++
++	/* Reset RC */
++	udelay(3000);
++	pcicore_write32(pc, BCMA_CORE_PCI_CTL, BCMA_CORE_PCI_CTL_RST_OE);
++	udelay(1000);
++	pcicore_write32(pc, BCMA_CORE_PCI_CTL, BCMA_CORE_PCI_CTL_RST |
++			BCMA_CORE_PCI_CTL_RST_OE);
++
++	/* 64 MB I/O access window. On 4716, use
++	 * sbtopcie0 to access the device registers. We
++	 * can't use address match 2 (1 GB window) region
++	 * as mips can't generate 64-bit address on the
++	 * backplane.
++	 */
++	if (bus->chipinfo.id == 0x4716 || bus->chipinfo.id == 0x4748) {
++		pc_host->mem_resource.start = BCMA_SOC_PCI_MEM;
++		pc_host->mem_resource.end = BCMA_SOC_PCI_MEM +
++					    BCMA_SOC_PCI_MEM_SZ - 1;
++		pcicore_write32(pc, BCMA_CORE_PCI_SBTOPCI0,
++				BCMA_CORE_PCI_SBTOPCI_MEM | BCMA_SOC_PCI_MEM);
++	} else if (bus->chipinfo.id == 0x5300) {
++		tmp = BCMA_CORE_PCI_SBTOPCI_MEM;
++		tmp |= BCMA_CORE_PCI_SBTOPCI_PREF;
++		tmp |= BCMA_CORE_PCI_SBTOPCI_BURST;
++		if (pc->core->core_unit == 0) {
++			pc_host->mem_resource.start = BCMA_SOC_PCI_MEM;
++			pc_host->mem_resource.end = BCMA_SOC_PCI_MEM +
++						    BCMA_SOC_PCI_MEM_SZ - 1;
++			pci_membase_1G = BCMA_SOC_PCIE_DMA_H32;
++			pcicore_write32(pc, BCMA_CORE_PCI_SBTOPCI0,
++					tmp | BCMA_SOC_PCI_MEM);
++		} else if (pc->core->core_unit == 1) {
++			pc_host->mem_resource.start = BCMA_SOC_PCI1_MEM;
++			pc_host->mem_resource.end = BCMA_SOC_PCI1_MEM +
++						    BCMA_SOC_PCI_MEM_SZ - 1;
++			pci_membase_1G = BCMA_SOC_PCIE1_DMA_H32;
++			pc_host->host_cfg_addr = BCMA_SOC_PCI1_CFG;
++			pcicore_write32(pc, BCMA_CORE_PCI_SBTOPCI0,
++					tmp | BCMA_SOC_PCI1_MEM);
++		}
++	} else
++		pcicore_write32(pc, BCMA_CORE_PCI_SBTOPCI0,
++				BCMA_CORE_PCI_SBTOPCI_IO);
++
++	/* 64 MB configuration access window */
++	pcicore_write32(pc, BCMA_CORE_PCI_SBTOPCI1, BCMA_CORE_PCI_SBTOPCI_CFG0);
++
++	/* 1 GB memory access window */
++	pcicore_write32(pc, BCMA_CORE_PCI_SBTOPCI2,
++			BCMA_CORE_PCI_SBTOPCI_MEM | pci_membase_1G);
++
++
++	/* As per PCI Express Base Spec 1.1 we need to wait for
++	 * at least 100 ms from the end of a reset (cold/warm/hot)
++	 * before issuing configuration requests to PCI Express
++	 * devices.
++	 */
++	udelay(100000);
++
++	bcma_core_pci_enable_crs(pc);
++
++	/* Enable PCI bridge BAR0 memory & master access */
++	tmp = PCI_COMMAND_MASTER | PCI_COMMAND_MEMORY;
++	bcma_extpci_write_config(pc, 0, 0, PCI_COMMAND, &tmp, sizeof(tmp));
++
++	/* Enable PCI interrupts */
++	pcicore_write32(pc, BCMA_CORE_PCI_IMASK, BCMA_CORE_PCI_IMASK_INTA);
++
++	/* Ok, ready to run, register it to the system.
++	 * The following needs change, if we want to port hostmode
++	 * to non-MIPS platform. */
++	io_map_base = (unsigned long)ioremap_nocache(BCMA_SOC_PCI_MEM,
++						     0x04000000);
++	pc_host->pci_controller.io_map_base = io_map_base;
++	set_io_port_base(pc_host->pci_controller.io_map_base);
++	/* Give some time to the PCI controller to configure itself with the new
++	 * values. Not waiting at this point causes crashes of the machine. */
++	mdelay(10);
++	register_pci_controller(&pc_host->pci_controller);
++	return;
++}
++
++/* Early PCI fixup for a device on the PCI-core bridge. */
++static void bcma_core_pci_fixup_pcibridge(struct pci_dev *dev)
++{
++	if (dev->bus->ops->read != bcma_core_pci_hostmode_read_config) {
++		/* This is not a device on the PCI-core bridge. */
++		return;
++	}
++	if (PCI_SLOT(dev->devfn) != 0)
++		return;
++
++	pr_info("PCI: Fixing up bridge %s\n", pci_name(dev));
++
++	/* Enable PCI bridge bus mastering and memory space */
++	pci_set_master(dev);
++	if (pcibios_enable_device(dev, ~0) < 0) {
++		pr_err("PCI: BCMA bridge enable failed\n");
++		return;
++	}
++
++	/* Enable PCI bridge BAR1 prefetch and burst */
++	pci_write_config_dword(dev, BCMA_PCI_BAR1_CONTROL, 3);
++}
++DECLARE_PCI_FIXUP_EARLY(PCI_ANY_ID, PCI_ANY_ID, bcma_core_pci_fixup_pcibridge);
++
++/* Early PCI fixup for all PCI-cores to set the correct memory address. */
++static void bcma_core_pci_fixup_addresses(struct pci_dev *dev)
++{
++	struct resource *res;
++	int pos;
++
++	if (dev->bus->ops->read != bcma_core_pci_hostmode_read_config) {
++		/* This is not a device on the PCI-core bridge. */
++		return;
++	}
++	if (PCI_SLOT(dev->devfn) == 0)
++		return;
++
++	pr_info("PCI: Fixing up addresses %s\n", pci_name(dev));
++
++	for (pos = 0; pos < 6; pos++) {
++		res = &dev->resource[pos];
++		if (res->flags & (IORESOURCE_IO | IORESOURCE_MEM))
++			pci_assign_resource(dev, pos);
++	}
++}
++DECLARE_PCI_FIXUP_HEADER(PCI_ANY_ID, PCI_ANY_ID, bcma_core_pci_fixup_addresses);
++
++/* This function is called when doing a pci_enable_device().
++ * We must first check if the device is a device on the PCI-core bridge. */
++int bcma_core_pci_plat_dev_init(struct pci_dev *dev)
++{
++	struct bcma_drv_pci_host *pc_host;
++
++	if (dev->bus->ops->read != bcma_core_pci_hostmode_read_config) {
++		/* This is not a device on the PCI-core bridge. */
++		return -ENODEV;
++	}
++	pc_host = container_of(dev->bus->ops, struct bcma_drv_pci_host,
++			       pci_ops);
++
++	pr_info("PCI: Fixing up device %s\n", pci_name(dev));
++
++	/* Fix up interrupt lines */
++	dev->irq = bcma_core_mips_irq(pc_host->pdev->core) + 2;
++	pci_write_config_byte(dev, PCI_INTERRUPT_LINE, dev->irq);
++
++	return 0;
++}
++EXPORT_SYMBOL(bcma_core_pci_plat_dev_init);
++
++/* PCI device IRQ mapping. */
++int bcma_core_pci_pcibios_map_irq(const struct pci_dev *dev)
++{
++	struct bcma_drv_pci_host *pc_host;
++
++	if (dev->bus->ops->read != bcma_core_pci_hostmode_read_config) {
++		/* This is not a device on the PCI-core bridge. */
++		return -ENODEV;
++	}
++
++	pc_host = container_of(dev->bus->ops, struct bcma_drv_pci_host,
++			       pci_ops);
++	return bcma_core_mips_irq(pc_host->pdev->core) + 2;
++}
++EXPORT_SYMBOL(bcma_core_pci_pcibios_map_irq);
+--- /dev/null
++++ b/drivers/bcma/driver_mips.c
+@@ -0,0 +1,256 @@
++/*
++ * Broadcom specific AMBA
++ * Broadcom MIPS32 74K core driver
++ *
++ * Copyright 2009, Broadcom Corporation
++ * Copyright 2006, 2007, Michael Buesch <mb@bu3sch.de>
++ * Copyright 2010, Bernhard Loos <bernhardloos@googlemail.com>
++ * Copyright 2011, Hauke Mehrtens <hauke@hauke-m.de>
++ *
++ * Licensed under the GNU/GPL. See COPYING for details.
++ */
++
++#include "bcma_private.h"
++
++#include <linux/bcma/bcma.h>
++
++#include <linux/serial.h>
++#include <linux/serial_core.h>
++#include <linux/serial_reg.h>
++#include <linux/time.h>
++
++/* The 47162a0 hangs when reading MIPS DMP registers registers */
++static inline bool bcma_core_mips_bcm47162a0_quirk(struct bcma_device *dev)
++{
++	return dev->bus->chipinfo.id == 47162 && dev->bus->chipinfo.rev == 0 &&
++	       dev->id.id == BCMA_CORE_MIPS_74K;
++}
++
++/* The 5357b0 hangs when reading USB20H DMP registers */
++static inline bool bcma_core_mips_bcm5357b0_quirk(struct bcma_device *dev)
++{
++	return (dev->bus->chipinfo.id == 0x5357 ||
++		dev->bus->chipinfo.id == 0x4749) &&
++	       dev->bus->chipinfo.pkg == 11 &&
++	       dev->id.id == BCMA_CORE_USB20_HOST;
++}
++
++static inline u32 mips_read32(struct bcma_drv_mips *mcore,
++			      u16 offset)
++{
++	return bcma_read32(mcore->core, offset);
++}
++
++static inline void mips_write32(struct bcma_drv_mips *mcore,
++				u16 offset,
++				u32 value)
++{
++	bcma_write32(mcore->core, offset, value);
++}
++
++static const u32 ipsflag_irq_mask[] = {
++	0,
++	BCMA_MIPS_IPSFLAG_IRQ1,
++	BCMA_MIPS_IPSFLAG_IRQ2,
++	BCMA_MIPS_IPSFLAG_IRQ3,
++	BCMA_MIPS_IPSFLAG_IRQ4,
++};
++
++static const u32 ipsflag_irq_shift[] = {
++	0,
++	BCMA_MIPS_IPSFLAG_IRQ1_SHIFT,
++	BCMA_MIPS_IPSFLAG_IRQ2_SHIFT,
++	BCMA_MIPS_IPSFLAG_IRQ3_SHIFT,
++	BCMA_MIPS_IPSFLAG_IRQ4_SHIFT,
++};
++
++static u32 bcma_core_mips_irqflag(struct bcma_device *dev)
++{
++	u32 flag;
++
++	if (bcma_core_mips_bcm47162a0_quirk(dev))
++		return dev->core_index;
++	if (bcma_core_mips_bcm5357b0_quirk(dev))
++		return dev->core_index;
++	flag = bcma_aread32(dev, BCMA_MIPS_OOBSELOUTA30);
++
++	return flag & 0x1F;
++}
++
++/* Get the MIPS IRQ assignment for a specified device.
++ * If unassigned, 0 is returned.
++ */
++unsigned int bcma_core_mips_irq(struct bcma_device *dev)
++{
++	struct bcma_device *mdev = dev->bus->drv_mips.core;
++	u32 irqflag;
++	unsigned int irq;
++
++	irqflag = bcma_core_mips_irqflag(dev);
++
++	for (irq = 1; irq <= 4; irq++)
++		if (bcma_read32(mdev, BCMA_MIPS_MIPS74K_INTMASK(irq)) &
++		    (1 << irqflag))
++			return irq;
++
++	return 0;
++}
++EXPORT_SYMBOL(bcma_core_mips_irq);
++
++static void bcma_core_mips_set_irq(struct bcma_device *dev, unsigned int irq)
++{
++	unsigned int oldirq = bcma_core_mips_irq(dev);
++	struct bcma_bus *bus = dev->bus;
++	struct bcma_device *mdev = bus->drv_mips.core;
++	u32 irqflag;
++
++	irqflag = bcma_core_mips_irqflag(dev);
++	BUG_ON(oldirq == 6);
++
++	dev->irq = irq + 2;
++
++	/* clear the old irq */
++	if (oldirq == 0)
++		bcma_write32(mdev, BCMA_MIPS_MIPS74K_INTMASK(0),
++			    bcma_read32(mdev, BCMA_MIPS_MIPS74K_INTMASK(0)) &
++			    ~(1 << irqflag));
++	else
++		bcma_write32(mdev, BCMA_MIPS_MIPS74K_INTMASK(irq), 0);
++
++	/* assign the new one */
++	if (irq == 0) {
++		bcma_write32(mdev, BCMA_MIPS_MIPS74K_INTMASK(0),
++			    bcma_read32(mdev, BCMA_MIPS_MIPS74K_INTMASK(0)) |
++			    (1 << irqflag));
++	} else {
++		u32 oldirqflag = bcma_read32(mdev,
++					     BCMA_MIPS_MIPS74K_INTMASK(irq));
++		if (oldirqflag) {
++			struct bcma_device *core;
++
++			/* backplane irq line is in use, find out who uses
++			 * it and set user to irq 0
++			 */
++			list_for_each_entry_reverse(core, &bus->cores, list) {
++				if ((1 << bcma_core_mips_irqflag(core)) ==
++				    oldirqflag) {
++					bcma_core_mips_set_irq(core, 0);
++					break;
++				}
++			}
++		}
++		bcma_write32(mdev, BCMA_MIPS_MIPS74K_INTMASK(irq),
++			     1 << irqflag);
++	}
++
++	pr_info("set_irq: core 0x%04x, irq %d => %d\n",
++		dev->id.id, oldirq + 2, irq + 2);
++}
++
++static void bcma_core_mips_print_irq(struct bcma_device *dev, unsigned int irq)
++{
++	int i;
++	static const char *irq_name[] = {"2(S)", "3", "4", "5", "6", "D", "I"};
++	printk(KERN_INFO KBUILD_MODNAME ": core 0x%04x, irq :", dev->id.id);
++	for (i = 0; i <= 6; i++)
++		printk(" %s%s", irq_name[i], i == irq ? "*" : " ");
++	printk("\n");
++}
++
++static void bcma_core_mips_dump_irq(struct bcma_bus *bus)
++{
++	struct bcma_device *core;
++
++	list_for_each_entry_reverse(core, &bus->cores, list) {
++		bcma_core_mips_print_irq(core, bcma_core_mips_irq(core));
++	}
++}
++
++u32 bcma_cpu_clock(struct bcma_drv_mips *mcore)
++{
++	struct bcma_bus *bus = mcore->core->bus;
++
++	if (bus->drv_cc.capabilities & BCMA_CC_CAP_PMU)
++		return bcma_pmu_get_clockcpu(&bus->drv_cc);
++
++	pr_err("No PMU available, need this to get the cpu clock\n");
++	return 0;
++}
++EXPORT_SYMBOL(bcma_cpu_clock);
++
++static void bcma_core_mips_flash_detect(struct bcma_drv_mips *mcore)
++{
++	struct bcma_bus *bus = mcore->core->bus;
++
++	switch (bus->drv_cc.capabilities & BCMA_CC_CAP_FLASHT) {
++	case BCMA_CC_FLASHT_STSER:
++	case BCMA_CC_FLASHT_ATSER:
++		pr_err("Serial flash not supported.\n");
++		break;
++	case BCMA_CC_FLASHT_PARA:
++		pr_info("found parallel flash.\n");
++		bus->drv_cc.pflash.window = 0x1c000000;
++		bus->drv_cc.pflash.window_size = 0x02000000;
++
++		if ((bcma_read32(bus->drv_cc.core, BCMA_CC_FLASH_CFG) &
++		     BCMA_CC_FLASH_CFG_DS) == 0)
++			bus->drv_cc.pflash.buswidth = 1;
++		else
++			bus->drv_cc.pflash.buswidth = 2;
++		break;
++	default:
++		pr_err("flash not supported.\n");
++	}
++}
++
++void bcma_core_mips_init(struct bcma_drv_mips *mcore)
++{
++	struct bcma_bus *bus;
++	struct bcma_device *core;
++	bus = mcore->core->bus;
++
++	pr_info("Initializing MIPS core...\n");
++
++	if (!mcore->setup_done)
++		mcore->assigned_irqs = 1;
++
++	/* Assign IRQs to all cores on the bus */
++	list_for_each_entry_reverse(core, &bus->cores, list) {
++		int mips_irq;
++		if (core->irq)
++			continue;
++
++		mips_irq = bcma_core_mips_irq(core);
++		if (mips_irq > 4)
++			core->irq = 0;
++		else
++			core->irq = mips_irq + 2;
++		if (core->irq > 5)
++			continue;
++		switch (core->id.id) {
++		case BCMA_CORE_PCI:
++		case BCMA_CORE_PCIE:
++		case BCMA_CORE_ETHERNET:
++		case BCMA_CORE_ETHERNET_GBIT:
++		case BCMA_CORE_MAC_GBIT:
++		case BCMA_CORE_80211:
++		case BCMA_CORE_USB20_HOST:
++			/* These devices get their own IRQ line if available,
++			 * the rest goes on IRQ0
++			 */
++			if (mcore->assigned_irqs <= 4)
++				bcma_core_mips_set_irq(core,
++						       mcore->assigned_irqs++);
++			break;
++		}
++	}
++	pr_info("IRQ reconfiguration done\n");
++	bcma_core_mips_dump_irq(bus);
++
++	if (mcore->setup_done)
++		return;
++
++	bcma_chipco_serial_init(&bus->drv_cc);
++	bcma_core_mips_flash_detect(mcore);
++	mcore->setup_done = true;
++}
+--- /dev/null
++++ b/drivers/bcma/host_soc.c
+@@ -0,0 +1,183 @@
++/*
++ * Broadcom specific AMBA
++ * System on Chip (SoC) Host
++ *
++ * Licensed under the GNU/GPL. See COPYING for details.
++ */
++
++#include "bcma_private.h"
++#include "scan.h"
++#include <linux/bcma/bcma.h>
++#include <linux/bcma/bcma_soc.h>
++
++static u8 bcma_host_soc_read8(struct bcma_device *core, u16 offset)
++{
++	return readb(core->io_addr + offset);
++}
++
++static u16 bcma_host_soc_read16(struct bcma_device *core, u16 offset)
++{
++	return readw(core->io_addr + offset);
++}
++
++static u32 bcma_host_soc_read32(struct bcma_device *core, u16 offset)
++{
++	return readl(core->io_addr + offset);
++}
++
++static void bcma_host_soc_write8(struct bcma_device *core, u16 offset,
++				 u8 value)
++{
++	writeb(value, core->io_addr + offset);
++}
++
++static void bcma_host_soc_write16(struct bcma_device *core, u16 offset,
++				 u16 value)
++{
++	writew(value, core->io_addr + offset);
++}
++
++static void bcma_host_soc_write32(struct bcma_device *core, u16 offset,
++				 u32 value)
++{
++	writel(value, core->io_addr + offset);
++}
++
++#ifdef CONFIG_BCMA_BLOCKIO
++static void bcma_host_soc_block_read(struct bcma_device *core, void *buffer,
++				     size_t count, u16 offset, u8 reg_width)
++{
++	void __iomem *addr = core->io_addr + offset;
++
++	switch (reg_width) {
++	case sizeof(u8): {
++		u8 *buf = buffer;
++
++		while (count) {
++			*buf = __raw_readb(addr);
++			buf++;
++			count--;
++		}
++		break;
++	}
++	case sizeof(u16): {
++		__le16 *buf = buffer;
++
++		WARN_ON(count & 1);
++		while (count) {
++			*buf = (__force __le16)__raw_readw(addr);
++			buf++;
++			count -= 2;
++		}
++		break;
++	}
++	case sizeof(u32): {
++		__le32 *buf = buffer;
++
++		WARN_ON(count & 3);
++		while (count) {
++			*buf = (__force __le32)__raw_readl(addr);
++			buf++;
++			count -= 4;
++		}
++		break;
++	}
++	default:
++		WARN_ON(1);
++	}
++}
++
++static void bcma_host_soc_block_write(struct bcma_device *core,
++				      const void *buffer,
++				      size_t count, u16 offset, u8 reg_width)
++{
++	void __iomem *addr = core->io_addr + offset;
++
++	switch (reg_width) {
++	case sizeof(u8): {
++		const u8 *buf = buffer;
++
++		while (count) {
++			__raw_writeb(*buf, addr);
++			buf++;
++			count--;
++		}
++		break;
++	}
++	case sizeof(u16): {
++		const __le16 *buf = buffer;
++
++		WARN_ON(count & 1);
++		while (count) {
++			__raw_writew((__force u16)(*buf), addr);
++			buf++;
++			count -= 2;
++		}
++		break;
++	}
++	case sizeof(u32): {
++		const __le32 *buf = buffer;
++
++		WARN_ON(count & 3);
++		while (count) {
++			__raw_writel((__force u32)(*buf), addr);
++			buf++;
++			count -= 4;
++		}
++		break;
++	}
++	default:
++		WARN_ON(1);
++	}
++}
++#endif /* CONFIG_BCMA_BLOCKIO */
++
++static u32 bcma_host_soc_aread32(struct bcma_device *core, u16 offset)
++{
++	return readl(core->io_wrap + offset);
++}
++
++static void bcma_host_soc_awrite32(struct bcma_device *core, u16 offset,
++				  u32 value)
++{
++	writel(value, core->io_wrap + offset);
++}
++
++const struct bcma_host_ops bcma_host_soc_ops = {
++	.read8		= bcma_host_soc_read8,
++	.read16		= bcma_host_soc_read16,
++	.read32		= bcma_host_soc_read32,
++	.write8		= bcma_host_soc_write8,
++	.write16	= bcma_host_soc_write16,
++	.write32	= bcma_host_soc_write32,
++#ifdef CONFIG_BCMA_BLOCKIO
++	.block_read	= bcma_host_soc_block_read,
++	.block_write	= bcma_host_soc_block_write,
++#endif
++	.aread32	= bcma_host_soc_aread32,
++	.awrite32	= bcma_host_soc_awrite32,
++};
++
++int __init bcma_host_soc_register(struct bcma_soc *soc)
++{
++	struct bcma_bus *bus = &soc->bus;
++	int err;
++
++	/* iomap only first core. We have to read some register on this core
++	 * to scan the bus.
++	 */
++	bus->mmio = ioremap_nocache(BCMA_ADDR_BASE, BCMA_CORE_SIZE * 1);
++	if (!bus->mmio)
++		return -ENOMEM;
++
++	/* Host specific */
++	bus->hosttype = BCMA_HOSTTYPE_SOC;
++	bus->ops = &bcma_host_soc_ops;
++
++	/* Register */
++	err = bcma_bus_early_register(bus, &soc->core_cc, &soc->core_mips);
++	if (err)
++		iounmap(bus->mmio);
++
++	return err;
++}
+--- /dev/null
++++ b/include/linux/bcma/bcma_driver_mips.h
+@@ -0,0 +1,51 @@
++#ifndef LINUX_BCMA_DRIVER_MIPS_H_
++#define LINUX_BCMA_DRIVER_MIPS_H_
++
++#define BCMA_MIPS_IPSFLAG		0x0F08
++/* which sbflags get routed to mips interrupt 1 */
++#define  BCMA_MIPS_IPSFLAG_IRQ1		0x0000003F
++#define  BCMA_MIPS_IPSFLAG_IRQ1_SHIFT	0
++/* which sbflags get routed to mips interrupt 2 */
++#define  BCMA_MIPS_IPSFLAG_IRQ2		0x00003F00
++#define  BCMA_MIPS_IPSFLAG_IRQ2_SHIFT	8
++/* which sbflags get routed to mips interrupt 3 */
++#define  BCMA_MIPS_IPSFLAG_IRQ3		0x003F0000
++#define  BCMA_MIPS_IPSFLAG_IRQ3_SHIFT	16
++/* which sbflags get routed to mips interrupt 4 */
++#define  BCMA_MIPS_IPSFLAG_IRQ4		0x3F000000
++#define  BCMA_MIPS_IPSFLAG_IRQ4_SHIFT	24
++
++/* MIPS 74K core registers */
++#define BCMA_MIPS_MIPS74K_CORECTL	0x0000
++#define BCMA_MIPS_MIPS74K_EXCEPTBASE	0x0004
++#define BCMA_MIPS_MIPS74K_BIST		0x000C
++#define BCMA_MIPS_MIPS74K_INTMASK_INT0	0x0014
++#define BCMA_MIPS_MIPS74K_INTMASK(int) \
++	((int) * 4 + BCMA_MIPS_MIPS74K_INTMASK_INT0)
++#define BCMA_MIPS_MIPS74K_NMIMASK	0x002C
++#define BCMA_MIPS_MIPS74K_GPIOSEL	0x0040
++#define BCMA_MIPS_MIPS74K_GPIOOUT	0x0044
++#define BCMA_MIPS_MIPS74K_GPIOEN	0x0048
++#define BCMA_MIPS_MIPS74K_CLKCTLST	0x01E0
++
++#define BCMA_MIPS_OOBSELOUTA30		0x100
++
++struct bcma_device;
++
++struct bcma_drv_mips {
++	struct bcma_device *core;
++	u8 setup_done:1;
++	unsigned int assigned_irqs;
++};
++
++#ifdef CONFIG_BCMA_DRIVER_MIPS
++extern void bcma_core_mips_init(struct bcma_drv_mips *mcore);
++#else
++static inline void bcma_core_mips_init(struct bcma_drv_mips *mcore) { }
++#endif
++
++extern u32 bcma_cpu_clock(struct bcma_drv_mips *mcore);
++
++extern unsigned int bcma_core_mips_irq(struct bcma_device *dev);
++
++#endif /* LINUX_BCMA_DRIVER_MIPS_H_ */
+--- /dev/null
++++ b/include/linux/bcma/bcma_soc.h
+@@ -0,0 +1,16 @@
++#ifndef LINUX_BCMA_SOC_H_
++#define LINUX_BCMA_SOC_H_
++
++#include <linux/bcma/bcma.h>
++
++struct bcma_soc {
++	struct bcma_bus bus;
++	struct bcma_device core_cc;
++	struct bcma_device core_mips;
++};
++
++int __init bcma_host_soc_register(struct bcma_soc *soc);
++
++int bcma_bus_register(struct bcma_bus *bus);
++
++#endif /* LINUX_BCMA_SOC_H_ */
diff -Nru a/target/linux/generic/patches-2.6.31/025-mips_disable_fpu.patch b/target/linux/generic/patches-2.6.31/025-mips_disable_fpu.patch
--- a/target/linux/generic/patches-2.6.31/025-mips_disable_fpu.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/025-mips_disable_fpu.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,155 @@
+MIPS: allow disabling the kernel FPU emulator
+
+This patch allows turning off the in-kernel Algorithmics
+FPU emulator support, which allows one to save a couple of
+precious blocks on an embedded system.
+
+Signed-off-by: Florian Fainelli <florian@openwrt.org>
+--
+--- a/arch/mips/Kconfig
++++ b/arch/mips/Kconfig
+@@ -825,6 +825,17 @@ config I8259
+ config MIPS_BONITO64
+ 	bool
+ 
++config MIPS_FPU_EMU
++	bool "Enable FPU emulation"
++	default y
++	help
++	   This option allows building a kernel with or without the Algorithmics
++	   FPU emulator enabled. Turning off this option results in a kernel which
++	   does not catch floating operations exceptions. Make sure that your toolchain
++	   is configured to enable software floating point emulation in that case.
++		
++	   If unsure say Y here.
++
+ config MIPS_MSC
+ 	bool
+ 
+--- a/arch/mips/math-emu/Makefile
++++ b/arch/mips/math-emu/Makefile
+@@ -2,12 +2,14 @@
+ # Makefile for the Linux/MIPS kernel FPU emulation.
+ #
+ 
+-obj-y	:= cp1emu.o ieee754m.o ieee754d.o ieee754dp.o ieee754sp.o ieee754.o \
++obj-y	:=	kernel_linkage.o dsemul.o cp1emu.o
++
++obj-$(CONFIG_MIPS_FPU_EMU)	+= ieee754m.o ieee754d.o ieee754dp.o ieee754sp.o ieee754.o \
+ 	   ieee754xcpt.o dp_frexp.o dp_modf.o dp_div.o dp_mul.o dp_sub.o \
+ 	   dp_add.o dp_fsp.o dp_cmp.o dp_logb.o dp_scalb.o dp_simple.o \
+ 	   dp_tint.o dp_fint.o dp_tlong.o dp_flong.o sp_frexp.o sp_modf.o \
+ 	   sp_div.o sp_mul.o sp_sub.o sp_add.o sp_fdp.o sp_cmp.o sp_logb.o \
+ 	   sp_scalb.o sp_simple.o sp_tint.o sp_fint.o sp_tlong.o sp_flong.o \
+-	   dp_sqrt.o sp_sqrt.o kernel_linkage.o dsemul.o
++	   dp_sqrt.o sp_sqrt.o
+ 
+ EXTRA_CFLAGS += -Werror
+--- a/arch/mips/math-emu/cp1emu.c
++++ b/arch/mips/math-emu/cp1emu.c
+@@ -56,6 +56,12 @@
+ #endif
+ #define __mips 4
+ 
++/* Further private data for which no space exists in mips_fpu_struct */
++
++struct mips_fpu_emulator_stats fpuemustats;
++
++#ifdef CONFIG_MIPS_FPU_EMU
++
+ /* Function which emulates a floating point instruction. */
+ 
+ static int fpu_emu(struct pt_regs *, struct mips_fpu_struct *,
+@@ -66,10 +72,6 @@ static int fpux_emu(struct pt_regs *,
+ 	struct mips_fpu_struct *, mips_instruction);
+ #endif
+ 
+-/* Further private data for which no space exists in mips_fpu_struct */
+-
+-struct mips_fpu_emulator_stats fpuemustats;
+-
+ /* Control registers */
+ 
+ #define FPCREG_RID	0	/* $0  = revision id */
+@@ -1273,6 +1275,13 @@ int fpu_emulator_cop1Handler(struct pt_r
+ 
+ 	return sig;
+ }
++#else
++int fpu_emulator_cop1Handler(struct pt_regs *xcp, struct mips_fpu_struct *ctx,
++        int has_fpu)
++{
++	return 0;
++}
++#endif /* CONFIG_MIPS_FPU_EMU */
+ 
+ #ifdef CONFIG_DEBUG_FS
+ extern struct dentry *mips_debugfs_dir;
+--- a/arch/mips/math-emu/dsemul.c
++++ b/arch/mips/math-emu/dsemul.c
+@@ -109,6 +109,7 @@ int mips_dsemul(struct pt_regs *regs, mi
+ 	return SIGILL;		/* force out of emulation loop */
+ }
+ 
++#ifdef CONFIG_MIPS_FPU_EMU
+ int do_dsemulret(struct pt_regs *xcp)
+ {
+ 	struct emuframe __user *fr;
+@@ -165,3 +166,9 @@ int do_dsemulret(struct pt_regs *xcp)
+ 
+ 	return 1;
+ }
++#else
++int do_dsemulret(struct pt_regs *xcp)
++{
++	return 0;
++}
++#endif /* CONFIG_MIPS_FPU_EMU */
+--- a/arch/mips/math-emu/kernel_linkage.c
++++ b/arch/mips/math-emu/kernel_linkage.c
+@@ -29,6 +29,7 @@
+ 
+ #define SIGNALLING_NAN 0x7ff800007ff80000LL
+ 
++#ifdef CONFIG_MIPS_FPU_EMU
+ void fpu_emulator_init_fpu(void)
+ {
+ 	static int first = 1;
+@@ -112,4 +113,36 @@ int fpu_emulator_restore_context32(struc
+ 
+ 	return err;
+ }
+-#endif
++#endif	/* CONFIG_64BIT */
++#else
++
++void fpu_emulator_init_fpu(void)
++{
++	printk(KERN_INFO "FPU emulator disabled, make sure your toolchain"
++		"was compiled with software floating point support (soft-float)\n");
++	return;
++}
++
++int fpu_emulator_save_context(struct sigcontext __user *sc)
++{
++	return 0;
++}
++
++int fpu_emulator_restore_context(struct sigcontext __user *sc)
++{
++	return 0;
++}
++
++int fpu_emulator_save_context32(struct sigcontext32 __user *sc)
++{
++	return 0;
++}
++
++int fpu_emulator_restore_context32(struct sigcontext32 __user *sc)
++{
++	return 0;
++}
++
++#ifdef CONFIG_64BIT
++#endif	/* CONFIG_64BIT */
++#endif /* CONFIG_MIPS_FPU_EMU */
diff -Nru a/target/linux/generic/patches-2.6.31/027-mips_module_reloc.patch b/target/linux/generic/patches-2.6.31/027-mips_module_reloc.patch
--- a/target/linux/generic/patches-2.6.31/027-mips_module_reloc.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/027-mips_module_reloc.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,368 @@
+--- a/arch/mips/Makefile
++++ b/arch/mips/Makefile
+@@ -83,7 +83,7 @@ all-$(CONFIG_BOOT_ELF64)	:= $(vmlinux-64
+ cflags-y			+= -G 0 -mno-abicalls -fno-pic -pipe
+ cflags-y			+= -msoft-float
+ LDFLAGS_vmlinux			+= -G 0 -static -n -nostdlib
+-MODFLAGS			+= -mlong-calls
++MODFLAGS			+= -mno-long-calls
+ 
+ cflags-y += -ffreestanding
+ 
+--- a/arch/mips/include/asm/module.h
++++ b/arch/mips/include/asm/module.h
+@@ -9,6 +9,11 @@ struct mod_arch_specific {
+ 	struct list_head dbe_list;
+ 	const struct exception_table_entry *dbe_start;
+ 	const struct exception_table_entry *dbe_end;
++
++	void *phys_plt_tbl;
++	void *virt_plt_tbl;
++	unsigned int phys_plt_offset;
++	unsigned int virt_plt_offset;
+ };
+ 
+ typedef uint8_t Elf64_Byte;		/* Type for a 8-bit quantity.  */
+--- a/arch/mips/kernel/module.c
++++ b/arch/mips/kernel/module.c
+@@ -43,6 +43,117 @@ static struct mips_hi16 *mips_hi16_list;
+ static LIST_HEAD(dbe_list);
+ static DEFINE_SPINLOCK(dbe_lock);
+ 
++/*
++ * Get the potential max trampolines size required of the init and
++ * non-init sections. Only used if we cannot find enough contiguous
++ * physically mapped memory to put the module into.
++ */
++static unsigned int
++get_plt_size(const Elf_Ehdr *hdr, const Elf_Shdr *sechdrs,
++             const char *secstrings, unsigned int symindex, bool is_init)
++{
++	unsigned long ret = 0;
++	unsigned int i, j;
++	Elf_Sym *syms;
++
++	/* Everything marked ALLOC (this includes the exported symbols) */
++	for (i = 1; i < hdr->e_shnum; ++i) {
++		unsigned int info = sechdrs[i].sh_info;
++
++		if (sechdrs[i].sh_type != SHT_REL
++		    && sechdrs[i].sh_type != SHT_RELA)
++			continue;
++
++		/* Not a valid relocation section? */
++		if (info >= hdr->e_shnum)
++			continue;
++
++		/* Don't bother with non-allocated sections */
++		if (!(sechdrs[info].sh_flags & SHF_ALLOC))
++			continue;
++
++		/* If it's called *.init*, and we're not init, we're
++                   not interested */
++		if ((strstr(secstrings + sechdrs[i].sh_name, ".init") != 0)
++		    != is_init)
++			continue;
++
++		syms = (Elf_Sym *) sechdrs[symindex].sh_addr;
++		if (sechdrs[i].sh_type == SHT_REL) {
++			Elf_Mips_Rel *rel = (void *) sechdrs[i].sh_addr;
++			unsigned int size = sechdrs[i].sh_size / sizeof(*rel);
++
++			for (j = 0; j < size; ++j) {
++				Elf_Sym *sym;
++
++				if (ELF_MIPS_R_TYPE(rel[j]) != R_MIPS_26)
++					continue;
++
++				sym = syms + ELF_MIPS_R_SYM(rel[j]);
++				if (!is_init && sym->st_shndx != SHN_UNDEF)
++					continue;
++
++				ret += 4 * sizeof(int);
++			}
++		} else {
++			Elf_Mips_Rela *rela = (void *) sechdrs[i].sh_addr;
++			unsigned int size = sechdrs[i].sh_size / sizeof(*rela);
++
++			for (j = 0; j < size; ++j) {
++				Elf_Sym *sym;
++
++				if (ELF_MIPS_R_TYPE(rela[j]) != R_MIPS_26)
++					continue;
++
++				sym = syms + ELF_MIPS_R_SYM(rela[j]);
++				if (!is_init && sym->st_shndx != SHN_UNDEF)
++					continue;
++
++				ret += 4 * sizeof(int);
++			}
++		}
++	}
++
++	return ret;
++}
++
++#ifndef MODULE_START
++static void *alloc_phys(unsigned long size)
++{
++	unsigned order;
++	struct page *page;
++	struct page *p;
++
++	size = PAGE_ALIGN(size);
++	order = get_order(size);
++
++	page = alloc_pages(GFP_KERNEL | __GFP_NORETRY | __GFP_NOWARN |
++			__GFP_THISNODE, order);
++	if (!page)
++		return NULL;
++
++	split_page(page, order);
++
++	for (p = page + (size >> PAGE_SHIFT); p < page + (1 << order); ++p)
++		__free_page(p);
++
++	return page_address(page);
++}
++#endif
++
++static void free_phys(void *ptr, unsigned long size)
++{
++	struct page *page;
++	struct page *end;
++
++	page = virt_to_page(ptr);
++	end = page + (PAGE_ALIGN(size) >> PAGE_SHIFT);
++
++	for (; page < end; ++page)
++		__free_page(page);
++}
++
++
+ void *module_alloc(unsigned long size)
+ {
+ #ifdef MODULE_START
+@@ -58,21 +169,99 @@ void *module_alloc(unsigned long size)
+ 
+ 	return __vmalloc_area(area, GFP_KERNEL, PAGE_KERNEL);
+ #else
++	void *ptr;
++
+ 	if (size == 0)
+ 		return NULL;
+-	return vmalloc(size);
++
++	ptr = alloc_phys(size);
++
++	/* If we failed to allocate physically contiguous memory,
++	 * fall back to regular vmalloc. The module loader code will
++	 * create jump tables to handle long jumps */
++	if (!ptr)
++		return vmalloc(size);
++
++	return ptr;
++#endif
++}
++
++static inline bool is_phys_addr(void *ptr)
++{
++#ifdef CONFIG_64BIT
++	return (KSEGX((unsigned long)ptr) == CKSEG0);
++#else
++	return (KSEGX(ptr) == KSEG0);
+ #endif
+ }
+ 
+ /* Free memory returned from module_alloc */
+ void module_free(struct module *mod, void *module_region)
+ {
+-	vfree(module_region);
++	if (is_phys_addr(module_region)) {
++		if (mod->module_init == module_region)
++			free_phys(module_region, mod->init_size);
++		else if (mod->module_core == module_region)
++			free_phys(module_region, mod->core_size);
++		else
++			BUG();
++	} else {
++		vfree(module_region);
++	}
++}
++
++static void *__module_alloc(int size, bool phys)
++{
++	void *ptr;
++
++	if (phys)
++		ptr = kmalloc(size, GFP_KERNEL);
++	else
++		ptr = vmalloc(size);
++	return ptr;
++}
++
++static void __module_free(void *ptr)
++{
++	if (is_phys_addr(ptr))
++		kfree(ptr);
++	else
++		vfree(ptr);
+ }
+ 
+ int module_frob_arch_sections(Elf_Ehdr *hdr, Elf_Shdr *sechdrs,
+ 			      char *secstrings, struct module *mod)
+ {
++	unsigned int symindex = 0;
++	unsigned int core_size, init_size;
++	int i;
++
++	for (i = 1; i < hdr->e_shnum; i++)
++		if (sechdrs[i].sh_type == SHT_SYMTAB)
++			symindex = i;
++
++	core_size = get_plt_size(hdr, sechdrs, secstrings, symindex, false);
++	init_size = get_plt_size(hdr, sechdrs, secstrings, symindex, true);
++
++	mod->arch.phys_plt_offset = 0;
++	mod->arch.virt_plt_offset = 0;
++	mod->arch.phys_plt_tbl = NULL;
++	mod->arch.virt_plt_tbl = NULL;
++
++	if ((core_size + init_size) == 0)
++		return 0;
++
++	mod->arch.phys_plt_tbl = __module_alloc(core_size + init_size, 1);
++	if (!mod->arch.phys_plt_tbl)
++		return -ENOMEM;
++
++	mod->arch.virt_plt_tbl = __module_alloc(core_size + init_size, 0);
++	if (!mod->arch.virt_plt_tbl) {
++		__module_free(mod->arch.phys_plt_tbl);
++		mod->arch.phys_plt_tbl = NULL;
++		return -ENOMEM;
++	}
++
+ 	return 0;
+ }
+ 
+@@ -95,28 +284,36 @@ static int apply_r_mips_32_rela(struct m
+ 	return 0;
+ }
+ 
+-static int apply_r_mips_26_rel(struct module *me, u32 *location, Elf_Addr v)
++static Elf_Addr add_plt_entry_to(unsigned *plt_offset,
++				 void *start, Elf_Addr v)
+ {
+-	if (v % 4) {
+-		pr_err("module %s: dangerous R_MIPS_26 REL relocation\n",
+-		       me->name);
+-		return -ENOEXEC;
+-	}
++	unsigned *tramp = start + *plt_offset;
++	*plt_offset += 4 * sizeof(int);
+ 
+-	if ((v & 0xf0000000) != (((unsigned long)location + 4) & 0xf0000000)) {
+-		printk(KERN_ERR
+-		       "module %s: relocation overflow\n",
+-		       me->name);
+-		return -ENOEXEC;
+-	}
++	/* adjust carry for addiu */
++	if (v & 0x00008000)
++		v += 0x10000;
+ 
+-	*location = (*location & ~0x03ffffff) |
+-	            ((*location + (v >> 2)) & 0x03ffffff);
++	tramp[0] = 0x3c190000 | (v >> 16);      /* lui t9, hi16 */
++	tramp[1] = 0x27390000 | (v & 0xffff);   /* addiu t9, t9, lo16 */
++	tramp[2] = 0x03200008;                  /* jr t9 */
++	tramp[3] = 0x00000000;                  /* nop */
+ 
+-	return 0;
++	return (Elf_Addr) tramp;
+ }
+ 
+-static int apply_r_mips_26_rela(struct module *me, u32 *location, Elf_Addr v)
++static Elf_Addr add_plt_entry(struct module *me, void *location, Elf_Addr v)
++{
++	if (is_phys_addr(location))
++		return add_plt_entry_to(&me->arch.phys_plt_offset,
++				me->arch.phys_plt_tbl, v);
++	else
++		return add_plt_entry_to(&me->arch.virt_plt_offset,
++				me->arch.virt_plt_tbl, v);
++
++}
++
++static int set_r_mips_26(struct module *me, u32 *location, u32 ofs, Elf_Addr v)
+ {
+ 	if (v % 4) {
+ 		pr_err("module %s: dangerous R_MIPS_26 RELArelocation\n",
+@@ -125,17 +322,31 @@ static int apply_r_mips_26_rela(struct m
+ 	}
+ 
+ 	if ((v & 0xf0000000) != (((unsigned long)location + 4) & 0xf0000000)) {
+-		printk(KERN_ERR
++	    v = add_plt_entry(me, location, v + (ofs << 2));
++		if (!v) {
++			printk(KERN_ERR
+ 		       "module %s: relocation overflow\n",
+ 		       me->name);
+-		return -ENOEXEC;
++			return -ENOEXEC;
++		}
++		ofs = 0;
+ 	}
+ 
+-	*location = (*location & ~0x03ffffff) | ((v >> 2) & 0x03ffffff);
++	*location = (*location & ~0x03ffffff) | ((ofs + (v >> 2)) & 0x03ffffff);
+ 
+ 	return 0;
+ }
+ 
++static int apply_r_mips_26_rel(struct module *me, u32 *location, Elf_Addr v)
++{
++	return set_r_mips_26(me, location, *location & 0x03ffffff, v);
++}
++
++static int apply_r_mips_26_rela(struct module *me, u32 *location, Elf_Addr v)
++{
++	return set_r_mips_26(me, location, 0, v);
++}
++
+ static int apply_r_mips_hi16_rel(struct module *me, u32 *location, Elf_Addr v)
+ {
+ 	struct mips_hi16 *n;
+@@ -400,11 +611,32 @@ int module_finalize(const Elf_Ehdr *hdr,
+ 		list_add(&me->arch.dbe_list, &dbe_list);
+ 		spin_unlock_irq(&dbe_lock);
+ 	}
++
++	/* Get rid of the fixup trampoline if we're running the module
++	 * from physically mapped address space */
++	if (me->arch.phys_plt_offset == 0) {
++		__module_free(me->arch.phys_plt_tbl);
++		me->arch.phys_plt_tbl = NULL;
++	}
++	if (me->arch.virt_plt_offset == 0) {
++		__module_free(me->arch.virt_plt_tbl);
++		me->arch.virt_plt_tbl = NULL;
++	}
++
+ 	return 0;
+ }
+ 
+ void module_arch_cleanup(struct module *mod)
+ {
++	if (mod->arch.phys_plt_tbl) {
++		__module_free(mod->arch.phys_plt_tbl);
++		mod->arch.phys_plt_tbl = NULL;
++	}
++	if (mod->arch.virt_plt_tbl) {
++		__module_free(mod->arch.virt_plt_tbl);
++		mod->arch.virt_plt_tbl = NULL;
++	}
++
+ 	spin_lock_irq(&dbe_lock);
+ 	list_del(&mod->arch.dbe_list);
+ 	spin_unlock_irq(&dbe_lock);
diff -Nru a/target/linux/generic/patches-2.6.31/028-module_exports.patch b/target/linux/generic/patches-2.6.31/028-module_exports.patch
--- a/target/linux/generic/patches-2.6.31/028-module_exports.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/028-module_exports.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,201 @@
+--- a/include/asm-generic/vmlinux.lds.h
++++ b/include/asm-generic/vmlinux.lds.h
+@@ -55,6 +55,27 @@
+ #define LOAD_OFFSET 0
+ #endif
+ 
++#ifndef SYMTAB_KEEP_STR
++#define SYMTAB_KEEP_STR *(__ksymtab_strings.*)
++#define SYMTAB_DISCARD_STR
++#else
++#define SYMTAB_DISCARD_STR *(__ksymtab_strings.*)
++#endif
++
++#ifndef SYMTAB_KEEP
++#define SYMTAB_KEEP *(__ksymtab.*)
++#define SYMTAB_DISCARD
++#else
++#define SYMTAB_DISCARD *(__ksymtab.*)
++#endif
++
++#ifndef SYMTAB_KEEP_GPL
++#define SYMTAB_KEEP_GPL *(__ksymtab_gpl.*)
++#define SYMTAB_DISCARD_GPL
++#else
++#define SYMTAB_DISCARD_GPL *(__ksymtab_gpl.*)
++#endif
++
+ #ifndef VMLINUX_SYMBOL
+ #define VMLINUX_SYMBOL(_sym_) _sym_
+ #endif
+@@ -256,35 +277,35 @@
+ 	/* Kernel symbol table: Normal symbols */			\
+ 	__ksymtab         : AT(ADDR(__ksymtab) - LOAD_OFFSET) {		\
+ 		VMLINUX_SYMBOL(__start___ksymtab) = .;			\
+-		*(__ksymtab)						\
++		SYMTAB_KEEP						\
+ 		VMLINUX_SYMBOL(__stop___ksymtab) = .;			\
+ 	}								\
+ 									\
+ 	/* Kernel symbol table: GPL-only symbols */			\
+ 	__ksymtab_gpl     : AT(ADDR(__ksymtab_gpl) - LOAD_OFFSET) {	\
+ 		VMLINUX_SYMBOL(__start___ksymtab_gpl) = .;		\
+-		*(__ksymtab_gpl)					\
++		SYMTAB_KEEP_GPL						\
+ 		VMLINUX_SYMBOL(__stop___ksymtab_gpl) = .;		\
+ 	}								\
+ 									\
+ 	/* Kernel symbol table: Normal unused symbols */		\
+ 	__ksymtab_unused  : AT(ADDR(__ksymtab_unused) - LOAD_OFFSET) {	\
+ 		VMLINUX_SYMBOL(__start___ksymtab_unused) = .;		\
+-		*(__ksymtab_unused)					\
++		*(__ksymtab_unused.*)					\
+ 		VMLINUX_SYMBOL(__stop___ksymtab_unused) = .;		\
+ 	}								\
+ 									\
+ 	/* Kernel symbol table: GPL-only unused symbols */		\
+ 	__ksymtab_unused_gpl : AT(ADDR(__ksymtab_unused_gpl) - LOAD_OFFSET) { \
+ 		VMLINUX_SYMBOL(__start___ksymtab_unused_gpl) = .;	\
+-		*(__ksymtab_unused_gpl)					\
++		*(__ksymtab_unused_gpl.*)				\
+ 		VMLINUX_SYMBOL(__stop___ksymtab_unused_gpl) = .;	\
+ 	}								\
+ 									\
+ 	/* Kernel symbol table: GPL-future-only symbols */		\
+ 	__ksymtab_gpl_future : AT(ADDR(__ksymtab_gpl_future) - LOAD_OFFSET) { \
+ 		VMLINUX_SYMBOL(__start___ksymtab_gpl_future) = .;	\
+-		*(__ksymtab_gpl_future)					\
++		*(__ksymtab_gpl_future.*)				\
+ 		VMLINUX_SYMBOL(__stop___ksymtab_gpl_future) = .;	\
+ 	}								\
+ 									\
+@@ -325,7 +346,13 @@
+ 									\
+ 	/* Kernel symbol table: strings */				\
+         __ksymtab_strings : AT(ADDR(__ksymtab_strings) - LOAD_OFFSET) {	\
+-		*(__ksymtab_strings)					\
++		SYMTAB_KEEP_STR						\
++	}								\
++									\
++	/DISCARD/ : {							\
++		SYMTAB_DISCARD						\
++		SYMTAB_DISCARD_GPL					\
++		SYMTAB_DISCARD_STR					\
+ 	}								\
+ 									\
+ 	/* __*init sections */						\
+--- a/include/linux/module.h
++++ b/include/linux/module.h
+@@ -188,16 +188,24 @@ void *__symbol_get_gpl(const char *symbo
+ #define __CRC_SYMBOL(sym, sec)
+ #endif
+ 
++#ifdef MODULE
++#define __EXPORT_SUFFIX(sym)
++#else
++#define __EXPORT_SUFFIX(sym) "." #sym
++#endif
++
+ /* For every exported symbol, place a struct in the __ksymtab section */
+ #define __EXPORT_SYMBOL(sym, sec)				\
+ 	extern typeof(sym) sym;					\
+ 	__CRC_SYMBOL(sym, sec)					\
+ 	static const char __kstrtab_##sym[]			\
+-	__attribute__((section("__ksymtab_strings"), aligned(1))) \
++	__attribute__((section("__ksymtab_strings"		\
++	  __EXPORT_SUFFIX(sym)), aligned(1)))			\
+ 	= MODULE_SYMBOL_PREFIX #sym;                    	\
+ 	static const struct kernel_symbol __ksymtab_##sym	\
+ 	__used							\
+-	__attribute__((section("__ksymtab" sec), unused))	\
++	__attribute__((section("__ksymtab" sec			\
++	  __EXPORT_SUFFIX(sym)), unused))			\
+ 	= { (unsigned long)&sym, __kstrtab_##sym }
+ 
+ #define EXPORT_SYMBOL(sym)					\
+--- a/arch/arm/kernel/vmlinux.lds.S
++++ b/arch/arm/kernel/vmlinux.lds.S
+@@ -79,26 +79,6 @@ SECTIONS
+ #endif
+ 	}
+ 
+-	/DISCARD/ : {			/* Exit code and data		*/
+-		EXIT_TEXT
+-		EXIT_DATA
+-		*(.exitcall.exit)
+-		*(.ARM.exidx.exit.text)
+-		*(.ARM.extab.exit.text)
+-#ifndef CONFIG_HOTPLUG_CPU
+-		*(.ARM.exidx.cpuexit.text)
+-		*(.ARM.extab.cpuexit.text)
+-#endif
+-#ifndef CONFIG_HOTPLUG
+-		*(.ARM.exidx.devexit.text)
+-		*(.ARM.extab.devexit.text)
+-#endif
+-#ifndef CONFIG_MMU
+-		*(.fixup)
+-		*(__ex_table)
+-#endif
+-	}
+-
+ 	.text : {			/* Real text segment		*/
+ 		_text = .;		/* Text and read-only data	*/
+ 			__exception_text_start = .;
+@@ -205,6 +185,28 @@ SECTIONS
+ 		__bss_stop = .;
+ 		_end = .;
+ 	}
++
++	/DISCARD/ : {			/* Exit code and data		*/
++		EXIT_TEXT
++		EXIT_DATA
++		*(.discard)
++		*(.exitcall.exit)
++		*(.ARM.exidx.exit.text)
++		*(.ARM.extab.exit.text)
++#ifndef CONFIG_HOTPLUG_CPU
++		*(.ARM.exidx.cpuexit.text)
++		*(.ARM.extab.cpuexit.text)
++#endif
++#ifndef CONFIG_HOTPLUG
++		*(.ARM.exidx.devexit.text)
++		*(.ARM.extab.devexit.text)
++#endif
++#ifndef CONFIG_MMU
++		*(.fixup)
++		*(__ex_table)
++#endif
++	}
++
+ 					/* Stabs debugging sections.	*/
+ 	.stab 0 : { *(.stab) }
+ 	.stabstr 0 : { *(.stabstr) }
+--- a/arch/powerpc/kernel/vmlinux.lds.S
++++ b/arch/powerpc/kernel/vmlinux.lds.S
+@@ -37,12 +37,6 @@ jiffies = jiffies_64 + 4;
+ #endif
+ SECTIONS
+ {
+-	/* Sections to be discarded. */
+-	/DISCARD/ : {
+-	*(.exitcall.exit)
+-	EXIT_DATA
+-	}
+-
+ 	. = KERNELBASE;
+ 
+ /*
+@@ -295,6 +289,12 @@ SECTIONS
+ 		__bss_stop = .;
+ 	}
+ 
++	/* Sections to be discarded. */
++	/DISCARD/ : {
++	*(.exitcall.exit)
++	EXIT_DATA
++	}
++
+ 	. = ALIGN(PAGE_SIZE);
+ 	_end = . ;
+ 	PROVIDE32 (end = .);
diff -Nru a/target/linux/generic/patches-2.6.31/029-arm_module_unresolved_weak_sym.patch b/target/linux/generic/patches-2.6.31/029-arm_module_unresolved_weak_sym.patch
--- a/target/linux/generic/patches-2.6.31/029-arm_module_unresolved_weak_sym.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/029-arm_module_unresolved_weak_sym.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,13 @@
+--- a/arch/arm/kernel/module.c
++++ b/arch/arm/kernel/module.c
+@@ -120,6 +120,10 @@ apply_relocate(Elf32_Shdr *sechdrs, cons
+ 			return -ENOEXEC;
+ 		}
+ 
++		if ((IS_ERR_VALUE(sym->st_value) || !sym->st_value) &&
++		    ELF_ST_BIND(sym->st_info) == STB_WEAK)
++			continue;
++
+ 		loc = dstsec->sh_addr + rel->r_offset;
+ 
+ 		switch (ELF32_R_TYPE(rel->r_info)) {
diff -Nru a/target/linux/generic/patches-2.6.31/030-pci_disable_common_quirks.patch b/target/linux/generic/patches-2.6.31/030-pci_disable_common_quirks.patch
--- a/target/linux/generic/patches-2.6.31/030-pci_disable_common_quirks.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/030-pci_disable_common_quirks.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,43 @@
+--- a/drivers/pci/Kconfig
++++ b/drivers/pci/Kconfig
+@@ -51,6 +51,12 @@ config PCI_STUB
+ 
+ 	  When in doubt, say N.
+ 
++config PCI_DISABLE_COMMON_QUIRKS
++	bool "PCI disable common quirks"
++	depends on PCI
++	help
++	  If you don't know what to do here, say N.
++
+ config HT_IRQ
+ 	bool "Interrupts on hypertransport devices"
+ 	default y
+--- a/drivers/pci/quirks.c
++++ b/drivers/pci/quirks.c
+@@ -98,6 +98,7 @@ static void __devinit quirk_resource_ali
+ }
+ DECLARE_PCI_FIXUP_HEADER(PCI_ANY_ID, PCI_ANY_ID, quirk_resource_alignment);
+ 
++#ifndef CONFIG_PCI_DISABLE_COMMON_QUIRKS
+ /* The Mellanox Tavor device gives false positive parity errors
+  * Mark this device with a broken_parity_status, to allow
+  * PCI scanning code to "skip" this now blacklisted device.
+@@ -1867,7 +1868,9 @@ static void __devinit fixup_rev1_53c810(
+ 	}
+ }
+ DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_NCR, PCI_DEVICE_ID_NCR_53C810, fixup_rev1_53c810);
++#endif /* !CONFIG_PCI_DISABLE_COMMON_QUIRKS */
+ 
++#ifndef CONFIG_PCI_DISABLE_COMMON_QUIRKS
+ /* Enable 1k I/O space granularity on the Intel P64H2 */
+ static void __devinit quirk_p64h2_1k_io(struct pci_dev *dev)
+ {
+@@ -2498,6 +2501,7 @@ DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_I
+ DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_INTEL, 0x150d, quirk_i82576_sriov);
+ 
+ #endif	/* CONFIG_PCI_IOV */
++#endif /* !CONFIG_PCI_DISABLE_COMMON_QUIRKS */
+ 
+ static void pci_do_fixups(struct pci_dev *dev, struct pci_fixup *f,
+ 			  struct pci_fixup *end)
diff -Nru a/target/linux/generic/patches-2.6.31/031-ppc_gcc_build_fix.patch b/target/linux/generic/patches-2.6.31/031-ppc_gcc_build_fix.patch
--- a/target/linux/generic/patches-2.6.31/031-ppc_gcc_build_fix.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/031-ppc_gcc_build_fix.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,226 @@
+GCC 4.4.x looks to be adding support for generating out-of-line register
+saves/restores based on:
+
+http://gcc.gnu.org/ml/gcc-patches/2008-04/msg01678.html
+
+This breaks the kernel build as we'd have to link with libgcc to get the
+implementation of the register save/restores.
+
+To workaround this issue, we just stole the save/restore code from gcc
+and simplified it down for our needs (integer only).  We only do this if
+PPC32 as gcc makes believe the linker on ppc64 will deal with this and
+only if CONFIG_CC_OPTIMIZE_FOR_SIZE is set (thus -Os).
+
+Signed-off-by: Kumar Gala <[EMAIL PROTECTED]>
+---
+
+If someone using cutting edge toolchains for ppc64 could test and make
+sure if we enable CONFIG_CC_OPTIMIZE_FOR_SIZE things work that would be
+nice.
+
+- k
+
+ arch/powerpc/kernel/misc_32.S   |   77 +++++++++++++++++++++++++++
+ arch/powerpc/kernel/ppc_ksyms.c |  111 +++++++++++++++++++++++++++++++++++++++
+ 2 files changed, 188 insertions(+), 0 deletions(-)
+
+--- a/arch/powerpc/kernel/misc_32.S
++++ b/arch/powerpc/kernel/misc_32.S
+@@ -813,3 +813,80 @@ relocate_new_kernel_end:
+ relocate_new_kernel_size:
+ 	.long relocate_new_kernel_end - relocate_new_kernel
+ #endif
++
++#if defined(CONFIG_PPC32) && defined(CONFIG_CC_OPTIMIZE_FOR_SIZE)
++/* Routines for saving integer registers, called by the compiler.  */
++/* Called with r11 pointing to the stack header word of the caller of the */
++/* function, just beyond the end of the integer save area.  */
++
++_GLOBAL(_savegpr_14)   stw     14,-72(11)      /* save gp registers */
++_GLOBAL(_savegpr_15)   stw     15,-68(11)
++_GLOBAL(_savegpr_16)   stw     16,-64(11)
++_GLOBAL(_savegpr_17)   stw     17,-60(11)
++_GLOBAL(_savegpr_18)   stw     18,-56(11)
++_GLOBAL(_savegpr_19)   stw     19,-52(11)
++_GLOBAL(_savegpr_20)   stw     20,-48(11)
++_GLOBAL(_savegpr_21)   stw     21,-44(11)
++_GLOBAL(_savegpr_22)   stw     22,-40(11)
++_GLOBAL(_savegpr_23)   stw     23,-36(11)
++_GLOBAL(_savegpr_24)   stw     24,-32(11)
++_GLOBAL(_savegpr_25)   stw     25,-28(11)
++_GLOBAL(_savegpr_26)   stw     26,-24(11)
++_GLOBAL(_savegpr_27)   stw     27,-20(11)
++_GLOBAL(_savegpr_28)   stw     28,-16(11)
++_GLOBAL(_savegpr_29)   stw     29,-12(11)
++_GLOBAL(_savegpr_30)   stw     30,-8(11)
++_GLOBAL(_savegpr_31)   stw     31,-4(11)
++                       blr
++
++/* Routines for restoring integer registers, called by the compiler.  */
++/* Called with r11 pointing to the stack header word of the caller of the */
++/* function, just beyond the end of the integer restore area.  */
++
++_GLOBAL(_restgpr_14)   lwz     14,-72(11)      /* restore gp registers */
++_GLOBAL(_restgpr_15)   lwz     15,-68(11)
++_GLOBAL(_restgpr_16)   lwz     16,-64(11)
++_GLOBAL(_restgpr_17)   lwz     17,-60(11)
++_GLOBAL(_restgpr_18)   lwz     18,-56(11)
++_GLOBAL(_restgpr_19)   lwz     19,-52(11)
++_GLOBAL(_restgpr_20)   lwz     20,-48(11)
++_GLOBAL(_restgpr_21)   lwz     21,-44(11)
++_GLOBAL(_restgpr_22)   lwz     22,-40(11)
++_GLOBAL(_restgpr_23)   lwz     23,-36(11)
++_GLOBAL(_restgpr_24)   lwz     24,-32(11)
++_GLOBAL(_restgpr_25)   lwz     25,-28(11)
++_GLOBAL(_restgpr_26)   lwz     26,-24(11)
++_GLOBAL(_restgpr_27)   lwz     27,-20(11)
++_GLOBAL(_restgpr_28)   lwz     28,-16(11)
++_GLOBAL(_restgpr_29)   lwz     29,-12(11)
++_GLOBAL(_restgpr_30)   lwz     30,-8(11)
++_GLOBAL(_restgpr_31)   lwz     31,-4(11)
++                       blr
++
++/* Routines for restoring integer registers, called by the compiler.  */
++/* Called with r11 pointing to the stack header word of the caller of the */
++/* function, just beyond the end of the integer restore area.  */
++
++_GLOBAL(_restgpr_14_x) lwz     14,-72(11)      /* restore gp registers */
++_GLOBAL(_restgpr_15_x) lwz     15,-68(11)
++_GLOBAL(_restgpr_16_x) lwz     16,-64(11)
++_GLOBAL(_restgpr_17_x) lwz     17,-60(11)
++_GLOBAL(_restgpr_18_x) lwz     18,-56(11)
++_GLOBAL(_restgpr_19_x) lwz     19,-52(11)
++_GLOBAL(_restgpr_20_x) lwz     20,-48(11)
++_GLOBAL(_restgpr_21_x) lwz     21,-44(11)
++_GLOBAL(_restgpr_22_x) lwz     22,-40(11)
++_GLOBAL(_restgpr_23_x) lwz     23,-36(11)
++_GLOBAL(_restgpr_24_x) lwz     24,-32(11)
++_GLOBAL(_restgpr_25_x) lwz     25,-28(11)
++_GLOBAL(_restgpr_26_x) lwz     26,-24(11)
++_GLOBAL(_restgpr_27_x) lwz     27,-20(11)
++_GLOBAL(_restgpr_28_x) lwz     28,-16(11)
++_GLOBAL(_restgpr_29_x) lwz     29,-12(11)
++_GLOBAL(_restgpr_30_x) lwz     30,-8(11)
++_GLOBAL(_restgpr_31_x) lwz     0,4(11)
++                       lwz     31,-4(11)
++                       mtlr    0
++                       mr      1,11
++                       blr
++#endif
+--- a/arch/powerpc/kernel/ppc_ksyms.c
++++ b/arch/powerpc/kernel/ppc_ksyms.c
+@@ -188,3 +188,114 @@ EXPORT_SYMBOL(__mtdcr);
+ EXPORT_SYMBOL(__mfdcr);
+ #endif
+ EXPORT_SYMBOL(empty_zero_page);
++
++#if defined(CONFIG_PPC32) && defined(CONFIG_CC_OPTIMIZE_FOR_SIZE)
++void _savegpr_14(void);
++void _savegpr_15(void);
++void _savegpr_16(void);
++void _savegpr_17(void);
++void _savegpr_18(void);
++void _savegpr_19(void);
++void _savegpr_20(void);
++void _savegpr_21(void);
++void _savegpr_22(void);
++void _savegpr_23(void);
++void _savegpr_24(void);
++void _savegpr_25(void);
++void _savegpr_26(void);
++void _savegpr_27(void);
++void _savegpr_28(void);
++void _savegpr_29(void);
++void _savegpr_30(void);
++void _savegpr_31(void);
++void _restgpr_14(void);
++void _restgpr_15(void);
++void _restgpr_16(void);
++void _restgpr_17(void);
++void _restgpr_18(void);
++void _restgpr_19(void);
++void _restgpr_20(void);
++void _restgpr_21(void);
++void _restgpr_22(void);
++void _restgpr_23(void);
++void _restgpr_24(void);
++void _restgpr_25(void);
++void _restgpr_26(void);
++void _restgpr_27(void);
++void _restgpr_28(void);
++void _restgpr_29(void);
++void _restgpr_30(void);
++void _restgpr_31(void);
++void _restgpr_14_x(void);
++void _restgpr_15_x(void);
++void _restgpr_16_x(void);
++void _restgpr_17_x(void);
++void _restgpr_18_x(void);
++void _restgpr_19_x(void);
++void _restgpr_20_x(void);
++void _restgpr_21_x(void);
++void _restgpr_22_x(void);
++void _restgpr_23_x(void);
++void _restgpr_24_x(void);
++void _restgpr_25_x(void);
++void _restgpr_26_x(void);
++void _restgpr_27_x(void);
++void _restgpr_28_x(void);
++void _restgpr_29_x(void);
++void _restgpr_30_x(void);
++void _restgpr_31_x(void);
++EXPORT_SYMBOL(_savegpr_14);
++EXPORT_SYMBOL(_savegpr_15);
++EXPORT_SYMBOL(_savegpr_16);
++EXPORT_SYMBOL(_savegpr_17);
++EXPORT_SYMBOL(_savegpr_18);
++EXPORT_SYMBOL(_savegpr_19);
++EXPORT_SYMBOL(_savegpr_20);
++EXPORT_SYMBOL(_savegpr_21);
++EXPORT_SYMBOL(_savegpr_22);
++EXPORT_SYMBOL(_savegpr_23);
++EXPORT_SYMBOL(_savegpr_24);
++EXPORT_SYMBOL(_savegpr_25);
++EXPORT_SYMBOL(_savegpr_26);
++EXPORT_SYMBOL(_savegpr_27);
++EXPORT_SYMBOL(_savegpr_28);
++EXPORT_SYMBOL(_savegpr_29);
++EXPORT_SYMBOL(_savegpr_30);
++EXPORT_SYMBOL(_savegpr_31);
++EXPORT_SYMBOL(_restgpr_14);
++EXPORT_SYMBOL(_restgpr_15);
++EXPORT_SYMBOL(_restgpr_16);
++EXPORT_SYMBOL(_restgpr_17);
++EXPORT_SYMBOL(_restgpr_18);
++EXPORT_SYMBOL(_restgpr_19);
++EXPORT_SYMBOL(_restgpr_20);
++EXPORT_SYMBOL(_restgpr_21);
++EXPORT_SYMBOL(_restgpr_22);
++EXPORT_SYMBOL(_restgpr_23);
++EXPORT_SYMBOL(_restgpr_24);
++EXPORT_SYMBOL(_restgpr_25);
++EXPORT_SYMBOL(_restgpr_26);
++EXPORT_SYMBOL(_restgpr_27);
++EXPORT_SYMBOL(_restgpr_28);
++EXPORT_SYMBOL(_restgpr_29);
++EXPORT_SYMBOL(_restgpr_30);
++EXPORT_SYMBOL(_restgpr_31);
++EXPORT_SYMBOL(_restgpr_14_x);
++EXPORT_SYMBOL(_restgpr_15_x);
++EXPORT_SYMBOL(_restgpr_16_x);
++EXPORT_SYMBOL(_restgpr_17_x);
++EXPORT_SYMBOL(_restgpr_18_x);
++EXPORT_SYMBOL(_restgpr_19_x);
++EXPORT_SYMBOL(_restgpr_20_x);
++EXPORT_SYMBOL(_restgpr_21_x);
++EXPORT_SYMBOL(_restgpr_22_x);
++EXPORT_SYMBOL(_restgpr_23_x);
++EXPORT_SYMBOL(_restgpr_24_x);
++EXPORT_SYMBOL(_restgpr_25_x);
++EXPORT_SYMBOL(_restgpr_26_x);
++EXPORT_SYMBOL(_restgpr_27_x);
++EXPORT_SYMBOL(_restgpr_28_x);
++EXPORT_SYMBOL(_restgpr_29_x);
++EXPORT_SYMBOL(_restgpr_30_x);
++EXPORT_SYMBOL(_restgpr_31_x);
++#endif /* CONFIG_PPC32 && CONFIG_CC_OPTIMIZE_FOR_SIZE */
diff -Nru a/target/linux/generic/patches-2.6.31/032-mips_vmlinux_lds.patch b/target/linux/generic/patches-2.6.31/032-mips_vmlinux_lds.patch
--- a/target/linux/generic/patches-2.6.31/032-mips_vmlinux_lds.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/032-mips_vmlinux_lds.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,11 @@
+--- a/arch/mips/kernel/Makefile
++++ b/arch/mips/kernel/Makefile
+@@ -4,6 +4,8 @@
+ 
+ CPPFLAGS_vmlinux.lds := $(KBUILD_CFLAGS)
+ 
++CPPFLAGS_vmlinux.lds := $(KBUILD_CFLAGS) $(EXTRA_LDSFLAGS)
++
+ extra-y		:= head.o init_task.o vmlinux.lds
+ 
+ obj-y		+= cpu-probe.o branch.o entry.o genex.o irq.o process.o \
diff -Nru a/target/linux/generic/patches-2.6.31/049-byteshift_h_fix_usage_for_compressed_kernels.patch b/target/linux/generic/patches-2.6.31/049-byteshift_h_fix_usage_for_compressed_kernels.patch
--- a/target/linux/generic/patches-2.6.31/049-byteshift_h_fix_usage_for_compressed_kernels.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/049-byteshift_h_fix_usage_for_compressed_kernels.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,72 @@
+From 2fa4341074cd02fb39aa23410740764948755635 Mon Sep 17 00:00:00 2001
+From: Albin Tonnerre <albin.tonnerre@free-electrons.com>
+Date: Wed, 23 Sep 2009 15:57:38 -0700
+Subject: [PATCH] include/linux/unaligned/{l,b}e_byteshift.h: fix usage for compressed kernels
+
+When unaligned accesses are required for uncompressing a kernel (such as
+for LZO decompression on ARM in a patch that follows), including
+<linux/kernel.h> causes issues as it brings in a lot of things that are
+not available in the decompression environment.
+
+linux/kernel.h brings at least:
+extern int console_printk[];
+extern const char hex_asc[];
+which causes errors at link-time as they are not available when
+compiling the pre-boot environement. There are also a few others:
+
+  arch/arm/boot/compressed/misc.o: In function `valid_user_regs':
+   arch/arm/include/asm/ptrace.h:158: undefined reference to `elf_hwcap'
+  arch/arm/boot/compressed/misc.o: In function `console_silent':
+   include/linux/kernel.h:292: undefined reference to `console_printk'
+  arch/arm/boot/compressed/misc.o: In function `console_verbose':
+   include/linux/kernel.h:297: undefined reference to `console_printk'
+  arch/arm/boot/compressed/misc.o: In function `pack_hex_byte':
+   include/linux/kernel.h:360: undefined reference to `hex_asc'
+  arch/arm/boot/compressed/misc.o: In function `hweight_long':
+   include/linux/bitops.h:45: undefined reference to `hweight32'
+  arch/arm/boot/compressed/misc.o: In function `__cmpxchg_local_generic':
+   include/asm-generic/cmpxchg-local.h:21: undefined reference to `wrong_size_cmpxchg'
+   include/asm-generic/cmpxchg-local.h:42: undefined reference to `wrong_size_cmpxchg'
+  arch/arm/boot/compressed/misc.o: In function `__xchg':
+   arch/arm/include/asm/system.h:309: undefined reference to `__bad_xchg'
+
+However, those files apparently use nothing from <linux/kernel.h>, all
+they need is the declaration of types such as u32 or u64, so
+<linux/types.h> should be enough
+
+Signed-off-by: Albin Tonnerre <albin.tonnerre@free-electrons.com>
+Cc: Sam Ravnborg <sam@ravnborg.org>
+Cc: Russell King <rmk@arm.linux.org.uk>
+Cc: Ingo Molnar <mingo@elte.hu>
+Cc: Thomas Gleixner <tglx@linutronix.de>
+Cc: "H. Peter Anvin" <hpa@zytor.com>
+Cc: Phillip Lougher <phillip@lougher.demon.co.uk>
+Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
+Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
+---
+ include/linux/unaligned/be_byteshift.h |    2 +-
+ include/linux/unaligned/le_byteshift.h |    2 +-
+ 2 files changed, 2 insertions(+), 2 deletions(-)
+
+--- a/include/linux/unaligned/be_byteshift.h
++++ b/include/linux/unaligned/be_byteshift.h
+@@ -1,7 +1,7 @@
+ #ifndef _LINUX_UNALIGNED_BE_BYTESHIFT_H
+ #define _LINUX_UNALIGNED_BE_BYTESHIFT_H
+ 
+-#include <linux/kernel.h>
++#include <linux/types.h>
+ 
+ static inline u16 __get_unaligned_be16(const u8 *p)
+ {
+--- a/include/linux/unaligned/le_byteshift.h
++++ b/include/linux/unaligned/le_byteshift.h
+@@ -1,7 +1,7 @@
+ #ifndef _LINUX_UNALIGNED_LE_BYTESHIFT_H
+ #define _LINUX_UNALIGNED_LE_BYTESHIFT_H
+ 
+-#include <linux/kernel.h>
++#include <linux/types.h>
+ 
+ static inline u16 __get_unaligned_le16(const u8 *p)
+ {
diff -Nru a/target/linux/generic/patches-2.6.31/050-lzo_compressed_kernels.patch b/target/linux/generic/patches-2.6.31/050-lzo_compressed_kernels.patch
--- a/target/linux/generic/patches-2.6.31/050-lzo_compressed_kernels.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/050-lzo_compressed_kernels.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,309 @@
+--- /dev/null
++++ b/include/linux/decompress/unlzo.h
+@@ -0,0 +1,10 @@
++#ifndef DECOMPRESS_UNLZO_H
++#define DECOMPRESS_UNLZO_H
++
++int unlzo(unsigned char *inbuf, int len,
++	int(*fill)(void*, unsigned int),
++	int(*flush)(void*, unsigned int),
++	unsigned char *output,
++	int *pos,
++	void(*error)(char *x));
++#endif
+--- a/init/Kconfig
++++ b/init/Kconfig
+@@ -115,10 +115,13 @@ config HAVE_KERNEL_BZIP2
+ config HAVE_KERNEL_LZMA
+ 	bool
+ 
++config HAVE_KERNEL_LZO
++	bool
++
+ choice
+ 	prompt "Kernel compression mode"
+ 	default KERNEL_GZIP
+-	depends on HAVE_KERNEL_GZIP || HAVE_KERNEL_BZIP2 || HAVE_KERNEL_LZMA
++	depends on HAVE_KERNEL_GZIP || HAVE_KERNEL_BZIP2 || HAVE_KERNEL_LZMA || HAVE_KERNEL_LZO
+ 	help
+ 	  The linux kernel is a kind of self-extracting executable.
+ 	  Several compression algorithms are available, which differ
+@@ -141,9 +144,8 @@ config KERNEL_GZIP
+ 	bool "Gzip"
+ 	depends on HAVE_KERNEL_GZIP
+ 	help
+-	  The old and tried gzip compression. Its compression ratio is
+-	  the poorest among the 3 choices; however its speed (both
+-	  compression and decompression) is the fastest.
++	  The old and tried gzip compression. It provides a good balance
++	  between compression ratio and decompression speed.
+ 
+ config KERNEL_BZIP2
+ 	bool "Bzip2"
+@@ -164,6 +166,14 @@ config KERNEL_LZMA
+ 	  two. Compression is slowest.	The kernel size is about 33%
+ 	  smaller with LZMA in comparison to gzip.
+ 
++config KERNEL_LZO
++	bool "LZO"
++	depends on HAVE_KERNEL_LZO
++	help
++	  Its compression ratio is the poorest among the 4. The kernel
++	  size is about about 10% bigger than gzip; however its speed
++	  (both compression and decompression) is the fastest.
++
+ endchoice
+ 
+ config SWAP
+--- /dev/null
++++ b/lib/decompress_unlzo.c
+@@ -0,0 +1,208 @@
++/*
++ * LZO decompressor for the Linux kernel. Code borrowed from the lzo
++ * implementation by Markus Franz Xaver Johannes Oberhumer.
++ *
++ * Linux kernel adaptation:
++ * Copyright (C) 2009
++ * Albin Tonnerre, Free Electrons <albin.tonnerre@free-electrons.com>
++ *
++ * Original code:
++ * Copyright (C) 1996-2005 Markus Franz Xaver Johannes Oberhumer
++ * All Rights Reserved.
++ *
++ * lzop and the LZO library are free software; you can redistribute them
++ * and/or modify them under the terms of the GNU General Public License as
++ * published by the Free Software Foundation; either version 2 of
++ * the License, or (at your option) any later version.
++ *
++ * This program is distributed in the hope that it will be useful,
++ * but WITHOUT ANY WARRANTY; without even the implied warranty of
++ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
++ * GNU General Public License for more details.
++ *
++ * You should have received a copy of the GNU General Public License
++ * along with this program; see the file COPYING.
++ * If not, write to the Free Software Foundation, Inc.,
++ * 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
++ *
++ * Markus F.X.J. Oberhumer
++ * <markus@oberhumer.com>
++ * http://www.oberhumer.com/opensource/lzop/
++ */
++
++#ifdef STATIC
++#include "lzo/lzo1x_decompress.c"
++#else
++#include <linux/slab.h>
++#include <linux/decompress/unlzo.h>
++#endif
++
++#include <linux/types.h>
++#include <linux/lzo.h>
++#include <linux/decompress/mm.h>
++
++#include <linux/compiler.h>
++#include <asm/unaligned.h>
++
++static const unsigned char lzop_magic[] =
++	{ 0x89, 0x4c, 0x5a, 0x4f, 0x00, 0x0d, 0x0a, 0x1a, 0x0a };
++
++#define LZO_BLOCK_SIZE        (256*1024l)
++#define HEADER_HAS_FILTER      0x00000800L
++
++STATIC inline int INIT parse_header(u8 *input, u8 *skip)
++{
++	int l;
++	u8 *parse = input;
++	u8 level = 0;
++	u16 version;
++
++	/* read magic: 9 first bits */
++	for (l = 0; l < 9; l++) {
++		if (*parse++ != lzop_magic[l])
++			return 0;
++	}
++	/* get version (2bytes), skip library version (2),
++	 * 'need to be extracted' version (2) and
++	 * method (1) */
++	version = get_unaligned_be16(parse);
++	parse += 7;
++	if (version >= 0x0940)
++		level = *parse++;
++	if (get_unaligned_be32(parse) & HEADER_HAS_FILTER)
++		parse += 8; /* flags + filter info */
++	else
++		parse += 4; /* flags */
++
++	/* skip mode and mtime_low */
++	parse += 8;
++	if (version >= 0x0940)
++		parse += 4;	/* skip mtime_high */
++
++	l = *parse++;
++	/* don't care about the file name, and skip checksum */
++	parse += l + 4;
++
++	*skip = parse - input;
++	return 1;
++}
++
++STATIC inline int INIT unlzo(u8 *input, int in_len,
++				int (*fill) (void *, unsigned int),
++				int (*flush) (void *, unsigned int),
++				u8 *output, int *posp,
++				void (*error_fn) (char *x))
++{
++	u8 skip = 0, r = 0;
++	u32 src_len, dst_len;
++	size_t tmp;
++	u8 *in_buf, *in_buf_save, *out_buf;
++	int obytes_processed = 0;
++
++	set_error_fn(error_fn);
++
++	if (output)
++		out_buf = output;
++	else if (!flush) {
++		error("NULL output pointer and no flush function provided");
++		goto exit;
++	} else {
++		out_buf = malloc(LZO_BLOCK_SIZE);
++		if (!out_buf) {
++			error("Could not allocate output buffer");
++			goto exit;
++		}
++	}
++
++	if (input && fill) {
++		error("Both input pointer and fill function provided, don't know what to do");
++		goto exit_1;
++	} else if (input)
++		in_buf = input;
++	else if (!fill || !posp) {
++		error("NULL input pointer and missing position pointer or fill function");
++		goto exit_1;
++	} else {
++		in_buf = malloc(lzo1x_worst_compress(LZO_BLOCK_SIZE));
++		if (!in_buf) {
++			error("Could not allocate input buffer");
++			goto exit_1;
++		}
++	}
++	in_buf_save = in_buf;
++
++	if (posp)
++		*posp = 0;
++
++	if (fill)
++		fill(in_buf, lzo1x_worst_compress(LZO_BLOCK_SIZE));
++
++	if (!parse_header(input, &skip)) {
++		error("invalid header");
++		goto exit_2;
++	}
++	in_buf += skip;
++
++	if (posp)
++		*posp = skip;
++
++	for (;;) {
++		/* read uncompressed block size */
++		dst_len = get_unaligned_be32(in_buf);
++		in_buf += 4;
++
++		/* exit if last block */
++		if (dst_len == 0) {
++			if (posp)
++				*posp += 4;
++			break;
++		}
++
++		if (dst_len > LZO_BLOCK_SIZE) {
++			error("dest len longer than block size");
++			goto exit_2;
++		}
++
++		/* read compressed block size, and skip block checksum info */
++		src_len = get_unaligned_be32(in_buf);
++		in_buf += 8;
++
++		if (src_len <= 0 || src_len > dst_len) {
++			error("file corrupted");
++			goto exit_2;
++		}
++
++		/* decompress */
++		tmp = dst_len;
++		r = lzo1x_decompress_safe((u8 *) in_buf, src_len, out_buf, &tmp);
++
++		if (r != LZO_E_OK || dst_len != tmp) {
++			error("Compressed data violation");
++			goto exit_2;
++		}
++
++		obytes_processed += dst_len;
++		if (flush)
++			flush(out_buf, dst_len);
++		if (output)
++			out_buf += dst_len;
++		if (posp)
++			*posp += src_len + 12;
++		if (fill) {
++			in_buf = in_buf_save;
++			fill(in_buf, lzo1x_worst_compress(LZO_BLOCK_SIZE));
++		} else
++			in_buf += src_len;
++	}
++
++exit_2:
++	if (!input)
++		free(in_buf);
++exit_1:
++	if (!output)
++		free(out_buf);
++exit:
++	return obytes_processed;
++}
++
++#define decompress unlzo
+--- a/lib/lzo/lzo1x_decompress.c
++++ b/lib/lzo/lzo1x_decompress.c
+@@ -11,11 +11,13 @@
+  *  Richard Purdie <rpurdie@openedhand.com>
+  */
+ 
++#ifndef STATIC
+ #include <linux/module.h>
+ #include <linux/kernel.h>
+-#include <linux/lzo.h>
+-#include <asm/byteorder.h>
++#endif
++
+ #include <asm/unaligned.h>
++#include <linux/lzo.h>
+ #include "lzodefs.h"
+ 
+ #define HAVE_IP(x, ip_end, ip) ((size_t)(ip_end - ip) < (x))
+@@ -244,9 +246,10 @@ lookbehind_overrun:
+ 	*out_len = op - out;
+ 	return LZO_E_LOOKBEHIND_OVERRUN;
+ }
+-
++#ifndef STATIC
+ EXPORT_SYMBOL_GPL(lzo1x_decompress_safe);
+ 
+ MODULE_LICENSE("GPL");
+ MODULE_DESCRIPTION("LZO1X Decompressor");
+ 
++#endif
+--- a/scripts/Makefile.lib
++++ b/scripts/Makefile.lib
+@@ -230,3 +230,8 @@ quiet_cmd_lzma = LZMA    $@
+ cmd_lzma = (cat $(filter-out FORCE,$^) | \
+ 	lzma -9 && $(call size_append, $(filter-out FORCE,$^))) > $@ || \
+ 	(rm -f $@ ; false)
++
++quiet_cmd_lzo = LZO    $@
++cmd_lzo = (cat $(filter-out FORCE,$^) | \
++	lzop -9 && $(call size_append, $(filter-out FORCE,$^))) > $@ || \
++	(rm -f $@ ; false)
diff -Nru a/target/linux/generic/patches-2.6.31/051-lzo_compressed_kernel_for_arm.patch b/target/linux/generic/patches-2.6.31/051-lzo_compressed_kernel_for_arm.patch
--- a/target/linux/generic/patches-2.6.31/051-lzo_compressed_kernel_for_arm.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/051-lzo_compressed_kernel_for_arm.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,283 @@
+--- a/arch/arm/Kconfig
++++ b/arch/arm/Kconfig
+@@ -18,6 +18,8 @@ config ARM
+ 	select HAVE_KRETPROBES if (HAVE_KPROBES)
+ 	select HAVE_FUNCTION_TRACER if (!XIP_KERNEL)
+ 	select HAVE_GENERIC_DMA_COHERENT
++	select HAVE_KERNEL_GZIP
++	select HAVE_KERNEL_LZO
+ 	help
+ 	  The ARM series is a line of low-power-consumption RISC chip designs
+ 	  licensed by ARM Ltd and targeted at embedded applications and
+--- a/arch/arm/boot/compressed/Makefile
++++ b/arch/arm/boot/compressed/Makefile
+@@ -63,8 +63,12 @@ endif
+ 
+ SEDFLAGS	= s/TEXT_START/$(ZTEXTADDR)/;s/BSS_START/$(ZBSSADDR)/
+ 
+-targets       := vmlinux vmlinux.lds piggy.gz piggy.o font.o font.c \
+-		 head.o misc.o $(OBJS)
++suffix_$(CONFIG_KERNEL_GZIP) = gzip
++suffix_$(CONFIG_KERNEL_LZO)  = lzo
++
++targets       := vmlinux vmlinux.lds \
++		 piggy.$(suffix_y) piggy.$(suffix_y).o \
++		 font.o font.c head.o misc.o $(OBJS)
+ 
+ ifeq ($(CONFIG_FUNCTION_TRACER),y)
+ ORIG_CFLAGS := $(KBUILD_CFLAGS)
+@@ -87,22 +91,31 @@ endif
+ ifneq ($(PARAMS_PHYS),)
+ LDFLAGS_vmlinux += --defsym params_phys=$(PARAMS_PHYS)
+ endif
+-LDFLAGS_vmlinux += -p --no-undefined -X \
+-	$(shell $(CC) $(KBUILD_CFLAGS) --print-libgcc-file-name) -T
++# ?
++LDFLAGS_vmlinux += -p
++# Report unresolved symbol references
++LDFLAGS_vmlinux += --no-undefined
++# Delete all temporary local symbols
++LDFLAGS_vmlinux += -X
++# Next argument is a linker script
++LDFLAGS_vmlinux += -T
++
++# For __aeabi_uidivmod
++lib1funcs = $(srctree)/arch/$(SRCARCH)/lib/lib1funcs.o
+ 
+ # Don't allow any static data in misc.o, which
+ # would otherwise mess up our GOT table
+ CFLAGS_misc.o := -Dstatic=
+ 
+-$(obj)/vmlinux: $(obj)/vmlinux.lds $(obj)/$(HEAD) $(obj)/piggy.o \
+-	 	$(addprefix $(obj)/, $(OBJS)) FORCE
++$(obj)/vmlinux: $(obj)/vmlinux.lds $(obj)/$(HEAD) $(obj)/piggy.$(suffix_y).o \
++	 	$(addprefix $(obj)/, $(OBJS)) $(lib1funcs) FORCE
+ 	$(call if_changed,ld)
+ 	@:
+ 
+-$(obj)/piggy.gz: $(obj)/../Image FORCE
+-	$(call if_changed,gzip)
++$(obj)/piggy.$(suffix_y): $(obj)/../Image FORCE
++	$(call if_changed,$(suffix_y))
+ 
+-$(obj)/piggy.o:  $(obj)/piggy.gz FORCE
++$(obj)/piggy.$(suffix_y).o:  $(obj)/piggy.$(suffix_y) FORCE
+ 
+ CFLAGS_font.o := -Dstatic=
+ 
+--- a/arch/arm/boot/compressed/misc.c
++++ b/arch/arm/boot/compressed/misc.c
+@@ -18,10 +18,15 @@
+ 
+ unsigned int __machine_arch_type;
+ 
++#define _LINUX_STRING_H_
++
+ #include <linux/compiler.h>	/* for inline */
+ #include <linux/types.h>	/* for size_t */
+ #include <linux/stddef.h>	/* for NULL */
+ #include <asm/string.h>
++#include <linux/linkage.h>
++
++#include <asm/unaligned.h>
+ 
+ #ifdef STANDALONE_DEBUG
+ #define putstr printf
+@@ -188,34 +193,8 @@ static inline __ptr_t memcpy(__ptr_t __d
+ /*
+  * gzip delarations
+  */
+-#define OF(args)  args
+ #define STATIC static
+ 
+-typedef unsigned char  uch;
+-typedef unsigned short ush;
+-typedef unsigned long  ulg;
+-
+-#define WSIZE 0x8000		/* Window size must be at least 32k, */
+-				/* and a power of two */
+-
+-static uch *inbuf;		/* input buffer */
+-static uch window[WSIZE];	/* Sliding window buffer */
+-
+-static unsigned insize;		/* valid bytes in inbuf */
+-static unsigned inptr;		/* index of next byte to be processed in inbuf */
+-static unsigned outcnt;		/* bytes in output buffer */
+-
+-/* gzip flag byte */
+-#define ASCII_FLAG   0x01 /* bit 0 set: file probably ascii text */
+-#define CONTINUATION 0x02 /* bit 1 set: continuation of multi-part gzip file */
+-#define EXTRA_FIELD  0x04 /* bit 2 set: extra field present */
+-#define ORIG_NAME    0x08 /* bit 3 set: original file name present */
+-#define COMMENT      0x10 /* bit 4 set: file comment present */
+-#define ENCRYPTED    0x20 /* bit 5 set: file is encrypted */
+-#define RESERVED     0xC0 /* bit 6,7:   reserved */
+-
+-#define get_byte()  (inptr < insize ? inbuf[inptr++] : fill_inbuf())
+-
+ /* Diagnostic functions */
+ #ifdef DEBUG
+ #  define Assert(cond,msg) {if(!(cond)) error(msg);}
+@@ -233,24 +212,20 @@ static unsigned outcnt;		/* bytes in out
+ #  define Tracecv(c,x)
+ #endif
+ 
+-static int  fill_inbuf(void);
+-static void flush_window(void);
+ static void error(char *m);
+ 
+ extern char input_data[];
+ extern char input_data_end[];
+ 
+-static uch *output_data;
+-static ulg output_ptr;
+-static ulg bytes_out;
++static unsigned char *output_data;
++static unsigned long output_ptr;
+ 
+ static void error(char *m);
+ 
+ static void putstr(const char *);
+ 
+-extern int end;
+-static ulg free_mem_ptr;
+-static ulg free_mem_end_ptr;
++static unsigned long free_mem_ptr;
++static unsigned long free_mem_end_ptr;
+ 
+ #ifdef STANDALONE_DEBUG
+ #define NO_INFLATE_MALLOC
+@@ -258,46 +233,13 @@ static ulg free_mem_end_ptr;
+ 
+ #define ARCH_HAS_DECOMP_WDOG
+ 
+-#include "../../../../lib/inflate.c"
+-
+-/* ===========================================================================
+- * Fill the input buffer. This is called only when the buffer is empty
+- * and at least one byte is really needed.
+- */
+-int fill_inbuf(void)
+-{
+-	if (insize != 0)
+-		error("ran out of input data");
+-
+-	inbuf = input_data;
+-	insize = &input_data_end[0] - &input_data[0];
+-
+-	inptr = 1;
+-	return inbuf[0];
+-}
++#ifdef CONFIG_KERNEL_GZIP
++#include "../../../../lib/decompress_inflate.c"
++#endif
+ 
+-/* ===========================================================================
+- * Write the output window window[0..outcnt-1] and update crc and bytes_out.
+- * (Used for the decompressed data only.)
+- */
+-void flush_window(void)
+-{
+-	ulg c = crc;
+-	unsigned n;
+-	uch *in, *out, ch;
+-
+-	in = window;
+-	out = &output_data[output_ptr];
+-	for (n = 0; n < outcnt; n++) {
+-		ch = *out++ = *in++;
+-		c = crc_32_tab[((int)c ^ ch) & 0xff] ^ (c >> 8);
+-	}
+-	crc = c;
+-	bytes_out += (ulg)outcnt;
+-	output_ptr += (ulg)outcnt;
+-	outcnt = 0;
+-	putstr(".");
+-}
++#ifdef CONFIG_KERNEL_LZO
++#include "../../../../lib/decompress_unlzo.c"
++#endif
+ 
+ #ifndef arch_error
+ #define arch_error(x)
+@@ -314,22 +256,33 @@ static void error(char *x)
+ 	while(1);	/* Halt */
+ }
+ 
++asmlinkage void __div0(void)
++{
++	error("Attempting division by 0!");
++}
++
+ #ifndef STANDALONE_DEBUG
+ 
+-ulg
+-decompress_kernel(ulg output_start, ulg free_mem_ptr_p, ulg free_mem_ptr_end_p,
+-		  int arch_id)
++unsigned long
++decompress_kernel(unsigned long output_start, unsigned long free_mem_ptr_p,
++		unsigned long free_mem_ptr_end_p,
++		int arch_id)
+ {
+-	output_data		= (uch *)output_start;	/* Points to kernel start */
++	unsigned char *tmp;
++
++	output_data		= (unsigned char *)output_start;
+ 	free_mem_ptr		= free_mem_ptr_p;
+ 	free_mem_end_ptr	= free_mem_ptr_end_p;
+ 	__machine_arch_type	= arch_id;
+ 
+ 	arch_decomp_setup();
+ 
+-	makecrc();
++	tmp = (unsigned char *) (((unsigned long)input_data_end) - 4);
++	output_ptr = get_unaligned_le32(tmp);
++
+ 	putstr("Uncompressing Linux...");
+-	gunzip();
++	decompress(input_data, input_data_end - input_data,
++			NULL, NULL, output_data, NULL, error);
+ 	putstr(" done, booting the kernel.\n");
+ 	return output_ptr;
+ }
+@@ -341,11 +294,10 @@ int main()
+ {
+ 	output_data = output_buffer;
+ 
+-	makecrc();
+ 	putstr("Uncompressing Linux...");
+-	gunzip();
++	decompress(input_data, input_data_end - input_data,
++			NULL, NULL, output_data, NULL, error);
+ 	putstr("done.\n");
+ 	return 0;
+ }
+ #endif
+-	
+--- a/arch/arm/boot/compressed/piggy.S
++++ /dev/null
+@@ -1,6 +0,0 @@
+-	.section .piggydata,#alloc
+-	.globl	input_data
+-input_data:
+-	.incbin	"arch/arm/boot/compressed/piggy.gz"
+-	.globl	input_data_end
+-input_data_end:
+--- /dev/null
++++ b/arch/arm/boot/compressed/piggy.gzip.S
+@@ -0,0 +1,6 @@
++	.section .piggydata,#alloc
++	.globl	input_data
++input_data:
++	.incbin	"arch/arm/boot/compressed/piggy.gzip"
++	.globl	input_data_end
++input_data_end:
+--- /dev/null
++++ b/arch/arm/boot/compressed/piggy.lzo.S
+@@ -0,0 +1,6 @@
++	.section .piggydata,#alloc
++	.globl	input_data
++input_data:
++	.incbin	"arch/arm/boot/compressed/piggy.lzo"
++	.globl	input_data_end
++input_data_end:
diff -Nru a/target/linux/generic/patches-2.6.31/052-lzo_compressed_kernel_for_x86.patch b/target/linux/generic/patches-2.6.31/052-lzo_compressed_kernel_for_x86.patch
--- a/target/linux/generic/patches-2.6.31/052-lzo_compressed_kernel_for_x86.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/052-lzo_compressed_kernel_for_x86.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,48 @@
+--- a/arch/x86/Kconfig
++++ b/arch/x86/Kconfig
+@@ -49,6 +49,7 @@ config X86
+ 	select HAVE_KERNEL_GZIP
+ 	select HAVE_KERNEL_BZIP2
+ 	select HAVE_KERNEL_LZMA
++	select HAVE_KERNEL_LZO
+ 	select HAVE_ARCH_KMEMCHECK
+ 
+ config OUTPUT_FORMAT
+--- a/arch/x86/boot/compressed/Makefile
++++ b/arch/x86/boot/compressed/Makefile
+@@ -4,7 +4,7 @@
+ # create a compressed vmlinux image from the original vmlinux
+ #
+ 
+-targets := vmlinux.lds vmlinux vmlinux.bin vmlinux.bin.gz vmlinux.bin.bz2 vmlinux.bin.lzma head_$(BITS).o misc.o piggy.o
++targets := vmlinux.lds vmlinux vmlinux.bin vmlinux.bin.gz vmlinux.bin.bz2 vmlinux.bin.lzma vmlinux.bin.lzo head_$(BITS).o misc.o piggy.o
+ 
+ KBUILD_CFLAGS := -m$(BITS) -D__KERNEL__ $(LINUX_INCLUDE) -O2
+ KBUILD_CFLAGS += -fno-strict-aliasing -fPIC
+@@ -48,10 +48,13 @@ $(obj)/vmlinux.bin.bz2: $(vmlinux.bin.al
+ 	$(call if_changed,bzip2)
+ $(obj)/vmlinux.bin.lzma: $(vmlinux.bin.all-y) FORCE
+ 	$(call if_changed,lzma)
++$(obj)/vmlinux.bin.lzo: $(vmlinux.bin.all-y) FORCE
++	$(call if_changed,lzo)
+ 
+ suffix-$(CONFIG_KERNEL_GZIP)	:= gz
+ suffix-$(CONFIG_KERNEL_BZIP2)	:= bz2
+ suffix-$(CONFIG_KERNEL_LZMA)	:= lzma
++suffix-$(CONFIG_KERNEL_LZO) 	:= lzo
+ 
+ quiet_cmd_mkpiggy = MKPIGGY $@
+       cmd_mkpiggy = $(obj)/mkpiggy $< > $@ || ( rm -f $@ ; false )
+--- a/arch/x86/boot/compressed/misc.c
++++ b/arch/x86/boot/compressed/misc.c
+@@ -162,6 +162,10 @@ static int lines, cols;
+ #include "../../../../lib/decompress_unlzma.c"
+ #endif
+ 
++#ifdef CONFIG_KERNEL_LZO
++#include "../../../../lib/decompress_unlzo.c"
++#endif
++
+ static void scroll(void)
+ {
+ 	int i;
diff -Nru a/target/linux/generic/patches-2.6.31/053-lzo_compression_for_initramfs.patch b/target/linux/generic/patches-2.6.31/053-lzo_compression_for_initramfs.patch
--- a/target/linux/generic/patches-2.6.31/053-lzo_compression_for_initramfs.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/053-lzo_compression_for_initramfs.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,106 @@
+--- a/lib/Kconfig
++++ b/lib/Kconfig
+@@ -120,6 +120,10 @@ config DECOMPRESS_LZMA
+ config DECOMPRESS_LZMA_NEEDED
+ 	 boolean
+ 
++config DECOMPRESS_LZO
++	select LZO_DECOMPRESS
++	tristate
++
+ #
+ # Generic allocator support is selected if needed
+ #
+--- a/lib/Makefile
++++ b/lib/Makefile
+@@ -69,6 +69,7 @@ obj-$(CONFIG_LZO_DECOMPRESS) += lzo/
+ lib-$(CONFIG_DECOMPRESS_GZIP) += decompress_inflate.o
+ lib-$(CONFIG_DECOMPRESS_BZIP2) += decompress_bunzip2.o
+ lib-$(CONFIG_DECOMPRESS_LZMA) += decompress_unlzma.o
++lib-$(CONFIG_DECOMPRESS_LZO) += decompress_unlzo.o
+ 
+ obj-$(CONFIG_TEXTSEARCH) += textsearch.o
+ obj-$(CONFIG_TEXTSEARCH_KMP) += ts_kmp.o
+--- a/lib/decompress.c
++++ b/lib/decompress.c
+@@ -9,6 +9,7 @@
+ #include <linux/decompress/bunzip2.h>
+ #include <linux/decompress/unlzma.h>
+ #include <linux/decompress/inflate.h>
++#include <linux/decompress/unlzo.h>
+ 
+ #include <linux/types.h>
+ #include <linux/string.h>
+@@ -22,6 +23,9 @@
+ #ifndef CONFIG_DECOMPRESS_LZMA
+ # define unlzma NULL
+ #endif
++#ifndef CONFIG_DECOMPRESS_LZO
++# define unlzo NULL
++#endif
+ 
+ static const struct compress_format {
+ 	unsigned char magic[2];
+@@ -32,6 +36,7 @@ static const struct compress_format {
+ 	{ {037, 0236}, "gzip", gunzip },
+ 	{ {0x42, 0x5a}, "bzip2", bunzip2 },
+ 	{ {0x5d, 0x00}, "lzma", unlzma },
++	{ {0x89, 0x4c}, "lzo", unlzo },
+ 	{ {0, 0}, NULL, NULL }
+ };
+ 
+--- a/usr/Kconfig
++++ b/usr/Kconfig
+@@ -72,6 +72,15 @@ config RD_LZMA
+ 	  Support loading of a LZMA encoded initial ramdisk or cpio buffer
+ 	  If unsure, say N.
+ 
++config RD_LZO
++	bool "Support initial ramdisks compressed using LZO" if EMBEDDED
++	default !EMBEDDED
++	depends on BLK_DEV_INITRD && HAVE_KERNEL_LZO
++	select DECOMPRESS_LZO
++	help
++	  Support loading of a LZO encoded initial ramdisk or cpio buffer
++	  If unsure, say N.
++
+ choice
+ 	prompt "Built-in initramfs compression mode" if INITRAMFS_SOURCE!=""
+ 	help
+@@ -108,16 +117,15 @@ config INITRAMFS_COMPRESSION_GZIP
+ 	bool "Gzip"
+ 	depends on RD_GZIP
+ 	help
+-	  The old and tried gzip compression. Its compression ratio is
+-	  the poorest among the 3 choices; however its speed (both
+-	  compression and decompression) is the fastest.
++	  The old and tried gzip compression. It provides a good balance
++	  between compression ratio and decompression speed.
+ 
+ config INITRAMFS_COMPRESSION_BZIP2
+ 	bool "Bzip2"
+ 	depends on RD_BZIP2
+ 	help
+ 	  Its compression ratio and speed is intermediate.
+-	  Decompression speed is slowest among the three.  The initramfs
++	  Decompression speed is slowest among the four.  The initramfs
+ 	  size is about 10% smaller with bzip2, in comparison to gzip.
+ 	  Bzip2 uses a large amount of memory. For modern kernels you
+ 	  will need at least 8MB RAM or more for booting.
+@@ -128,7 +136,15 @@ config INITRAMFS_COMPRESSION_LZMA
+ 	help
+ 	  The most recent compression algorithm.
+ 	  Its ratio is best, decompression speed is between the other
+-	  two. Compression is slowest.	The initramfs size is about 33%
++	  three. Compression is slowest. The initramfs size is about 33%
+ 	  smaller with LZMA in comparison to gzip.
+ 
++config INITRAMFS_COMPRESSION_LZO
++	bool "LZO"
++	depends on RD_LZO
++	help
++	  Its compression ratio is the poorest among the four. The kernel
++	  size is about about 10% bigger than gzip; however its speed
++	  (both compression and decompression) is the fastest.
++
+ endchoice
diff -Nru a/target/linux/generic/patches-2.6.31/055-lzma_arm_kernel.patch b/target/linux/generic/patches-2.6.31/055-lzma_arm_kernel.patch
--- a/target/linux/generic/patches-2.6.31/055-lzma_arm_kernel.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/055-lzma_arm_kernel.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,57 @@
+From d0f226a0f104c7d1da1d215b8013359273e39e18 Mon Sep 17 00:00:00 2001
+From: Albin Tonnerre <albin.tonnerre@free-electrons.com>
+Date: Fri, 16 Oct 2009 16:17:22 +0200
+Subject: [PATCH] Add LZMA decompression on ARM
+
+
+Signed-off-by: Albin Tonnerre <albin.tonnerre@free-electrons.com>
+---
+ arch/arm/Kconfig                      |    1 +
+ arch/arm/boot/compressed/Makefile     |    1 +
+ arch/arm/boot/compressed/misc.c       |    4 ++++
+ arch/arm/boot/compressed/piggy.lzma.S |    6 ++++++
+ 4 files changed, 12 insertions(+), 0 deletions(-)
+ create mode 100644 arch/arm/boot/compressed/piggy.lzma.S
+
+--- a/arch/arm/Kconfig
++++ b/arch/arm/Kconfig
+@@ -20,6 +20,7 @@ config ARM
+ 	select HAVE_GENERIC_DMA_COHERENT
+ 	select HAVE_KERNEL_GZIP
+ 	select HAVE_KERNEL_LZO
++	select HAVE_KERNEL_LZMA
+ 	help
+ 	  The ARM series is a line of low-power-consumption RISC chip designs
+ 	  licensed by ARM Ltd and targeted at embedded applications and
+--- a/arch/arm/boot/compressed/Makefile
++++ b/arch/arm/boot/compressed/Makefile
+@@ -65,6 +65,7 @@ SEDFLAGS	= s/TEXT_START/$(ZTEXTADDR)/;s/
+ 
+ suffix_$(CONFIG_KERNEL_GZIP) = gzip
+ suffix_$(CONFIG_KERNEL_LZO)  = lzo
++suffix_$(CONFIG_KERNEL_LZMA)  = lzma
+ 
+ targets       := vmlinux vmlinux.lds \
+ 		 piggy.$(suffix_y) piggy.$(suffix_y).o \
+--- a/arch/arm/boot/compressed/misc.c
++++ b/arch/arm/boot/compressed/misc.c
+@@ -237,6 +237,10 @@ static unsigned long free_mem_end_ptr;
+ #include "../../../../lib/decompress_inflate.c"
+ #endif
+ 
++#ifdef CONFIG_KERNEL_LZMA
++#include "../../../../lib/decompress_unlzma.c"
++#endif
++
+ #ifdef CONFIG_KERNEL_LZO
+ #include "../../../../lib/decompress_unlzo.c"
+ #endif
+--- /dev/null
++++ b/arch/arm/boot/compressed/piggy.lzma.S
+@@ -0,0 +1,6 @@
++	.section .piggydata,#alloc
++	.globl	input_data
++input_data:
++	.incbin	"arch/arm/boot/compressed/piggy.lzma"
++	.globl	input_data_end
++input_data_end:
diff -Nru a/target/linux/generic/patches-2.6.31/060-block2mtd_init.patch b/target/linux/generic/patches-2.6.31/060-block2mtd_init.patch
--- a/target/linux/generic/patches-2.6.31/060-block2mtd_init.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/060-block2mtd_init.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,110 @@
+--- a/drivers/mtd/devices/block2mtd.c
++++ b/drivers/mtd/devices/block2mtd.c
+@@ -14,6 +14,7 @@
+ #include <linux/list.h>
+ #include <linux/init.h>
+ #include <linux/mtd/mtd.h>
++#include <linux/mtd/partitions.h>
+ #include <linux/buffer_head.h>
+ #include <linux/mutex.h>
+ #include <linux/mount.h>
+@@ -232,10 +233,11 @@ static void block2mtd_free_device(struct
+ 
+ 
+ /* FIXME: ensure that mtd->size % erase_size == 0 */
+-static struct block2mtd_dev *add_device(char *devname, int erase_size)
++static struct block2mtd_dev *add_device(char *devname, int erase_size, const char *mtdname)
+ {
+ 	struct block_device *bdev;
+ 	struct block2mtd_dev *dev;
++	struct mtd_partition *part;
+ 	char *name;
+ 
+ 	if (!devname)
+@@ -273,17 +275,17 @@ static struct block2mtd_dev *add_device(
+ 
+ 	mutex_init(&dev->write_mutex);
+ 
+-	/* Setup the MTD structure */
+-	/* make the name contain the block device in */
+-	name = kmalloc(sizeof("block2mtd: ") + strlen(devname) + 1,
+-			GFP_KERNEL);
++	if (!mtdname)
++		mtdname = devname;
++
++	name = kmalloc(strlen(mtdname) + 1, GFP_KERNEL);
+ 	if (!name)
+ 		goto devinit_err;
+ 
+-	sprintf(name, "block2mtd: %s", devname);
++	strcpy(name, mtdname);
+ 	dev->mtd.name = name;
+ 
+-	dev->mtd.size = dev->blkdev->bd_inode->i_size & PAGE_MASK;
++	dev->mtd.size = dev->blkdev->bd_inode->i_size & PAGE_MASK & ~(erase_size - 1);
+ 	dev->mtd.erasesize = erase_size;
+ 	dev->mtd.writesize = 1;
+ 	dev->mtd.type = MTD_RAM;
+@@ -296,14 +298,17 @@ static struct block2mtd_dev *add_device(
+ 	dev->mtd.priv = dev;
+ 	dev->mtd.owner = THIS_MODULE;
+ 
+-	if (add_mtd_device(&dev->mtd)) {
++	part = kzalloc(sizeof(struct mtd_partition), GFP_KERNEL);
++	part->name = dev->mtd.name;
++	part->offset = 0;
++	part->size = dev->mtd.size;
++	if (add_mtd_partitions(&dev->mtd, part, 1)) {
+ 		/* Device didnt get added, so free the entry */
+ 		goto devinit_err;
+ 	}
+ 	list_add(&dev->list, &blkmtd_device_list);
+ 	INFO("mtd%d: [%s] erase_size = %dKiB [%d]", dev->mtd.index,
+-			dev->mtd.name + strlen("block2mtd: "),
+-			dev->mtd.erasesize >> 10, dev->mtd.erasesize);
++			mtdname, dev->mtd.erasesize >> 10, dev->mtd.erasesize);
+ 	return dev;
+ 
+ devinit_err:
+@@ -376,9 +381,9 @@ static char block2mtd_paramline[80 + 12]
+ 
+ static int block2mtd_setup2(const char *val)
+ {
+-	char buf[80 + 12]; /* 80 for device, 12 for erase size */
++	char buf[80 + 12 + 80]; /* 80 for device, 12 for erase size, 80 for name */
+ 	char *str = buf;
+-	char *token[2];
++	char *token[3];
+ 	char *name;
+ 	size_t erase_size = PAGE_SIZE;
+ 	int i, ret;
+@@ -389,7 +394,7 @@ static int block2mtd_setup2(const char *
+ 	strcpy(str, val);
+ 	kill_final_newline(str);
+ 
+-	for (i = 0; i < 2; i++)
++	for (i = 0; i < 3; i++)
+ 		token[i] = strsep(&str, ",");
+ 
+ 	if (str)
+@@ -408,8 +413,10 @@ static int block2mtd_setup2(const char *
+ 			parse_err("illegal erase size");
+ 		}
+ 	}
++	if (token[2] && (strlen(token[2]) + 1 > 80))
++		parse_err("mtd device name too long");
+ 
+-	add_device(name, erase_size);
++	add_device(name, erase_size, token[2]);
+ 
+ 	return 0;
+ }
+@@ -443,7 +450,7 @@ static int block2mtd_setup(const char *v
+ 
+ 
+ module_param_call(block2mtd, block2mtd_setup, NULL, NULL, 0200);
+-MODULE_PARM_DESC(block2mtd, "Device to use. \"block2mtd=<dev>[,<erasesize>]\"");
++MODULE_PARM_DESC(block2mtd, "Device to use. \"block2mtd=<dev>[,<erasesize>[,<name>]]\"");
+ 
+ static int __init block2mtd_init(void)
+ {
diff -Nru a/target/linux/generic/patches-2.6.31/065-rootfs_split.patch b/target/linux/generic/patches-2.6.31/065-rootfs_split.patch
--- a/target/linux/generic/patches-2.6.31/065-rootfs_split.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/065-rootfs_split.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,627 @@
+--- a/drivers/mtd/Kconfig
++++ b/drivers/mtd/Kconfig
+@@ -53,6 +53,16 @@ config MTD_TESTS
+ 	  should normally be compiled as kernel modules. The modules perform
+ 	  various checks and verifications when loaded.
+ 
++config MTD_ROOTFS_ROOT_DEV
++	bool "Automatically set 'rootfs' partition to be root filesystem"
++	depends on MTD_PARTITIONS
++	default y
++
++config MTD_ROOTFS_SPLIT
++	bool "Automatically split 'rootfs' partition for squashfs"
++	depends on MTD_PARTITIONS
++	default y
++
+ config MTD_REDBOOT_PARTS
+ 	tristate "RedBoot partition table parsing"
+ 	depends on MTD_PARTITIONS
+--- a/drivers/mtd/mtdpart.c
++++ b/drivers/mtd/mtdpart.c
+@@ -18,6 +18,8 @@
+ #include <linux/mtd/mtd.h>
+ #include <linux/mtd/partitions.h>
+ #include <linux/mtd/compatmac.h>
++#include <linux/root_dev.h>
++#include <linux/magic.h>
+ 
+ /* Our partition linked list */
+ static LIST_HEAD(mtd_partitions);
+@@ -35,7 +37,7 @@ struct mtd_part {
+  * the pointer to that structure with this macro.
+  */
+ #define PART(x)  ((struct mtd_part *)(x))
+-
++#define IS_PART(mtd) (mtd->read == part_read)
+ 
+ /*
+  * MTD methods which simply translate the effective address and pass through
+@@ -502,6 +504,152 @@ out_register:
+ 	return slave;
+ }
+ 
++#ifdef CONFIG_MTD_ROOTFS_SPLIT
++#define ROOTFS_SPLIT_NAME "rootfs_data"
++#define ROOTFS_REMOVED_NAME "<removed>"
++
++struct squashfs_super_block {
++	__le32 s_magic;
++	__le32 pad0[9];
++	__le64 bytes_used;
++};
++
++
++static int split_squashfs(struct mtd_info *master, int offset, int *split_offset)
++{
++	struct squashfs_super_block sb;
++	int len, ret;
++
++	ret = master->read(master, offset, sizeof(sb), &len, (void *) &sb);
++	if (ret || (len != sizeof(sb))) {
++		printk(KERN_ALERT "split_squashfs: error occured while reading "
++			"from \"%s\"\n", master->name);
++		return -EINVAL;
++	}
++
++	if (SQUASHFS_MAGIC != le32_to_cpu(sb.s_magic) ) {
++		printk(KERN_ALERT "split_squashfs: no squashfs found in \"%s\"\n",
++			master->name);
++		*split_offset = 0;
++		return 0;
++	}
++
++	if (le64_to_cpu((sb.bytes_used)) <= 0) {
++		printk(KERN_ALERT "split_squashfs: squashfs is empty in \"%s\"\n",
++			master->name);
++		*split_offset = 0;
++		return 0;
++	}
++
++	len = (u32) le64_to_cpu(sb.bytes_used);
++	len += (offset & 0x000fffff);
++	len +=  (master->erasesize - 1);
++	len &= ~(master->erasesize - 1);
++	len -= (offset & 0x000fffff);
++	*split_offset = offset + len;
++
++	return 0;
++}
++
++static int split_rootfs_data(struct mtd_info *master, struct mtd_info *rpart, const struct mtd_partition *part)
++{
++	struct mtd_partition *dpart;
++	struct mtd_part *slave = NULL;
++	struct mtd_part *spart;
++	int split_offset = 0;
++	int ret;
++
++	spart = PART(rpart);
++	ret = split_squashfs(master, spart->offset, &split_offset);
++	if (ret)
++		return ret;
++
++	if (split_offset <= 0)
++		return 0;
++
++	dpart = kmalloc(sizeof(*part)+sizeof(ROOTFS_SPLIT_NAME)+1, GFP_KERNEL);
++	if (dpart == NULL) {
++		printk(KERN_INFO "split_squashfs: no memory for partition \"%s\"\n",
++			ROOTFS_SPLIT_NAME);
++		return -ENOMEM;
++	}
++
++	memcpy(dpart, part, sizeof(*part));
++	dpart->name = (unsigned char *)&dpart[1];
++	strcpy(dpart->name, ROOTFS_SPLIT_NAME);
++
++	dpart->size = rpart->size - (split_offset - spart->offset);
++	dpart->offset = split_offset;
++
++	if (dpart == NULL)
++		return 1;
++
++	printk(KERN_INFO "mtd: partition \"%s\" created automatically, ofs=%llX, len=%llX \n",
++		ROOTFS_SPLIT_NAME, dpart->offset, dpart->size);
++
++	slave = add_one_partition(master, dpart, 0, split_offset);
++	if (!slave) {
++		kfree(dpart);
++		return -ENOMEM;
++	}
++	rpart->split = &slave->mtd;
++
++	return 0;
++}
++
++static int refresh_rootfs_split(struct mtd_info *mtd)
++{
++	struct mtd_partition tpart;
++	struct mtd_part *part;
++	char *name;
++	//int index = 0;
++	int offset, size;
++	int ret;
++
++	part = PART(mtd);
++
++	/* check for the new squashfs offset first */
++	ret = split_squashfs(part->master, part->offset, &offset);
++	if (ret)
++		return ret;
++
++	if ((offset > 0) && !mtd->split) {
++		printk(KERN_INFO "%s: creating new split partition for \"%s\"\n", __func__, mtd->name);
++		/* if we don't have a rootfs split partition, create a new one */
++		tpart.name = (char *) mtd->name;
++		tpart.size = mtd->size;
++		tpart.offset = part->offset;
++
++		return split_rootfs_data(part->master, &part->mtd, &tpart);
++	} else if ((offset > 0) && mtd->split) {
++		/* update the offsets of the existing partition */
++		size = mtd->size + part->offset - offset;
++
++		part = PART(mtd->split);
++		part->offset = offset;
++		part->mtd.size = size;
++		printk(KERN_INFO "%s: %s partition \"" ROOTFS_SPLIT_NAME "\", offset: 0x%06x (0x%06x)\n",
++			__func__, (!strcmp(part->mtd.name, ROOTFS_SPLIT_NAME) ? "updating" : "creating"),
++			(u32) part->offset, (u32) part->mtd.size);
++		name = kmalloc(sizeof(ROOTFS_SPLIT_NAME) + 1, GFP_KERNEL);
++		strcpy(name, ROOTFS_SPLIT_NAME);
++		part->mtd.name = name;
++	} else if ((offset <= 0) && mtd->split) {
++		printk(KERN_INFO "%s: removing partition \"%s\"\n", __func__, mtd->split->name);
++
++		/* mark existing partition as removed */
++		part = PART(mtd->split);
++		name = kmalloc(sizeof(ROOTFS_SPLIT_NAME) + 1, GFP_KERNEL);
++		strcpy(name, ROOTFS_REMOVED_NAME);
++		part->mtd.name = name;
++		part->offset = 0;
++		part->mtd.size = 0;
++	}
++
++	return 0;
++}
++#endif /* CONFIG_MTD_ROOTFS_SPLIT */
++
+ /*
+  * This function, given a master MTD object and a partition table, creates
+  * and registers slave MTD objects which are bound to the master according to
+@@ -517,7 +665,7 @@ int add_mtd_partitions(struct mtd_info *
+ {
+ 	struct mtd_part *slave;
+ 	uint64_t cur_offset = 0;
+-	int i;
++	int i, ret;
+ 
+ 	printk(KERN_NOTICE "Creating %d MTD partitions on \"%s\":\n", nbparts, master->name);
+ 
+@@ -525,6 +673,21 @@ int add_mtd_partitions(struct mtd_info *
+ 		slave = add_one_partition(master, parts + i, i, cur_offset);
+ 		if (!slave)
+ 			return -ENOMEM;
++
++		if (!strcmp(parts[i].name, "rootfs")) {
++#ifdef CONFIG_MTD_ROOTFS_ROOT_DEV
++			if (ROOT_DEV == 0) {
++				printk(KERN_NOTICE "mtd: partition \"rootfs\" "
++					"set to be root filesystem\n");
++				ROOT_DEV = MKDEV(MTD_BLOCK_MAJOR, slave->mtd.index);
++			}
++#endif
++#ifdef CONFIG_MTD_ROOTFS_SPLIT
++			ret = split_rootfs_data(master, &slave->mtd, &parts[i]);
++			/* if (ret == 0)
++				j++; */
++#endif
++		}
+ 		cur_offset = slave->offset + slave->mtd.size;
+ 	}
+ 
+@@ -532,6 +695,32 @@ int add_mtd_partitions(struct mtd_info *
+ }
+ EXPORT_SYMBOL(add_mtd_partitions);
+ 
++int refresh_mtd_partitions(struct mtd_info *mtd)
++{
++	int ret = 0;
++
++	if (IS_PART(mtd)) {
++		struct mtd_part *part;
++		struct mtd_info *master;
++
++		part = PART(mtd);
++		master = part->master;
++		if (master->refresh_device)
++			ret = master->refresh_device(master);
++	}
++
++	if (!ret && mtd->refresh_device)
++		ret = mtd->refresh_device(mtd);
++
++#ifdef CONFIG_MTD_ROOTFS_SPLIT
++	if (!ret && IS_PART(mtd) && !strcmp(mtd->name, "rootfs"))
++		refresh_rootfs_split(mtd);
++#endif
++
++	return 0;
++}
++EXPORT_SYMBOL_GPL(refresh_mtd_partitions);
++
+ static DEFINE_SPINLOCK(part_parser_lock);
+ static LIST_HEAD(part_parsers);
+ 
+--- a/drivers/mtd/devices/block2mtd.c
++++ b/drivers/mtd/devices/block2mtd.c
+@@ -29,6 +29,8 @@ struct block2mtd_dev {
+ 	struct block_device *blkdev;
+ 	struct mtd_info mtd;
+ 	struct mutex write_mutex;
++	rwlock_t bdev_mutex;
++	char devname[0];
+ };
+ 
+ 
+@@ -81,6 +83,12 @@ static int block2mtd_erase(struct mtd_in
+ 	size_t len = instr->len;
+ 	int err;
+ 
++	read_lock(&dev->bdev_mutex);
++	if (!dev->blkdev) {
++		err = -EINVAL;
++		goto done;
++	}
++
+ 	instr->state = MTD_ERASING;
+ 	mutex_lock(&dev->write_mutex);
+ 	err = _block2mtd_erase(dev, from, len);
+@@ -93,6 +101,10 @@ static int block2mtd_erase(struct mtd_in
+ 
+ 	instr->state = MTD_ERASE_DONE;
+ 	mtd_erase_callback(instr);
++
++done:
++	read_unlock(&dev->bdev_mutex);
++
+ 	return err;
+ }
+ 
+@@ -104,10 +116,14 @@ static int block2mtd_read(struct mtd_inf
+ 	struct page *page;
+ 	int index = from >> PAGE_SHIFT;
+ 	int offset = from & (PAGE_SIZE-1);
+-	int cpylen;
++	int cpylen, err = 0;
++
++	read_lock(&dev->bdev_mutex);
++	if (!dev->blkdev || (from > mtd->size)) {
++		err = -EINVAL;
++		goto done;
++	}
+ 
+-	if (from > mtd->size)
+-		return -EINVAL;
+ 	if (from + len > mtd->size)
+ 		len = mtd->size - from;
+ 
+@@ -122,10 +138,14 @@ static int block2mtd_read(struct mtd_inf
+ 		len = len - cpylen;
+ 
+ 		page = page_read(dev->blkdev->bd_inode->i_mapping, index);
+-		if (!page)
+-			return -ENOMEM;
+-		if (IS_ERR(page))
+-			return PTR_ERR(page);
++		if (!page) {
++			err = -ENOMEM;
++			goto done;
++		}
++		if (IS_ERR(page)) {
++			err = PTR_ERR(page);
++			goto done;
++		}
+ 
+ 		memcpy(buf, page_address(page) + offset, cpylen);
+ 		page_cache_release(page);
+@@ -136,7 +156,10 @@ static int block2mtd_read(struct mtd_inf
+ 		offset = 0;
+ 		index++;
+ 	}
+-	return 0;
++
++done:
++	read_unlock(&dev->bdev_mutex);
++	return err;
+ }
+ 
+ 
+@@ -188,12 +211,22 @@ static int block2mtd_write(struct mtd_in
+ 		size_t *retlen, const u_char *buf)
+ {
+ 	struct block2mtd_dev *dev = mtd->priv;
+-	int err;
++	int err = 0;
++
++	read_lock(&dev->bdev_mutex);
++	if (!dev->blkdev) {
++		err = -EINVAL;
++		goto done;
++	}
+ 
+ 	if (!len)
+-		return 0;
+-	if (to >= mtd->size)
+-		return -ENOSPC;
++		goto done;
++
++	if (to >= mtd->size) {
++		err = -ENOSPC;
++		goto done;
++	}
++
+ 	if (to + len > mtd->size)
+ 		len = mtd->size - to;
+ 
+@@ -202,6 +235,9 @@ static int block2mtd_write(struct mtd_in
+ 	mutex_unlock(&dev->write_mutex);
+ 	if (err > 0)
+ 		err = 0;
++
++done:
++	read_unlock(&dev->bdev_mutex);
+ 	return err;
+ }
+ 
+@@ -210,52 +246,29 @@ static int block2mtd_write(struct mtd_in
+ static void block2mtd_sync(struct mtd_info *mtd)
+ {
+ 	struct block2mtd_dev *dev = mtd->priv;
+-	sync_blockdev(dev->blkdev);
+-	return;
+-}
+-
+-
+-static void block2mtd_free_device(struct block2mtd_dev *dev)
+-{
+-	if (!dev)
+-		return;
+-
+-	kfree(dev->mtd.name);
+ 
+-	if (dev->blkdev) {
+-		invalidate_mapping_pages(dev->blkdev->bd_inode->i_mapping,
+-					0, -1);
+-		close_bdev_exclusive(dev->blkdev, FMODE_READ|FMODE_WRITE);
+-	}
++	read_lock(&dev->bdev_mutex);
++	if (dev->blkdev)
++		sync_blockdev(dev->blkdev);
++	read_unlock(&dev->bdev_mutex);
+ 
+-	kfree(dev);
++	return;
+ }
+ 
+ 
+-/* FIXME: ensure that mtd->size % erase_size == 0 */
+-static struct block2mtd_dev *add_device(char *devname, int erase_size, const char *mtdname)
++static int _open_bdev(struct block2mtd_dev *dev)
+ {
+ 	struct block_device *bdev;
+-	struct block2mtd_dev *dev;
+-	struct mtd_partition *part;
+-	char *name;
+-
+-	if (!devname)
+-		return NULL;
+-
+-	dev = kzalloc(sizeof(struct block2mtd_dev), GFP_KERNEL);
+-	if (!dev)
+-		return NULL;
+ 
+ 	/* Get a handle on the device */
+-	bdev = open_bdev_exclusive(devname, FMODE_READ|FMODE_WRITE, NULL);
++	bdev = open_bdev_exclusive(dev->devname, FMODE_READ|FMODE_WRITE, NULL);
+ #ifndef MODULE
+ 	if (IS_ERR(bdev)) {
+ 
+ 		/* We might not have rootfs mounted at this point. Try
+ 		   to resolve the device name by other means. */
+ 
+-		dev_t devt = name_to_dev_t(devname);
++		dev_t devt = name_to_dev_t(dev->devname);
+ 		if (devt) {
+ 			bdev = open_by_devnum(devt, FMODE_WRITE | FMODE_READ);
+ 		}
+@@ -263,17 +276,98 @@ static struct block2mtd_dev *add_device(
+ #endif
+ 
+ 	if (IS_ERR(bdev)) {
+-		ERROR("error: cannot open device %s", devname);
+-		goto devinit_err;
++		ERROR("error: cannot open device %s", dev->devname);
++		return 1;
+ 	}
+ 	dev->blkdev = bdev;
+ 
+ 	if (MAJOR(bdev->bd_dev) == MTD_BLOCK_MAJOR) {
+ 		ERROR("attempting to use an MTD device as a block device");
+-		goto devinit_err;
++		return 1;
+ 	}
+ 
++	return 0;
++}
++
++static void _close_bdev(struct block2mtd_dev *dev)
++{
++	struct block_device *bdev;
++
++	if (!dev->blkdev)
++		return;
++
++	bdev = dev->blkdev;
++	invalidate_mapping_pages(dev->blkdev->bd_inode->i_mapping, 0, -1);
++	close_bdev_exclusive(dev->blkdev, FMODE_READ|FMODE_WRITE);
++	dev->blkdev = NULL;
++}
++
++static void block2mtd_free_device(struct block2mtd_dev *dev)
++{
++	if (!dev)
++		return;
++
++	kfree(dev->mtd.name);
++	_close_bdev(dev);
++	kfree(dev);
++}
++
++
++static int block2mtd_refresh(struct mtd_info *mtd)
++{
++	struct block2mtd_dev *dev = mtd->priv;
++	struct block_device *bdev;
++	dev_t devt;
++	int err = 0;
++
++	/* no other mtd function can run at this point */
++	write_lock(&dev->bdev_mutex);
++
++	/* get the device number for the whole disk */
++	devt = MKDEV(MAJOR(dev->blkdev->bd_dev), 0);
++
++	/* close the old block device */
++	_close_bdev(dev);
++
++	/* open the whole disk, issue a partition rescan, then */
++	bdev = open_by_devnum(devt, FMODE_WRITE | FMODE_READ);
++	if (!bdev || !bdev->bd_disk)
++		err = -EINVAL;
++#ifndef CONFIG_MTD_BLOCK2MTD_MODULE
++	else
++		err = rescan_partitions(bdev->bd_disk, bdev);
++#endif
++	if (bdev)
++		close_bdev_exclusive(bdev, FMODE_READ|FMODE_WRITE);
++
++	/* try to open the partition block device again */
++	_open_bdev(dev);
++	write_unlock(&dev->bdev_mutex);
++
++	return err;
++}
++
++/* FIXME: ensure that mtd->size % erase_size == 0 */
++static struct block2mtd_dev *add_device(char *devname, int erase_size, char *mtdname)
++{
++	struct block2mtd_dev *dev;
++	struct mtd_partition *part;
++	char *name;
++
++	if (!devname)
++		return NULL;
++
++	dev = kzalloc(sizeof(struct block2mtd_dev) + strlen(devname) + 1, GFP_KERNEL);
++	if (!dev)
++		return NULL;
++
++	strcpy(dev->devname, devname);
++
++	if (_open_bdev(dev))
++		goto devinit_err;
++
+ 	mutex_init(&dev->write_mutex);
++	rwlock_init(&dev->bdev_mutex);
+ 
+ 	if (!mtdname)
+ 		mtdname = devname;
+@@ -297,6 +391,7 @@ static struct block2mtd_dev *add_device(
+ 	dev->mtd.read = block2mtd_read;
+ 	dev->mtd.priv = dev;
+ 	dev->mtd.owner = THIS_MODULE;
++	dev->mtd.refresh_device = block2mtd_refresh;
+ 
+ 	part = kzalloc(sizeof(struct mtd_partition), GFP_KERNEL);
+ 	part->name = dev->mtd.name;
+--- a/drivers/mtd/mtdchar.c
++++ b/drivers/mtd/mtdchar.c
+@@ -18,6 +18,7 @@
+ 
+ #include <linux/mtd/mtd.h>
+ #include <linux/mtd/compatmac.h>
++#include <linux/mtd/partitions.h>
+ 
+ #include <asm/uaccess.h>
+ 
+@@ -814,6 +815,13 @@ static int mtd_ioctl(struct inode *inode
+ 		file->f_pos = 0;
+ 		break;
+ 	}
++#ifdef CONFIG_MTD_PARTITIONS
++	case MTDREFRESH:
++	{
++		ret = refresh_mtd_partitions(mtd);
++		break;
++	}
++#endif
+ 
+ 	default:
+ 		ret = -ENOTTY;
+--- a/include/linux/mtd/mtd.h
++++ b/include/linux/mtd/mtd.h
+@@ -101,6 +101,7 @@ struct mtd_oob_ops {
+ 	uint8_t		*oobbuf;
+ };
+ 
++struct mtd_info;
+ struct mtd_info {
+ 	u_char type;
+ 	uint32_t flags;
+@@ -241,6 +242,9 @@ struct mtd_info {
+ 	struct device dev;
+ 	int usecount;
+ 
++	int (*refresh_device)(struct mtd_info *mtd);
++	struct mtd_info *split;
++
+ 	/* If the driver is something smart, like UBI, it may need to maintain
+ 	 * its own reference counting. The below functions are only for driver.
+ 	 * The driver may register its callbacks. These callbacks are not
+--- a/include/linux/mtd/partitions.h
++++ b/include/linux/mtd/partitions.h
+@@ -34,12 +34,14 @@
+  * erasesize aligned (e.g. use MTDPART_OFS_NEXTBLK).
+  */
+ 
++struct mtd_partition;
+ struct mtd_partition {
+ 	char *name;			/* identifier string */
+ 	uint64_t size;			/* partition size */
+ 	uint64_t offset;		/* offset within the master MTD space */
+ 	uint32_t mask_flags;		/* master MTD flags to mask out for this partition */
+ 	struct nand_ecclayout *ecclayout;	/* out of band layout for this partition (NAND only)*/
++	int (*refresh_partition)(struct mtd_info *);
+ };
+ 
+ #define MTDPART_OFS_NXTBLK	(-2)
+@@ -51,6 +53,7 @@ struct mtd_info;
+ 
+ int add_mtd_partitions(struct mtd_info *, const struct mtd_partition *, int);
+ int del_mtd_partitions(struct mtd_info *);
++int refresh_mtd_partitions(struct mtd_info *);
+ 
+ /*
+  * Functions dealing with the various ways of partitioning the space
+--- a/include/mtd/mtd-abi.h
++++ b/include/mtd/mtd-abi.h
+@@ -110,6 +110,7 @@ struct otp_info {
+ #define MEMERASE64		_IOW('M', 20, struct erase_info_user64)
+ #define MEMWRITEOOB64		_IOWR('M', 21, struct mtd_oob_buf64)
+ #define MEMREADOOB64		_IOWR('M', 22, struct mtd_oob_buf64)
++#define MTDREFRESH		_IO('M', 50)
+ 
+ /*
+  * Obsolete legacy interface. Keep it in order not to break userspace
diff -Nru a/target/linux/generic/patches-2.6.31/066-block2mtd_probe.patch b/target/linux/generic/patches-2.6.31/066-block2mtd_probe.patch
--- a/target/linux/generic/patches-2.6.31/066-block2mtd_probe.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/066-block2mtd_probe.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,10 @@
+--- a/drivers/mtd/devices/block2mtd.c
++++ b/drivers/mtd/devices/block2mtd.c
+@@ -268,6 +268,7 @@ static int _open_bdev(struct block2mtd_d
+ 		/* We might not have rootfs mounted at this point. Try
+ 		   to resolve the device name by other means. */
+ 
++		wait_for_device_probe();
+ 		dev_t devt = name_to_dev_t(dev->devname);
+ 		if (devt) {
+ 			bdev = open_by_devnum(devt, FMODE_WRITE | FMODE_READ);
diff -Nru a/target/linux/generic/patches-2.6.31/070-redboot_space.patch b/target/linux/generic/patches-2.6.31/070-redboot_space.patch
--- a/target/linux/generic/patches-2.6.31/070-redboot_space.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/070-redboot_space.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,30 @@
+--- a/drivers/mtd/redboot.c
++++ b/drivers/mtd/redboot.c
+@@ -249,14 +249,21 @@ static int parse_redboot_partitions(stru
+ #endif
+ 		names += strlen(names)+1;
+ 
+-#ifdef CONFIG_MTD_REDBOOT_PARTS_UNALLOCATED
+ 		if(fl->next && fl->img->flash_base + fl->img->size + master->erasesize <= fl->next->img->flash_base) {
+-			i++;
+-			parts[i].offset = parts[i-1].size + parts[i-1].offset;
+-			parts[i].size = fl->next->img->flash_base - parts[i].offset;
+-			parts[i].name = nullname;
+-		}
++			if (!strcmp(parts[i].name, "rootfs")) {
++				parts[i].size = fl->next->img->flash_base;
++				parts[i].size &= ~(master->erasesize - 1);
++				parts[i].size -= parts[i].offset;
++#ifdef CONFIG_MTD_REDBOOT_PARTS_UNALLOCATED
++				nrparts--;
++			} else {
++				i++;
++				parts[i].offset = parts[i-1].size + parts[i-1].offset;
++				parts[i].size = fl->next->img->flash_base - parts[i].offset;
++				parts[i].name = nullname;
+ #endif
++			}
++		}
+ 		tmp_fl = fl;
+ 		fl = fl->next;
+ 		kfree(tmp_fl);
diff -Nru a/target/linux/generic/patches-2.6.31/071-redboot_boardconfig.patch b/target/linux/generic/patches-2.6.31/071-redboot_boardconfig.patch
--- a/target/linux/generic/patches-2.6.31/071-redboot_boardconfig.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/071-redboot_boardconfig.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,60 @@
+--- a/drivers/mtd/redboot.c
++++ b/drivers/mtd/redboot.c
+@@ -11,6 +11,8 @@
+ #include <linux/mtd/mtd.h>
+ #include <linux/mtd/partitions.h>
+ 
++#define BOARD_CONFIG_PART		"boardconfig"
++
+ struct fis_image_desc {
+     unsigned char name[16];      // Null terminated name
+     uint32_t	  flash_base;    // Address within FLASH of image
+@@ -41,6 +43,7 @@ static int parse_redboot_partitions(stru
+                              struct mtd_partition **pparts,
+                              unsigned long fis_origin)
+ {
++	unsigned long max_offset = 0;
+ 	int nrparts = 0;
+ 	struct fis_image_desc *buf;
+ 	struct mtd_partition *parts;
+@@ -209,14 +212,14 @@ static int parse_redboot_partitions(stru
+ 		}
+ 	}
+ #endif
+-	parts = kzalloc(sizeof(*parts)*nrparts + nulllen + namelen, GFP_KERNEL);
++	parts = kzalloc(sizeof(*parts) * (nrparts + 1) + nulllen + namelen + sizeof(BOARD_CONFIG_PART), GFP_KERNEL);
+ 
+ 	if (!parts) {
+ 		ret = -ENOMEM;
+ 		goto out;
+ 	}
+ 
+-	nullname = (char *)&parts[nrparts];
++	nullname = (char *)&parts[nrparts + 1];
+ #ifdef CONFIG_MTD_REDBOOT_PARTS_UNALLOCATED
+ 	if (nulllen > 0) {
+ 		strcpy(nullname, nullstring);
+@@ -235,6 +238,8 @@ static int parse_redboot_partitions(stru
+ 	}
+ #endif
+ 	for ( ; i<nrparts; i++) {
++		if(max_offset < buf[i].flash_base + buf[i].size)
++			max_offset = buf[i].flash_base + buf[i].size;
+ 		parts[i].size = fl->img->size;
+ 		parts[i].offset = fl->img->flash_base;
+ 		parts[i].name = names;
+@@ -268,6 +273,14 @@ static int parse_redboot_partitions(stru
+ 		fl = fl->next;
+ 		kfree(tmp_fl);
+ 	}
++	if(master->size - max_offset >= master->erasesize)
++	{
++		parts[nrparts].size = master->size - max_offset;
++		parts[nrparts].offset = max_offset;
++		parts[nrparts].name = names;
++		strcpy(names, BOARD_CONFIG_PART);
++		nrparts++;
++	}
+ 	ret = nrparts;
+ 	*pparts = parts;
+  out:
diff -Nru a/target/linux/generic/patches-2.6.31/080-mtd_plat_nand_chip_fixup.patch b/target/linux/generic/patches-2.6.31/080-mtd_plat_nand_chip_fixup.patch
--- a/target/linux/generic/patches-2.6.31/080-mtd_plat_nand_chip_fixup.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/080-mtd_plat_nand_chip_fixup.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,32 @@
+--- a/include/linux/mtd/nand.h
++++ b/include/linux/mtd/nand.h
+@@ -575,6 +575,7 @@ struct platform_nand_chip {
+ 	int			chip_delay;
+ 	unsigned int		options;
+ 	const char		**part_probe_types;
++	int			(*chip_fixup)(struct mtd_info *mtd);
+ 	void			(*set_parts)(uint64_t size,
+ 					struct platform_nand_chip *chip);
+ 	void			*priv;
+--- a/drivers/mtd/nand/plat_nand.c
++++ b/drivers/mtd/nand/plat_nand.c
+@@ -80,7 +80,18 @@ static int __devinit plat_nand_probe(str
+ 	}
+ 
+ 	/* Scan to find existance of the device */
+-	if (nand_scan(&data->mtd, 1)) {
++	if (nand_scan_ident(&data->mtd, 1)) {
++		res = -ENXIO;
++		goto out;
++	}
++
++	if (pdata->chip.chip_fixup) {
++		res = pdata->chip.chip_fixup(&data->mtd);
++		if (res)
++			goto out;
++	}
++
++	if (nand_scan_tail(&data->mtd)) {
+ 		res = -ENXIO;
+ 		goto out;
+ 	}
diff -Nru a/target/linux/generic/patches-2.6.31/081-mtd_myloader_partition_parser.patch b/target/linux/generic/patches-2.6.31/081-mtd_myloader_partition_parser.patch
--- a/target/linux/generic/patches-2.6.31/081-mtd_myloader_partition_parser.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/081-mtd_myloader_partition_parser.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,35 @@
+--- a/drivers/mtd/Kconfig
++++ b/drivers/mtd/Kconfig
+@@ -181,6 +181,22 @@ config MTD_AR7_PARTS
+ 	---help---
+ 	  TI AR7 partitioning support
+ 
++config MTD_MYLOADER_PARTS
++	tristate "MyLoader partition parsing"
++	depends on MTD_PARTITIONS && (ADM5120 || ATHEROS_AR231X || ATHEROS_AR71XX)
++	---help---
++	  MyLoader is a bootloader which allows the user to define partitions
++	  in flash devices, by putting a table in the second erase block
++	  on the device, similar to a partition table. This table gives the 
++	  offsets and lengths of the user defined partitions.
++
++	  If you need code which can detect and parse these tables, and
++	  register MTD 'partitions' corresponding to each image detected,
++	  enable this option.
++
++	  You will still need the parsing functions to be called by the driver
++	  for your particular device. It won't happen automatically.
++
+ comment "User Modules And Translation Layers"
+ 
+ config MTD_CHAR
+--- a/drivers/mtd/Makefile
++++ b/drivers/mtd/Makefile
+@@ -13,6 +13,7 @@ obj-$(CONFIG_MTD_CMDLINE_PARTS) += cmdli
+ obj-$(CONFIG_MTD_AFS_PARTS)	+= afs.o
+ obj-$(CONFIG_MTD_AR7_PARTS)	+= ar7part.o
+ obj-$(CONFIG_MTD_OF_PARTS)      += ofpart.o
++obj-$(CONFIG_MTD_MYLOADER_PARTS) += myloader.o
+ 
+ # 'Users' - code which presents functionality to userspace.
+ obj-$(CONFIG_MTD_CHAR)		+= mtdchar.o
diff -Nru a/target/linux/generic/patches-2.6.31/082-mtd_info_move_forward_decl.patch b/target/linux/generic/patches-2.6.31/082-mtd_info_move_forward_decl.patch
--- a/target/linux/generic/patches-2.6.31/082-mtd_info_move_forward_decl.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/082-mtd_info_move_forward_decl.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,18 @@
+--- a/include/linux/mtd/partitions.h
++++ b/include/linux/mtd/partitions.h
+@@ -33,6 +33,7 @@
+  * Note: writeable partitions require their size and offset be
+  * erasesize aligned (e.g. use MTDPART_OFS_NEXTBLK).
+  */
++struct mtd_info;
+ 
+ struct mtd_partition;
+ struct mtd_partition {
+@@ -49,7 +50,6 @@ struct mtd_partition {
+ #define MTDPART_SIZ_FULL	(0)
+ 
+ 
+-struct mtd_info;
+ 
+ int add_mtd_partitions(struct mtd_info *, const struct mtd_partition *, int);
+ int del_mtd_partitions(struct mtd_info *);
diff -Nru a/target/linux/generic/patches-2.6.31/090-mtd_fix_nand_correct_data_return_code.patch b/target/linux/generic/patches-2.6.31/090-mtd_fix_nand_correct_data_return_code.patch
--- a/target/linux/generic/patches-2.6.31/090-mtd_fix_nand_correct_data_return_code.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/090-mtd_fix_nand_correct_data_return_code.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,12 @@
+--- a/drivers/mtd/nand/nand_ecc.c
++++ b/drivers/mtd/nand/nand_ecc.c
+@@ -492,8 +492,7 @@ int nand_correct_data(struct mtd_info *m
+ 	if ((bitsperbyte[b0] + bitsperbyte[b1] + bitsperbyte[b2]) == 1)
+ 		return 1;	/* error in ecc data; no action needed */
+ 
+-	printk(KERN_ERR "uncorrectable error : ");
+-	return -1;
++	return -EBADMSG;
+ }
+ EXPORT_SYMBOL(nand_correct_data);
+ 
diff -Nru a/target/linux/generic/patches-2.6.31/100-netfilter_layer7_2.21.patch b/target/linux/generic/patches-2.6.31/100-netfilter_layer7_2.21.patch
--- a/target/linux/generic/patches-2.6.31/100-netfilter_layer7_2.21.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/100-netfilter_layer7_2.21.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,2132 @@
+--- /dev/null
++++ b/include/linux/netfilter/xt_layer7.h
+@@ -0,0 +1,13 @@
++#ifndef _XT_LAYER7_H
++#define _XT_LAYER7_H
++
++#define MAX_PATTERN_LEN 8192
++#define MAX_PROTOCOL_LEN 256
++
++struct xt_layer7_info {
++    char protocol[MAX_PROTOCOL_LEN];
++    char pattern[MAX_PATTERN_LEN];
++    u_int8_t invert;
++};
++
++#endif /* _XT_LAYER7_H */
+--- a/include/net/netfilter/nf_conntrack.h
++++ b/include/net/netfilter/nf_conntrack.h
+@@ -116,6 +116,22 @@ struct nf_conn {
+ 	u_int32_t secmark;
+ #endif
+ 
++#if defined(CONFIG_NETFILTER_XT_MATCH_LAYER7) || \
++    defined(CONFIG_NETFILTER_XT_MATCH_LAYER7_MODULE)
++	struct {
++		/*
++		 * e.g. "http". NULL before decision. "unknown" after decision
++		 * if no match.
++		 */
++		char *app_proto;
++		/*
++		 * application layer data so far. NULL after match decision.
++		 */
++		char *app_data;
++		unsigned int app_data_len;
++	} layer7;
++#endif
++
+ 	/* Storage reserved for other modules: */
+ 	union nf_conntrack_proto proto;
+ 
+--- a/net/netfilter/Kconfig
++++ b/net/netfilter/Kconfig
+@@ -858,6 +858,27 @@ config NETFILTER_XT_MATCH_STATE
+ 
+ 	  To compile it as a module, choose M here.  If unsure, say N.
+ 
++config NETFILTER_XT_MATCH_LAYER7
++	tristate '"layer7" match support'
++	depends on NETFILTER_XTABLES
++	depends on EXPERIMENTAL && (IP_NF_CONNTRACK || NF_CONNTRACK)
++       depends on NF_CT_ACCT
++	help
++	  Say Y if you want to be able to classify connections (and their
++	  packets) based on regular expression matching of their application
++	  layer data.   This is one way to classify applications such as
++	  peer-to-peer filesharing systems that do not always use the same
++	  port.
++
++	  To compile it as a module, choose M here.  If unsure, say N.
++
++config NETFILTER_XT_MATCH_LAYER7_DEBUG
++        bool 'Layer 7 debugging output'
++        depends on NETFILTER_XT_MATCH_LAYER7
++        help
++          Say Y to get lots of debugging output.
++
++
+ config NETFILTER_XT_MATCH_STATISTIC
+ 	tristate '"statistic" match support'
+ 	depends on NETFILTER_ADVANCED
+--- a/net/netfilter/Makefile
++++ b/net/netfilter/Makefile
+@@ -89,6 +89,7 @@ obj-$(CONFIG_NETFILTER_XT_MATCH_RECENT)
+ obj-$(CONFIG_NETFILTER_XT_MATCH_SCTP) += xt_sctp.o
+ obj-$(CONFIG_NETFILTER_XT_MATCH_SOCKET) += xt_socket.o
+ obj-$(CONFIG_NETFILTER_XT_MATCH_STATE) += xt_state.o
++obj-$(CONFIG_NETFILTER_XT_MATCH_LAYER7) += xt_layer7.o
+ obj-$(CONFIG_NETFILTER_XT_MATCH_STATISTIC) += xt_statistic.o
+ obj-$(CONFIG_NETFILTER_XT_MATCH_STRING) += xt_string.o
+ obj-$(CONFIG_NETFILTER_XT_MATCH_TCPMSS) += xt_tcpmss.o
+--- a/net/netfilter/nf_conntrack_core.c
++++ b/net/netfilter/nf_conntrack_core.c
+@@ -200,6 +200,14 @@ destroy_conntrack(struct nf_conntrack *n
+ 	 * too. */
+ 	nf_ct_remove_expectations(ct);
+ 
++	#if defined(CONFIG_NETFILTER_XT_MATCH_LAYER7) || defined(CONFIG_NETFILTER_XT_MATCH_LAYER7_MODULE)
++	if(ct->layer7.app_proto)
++		kfree(ct->layer7.app_proto);
++	if(ct->layer7.app_data)
++	kfree(ct->layer7.app_data);
++	#endif
++
++
+ 	/* We overload first tuple to link into unconfirmed list. */
+ 	if (!nf_ct_is_confirmed(ct)) {
+ 		BUG_ON(hlist_nulls_unhashed(&ct->tuplehash[IP_CT_DIR_ORIGINAL].hnnode));
+--- a/net/netfilter/nf_conntrack_standalone.c
++++ b/net/netfilter/nf_conntrack_standalone.c
+@@ -171,6 +171,12 @@ static int ct_seq_show(struct seq_file *
+ 		goto release;
+ #endif
+ 
++#if defined(CONFIG_NETFILTER_XT_MATCH_LAYER7) || defined(CONFIG_NETFILTER_XT_MATCH_LAYER7_MODULE)
++	if(ct->layer7.app_proto &&
++           seq_printf(s, "l7proto=%s ", ct->layer7.app_proto))
++		return -ENOSPC;
++#endif
++
+ 	if (seq_printf(s, "use=%u\n", atomic_read(&ct->ct_general.use)))
+ 		goto release;
+ 
+--- /dev/null
++++ b/net/netfilter/regexp/regexp.c
+@@ -0,0 +1,1197 @@
++/*
++ * regcomp and regexec -- regsub and regerror are elsewhere
++ * @(#)regexp.c	1.3 of 18 April 87
++ *
++ *	Copyright (c) 1986 by University of Toronto.
++ *	Written by Henry Spencer.  Not derived from licensed software.
++ *
++ *	Permission is granted to anyone to use this software for any
++ *	purpose on any computer system, and to redistribute it freely,
++ *	subject to the following restrictions:
++ *
++ *	1. The author is not responsible for the consequences of use of
++ *		this software, no matter how awful, even if they arise
++ *		from defects in it.
++ *
++ *	2. The origin of this software must not be misrepresented, either
++ *		by explicit claim or by omission.
++ *
++ *	3. Altered versions must be plainly marked as such, and must not
++ *		be misrepresented as being the original software.
++ *
++ * Beware that some of this code is subtly aware of the way operator
++ * precedence is structured in regular expressions.  Serious changes in
++ * regular-expression syntax might require a total rethink.
++ *
++ * This code was modified by Ethan Sommer to work within the kernel
++ * (it now uses kmalloc etc..)
++ *
++ * Modified slightly by Matthew Strait to use more modern C.
++ */
++
++#include "regexp.h"
++#include "regmagic.h"
++
++/* added by ethan and matt.  Lets it work in both kernel and user space.
++(So iptables can use it, for instance.)  Yea, it goes both ways... */
++#if __KERNEL__
++  #define malloc(foo) kmalloc(foo,GFP_ATOMIC)
++#else
++  #define printk(format,args...) printf(format,##args)
++#endif
++
++void regerror(char * s)
++{
++        printk("<3>Regexp: %s\n", s);
++        /* NOTREACHED */
++}
++
++/*
++ * The "internal use only" fields in regexp.h are present to pass info from
++ * compile to execute that permits the execute phase to run lots faster on
++ * simple cases.  They are:
++ *
++ * regstart	char that must begin a match; '\0' if none obvious
++ * reganch	is the match anchored (at beginning-of-line only)?
++ * regmust	string (pointer into program) that match must include, or NULL
++ * regmlen	length of regmust string
++ *
++ * Regstart and reganch permit very fast decisions on suitable starting points
++ * for a match, cutting down the work a lot.  Regmust permits fast rejection
++ * of lines that cannot possibly match.  The regmust tests are costly enough
++ * that regcomp() supplies a regmust only if the r.e. contains something
++ * potentially expensive (at present, the only such thing detected is * or +
++ * at the start of the r.e., which can involve a lot of backup).  Regmlen is
++ * supplied because the test in regexec() needs it and regcomp() is computing
++ * it anyway.
++ */
++
++/*
++ * Structure for regexp "program".  This is essentially a linear encoding
++ * of a nondeterministic finite-state machine (aka syntax charts or
++ * "railroad normal form" in parsing technology).  Each node is an opcode
++ * plus a "next" pointer, possibly plus an operand.  "Next" pointers of
++ * all nodes except BRANCH implement concatenation; a "next" pointer with
++ * a BRANCH on both ends of it is connecting two alternatives.  (Here we
++ * have one of the subtle syntax dependencies:  an individual BRANCH (as
++ * opposed to a collection of them) is never concatenated with anything
++ * because of operator precedence.)  The operand of some types of node is
++ * a literal string; for others, it is a node leading into a sub-FSM.  In
++ * particular, the operand of a BRANCH node is the first node of the branch.
++ * (NB this is *not* a tree structure:  the tail of the branch connects
++ * to the thing following the set of BRANCHes.)  The opcodes are:
++ */
++
++/* definition	number	opnd?	meaning */
++#define	END	0	/* no	End of program. */
++#define	BOL	1	/* no	Match "" at beginning of line. */
++#define	EOL	2	/* no	Match "" at end of line. */
++#define	ANY	3	/* no	Match any one character. */
++#define	ANYOF	4	/* str	Match any character in this string. */
++#define	ANYBUT	5	/* str	Match any character not in this string. */
++#define	BRANCH	6	/* node	Match this alternative, or the next... */
++#define	BACK	7	/* no	Match "", "next" ptr points backward. */
++#define	EXACTLY	8	/* str	Match this string. */
++#define	NOTHING	9	/* no	Match empty string. */
++#define	STAR	10	/* node	Match this (simple) thing 0 or more times. */
++#define	PLUS	11	/* node	Match this (simple) thing 1 or more times. */
++#define	OPEN	20	/* no	Mark this point in input as start of #n. */
++			/*	OPEN+1 is number 1, etc. */
++#define	CLOSE	30	/* no	Analogous to OPEN. */
++
++/*
++ * Opcode notes:
++ *
++ * BRANCH	The set of branches constituting a single choice are hooked
++ *		together with their "next" pointers, since precedence prevents
++ *		anything being concatenated to any individual branch.  The
++ *		"next" pointer of the last BRANCH in a choice points to the
++ *		thing following the whole choice.  This is also where the
++ *		final "next" pointer of each individual branch points; each
++ *		branch starts with the operand node of a BRANCH node.
++ *
++ * BACK		Normal "next" pointers all implicitly point forward; BACK
++ *		exists to make loop structures possible.
++ *
++ * STAR,PLUS	'?', and complex '*' and '+', are implemented as circular
++ *		BRANCH structures using BACK.  Simple cases (one character
++ *		per match) are implemented with STAR and PLUS for speed
++ *		and to minimize recursive plunges.
++ *
++ * OPEN,CLOSE	...are numbered at compile time.
++ */
++
++/*
++ * A node is one char of opcode followed by two chars of "next" pointer.
++ * "Next" pointers are stored as two 8-bit pieces, high order first.  The
++ * value is a positive offset from the opcode of the node containing it.
++ * An operand, if any, simply follows the node.  (Note that much of the
++ * code generation knows about this implicit relationship.)
++ *
++ * Using two bytes for the "next" pointer is vast overkill for most things,
++ * but allows patterns to get big without disasters.
++ */
++#define	OP(p)	(*(p))
++#define	NEXT(p)	(((*((p)+1)&0377)<<8) + (*((p)+2)&0377))
++#define	OPERAND(p)	((p) + 3)
++
++/*
++ * See regmagic.h for one further detail of program structure.
++ */
++
++
++/*
++ * Utility definitions.
++ */
++#ifndef CHARBITS
++#define	UCHARAT(p)	((int)*(unsigned char *)(p))
++#else
++#define	UCHARAT(p)	((int)*(p)&CHARBITS)
++#endif
++
++#define	FAIL(m)	{ regerror(m); return(NULL); }
++#define	ISMULT(c)	((c) == '*' || (c) == '+' || (c) == '?')
++#define	META	"^$.[()|?+*\\"
++
++/*
++ * Flags to be passed up and down.
++ */
++#define	HASWIDTH	01	/* Known never to match null string. */
++#define	SIMPLE		02	/* Simple enough to be STAR/PLUS operand. */
++#define	SPSTART		04	/* Starts with * or +. */
++#define	WORST		0	/* Worst case. */
++
++/*
++ * Global work variables for regcomp().
++ */
++struct match_globals {
++char *reginput;		/* String-input pointer. */
++char *regbol;		/* Beginning of input, for ^ check. */
++char **regstartp;	/* Pointer to startp array. */
++char **regendp;		/* Ditto for endp. */
++char *regparse;		/* Input-scan pointer. */
++int regnpar;		/* () count. */
++char regdummy;
++char *regcode;		/* Code-emit pointer; &regdummy = don't. */
++long regsize;		/* Code size. */
++};
++
++/*
++ * Forward declarations for regcomp()'s friends.
++ */
++#ifndef STATIC
++#define	STATIC	static
++#endif
++STATIC char *reg(struct match_globals *g, int paren,int *flagp);
++STATIC char *regbranch(struct match_globals *g, int *flagp);
++STATIC char *regpiece(struct match_globals *g, int *flagp);
++STATIC char *regatom(struct match_globals *g, int *flagp);
++STATIC char *regnode(struct match_globals *g, char op);
++STATIC char *regnext(struct match_globals *g, char *p);
++STATIC void regc(struct match_globals *g, char b);
++STATIC void reginsert(struct match_globals *g, char op, char *opnd);
++STATIC void regtail(struct match_globals *g, char *p, char *val);
++STATIC void regoptail(struct match_globals *g, char *p, char *val);
++
++
++__kernel_size_t my_strcspn(const char *s1,const char *s2)
++{
++        char *scan1;
++        char *scan2;
++        int count;
++
++        count = 0;
++        for (scan1 = (char *)s1; *scan1 != '\0'; scan1++) {
++                for (scan2 = (char *)s2; *scan2 != '\0';)       /* ++ moved down. */
++                        if (*scan1 == *scan2++)
++                                return(count);
++                count++;
++        }
++        return(count);
++}
++
++/*
++ - regcomp - compile a regular expression into internal code
++ *
++ * We can't allocate space until we know how big the compiled form will be,
++ * but we can't compile it (and thus know how big it is) until we've got a
++ * place to put the code.  So we cheat:  we compile it twice, once with code
++ * generation turned off and size counting turned on, and once "for real".
++ * This also means that we don't allocate space until we are sure that the
++ * thing really will compile successfully, and we never have to move the
++ * code and thus invalidate pointers into it.  (Note that it has to be in
++ * one piece because free() must be able to free it all.)
++ *
++ * Beware that the optimization-preparation code in here knows about some
++ * of the structure of the compiled regexp.
++ */
++regexp *
++regcomp(char *exp,int *patternsize)
++{
++	register regexp *r;
++	register char *scan;
++	register char *longest;
++	register int len;
++	int flags;
++	struct match_globals g;
++	
++	/* commented out by ethan
++	   extern char *malloc();
++	*/
++
++	if (exp == NULL)
++		FAIL("NULL argument");
++
++	/* First pass: determine size, legality. */
++	g.regparse = exp;
++	g.regnpar = 1;
++	g.regsize = 0L;
++	g.regcode = &g.regdummy;
++	regc(&g, MAGIC);
++	if (reg(&g, 0, &flags) == NULL)
++		return(NULL);
++
++	/* Small enough for pointer-storage convention? */
++	if (g.regsize >= 32767L)		/* Probably could be 65535L. */
++		FAIL("regexp too big");
++
++	/* Allocate space. */
++	*patternsize=sizeof(regexp) + (unsigned)g.regsize;
++	r = (regexp *)malloc(sizeof(regexp) + (unsigned)g.regsize);
++	if (r == NULL)
++		FAIL("out of space");
++
++	/* Second pass: emit code. */
++	g.regparse = exp;
++	g.regnpar = 1;
++	g.regcode = r->program;
++	regc(&g, MAGIC);
++	if (reg(&g, 0, &flags) == NULL)
++		return(NULL);
++
++	/* Dig out information for optimizations. */
++	r->regstart = '\0';	/* Worst-case defaults. */
++	r->reganch = 0;
++	r->regmust = NULL;
++	r->regmlen = 0;
++	scan = r->program+1;			/* First BRANCH. */
++	if (OP(regnext(&g, scan)) == END) {		/* Only one top-level choice. */
++		scan = OPERAND(scan);
++
++		/* Starting-point info. */
++		if (OP(scan) == EXACTLY)
++			r->regstart = *OPERAND(scan);
++		else if (OP(scan) == BOL)
++			r->reganch++;
++
++		/*
++		 * If there's something expensive in the r.e., find the
++		 * longest literal string that must appear and make it the
++		 * regmust.  Resolve ties in favor of later strings, since
++		 * the regstart check works with the beginning of the r.e.
++		 * and avoiding duplication strengthens checking.  Not a
++		 * strong reason, but sufficient in the absence of others.
++		 */
++		if (flags&SPSTART) {
++			longest = NULL;
++			len = 0;
++			for (; scan != NULL; scan = regnext(&g, scan))
++				if (OP(scan) == EXACTLY && strlen(OPERAND(scan)) >= len) {
++					longest = OPERAND(scan);
++					len = strlen(OPERAND(scan));
++				}
++			r->regmust = longest;
++			r->regmlen = len;
++		}
++	}
++
++	return(r);
++}
++
++/*
++ - reg - regular expression, i.e. main body or parenthesized thing
++ *
++ * Caller must absorb opening parenthesis.
++ *
++ * Combining parenthesis handling with the base level of regular expression
++ * is a trifle forced, but the need to tie the tails of the branches to what
++ * follows makes it hard to avoid.
++ */
++static char *
++reg(struct match_globals *g, int paren, int *flagp /* Parenthesized? */ )
++{
++	register char *ret;
++	register char *br;
++	register char *ender;
++	register int parno = 0; /* 0 makes gcc happy */
++	int flags;
++
++	*flagp = HASWIDTH;	/* Tentatively. */
++
++	/* Make an OPEN node, if parenthesized. */
++	if (paren) {
++		if (g->regnpar >= NSUBEXP)
++			FAIL("too many ()");
++		parno = g->regnpar;
++		g->regnpar++;
++		ret = regnode(g, OPEN+parno);
++	} else
++		ret = NULL;
++
++	/* Pick up the branches, linking them together. */
++	br = regbranch(g, &flags);
++	if (br == NULL)
++		return(NULL);
++	if (ret != NULL)
++		regtail(g, ret, br);	/* OPEN -> first. */
++	else
++		ret = br;
++	if (!(flags&HASWIDTH))
++		*flagp &= ~HASWIDTH;
++	*flagp |= flags&SPSTART;
++	while (*g->regparse == '|') {
++		g->regparse++;
++		br = regbranch(g, &flags);
++		if (br == NULL)
++			return(NULL);
++		regtail(g, ret, br);	/* BRANCH -> BRANCH. */
++		if (!(flags&HASWIDTH))
++			*flagp &= ~HASWIDTH;
++		*flagp |= flags&SPSTART;
++	}
++
++	/* Make a closing node, and hook it on the end. */
++	ender = regnode(g, (paren) ? CLOSE+parno : END);	
++	regtail(g, ret, ender);
++
++	/* Hook the tails of the branches to the closing node. */
++	for (br = ret; br != NULL; br = regnext(g, br))
++		regoptail(g, br, ender);
++
++	/* Check for proper termination. */
++	if (paren && *g->regparse++ != ')') {
++		FAIL("unmatched ()");
++	} else if (!paren && *g->regparse != '\0') {
++		if (*g->regparse == ')') {
++			FAIL("unmatched ()");
++		} else
++			FAIL("junk on end");	/* "Can't happen". */
++		/* NOTREACHED */
++	}
++
++	return(ret);
++}
++
++/*
++ - regbranch - one alternative of an | operator
++ *
++ * Implements the concatenation operator.
++ */
++static char *
++regbranch(struct match_globals *g, int *flagp)
++{
++	register char *ret;
++	register char *chain;
++	register char *latest;
++	int flags;
++
++	*flagp = WORST;		/* Tentatively. */
++
++	ret = regnode(g, BRANCH);
++	chain = NULL;
++	while (*g->regparse != '\0' && *g->regparse != '|' && *g->regparse != ')') {
++		latest = regpiece(g, &flags);
++		if (latest == NULL)
++			return(NULL);
++		*flagp |= flags&HASWIDTH;
++		if (chain == NULL)	/* First piece. */
++			*flagp |= flags&SPSTART;
++		else
++			regtail(g, chain, latest);
++		chain = latest;
++	}
++	if (chain == NULL)	/* Loop ran zero times. */
++		(void) regnode(g, NOTHING);
++
++	return(ret);
++}
++
++/*
++ - regpiece - something followed by possible [*+?]
++ *
++ * Note that the branching code sequences used for ? and the general cases
++ * of * and + are somewhat optimized:  they use the same NOTHING node as
++ * both the endmarker for their branch list and the body of the last branch.
++ * It might seem that this node could be dispensed with entirely, but the
++ * endmarker role is not redundant.
++ */
++static char *
++regpiece(struct match_globals *g, int *flagp)
++{
++	register char *ret;
++	register char op;
++	register char *next;
++	int flags;
++
++	ret = regatom(g, &flags);
++	if (ret == NULL)
++		return(NULL);
++
++	op = *g->regparse;
++	if (!ISMULT(op)) {
++		*flagp = flags;
++		return(ret);
++	}
++
++	if (!(flags&HASWIDTH) && op != '?')
++		FAIL("*+ operand could be empty");
++	*flagp = (op != '+') ? (WORST|SPSTART) : (WORST|HASWIDTH);
++
++	if (op == '*' && (flags&SIMPLE))
++		reginsert(g, STAR, ret);
++	else if (op == '*') {
++		/* Emit x* as (x&|), where & means "self". */
++		reginsert(g, BRANCH, ret);			/* Either x */
++		regoptail(g, ret, regnode(g, BACK));		/* and loop */
++		regoptail(g, ret, ret);			/* back */
++		regtail(g, ret, regnode(g, BRANCH));		/* or */
++		regtail(g, ret, regnode(g, NOTHING));		/* null. */
++	} else if (op == '+' && (flags&SIMPLE))
++		reginsert(g, PLUS, ret);
++	else if (op == '+') {
++		/* Emit x+ as x(&|), where & means "self". */
++		next = regnode(g, BRANCH);			/* Either */
++		regtail(g, ret, next);
++		regtail(g, regnode(g, BACK), ret);		/* loop back */
++		regtail(g, next, regnode(g, BRANCH));		/* or */
++		regtail(g, ret, regnode(g, NOTHING));		/* null. */
++	} else if (op == '?') {
++		/* Emit x? as (x|) */
++		reginsert(g, BRANCH, ret);			/* Either x */
++		regtail(g, ret, regnode(g, BRANCH));		/* or */
++		next = regnode(g, NOTHING);		/* null. */
++		regtail(g, ret, next);
++		regoptail(g, ret, next);
++	}
++	g->regparse++;
++	if (ISMULT(*g->regparse))
++		FAIL("nested *?+");
++
++	return(ret);
++}
++
++/*
++ - regatom - the lowest level
++ *
++ * Optimization:  gobbles an entire sequence of ordinary characters so that
++ * it can turn them into a single node, which is smaller to store and
++ * faster to run.  Backslashed characters are exceptions, each becoming a
++ * separate node; the code is simpler that way and it's not worth fixing.
++ */
++static char *
++regatom(struct match_globals *g, int *flagp)
++{
++	register char *ret;
++	int flags;
++
++	*flagp = WORST;		/* Tentatively. */
++
++	switch (*g->regparse++) {
++	case '^':
++		ret = regnode(g, BOL);
++		break;
++	case '$':
++		ret = regnode(g, EOL);
++		break;
++	case '.':
++		ret = regnode(g, ANY);
++		*flagp |= HASWIDTH|SIMPLE;
++		break;
++	case '[': {
++			register int class;
++			register int classend;
++
++			if (*g->regparse == '^') {	/* Complement of range. */
++				ret = regnode(g, ANYBUT);
++				g->regparse++;
++			} else
++				ret = regnode(g, ANYOF);
++			if (*g->regparse == ']' || *g->regparse == '-')
++				regc(g, *g->regparse++);
++			while (*g->regparse != '\0' && *g->regparse != ']') {
++				if (*g->regparse == '-') {
++					g->regparse++;
++					if (*g->regparse == ']' || *g->regparse == '\0')
++						regc(g, '-');
++					else {
++						class = UCHARAT(g->regparse-2)+1;
++						classend = UCHARAT(g->regparse);
++						if (class > classend+1)
++							FAIL("invalid [] range");
++						for (; class <= classend; class++)
++							regc(g, class);
++						g->regparse++;
++					}
++				} else
++					regc(g, *g->regparse++);
++			}
++			regc(g, '\0');
++			if (*g->regparse != ']')
++				FAIL("unmatched []");
++			g->regparse++;
++			*flagp |= HASWIDTH|SIMPLE;
++		}
++		break;
++	case '(':
++		ret = reg(g, 1, &flags);
++		if (ret == NULL)
++			return(NULL);
++		*flagp |= flags&(HASWIDTH|SPSTART);
++		break;
++	case '\0':
++	case '|':
++	case ')':
++		FAIL("internal urp");	/* Supposed to be caught earlier. */
++		break;
++	case '?':
++	case '+':
++	case '*':
++		FAIL("?+* follows nothing");
++		break;
++	case '\\':
++		if (*g->regparse == '\0')
++			FAIL("trailing \\");
++		ret = regnode(g, EXACTLY);
++		regc(g, *g->regparse++);
++		regc(g, '\0');
++		*flagp |= HASWIDTH|SIMPLE;
++		break;
++	default: {
++			register int len;
++			register char ender;
++
++			g->regparse--;
++			len = my_strcspn((const char *)g->regparse, (const char *)META);
++			if (len <= 0)
++				FAIL("internal disaster");
++			ender = *(g->regparse+len);
++			if (len > 1 && ISMULT(ender))
++				len--;		/* Back off clear of ?+* operand. */
++			*flagp |= HASWIDTH;
++			if (len == 1)
++				*flagp |= SIMPLE;
++			ret = regnode(g, EXACTLY);
++			while (len > 0) {
++				regc(g, *g->regparse++);
++				len--;
++			}
++			regc(g, '\0');
++		}
++		break;
++	}
++
++	return(ret);
++}
++
++/*
++ - regnode - emit a node
++ */
++static char *			/* Location. */
++regnode(struct match_globals *g, char op)
++{
++	register char *ret;
++	register char *ptr;
++
++	ret = g->regcode;
++	if (ret == &g->regdummy) {
++		g->regsize += 3;
++		return(ret);
++	}
++
++	ptr = ret;
++	*ptr++ = op;
++	*ptr++ = '\0';		/* Null "next" pointer. */
++	*ptr++ = '\0';
++	g->regcode = ptr;
++
++	return(ret);
++}
++
++/*
++ - regc - emit (if appropriate) a byte of code
++ */
++static void
++regc(struct match_globals *g, char b)
++{
++	if (g->regcode != &g->regdummy)
++		*g->regcode++ = b;
++	else
++		g->regsize++;
++}
++
++/*
++ - reginsert - insert an operator in front of already-emitted operand
++ *
++ * Means relocating the operand.
++ */
++static void
++reginsert(struct match_globals *g, char op, char* opnd)
++{
++	register char *src;
++	register char *dst;
++	register char *place;
++
++	if (g->regcode == &g->regdummy) {
++		g->regsize += 3;
++		return;
++	}
++
++	src = g->regcode;
++	g->regcode += 3;
++	dst = g->regcode;
++	while (src > opnd)
++		*--dst = *--src;
++
++	place = opnd;		/* Op node, where operand used to be. */
++	*place++ = op;
++	*place++ = '\0';
++	*place++ = '\0';
++}
++
++/*
++ - regtail - set the next-pointer at the end of a node chain
++ */
++static void
++regtail(struct match_globals *g, char *p, char *val)
++{
++	register char *scan;
++	register char *temp;
++	register int offset;
++
++	if (p == &g->regdummy)
++		return;
++
++	/* Find last node. */
++	scan = p;
++	for (;;) {
++		temp = regnext(g, scan);
++		if (temp == NULL)
++			break;
++		scan = temp;
++	}
++
++	if (OP(scan) == BACK)
++		offset = scan - val;
++	else
++		offset = val - scan;
++	*(scan+1) = (offset>>8)&0377;
++	*(scan+2) = offset&0377;
++}
++
++/*
++ - regoptail - regtail on operand of first argument; nop if operandless
++ */
++static void
++regoptail(struct match_globals *g, char *p, char *val)
++{
++	/* "Operandless" and "op != BRANCH" are synonymous in practice. */
++	if (p == NULL || p == &g->regdummy || OP(p) != BRANCH)
++		return;
++	regtail(g, OPERAND(p), val);
++}
++
++/*
++ * regexec and friends
++ */
++
++
++/*
++ * Forwards.
++ */
++STATIC int regtry(struct match_globals *g, regexp *prog, char *string);
++STATIC int regmatch(struct match_globals *g, char *prog);
++STATIC int regrepeat(struct match_globals *g, char *p);
++
++#ifdef DEBUG
++int regnarrate = 0;
++void regdump();
++STATIC char *regprop(char *op);
++#endif
++
++/*
++ - regexec - match a regexp against a string
++ */
++int
++regexec(regexp *prog, char *string)
++{
++	register char *s;
++	struct match_globals g;
++
++	/* Be paranoid... */
++	if (prog == NULL || string == NULL) {
++		printk("<3>Regexp: NULL parameter\n");
++		return(0);
++	}
++
++	/* Check validity of program. */
++	if (UCHARAT(prog->program) != MAGIC) {
++		printk("<3>Regexp: corrupted program\n");
++		return(0);
++	}
++
++	/* If there is a "must appear" string, look for it. */
++	if (prog->regmust != NULL) {
++		s = string;
++		while ((s = strchr(s, prog->regmust[0])) != NULL) {
++			if (strncmp(s, prog->regmust, prog->regmlen) == 0)
++				break;	/* Found it. */
++			s++;
++		}
++		if (s == NULL)	/* Not present. */
++			return(0);
++	}
++
++	/* Mark beginning of line for ^ . */
++	g.regbol = string;
++
++	/* Simplest case:  anchored match need be tried only once. */
++	if (prog->reganch)
++		return(regtry(&g, prog, string));
++
++	/* Messy cases:  unanchored match. */
++	s = string;
++	if (prog->regstart != '\0')
++		/* We know what char it must start with. */
++		while ((s = strchr(s, prog->regstart)) != NULL) {
++			if (regtry(&g, prog, s))
++				return(1);
++			s++;
++		}
++	else
++		/* We don't -- general case. */
++		do {
++			if (regtry(&g, prog, s))
++				return(1);
++		} while (*s++ != '\0');
++
++	/* Failure. */
++	return(0);
++}
++
++/*
++ - regtry - try match at specific point
++ */
++static int			/* 0 failure, 1 success */
++regtry(struct match_globals *g, regexp *prog, char *string)
++{
++	register int i;
++	register char **sp;
++	register char **ep;
++
++	g->reginput = string;
++	g->regstartp = prog->startp;
++	g->regendp = prog->endp;
++
++	sp = prog->startp;
++	ep = prog->endp;
++	for (i = NSUBEXP; i > 0; i--) {
++		*sp++ = NULL;
++		*ep++ = NULL;
++	}
++	if (regmatch(g, prog->program + 1)) {
++		prog->startp[0] = string;
++		prog->endp[0] = g->reginput;
++		return(1);
++	} else
++		return(0);
++}
++
++/*
++ - regmatch - main matching routine
++ *
++ * Conceptually the strategy is simple:  check to see whether the current
++ * node matches, call self recursively to see whether the rest matches,
++ * and then act accordingly.  In practice we make some effort to avoid
++ * recursion, in particular by going through "ordinary" nodes (that don't
++ * need to know whether the rest of the match failed) by a loop instead of
++ * by recursion.
++ */
++static int			/* 0 failure, 1 success */
++regmatch(struct match_globals *g, char *prog)
++{
++	register char *scan = prog; /* Current node. */
++	char *next;		    /* Next node. */
++
++#ifdef DEBUG
++	if (scan != NULL && regnarrate)
++		fprintf(stderr, "%s(\n", regprop(scan));
++#endif
++	while (scan != NULL) {
++#ifdef DEBUG
++		if (regnarrate)
++			fprintf(stderr, "%s...\n", regprop(scan));
++#endif
++		next = regnext(g, scan);
++
++		switch (OP(scan)) {
++		case BOL:
++			if (g->reginput != g->regbol)
++				return(0);
++			break;
++		case EOL:
++			if (*g->reginput != '\0')
++				return(0);
++			break;
++		case ANY:
++			if (*g->reginput == '\0')
++				return(0);
++			g->reginput++;
++			break;
++		case EXACTLY: {
++				register int len;
++				register char *opnd;
++
++				opnd = OPERAND(scan);
++				/* Inline the first character, for speed. */
++				if (*opnd != *g->reginput)
++					return(0);
++				len = strlen(opnd);
++				if (len > 1 && strncmp(opnd, g->reginput, len) != 0)
++					return(0);
++				g->reginput += len;
++			}
++			break;
++		case ANYOF:
++			if (*g->reginput == '\0' || strchr(OPERAND(scan), *g->reginput) == NULL)
++				return(0);
++			g->reginput++;
++			break;
++		case ANYBUT:
++			if (*g->reginput == '\0' || strchr(OPERAND(scan), *g->reginput) != NULL)
++				return(0);
++			g->reginput++;
++			break;
++		case NOTHING:
++		case BACK:
++			break;
++		case OPEN+1:
++		case OPEN+2:
++		case OPEN+3:
++		case OPEN+4:
++		case OPEN+5:
++		case OPEN+6:
++		case OPEN+7:
++		case OPEN+8:
++		case OPEN+9: {
++				register int no;
++				register char *save;
++
++				no = OP(scan) - OPEN;
++				save = g->reginput;
++
++				if (regmatch(g, next)) {
++					/*
++					 * Don't set startp if some later
++					 * invocation of the same parentheses
++					 * already has.
++					 */
++					if (g->regstartp[no] == NULL)
++						g->regstartp[no] = save;
++					return(1);
++				} else
++					return(0);
++			}
++			break;
++		case CLOSE+1:
++		case CLOSE+2:
++		case CLOSE+3:
++		case CLOSE+4:
++		case CLOSE+5:
++		case CLOSE+6:
++		case CLOSE+7:
++		case CLOSE+8:
++		case CLOSE+9:
++			{
++				register int no;
++				register char *save;
++
++				no = OP(scan) - CLOSE;
++				save = g->reginput;
++
++				if (regmatch(g, next)) {
++					/*
++					 * Don't set endp if some later
++					 * invocation of the same parentheses
++					 * already has.
++					 */
++					if (g->regendp[no] == NULL)
++						g->regendp[no] = save;
++					return(1);
++				} else
++					return(0);
++			}
++			break;
++		case BRANCH: {
++				register char *save;
++
++				if (OP(next) != BRANCH)		/* No choice. */
++					next = OPERAND(scan);	/* Avoid recursion. */
++				else {
++					do {
++						save = g->reginput;
++						if (regmatch(g, OPERAND(scan)))
++							return(1);
++						g->reginput = save;
++						scan = regnext(g, scan);
++					} while (scan != NULL && OP(scan) == BRANCH);
++					return(0);
++					/* NOTREACHED */
++				}
++			}
++			break;
++		case STAR:
++		case PLUS: {
++				register char nextch;
++				register int no;
++				register char *save;
++				register int min;
++
++				/*
++				 * Lookahead to avoid useless match attempts
++				 * when we know what character comes next.
++				 */
++				nextch = '\0';
++				if (OP(next) == EXACTLY)
++					nextch = *OPERAND(next);
++				min = (OP(scan) == STAR) ? 0 : 1;
++				save = g->reginput;
++				no = regrepeat(g, OPERAND(scan));
++				while (no >= min) {
++					/* If it could work, try it. */
++					if (nextch == '\0' || *g->reginput == nextch)
++						if (regmatch(g, next))
++							return(1);
++					/* Couldn't or didn't -- back up. */
++					no--;
++					g->reginput = save + no;
++				}
++				return(0);
++			}
++			break;
++		case END:
++			return(1);	/* Success! */
++			break;
++		default:
++			printk("<3>Regexp: memory corruption\n");
++			return(0);
++			break;
++		}
++
++		scan = next;
++	}
++
++	/*
++	 * We get here only if there's trouble -- normally "case END" is
++	 * the terminating point.
++	 */
++	printk("<3>Regexp: corrupted pointers\n");
++	return(0);
++}
++
++/*
++ - regrepeat - repeatedly match something simple, report how many
++ */
++static int
++regrepeat(struct match_globals *g, char *p)
++{
++	register int count = 0;
++	register char *scan;
++	register char *opnd;
++
++	scan = g->reginput;
++	opnd = OPERAND(p);
++	switch (OP(p)) {
++	case ANY:
++		count = strlen(scan);
++		scan += count;
++		break;
++	case EXACTLY:
++		while (*opnd == *scan) {
++			count++;
++			scan++;
++		}
++		break;
++	case ANYOF:
++		while (*scan != '\0' && strchr(opnd, *scan) != NULL) {
++			count++;
++			scan++;
++		}
++		break;
++	case ANYBUT:
++		while (*scan != '\0' && strchr(opnd, *scan) == NULL) {
++			count++;
++			scan++;
++		}
++		break;
++	default:		/* Oh dear.  Called inappropriately. */
++		printk("<3>Regexp: internal foulup\n");
++		count = 0;	/* Best compromise. */
++		break;
++	}
++	g->reginput = scan;
++
++	return(count);
++}
++
++/*
++ - regnext - dig the "next" pointer out of a node
++ */
++static char*
++regnext(struct match_globals *g, char *p)
++{
++	register int offset;
++
++	if (p == &g->regdummy)
++		return(NULL);
++
++	offset = NEXT(p);
++	if (offset == 0)
++		return(NULL);
++
++	if (OP(p) == BACK)
++		return(p-offset);
++	else
++		return(p+offset);
++}
++
++#ifdef DEBUG
++
++STATIC char *regprop();
++
++/*
++ - regdump - dump a regexp onto stdout in vaguely comprehensible form
++ */
++void
++regdump(regexp *r)
++{
++	register char *s;
++	register char op = EXACTLY;	/* Arbitrary non-END op. */
++	register char *next;
++	/* extern char *strchr(); */
++
++
++	s = r->program + 1;
++	while (op != END) {	/* While that wasn't END last time... */
++		op = OP(s);
++		printf("%2d%s", s-r->program, regprop(s));	/* Where, what. */
++		next = regnext(s);
++		if (next == NULL)		/* Next ptr. */
++			printf("(0)");
++		else
++			printf("(%d)", (s-r->program)+(next-s));
++		s += 3;
++		if (op == ANYOF || op == ANYBUT || op == EXACTLY) {
++			/* Literal string, where present. */
++			while (*s != '\0') {
++				putchar(*s);
++				s++;
++			}
++			s++;
++		}
++		putchar('\n');
++	}
++
++	/* Header fields of interest. */
++	if (r->regstart != '\0')
++		printf("start `%c' ", r->regstart);
++	if (r->reganch)
++		printf("anchored ");
++	if (r->regmust != NULL)
++		printf("must have \"%s\"", r->regmust);
++	printf("\n");
++}
++
++/*
++ - regprop - printable representation of opcode
++ */
++static char *
++regprop(char *op)
++{
++#define BUFLEN 50
++	register char *p;
++	static char buf[BUFLEN];
++
++	strcpy(buf, ":");
++
++	switch (OP(op)) {
++	case BOL:
++		p = "BOL";
++		break;
++	case EOL:
++		p = "EOL";
++		break;
++	case ANY:
++		p = "ANY";
++		break;
++	case ANYOF:
++		p = "ANYOF";
++		break;
++	case ANYBUT:
++		p = "ANYBUT";
++		break;
++	case BRANCH:
++		p = "BRANCH";
++		break;
++	case EXACTLY:
++		p = "EXACTLY";
++		break;
++	case NOTHING:
++		p = "NOTHING";
++		break;
++	case BACK:
++		p = "BACK";
++		break;
++	case END:
++		p = "END";
++		break;
++	case OPEN+1:
++	case OPEN+2:
++	case OPEN+3:
++	case OPEN+4:
++	case OPEN+5:
++	case OPEN+6:
++	case OPEN+7:
++	case OPEN+8:
++	case OPEN+9:
++		snprintf(buf+strlen(buf),BUFLEN-strlen(buf), "OPEN%d", OP(op)-OPEN);
++		p = NULL;
++		break;
++	case CLOSE+1:
++	case CLOSE+2:
++	case CLOSE+3:
++	case CLOSE+4:
++	case CLOSE+5:
++	case CLOSE+6:
++	case CLOSE+7:
++	case CLOSE+8:
++	case CLOSE+9:
++		snprintf(buf+strlen(buf),BUFLEN-strlen(buf), "CLOSE%d", OP(op)-CLOSE);
++		p = NULL;
++		break;
++	case STAR:
++		p = "STAR";
++		break;
++	case PLUS:
++		p = "PLUS";
++		break;
++	default:
++		printk("<3>Regexp: corrupted opcode\n");
++		break;
++	}
++	if (p != NULL)
++		strncat(buf, p, BUFLEN-strlen(buf));
++	return(buf);
++}
++#endif
++
++
+--- /dev/null
++++ b/net/netfilter/regexp/regexp.h
+@@ -0,0 +1,41 @@
++/*
++ * Definitions etc. for regexp(3) routines.
++ *
++ * Caveat:  this is V8 regexp(3) [actually, a reimplementation thereof],
++ * not the System V one.
++ */
++
++#ifndef REGEXP_H
++#define REGEXP_H
++
++
++/*
++http://www.opensource.apple.com/darwinsource/10.3/expect-1/expect/expect.h ,
++which contains a version of this library, says:
++
++ *
++ * NSUBEXP must be at least 10, and no greater than 117 or the parser
++ * will not work properly.
++ *
++
++However, it looks rather like this library is limited to 10.  If you think
++otherwise, let us know.
++*/
++
++#define NSUBEXP  10
++typedef struct regexp {
++	char *startp[NSUBEXP];
++	char *endp[NSUBEXP];
++	char regstart;		/* Internal use only. */
++	char reganch;		/* Internal use only. */
++	char *regmust;		/* Internal use only. */
++	int regmlen;		/* Internal use only. */
++	char program[1];	/* Unwarranted chumminess with compiler. */
++} regexp;
++
++regexp * regcomp(char *exp, int *patternsize);
++int regexec(regexp *prog, char *string);
++void regsub(regexp *prog, char *source, char *dest);
++void regerror(char *s);
++
++#endif
+--- /dev/null
++++ b/net/netfilter/regexp/regmagic.h
+@@ -0,0 +1,5 @@
++/*
++ * The first byte of the regexp internal "program" is actually this magic
++ * number; the start node begins in the second byte.
++ */
++#define	MAGIC	0234
+--- /dev/null
++++ b/net/netfilter/regexp/regsub.c
+@@ -0,0 +1,95 @@
++/*
++ * regsub
++ * @(#)regsub.c	1.3 of 2 April 86
++ *
++ *	Copyright (c) 1986 by University of Toronto.
++ *	Written by Henry Spencer.  Not derived from licensed software.
++ *
++ *	Permission is granted to anyone to use this software for any
++ *	purpose on any computer system, and to redistribute it freely,
++ *	subject to the following restrictions:
++ *
++ *	1. The author is not responsible for the consequences of use of
++ *		this software, no matter how awful, even if they arise
++ *		from defects in it.
++ *
++ *	2. The origin of this software must not be misrepresented, either
++ *		by explicit claim or by omission.
++ *
++ *	3. Altered versions must be plainly marked as such, and must not
++ *		be misrepresented as being the original software.
++ *
++ *
++ * This code was modified by Ethan Sommer to work within the kernel
++ * (it now uses kmalloc etc..)
++ *
++ */
++#include "regexp.h"
++#include "regmagic.h"
++#include <linux/string.h>
++
++
++#ifndef CHARBITS
++#define	UCHARAT(p)	((int)*(unsigned char *)(p))
++#else
++#define	UCHARAT(p)	((int)*(p)&CHARBITS)
++#endif
++
++#if 0
++//void regerror(char * s)
++//{
++//        printk("regexp(3): %s", s);
++//        /* NOTREACHED */
++//}
++#endif
++
++/*
++ - regsub - perform substitutions after a regexp match
++ */
++void
++regsub(regexp * prog, char * source, char * dest)
++{
++	register char *src;
++	register char *dst;
++	register char c;
++	register int no;
++	register int len;
++	
++	/* Not necessary and gcc doesn't like it -MLS */
++	/*extern char *strncpy();*/
++
++	if (prog == NULL || source == NULL || dest == NULL) {
++		regerror("NULL parm to regsub");
++		return;
++	}
++	if (UCHARAT(prog->program) != MAGIC) {
++		regerror("damaged regexp fed to regsub");
++		return;
++	}
++
++	src = source;
++	dst = dest;
++	while ((c = *src++) != '\0') {
++		if (c == '&')
++			no = 0;
++		else if (c == '\\' && '0' <= *src && *src <= '9')
++			no = *src++ - '0';
++		else
++			no = -1;
++
++		if (no < 0) {	/* Ordinary character. */
++			if (c == '\\' && (*src == '\\' || *src == '&'))
++				c = *src++;
++			*dst++ = c;
++		} else if (prog->startp[no] != NULL && prog->endp[no] != NULL) {
++			len = prog->endp[no] - prog->startp[no];
++			(void) strncpy(dst, prog->startp[no], len);
++			dst += len;
++			if (len != 0 && *(dst-1) == '\0') {	/* strncpy hit NUL. */
++				regerror("damaged match string");
++				return;
++			}
++		}
++	}
++	*dst++ = '\0';
++}
+--- /dev/null
++++ b/net/netfilter/xt_layer7.c
+@@ -0,0 +1,666 @@
++/*
++  Kernel module to match application layer (OSI layer 7) data in connections.
++
++  http://l7-filter.sf.net
++
++  (C) 2003-2009 Matthew Strait and Ethan Sommer.
++
++  This program is free software; you can redistribute it and/or
++  modify it under the terms of the GNU General Public License
++  as published by the Free Software Foundation; either version
++  2 of the License, or (at your option) any later version.
++  http://www.gnu.org/licenses/gpl.txt
++
++  Based on ipt_string.c (C) 2000 Emmanuel Roger <winfield@freegates.be>,
++  xt_helper.c (C) 2002 Harald Welte and cls_layer7.c (C) 2003 Matthew Strait,
++  Ethan Sommer, Justin Levandoski.
++*/
++
++#include <linux/spinlock.h>
++#include <linux/version.h>
++#include <net/ip.h>
++#include <net/tcp.h>
++#include <linux/module.h>
++#include <linux/skbuff.h>
++#include <linux/netfilter.h>
++#include <net/netfilter/nf_conntrack.h>
++#include <net/netfilter/nf_conntrack_core.h>
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 27)
++#include <net/netfilter/nf_conntrack_extend.h>
++#include <net/netfilter/nf_conntrack_acct.h>
++#endif
++#include <linux/netfilter/x_tables.h>
++#include <linux/netfilter/xt_layer7.h>
++#include <linux/ctype.h>
++#include <linux/proc_fs.h>
++
++#include "regexp/regexp.c"
++
++MODULE_LICENSE("GPL");
++MODULE_AUTHOR("Matthew Strait <quadong@users.sf.net>, Ethan Sommer <sommere@users.sf.net>");
++MODULE_DESCRIPTION("iptables application layer match module");
++MODULE_ALIAS("ipt_layer7");
++MODULE_VERSION("2.21");
++
++static int maxdatalen = 2048; // this is the default
++module_param(maxdatalen, int, 0444);
++MODULE_PARM_DESC(maxdatalen, "maximum bytes of data looked at by l7-filter");
++#ifdef CONFIG_NETFILTER_XT_MATCH_LAYER7_DEBUG
++	#define DPRINTK(format,args...) printk(format,##args)
++#else
++	#define DPRINTK(format,args...)
++#endif
++
++/* Number of packets whose data we look at.
++This can be modified through /proc/net/layer7_numpackets */
++static int num_packets = 10;
++
++static struct pattern_cache {
++	char * regex_string;
++	regexp * pattern;
++	struct pattern_cache * next;
++} * first_pattern_cache = NULL;
++
++DEFINE_SPINLOCK(l7_lock);
++
++static int total_acct_packets(struct nf_conn *ct)
++{
++#if LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 26)
++	BUG_ON(ct == NULL);
++	return (ct->counters[IP_CT_DIR_ORIGINAL].packets + ct->counters[IP_CT_DIR_REPLY].packets);
++#else
++	struct nf_conn_counter *acct;
++
++	BUG_ON(ct == NULL);
++	acct = nf_conn_acct_find(ct);
++	if (!acct)
++		return 0;
++	return (acct[IP_CT_DIR_ORIGINAL].packets + acct[IP_CT_DIR_REPLY].packets);
++#endif
++}
++
++#ifdef CONFIG_IP_NF_MATCH_LAYER7_DEBUG
++/* Converts an unfriendly string into a friendly one by
++replacing unprintables with periods and all whitespace with " ". */
++static char * friendly_print(unsigned char * s)
++{
++	char * f = kmalloc(strlen(s) + 1, GFP_ATOMIC);
++	int i;
++
++	if(!f) {
++		if (net_ratelimit())
++			printk(KERN_ERR "layer7: out of memory in "
++					"friendly_print, bailing.\n");
++		return NULL;
++	}
++
++	for(i = 0; i < strlen(s); i++){
++		if(isprint(s[i]) && s[i] < 128)	f[i] = s[i];
++		else if(isspace(s[i]))		f[i] = ' ';
++		else 				f[i] = '.';
++	}
++	f[i] = '\0';
++	return f;
++}
++
++static char dec2hex(int i)
++{
++	switch (i) {
++		case 0 ... 9:
++			return (i + '0');
++			break;
++		case 10 ... 15:
++			return (i - 10 + 'a');
++			break;
++		default:
++			if (net_ratelimit())
++				printk("layer7: Problem in dec2hex\n");
++			return '\0';
++	}
++}
++
++static char * hex_print(unsigned char * s)
++{
++	char * g = kmalloc(strlen(s)*3 + 1, GFP_ATOMIC);
++	int i;
++
++	if(!g) {
++	       if (net_ratelimit())
++			printk(KERN_ERR "layer7: out of memory in hex_print, "
++					"bailing.\n");
++	       return NULL;
++	}
++
++	for(i = 0; i < strlen(s); i++) {
++		g[i*3    ] = dec2hex(s[i]/16);
++		g[i*3 + 1] = dec2hex(s[i]%16);
++		g[i*3 + 2] = ' ';
++	}
++	g[i*3] = '\0';
++
++	return g;
++}
++#endif // DEBUG
++
++/* Use instead of regcomp.  As we expect to be seeing the same regexps over and
++over again, it make sense to cache the results. */
++static regexp * compile_and_cache(const char * regex_string, 
++                                  const char * protocol)
++{
++	struct pattern_cache * node               = first_pattern_cache;
++	struct pattern_cache * last_pattern_cache = first_pattern_cache;
++	struct pattern_cache * tmp;
++	unsigned int len;
++
++	while (node != NULL) {
++		if (!strcmp(node->regex_string, regex_string))
++		return node->pattern;
++
++		last_pattern_cache = node;/* points at the last non-NULL node */
++		node = node->next;
++	}
++
++	/* If we reach the end of the list, then we have not yet cached
++	   the pattern for this regex. Let's do that now.
++	   Be paranoid about running out of memory to avoid list corruption. */
++	tmp = kmalloc(sizeof(struct pattern_cache), GFP_ATOMIC);
++
++	if(!tmp) {
++		if (net_ratelimit())
++			printk(KERN_ERR "layer7: out of memory in "
++					"compile_and_cache, bailing.\n");
++		return NULL;
++	}
++
++	tmp->regex_string  = kmalloc(strlen(regex_string) + 1, GFP_ATOMIC);
++	tmp->pattern       = kmalloc(sizeof(struct regexp),    GFP_ATOMIC);
++	tmp->next = NULL;
++
++	if(!tmp->regex_string || !tmp->pattern) {
++		if (net_ratelimit())
++			printk(KERN_ERR "layer7: out of memory in "
++					"compile_and_cache, bailing.\n");
++		kfree(tmp->regex_string);
++		kfree(tmp->pattern);
++		kfree(tmp);
++		return NULL;
++	}
++
++	/* Ok.  The new node is all ready now. */
++	node = tmp;
++
++	if(first_pattern_cache == NULL) /* list is empty */
++		first_pattern_cache = node; /* make node the beginning */
++	else
++		last_pattern_cache->next = node; /* attach node to the end */
++
++	/* copy the string and compile the regex */
++	len = strlen(regex_string);
++	DPRINTK("About to compile this: \"%s\"\n", regex_string);
++	node->pattern = regcomp((char *)regex_string, &len);
++	if ( !node->pattern ) {
++		if (net_ratelimit())
++			printk(KERN_ERR "layer7: Error compiling regexp "
++					"\"%s\" (%s)\n", 
++					regex_string, protocol);
++		/* pattern is now cached as NULL, so we won't try again. */
++	}
++
++	strcpy(node->regex_string, regex_string);
++	return node->pattern;
++}
++
++static int can_handle(const struct sk_buff *skb)
++{
++	if(!ip_hdr(skb)) /* not IP */
++		return 0;
++	if(ip_hdr(skb)->protocol != IPPROTO_TCP &&
++	   ip_hdr(skb)->protocol != IPPROTO_UDP &&
++	   ip_hdr(skb)->protocol != IPPROTO_ICMP)
++		return 0;
++	return 1;
++}
++
++/* Returns offset the into the skb->data that the application data starts */
++static int app_data_offset(const struct sk_buff *skb)
++{
++	/* In case we are ported somewhere (ebtables?) where ip_hdr(skb)
++	isn't set, this can be gotten from 4*(skb->data[0] & 0x0f) as well. */
++	int ip_hl = 4*ip_hdr(skb)->ihl;
++
++	if( ip_hdr(skb)->protocol == IPPROTO_TCP ) {
++		/* 12 == offset into TCP header for the header length field.
++		Can't get this with skb->h.th->doff because the tcphdr
++		struct doesn't get set when routing (this is confirmed to be
++		true in Netfilter as well as QoS.) */
++		int tcp_hl = 4*(skb->data[ip_hl + 12] >> 4);
++
++		return ip_hl + tcp_hl;
++	} else if( ip_hdr(skb)->protocol == IPPROTO_UDP  ) {
++		return ip_hl + 8; /* UDP header is always 8 bytes */
++	} else if( ip_hdr(skb)->protocol == IPPROTO_ICMP ) {
++		return ip_hl + 8; /* ICMP header is 8 bytes */
++	} else {
++		if (net_ratelimit())
++			printk(KERN_ERR "layer7: tried to handle unknown "
++					"protocol!\n");
++		return ip_hl + 8; /* something reasonable */
++	}
++}
++
++/* handles whether there's a match when we aren't appending data anymore */
++static int match_no_append(struct nf_conn * conntrack, 
++                           struct nf_conn * master_conntrack, 
++                           enum ip_conntrack_info ctinfo,
++                           enum ip_conntrack_info master_ctinfo,
++                           const struct xt_layer7_info * info)
++{
++	/* If we're in here, throw the app data away */
++	if(master_conntrack->layer7.app_data != NULL) {
++
++	#ifdef CONFIG_IP_NF_MATCH_LAYER7_DEBUG
++		if(!master_conntrack->layer7.app_proto) {
++			char * f = 
++			  friendly_print(master_conntrack->layer7.app_data);
++			char * g = 
++			  hex_print(master_conntrack->layer7.app_data);
++			DPRINTK("\nl7-filter gave up after %d bytes "
++				"(%d packets):\n%s\n",
++				strlen(f), total_acct_packets(master_conntrack), f);
++			kfree(f);
++			DPRINTK("In hex: %s\n", g);
++			kfree(g);
++		}
++	#endif
++
++		kfree(master_conntrack->layer7.app_data);
++		master_conntrack->layer7.app_data = NULL; /* don't free again */
++	}
++
++	if(master_conntrack->layer7.app_proto){
++		/* Here child connections set their .app_proto (for /proc) */
++		if(!conntrack->layer7.app_proto) {
++			conntrack->layer7.app_proto = 
++			  kmalloc(strlen(master_conntrack->layer7.app_proto)+1, 
++			    GFP_ATOMIC);
++			if(!conntrack->layer7.app_proto){
++				if (net_ratelimit())
++					printk(KERN_ERR "layer7: out of memory "
++							"in match_no_append, "
++							"bailing.\n");
++				return 1;
++			}
++			strcpy(conntrack->layer7.app_proto, 
++				master_conntrack->layer7.app_proto);
++		}
++
++		return (!strcmp(master_conntrack->layer7.app_proto, 
++				info->protocol));
++	}
++	else {
++		/* If not classified, set to "unknown" to distinguish from
++		connections that are still being tested. */
++		master_conntrack->layer7.app_proto = 
++			kmalloc(strlen("unknown")+1, GFP_ATOMIC);
++		if(!master_conntrack->layer7.app_proto){
++			if (net_ratelimit())
++				printk(KERN_ERR "layer7: out of memory in "
++						"match_no_append, bailing.\n");
++			return 1;
++		}
++		strcpy(master_conntrack->layer7.app_proto, "unknown");
++		return 0;
++	}
++}
++
++/* add the new app data to the conntrack.  Return number of bytes added. */
++static int add_data(struct nf_conn * master_conntrack,
++                    char * app_data, int appdatalen)
++{
++	int length = 0, i;
++	int oldlength = master_conntrack->layer7.app_data_len;
++
++	/* This is a fix for a race condition by Deti Fliegl. However, I'm not 
++	   clear on whether the race condition exists or whether this really 
++	   fixes it.  I might just be being dense... Anyway, if it's not really 
++	   a fix, all it does is waste a very small amount of time. */
++	if(!master_conntrack->layer7.app_data) return 0;
++
++	/* Strip nulls. Make everything lower case (our regex lib doesn't
++	do case insensitivity).  Add it to the end of the current data. */
++	for(i = 0; i < maxdatalen-oldlength-1 &&
++		   i < appdatalen; i++) {
++		if(app_data[i] != '\0') {
++			/* the kernel version of tolower mungs 'upper ascii' */
++			master_conntrack->layer7.app_data[length+oldlength] =
++				isascii(app_data[i])? 
++					tolower(app_data[i]) : app_data[i];
++			length++;
++		}
++	}
++
++	master_conntrack->layer7.app_data[length+oldlength] = '\0';
++	master_conntrack->layer7.app_data_len = length + oldlength;
++
++	return length;
++}
++
++/* taken from drivers/video/modedb.c */
++static int my_atoi(const char *s)
++{
++	int val = 0;
++
++	for (;; s++) {
++		switch (*s) {
++			case '0'...'9':
++			val = 10*val+(*s-'0');
++			break;
++		default:
++			return val;
++		}
++	}
++}
++
++/* write out num_packets to userland. */
++static int layer7_read_proc(char* page, char ** start, off_t off, int count,
++                            int* eof, void * data)
++{
++	if(num_packets > 99 && net_ratelimit())
++		printk(KERN_ERR "layer7: NOT REACHED. num_packets too big\n");
++
++	page[0] = num_packets/10 + '0';
++	page[1] = num_packets%10 + '0';
++	page[2] = '\n';
++	page[3] = '\0';
++
++	*eof=1;
++
++	return 3;
++}
++
++/* Read in num_packets from userland */
++static int layer7_write_proc(struct file* file, const char* buffer,
++                             unsigned long count, void *data)
++{
++	char * foo = kmalloc(count, GFP_ATOMIC);
++
++	if(!foo){
++		if (net_ratelimit())
++			printk(KERN_ERR "layer7: out of memory, bailing. "
++					"num_packets unchanged.\n");
++		return count;
++	}
++
++	if(copy_from_user(foo, buffer, count)) {
++		return -EFAULT;
++	}
++
++
++	num_packets = my_atoi(foo);
++	kfree (foo);
++
++	/* This has an arbitrary limit to make the math easier. I'm lazy.
++	But anyway, 99 is a LOT! If you want more, you're doing it wrong! */
++	if(num_packets > 99) {
++		printk(KERN_WARNING "layer7: num_packets can't be > 99.\n");
++		num_packets = 99;
++	} else if(num_packets < 1) {
++		printk(KERN_WARNING "layer7: num_packets can't be < 1.\n");
++		num_packets = 1;
++	}
++
++	return count;
++}
++
++static bool
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 28)
++match(const struct sk_buff *skbin, const struct xt_match_param *par)
++#else
++match(const struct sk_buff *skbin,
++      const struct net_device *in,
++      const struct net_device *out,
++      const struct xt_match *match,
++      const void *matchinfo,
++      int offset,
++      unsigned int protoff,
++      bool *hotdrop)
++#endif
++{
++	/* sidestep const without getting a compiler warning... */
++	struct sk_buff * skb = (struct sk_buff *)skbin; 
++
++	const struct xt_layer7_info * info = 
++	#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 28)
++		par->matchinfo;
++	#else
++		matchinfo;
++	#endif
++
++	enum ip_conntrack_info master_ctinfo, ctinfo;
++	struct nf_conn *master_conntrack, *conntrack;
++	unsigned char * app_data;
++	unsigned int pattern_result, appdatalen;
++	regexp * comppattern;
++
++	/* Be paranoid/incompetent - lock the entire match function. */
++	spin_lock_bh(&l7_lock);
++
++	if(!can_handle(skb)){
++		DPRINTK("layer7: This is some protocol I can't handle.\n");
++		spin_unlock_bh(&l7_lock);
++		return info->invert;
++	}
++
++	/* Treat parent & all its children together as one connection, except
++	for the purpose of setting conntrack->layer7.app_proto in the actual
++	connection. This makes /proc/net/ip_conntrack more satisfying. */
++	if(!(conntrack = nf_ct_get(skb, &ctinfo)) ||
++	   !(master_conntrack=nf_ct_get(skb,&master_ctinfo))){
++		DPRINTK("layer7: couldn't get conntrack.\n");
++		spin_unlock_bh(&l7_lock);
++		return info->invert;
++	}
++
++	/* Try to get a master conntrack (and its master etc) for FTP, etc. */
++	while (master_ct(master_conntrack) != NULL)
++		master_conntrack = master_ct(master_conntrack);
++
++	/* if we've classified it or seen too many packets */
++	if(total_acct_packets(master_conntrack) > num_packets ||
++	   master_conntrack->layer7.app_proto) {
++
++		pattern_result = match_no_append(conntrack, master_conntrack, 
++						 ctinfo, master_ctinfo, info);
++
++		/* skb->cb[0] == seen. Don't do things twice if there are 
++		multiple l7 rules. I'm not sure that using cb for this purpose 
++		is correct, even though it says "put your private variables 
++		there". But it doesn't look like it is being used for anything
++		else in the skbs that make it here. */
++		skb->cb[0] = 1; /* marking it seen here's probably irrelevant */
++
++		spin_unlock_bh(&l7_lock);
++		return (pattern_result ^ info->invert);
++	}
++
++	if(skb_is_nonlinear(skb)){
++		if(skb_linearize(skb) != 0){
++			if (net_ratelimit())
++				printk(KERN_ERR "layer7: failed to linearize "
++						"packet, bailing.\n");
++			spin_unlock_bh(&l7_lock);
++			return info->invert;
++		}
++	}
++
++	/* now that the skb is linearized, it's safe to set these. */
++	app_data = skb->data + app_data_offset(skb);
++	appdatalen = skb_tail_pointer(skb) - app_data;
++
++	/* the return value gets checked later, when we're ready to use it */
++	comppattern = compile_and_cache(info->pattern, info->protocol);
++
++	/* On the first packet of a connection, allocate space for app data */
++	if(total_acct_packets(master_conntrack) == 1 && !skb->cb[0] && 
++	   !master_conntrack->layer7.app_data){
++		master_conntrack->layer7.app_data = 
++			kmalloc(maxdatalen, GFP_ATOMIC);
++		if(!master_conntrack->layer7.app_data){
++			if (net_ratelimit())
++				printk(KERN_ERR "layer7: out of memory in "
++						"match, bailing.\n");
++			spin_unlock_bh(&l7_lock);
++			return info->invert;
++		}
++
++		master_conntrack->layer7.app_data[0] = '\0';
++	}
++
++	/* Can be here, but unallocated, if numpackets is increased near
++	the beginning of a connection */
++	if(master_conntrack->layer7.app_data == NULL){
++		spin_unlock_bh(&l7_lock);
++		return info->invert; /* unmatched */
++	}
++
++	if(!skb->cb[0]){
++		int newbytes;
++		newbytes = add_data(master_conntrack, app_data, appdatalen);
++
++		if(newbytes == 0) { /* didn't add any data */
++			skb->cb[0] = 1;
++			/* Didn't match before, not going to match now */
++			spin_unlock_bh(&l7_lock);
++			return info->invert;
++		}
++	}
++
++	/* If looking for "unknown", then never match.  "Unknown" means that
++	we've given up; we're still trying with these packets. */
++	if(!strcmp(info->protocol, "unknown")) {
++		pattern_result = 0;
++	/* If looking for "unset", then always match. "Unset" means that we
++	haven't yet classified the connection. */
++	} else if(!strcmp(info->protocol, "unset")) {
++		pattern_result = 2;
++		DPRINTK("layer7: matched unset: not yet classified "
++			"(%d/%d packets)\n",
++                        total_acct_packets(master_conntrack), num_packets);
++	/* If the regexp failed to compile, don't bother running it */
++	} else if(comppattern && 
++		  regexec(comppattern, master_conntrack->layer7.app_data)){
++		DPRINTK("layer7: matched %s\n", info->protocol);
++		pattern_result = 1;
++	} else pattern_result = 0;
++
++	if(pattern_result == 1) {
++		master_conntrack->layer7.app_proto = 
++			kmalloc(strlen(info->protocol)+1, GFP_ATOMIC);
++		if(!master_conntrack->layer7.app_proto){
++			if (net_ratelimit())
++				printk(KERN_ERR "layer7: out of memory in "
++						"match, bailing.\n");
++			spin_unlock_bh(&l7_lock);
++			return (pattern_result ^ info->invert);
++		}
++		strcpy(master_conntrack->layer7.app_proto, info->protocol);
++	} else if(pattern_result > 1) { /* cleanup from "unset" */
++		pattern_result = 1;
++	}
++
++	/* mark the packet seen */
++	skb->cb[0] = 1;
++
++	spin_unlock_bh(&l7_lock);
++	return (pattern_result ^ info->invert);
++}
++
++// load nf_conntrack_ipv4
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 28)
++static bool check(const struct xt_mtchk_param *par)
++{
++        if (nf_ct_l3proto_try_module_get(par->match->family) < 0) {
++                printk(KERN_WARNING "can't load conntrack support for "
++                                    "proto=%d\n", par->match->family);
++#else
++static bool check(const char *tablename, const void *inf,
++		 const struct xt_match *match, void *matchinfo,
++		 unsigned int hook_mask)
++{
++        if (nf_ct_l3proto_try_module_get(match->family) < 0) {
++                printk(KERN_WARNING "can't load conntrack support for "
++                                    "proto=%d\n", match->family);
++#endif
++                return 0;
++        }
++	return 1;
++}
++
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 28)
++	static void destroy(const struct xt_mtdtor_param *par)
++	{
++		nf_ct_l3proto_module_put(par->match->family);
++	}
++#else
++	static void destroy(const struct xt_match *match, void *matchinfo)
++	{
++		nf_ct_l3proto_module_put(match->family);
++	}
++#endif
++
++static struct xt_match xt_layer7_match[] __read_mostly = {
++{
++	.name		= "layer7",
++	.family		= AF_INET,
++	.checkentry	= check,
++	.match		= match,
++	.destroy	= destroy,
++	.matchsize	= sizeof(struct xt_layer7_info),
++	.me		= THIS_MODULE
++}
++};
++
++static void layer7_cleanup_proc(void)
++{
++	remove_proc_entry("layer7_numpackets", init_net.proc_net);
++}
++
++/* register the proc file */
++static void layer7_init_proc(void)
++{
++	struct proc_dir_entry* entry;
++	entry = create_proc_entry("layer7_numpackets", 0644, init_net.proc_net);
++	entry->read_proc = layer7_read_proc;
++	entry->write_proc = layer7_write_proc;
++}
++
++static int __init xt_layer7_init(void)
++{
++	need_conntrack();
++
++	layer7_init_proc();
++	if(maxdatalen < 1) {
++		printk(KERN_WARNING "layer7: maxdatalen can't be < 1, "
++			"using 1\n");
++		maxdatalen = 1;
++	}
++	/* This is not a hard limit.  It's just here to prevent people from
++	bringing their slow machines to a grinding halt. */
++	else if(maxdatalen > 65536) {
++		printk(KERN_WARNING "layer7: maxdatalen can't be > 65536, "
++			"using 65536\n");
++		maxdatalen = 65536;
++	}
++	return xt_register_matches(xt_layer7_match,
++				   ARRAY_SIZE(xt_layer7_match));
++}
++
++static void __exit xt_layer7_fini(void)
++{
++	layer7_cleanup_proc();
++	xt_unregister_matches(xt_layer7_match, ARRAY_SIZE(xt_layer7_match));
++}
++
++module_init(xt_layer7_init);
++module_exit(xt_layer7_fini);
diff -Nru a/target/linux/generic/patches-2.6.31/101-netfilter_layer7_pktmatch.patch b/target/linux/generic/patches-2.6.31/101-netfilter_layer7_pktmatch.patch
--- a/target/linux/generic/patches-2.6.31/101-netfilter_layer7_pktmatch.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/101-netfilter_layer7_pktmatch.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,108 @@
+--- a/include/linux/netfilter/xt_layer7.h
++++ b/include/linux/netfilter/xt_layer7.h
+@@ -8,6 +8,7 @@ struct xt_layer7_info {
+     char protocol[MAX_PROTOCOL_LEN];
+     char pattern[MAX_PATTERN_LEN];
+     u_int8_t invert;
++    u_int8_t pkt;
+ };
+ 
+ #endif /* _XT_LAYER7_H */
+--- a/net/netfilter/xt_layer7.c
++++ b/net/netfilter/xt_layer7.c
+@@ -314,33 +314,35 @@ static int match_no_append(struct nf_con
+ }
+ 
+ /* add the new app data to the conntrack.  Return number of bytes added. */
+-static int add_data(struct nf_conn * master_conntrack,
+-                    char * app_data, int appdatalen)
++static int add_datastr(char *target, int offset, char *app_data, int len)
+ {
+ 	int length = 0, i;
+-	int oldlength = master_conntrack->layer7.app_data_len;
+-
+-	/* This is a fix for a race condition by Deti Fliegl. However, I'm not 
+-	   clear on whether the race condition exists or whether this really 
+-	   fixes it.  I might just be being dense... Anyway, if it's not really 
+-	   a fix, all it does is waste a very small amount of time. */
+-	if(!master_conntrack->layer7.app_data) return 0;
++	if (!target) return 0;
+ 
+ 	/* Strip nulls. Make everything lower case (our regex lib doesn't
+ 	do case insensitivity).  Add it to the end of the current data. */
+-	for(i = 0; i < maxdatalen-oldlength-1 &&
+-		   i < appdatalen; i++) {
++ 	for(i = 0; i < maxdatalen-offset-1 && i < len; i++) {
+ 		if(app_data[i] != '\0') {
+ 			/* the kernel version of tolower mungs 'upper ascii' */
+-			master_conntrack->layer7.app_data[length+oldlength] =
++			target[length+offset] =
+ 				isascii(app_data[i])? 
+ 					tolower(app_data[i]) : app_data[i];
+ 			length++;
+ 		}
+ 	}
++	target[length+offset] = '\0';
++
++	return length;
++}
++
++/* add the new app data to the conntrack.  Return number of bytes added. */
++static int add_data(struct nf_conn * master_conntrack,
++                    char * app_data, int appdatalen)
++{
++	int length;
+ 
+-	master_conntrack->layer7.app_data[length+oldlength] = '\0';
+-	master_conntrack->layer7.app_data_len = length + oldlength;
++	length = add_datastr(master_conntrack->layer7.app_data, master_conntrack->layer7.app_data_len, app_data, appdatalen);
++	master_conntrack->layer7.app_data_len += length;
+ 
+ 	return length;
+ }
+@@ -438,7 +440,7 @@ match(const struct sk_buff *skbin,
+ 
+ 	enum ip_conntrack_info master_ctinfo, ctinfo;
+ 	struct nf_conn *master_conntrack, *conntrack;
+-	unsigned char * app_data;
++	unsigned char *app_data, *tmp_data;
+ 	unsigned int pattern_result, appdatalen;
+ 	regexp * comppattern;
+ 
+@@ -466,8 +468,8 @@ match(const struct sk_buff *skbin,
+ 		master_conntrack = master_ct(master_conntrack);
+ 
+ 	/* if we've classified it or seen too many packets */
+-	if(total_acct_packets(master_conntrack) > num_packets ||
+-	   master_conntrack->layer7.app_proto) {
++	if(!info->pkt && (total_acct_packets(master_conntrack) > num_packets ||
++	   master_conntrack->layer7.app_proto)) {
+ 
+ 		pattern_result = match_no_append(conntrack, master_conntrack, 
+ 						 ctinfo, master_ctinfo, info);
+@@ -500,6 +502,25 @@ match(const struct sk_buff *skbin,
+ 	/* the return value gets checked later, when we're ready to use it */
+ 	comppattern = compile_and_cache(info->pattern, info->protocol);
+ 
++	if (info->pkt) {
++		tmp_data = kmalloc(maxdatalen, GFP_ATOMIC);
++		if(!tmp_data){
++			if (net_ratelimit())
++				printk(KERN_ERR "layer7: out of memory in match, bailing.\n");
++			return info->invert;
++		}
++
++		tmp_data[0] = '\0';
++		add_datastr(tmp_data, 0, app_data, appdatalen);
++		pattern_result = ((comppattern && regexec(comppattern, tmp_data)) ? 1 : 0);
++
++		kfree(tmp_data);
++		tmp_data = NULL;
++		spin_unlock_bh(&l7_lock);
++
++		return (pattern_result ^ info->invert);
++	}
++
+ 	/* On the first packet of a connection, allocate space for app data */
+ 	if(total_acct_packets(master_conntrack) == 1 && !skb->cb[0] && 
+ 	   !master_conntrack->layer7.app_data){
diff -Nru a/target/linux/generic/patches-2.6.31/110-netfilter_match_speedup.patch b/target/linux/generic/patches-2.6.31/110-netfilter_match_speedup.patch
--- a/target/linux/generic/patches-2.6.31/110-netfilter_match_speedup.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/110-netfilter_match_speedup.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,144 @@
+--- a/include/linux/netfilter_ipv4/ip_tables.h
++++ b/include/linux/netfilter_ipv4/ip_tables.h
+@@ -62,6 +62,7 @@ struct ipt_ip {
+ #define IPT_F_FRAG		0x01	/* Set if rule is a fragment rule */
+ #define IPT_F_GOTO		0x02	/* Set if jump is a goto */
+ #define IPT_F_MASK		0x03	/* All possible flag bits mask. */
++#define IPT_F_NO_DEF_MATCH	0x80	/* Internal: no default match rules present */
+ 
+ /* Values for "inv" field in struct ipt_ip. */
+ #define IPT_INV_VIA_IN		0x01	/* Invert the sense of IN IFACE. */
+--- a/net/ipv4/netfilter/ip_tables.c
++++ b/net/ipv4/netfilter/ip_tables.c
+@@ -87,6 +87,9 @@ ip_packet_match(const struct iphdr *ip,
+ 
+ #define FWINV(bool, invflg) ((bool) ^ !!(ipinfo->invflags & (invflg)))
+ 
++	if (ipinfo->flags & IPT_F_NO_DEF_MATCH)
++		return true;
++
+ 	if (FWINV((ip->saddr&ipinfo->smsk.s_addr) != ipinfo->src.s_addr,
+ 		  IPT_INV_SRCIP)
+ 	    || FWINV((ip->daddr&ipinfo->dmsk.s_addr) != ipinfo->dst.s_addr,
+@@ -137,13 +140,35 @@ ip_packet_match(const struct iphdr *ip,
+ 		return false;
+ 	}
+ 
++#undef FWINV
+ 	return true;
+ }
+ 
+ static bool
+-ip_checkentry(const struct ipt_ip *ip)
++ip_checkentry(struct ipt_ip *ip)
+ {
+-	if (ip->flags & ~IPT_F_MASK) {
++#define FWINV(bool, invflg) ((bool) || (ip->invflags & (invflg)))
++
++	if (FWINV(ip->smsk.s_addr, IPT_INV_SRCIP) ||
++		FWINV(ip->dmsk.s_addr, IPT_INV_DSTIP))
++		goto has_match_rules;
++
++	if (FWINV(!!((const unsigned long *)ip->iniface_mask)[0],
++		IPT_INV_VIA_IN) ||
++	    FWINV(!!((const unsigned long *)ip->outiface_mask)[0],
++		IPT_INV_VIA_OUT))
++		goto has_match_rules;
++
++	if (FWINV(ip->proto, IPT_INV_PROTO))
++		goto has_match_rules;
++
++	if (FWINV(ip->flags&IPT_F_FRAG, IPT_INV_FRAG))
++		goto has_match_rules;
++
++	ip->flags |= IPT_F_NO_DEF_MATCH;
++
++has_match_rules:
++	if (ip->flags & ~(IPT_F_MASK|IPT_F_NO_DEF_MATCH)) {
+ 		duprintf("Unknown flag bits set: %08X\n",
+ 			 ip->flags & ~IPT_F_MASK);
+ 		return false;
+@@ -153,6 +178,8 @@ ip_checkentry(const struct ipt_ip *ip)
+ 			 ip->invflags & ~IPT_INV_MASK);
+ 		return false;
+ 	}
++
++#undef FWINV
+ 	return true;
+ }
+ 
+@@ -200,7 +227,6 @@ unconditional(const struct ipt_ip *ip)
+ 			return 0;
+ 
+ 	return 1;
+-#undef FWINV
+ }
+ 
+ #if defined(CONFIG_NETFILTER_XT_TARGET_TRACE) || \
+@@ -326,8 +352,28 @@ ipt_do_table(struct sk_buff *skb,
+ 	struct xt_match_param mtpar;
+ 	struct xt_target_param tgpar;
+ 
+-	/* Initialization */
+ 	ip = ip_hdr(skb);
++
++	IP_NF_ASSERT(table->valid_hooks & (1 << hook));
++	xt_info_rdlock_bh();
++	private = table->private;
++	table_base = private->entries[smp_processor_id()];
++	e = get_entry(table_base, private->hook_entry[hook]);
++
++	if (e->target_offset <= sizeof(struct ipt_entry) &&
++		(e->ip.flags & IPT_F_NO_DEF_MATCH)) {
++			struct ipt_entry_target *t = ipt_get_target(e);
++			if (!t->u.kernel.target->target) {
++				int v = ((struct ipt_standard_target *)t)->verdict;
++				if ((v < 0) && (v != IPT_RETURN)) {
++					ADD_COUNTER(e->counters, ntohs(ip->tot_len), 1);
++					xt_info_rdunlock_bh();
++					return (unsigned)(-v) - 1;
++				}
++			}
++	}
++
++	/* Initialization */
+ 	datalen = skb->len - ip->ihl * 4;
+ 	indev = in ? in->name : nulldevname;
+ 	outdev = out ? out->name : nulldevname;
+@@ -345,13 +391,6 @@ ipt_do_table(struct sk_buff *skb,
+ 	mtpar.family  = tgpar.family = NFPROTO_IPV4;
+ 	mtpar.hooknum = tgpar.hooknum = hook;
+ 
+-	IP_NF_ASSERT(table->valid_hooks & (1 << hook));
+-	xt_info_rdlock_bh();
+-	private = table->private;
+-	table_base = private->entries[smp_processor_id()];
+-
+-	e = get_entry(table_base, private->hook_entry[hook]);
+-
+ 	/* For return from builtin chain */
+ 	back = get_entry(table_base, private->underflow[hook]);
+ 
+@@ -978,6 +1017,7 @@ copy_entries_to_user(unsigned int total_
+ 		unsigned int i;
+ 		const struct ipt_entry_match *m;
+ 		const struct ipt_entry_target *t;
++		u8 flags;
+ 
+ 		e = (struct ipt_entry *)(loc_cpu_entry + off);
+ 		if (copy_to_user(userptr + off
+@@ -987,6 +1027,14 @@ copy_entries_to_user(unsigned int total_
+ 			ret = -EFAULT;
+ 			goto free_counters;
+ 		}
++
++		flags = e->ip.flags & ~IPT_F_NO_DEF_MATCH;
++		if (copy_to_user(userptr + off
++				 + offsetof(struct ipt_entry, ip.flags),
++				 &flags, sizeof(flags)) != 0) {
++			ret = -EFAULT;
++			goto free_counters;
++		}
+ 
+ 		for (i = sizeof(struct ipt_entry);
+ 		     i < e->target_offset;
diff -Nru a/target/linux/generic/patches-2.6.31/120-netfilter_recent_reap.patch b/target/linux/generic/patches-2.6.31/120-netfilter_recent_reap.patch
--- a/target/linux/generic/patches-2.6.31/120-netfilter_recent_reap.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/120-netfilter_recent_reap.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,71 @@
+--- a/include/linux/netfilter/xt_recent.h
++++ b/include/linux/netfilter/xt_recent.h
+@@ -9,6 +9,7 @@ enum {
+ 	XT_RECENT_UPDATE   = 1 << 2,
+ 	XT_RECENT_REMOVE   = 1 << 3,
+ 	XT_RECENT_TTL      = 1 << 4,
++	XT_RECENT_REAP     = 1 << 5,
+ 
+ 	XT_RECENT_SOURCE   = 0,
+ 	XT_RECENT_DEST     = 1,
+@@ -16,6 +17,9 @@ enum {
+ 	XT_RECENT_NAME_LEN = 200,
+ };
+ 
++/* Only allowed with --rcheck and --update */
++#define XT_RECENT_MODIFIERS (XT_RECENT_TTL|XT_RECENT_REAP)
++
+ struct xt_recent_mtinfo {
+ 	__u32 seconds;
+ 	__u32 hit_count;
+--- a/net/netfilter/xt_recent.c
++++ b/net/netfilter/xt_recent.c
+@@ -142,6 +142,25 @@ static void recent_entry_remove(struct r
+ 	t->entries--;
+ }
+ 
++/*
++ * Drop entries with timestamps older then 'time'.
++ */
++static void recent_entry_reap(struct recent_table *t, unsigned long time)
++{
++	struct recent_entry *e;
++
++	/*
++	 * The head of the LRU list is always the oldest entry.
++	 */
++	e = list_entry(t->lru_list.next, struct recent_entry, lru_list);
++
++	/*
++	 * The last time stamp is the most recent.
++	 */
++	if (time_after(time, e->stamps[e->index-1]))
++		recent_entry_remove(t, e);
++}
++
+ static struct recent_entry *
+ recent_entry_init(struct recent_table *t, const union nf_inet_addr *addr,
+ 		  u_int16_t family, u_int8_t ttl)
+@@ -265,6 +284,10 @@ recent_mt(const struct sk_buff *skb, con
+ 				break;
+ 			}
+ 		}
++
++		/* info->seconds must be non-zero */
++		if (info->check_set & XT_RECENT_REAP)
++			recent_entry_reap(t, time);
+ 	}
+ 
+ 	if (info->check_set & XT_RECENT_SET ||
+@@ -292,7 +315,10 @@ static bool recent_mt_check(const struct
+ 		      XT_RECENT_CHECK | XT_RECENT_UPDATE)) != 1)
+ 		return false;
+ 	if ((info->check_set & (XT_RECENT_SET | XT_RECENT_REMOVE)) &&
+-	    (info->seconds || info->hit_count))
++	    (info->seconds || info->hit_count ||
++	    (info->check_set & XT_RECENT_MODIFIERS)))
++		return false;
++	if ((info->check_set & XT_RECENT_REAP) && !info->seconds)
+ 		return false;
+ 	if (info->hit_count > ip_pkt_list_tot)
+ 		return false;
diff -Nru a/target/linux/generic/patches-2.6.31/130-netfilter_dscp_ipv6_mangle.patch b/target/linux/generic/patches-2.6.31/130-netfilter_dscp_ipv6_mangle.patch
--- a/target/linux/generic/patches-2.6.31/130-netfilter_dscp_ipv6_mangle.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/130-netfilter_dscp_ipv6_mangle.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,26 @@
+From: Fernando Luis Vazquez Cao <fernando@oss.ntt.co.jp>
+Date: Tue, 10 May 2011 08:00:21 +0000 (+0200)
+Subject: netfilter: IPv6: fix DSCP mangle code
+X-Git-Tag: v2.6.39~15^2~13^2~1
+X-Git-Url: http://git390.marist.edu/cgi-bin/gitweb.cgi?p=linux-2.6.git;a=commitdiff_plain;h=1ed2f73d90fb49bcf5704aee7e9084adb882bfc5
+
+netfilter: IPv6: fix DSCP mangle code
+
+The mask indicates the bits one wants to zero out, so it needs to be
+inverted before applying to the original TOS field.
+
+Signed-off-by: Fernando Luis Vazquez Cao <fernando@oss.ntt.co.jp>
+Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
+---
+
+--- a/net/netfilter/xt_DSCP.c
++++ b/net/netfilter/xt_DSCP.c
+@@ -135,7 +135,7 @@ tos_tg6(struct sk_buff *skb, const struc
+ 	u_int8_t orig, nv;
+ 
+ 	orig = ipv6_get_dsfield(iph);
+-	nv   = (orig & info->tos_mask) ^ info->tos_value;
++	nv   = (orig & ~info->tos_mask) ^ info->tos_value;
+ 
+ 	if (orig != nv) {
+ 		if (!skb_make_writable(skb, sizeof(struct iphdr)))
diff -Nru a/target/linux/generic/patches-2.6.31/180-netfilter_depends.patch b/target/linux/generic/patches-2.6.31/180-netfilter_depends.patch
--- a/target/linux/generic/patches-2.6.31/180-netfilter_depends.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/180-netfilter_depends.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,18 @@
+--- a/net/netfilter/Kconfig
++++ b/net/netfilter/Kconfig
+@@ -160,7 +160,6 @@ config NF_CONNTRACK_FTP
+ 
+ config NF_CONNTRACK_H323
+ 	tristate "H.323 protocol support"
+-	depends on (IPV6 || IPV6=n)
+ 	depends on NETFILTER_ADVANCED
+ 	help
+ 	  H.323 is a VoIP signalling protocol from ITU-T. As one of the most
+@@ -493,7 +492,6 @@ config NETFILTER_XT_TARGET_SECMARK
+ 
+ config NETFILTER_XT_TARGET_TCPMSS
+ 	tristate '"TCPMSS" target support'
+-	depends on (IPV6 || IPV6=n)
+ 	default m if NETFILTER_ADVANCED=n
+ 	---help---
+ 	  This option adds a `TCPMSS' target, which allows you to alter the
diff -Nru a/target/linux/generic/patches-2.6.31/200-sched_esfq.patch b/target/linux/generic/patches-2.6.31/200-sched_esfq.patch
--- a/target/linux/generic/patches-2.6.31/200-sched_esfq.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/200-sched_esfq.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,795 @@
+--- a/include/linux/pkt_sched.h
++++ b/include/linux/pkt_sched.h
+@@ -182,8 +182,37 @@ struct tc_sfq_xstats
+  *
+  *	The only reason for this is efficiency, it is possible
+  *	to change these parameters in compile time.
++ *
++ *	If you need to play with these values, use esfq instead.
+  */
+ 
++/* ESFQ section */
++
++enum
++{
++        /* traditional */
++	TCA_SFQ_HASH_CLASSIC,
++	TCA_SFQ_HASH_DST,
++	TCA_SFQ_HASH_SRC,
++	TCA_SFQ_HASH_FWMARK,
++	/* conntrack */
++	TCA_SFQ_HASH_CTORIGDST,
++	TCA_SFQ_HASH_CTORIGSRC,
++	TCA_SFQ_HASH_CTREPLDST,
++	TCA_SFQ_HASH_CTREPLSRC,
++	TCA_SFQ_HASH_CTNATCHG,
++};
++
++struct tc_esfq_qopt
++{
++	unsigned	quantum;	/* Bytes per round allocated to flow */
++	int		perturb_period;	/* Period of hash perturbation */
++	__u32		limit;		/* Maximal packets in queue */
++	unsigned	divisor;	/* Hash divisor  */
++	unsigned	flows;		/* Maximal number of flows  */
++	unsigned	hash_kind;	/* Hash function to use for flow identification */
++};
++
+ /* RED section */
+ 
+ enum
+--- a/net/sched/Kconfig
++++ b/net/sched/Kconfig
+@@ -137,6 +137,37 @@ config NET_SCH_SFQ
+ 	  To compile this code as a module, choose M here: the
+ 	  module will be called sch_sfq.
+ 
++config NET_SCH_ESFQ
++	tristate "Enhanced Stochastic Fairness Queueing (ESFQ)"
++	---help---
++	  Say Y here if you want to use the Enhanced Stochastic Fairness
++	  Queueing (ESFQ) packet scheduling algorithm for some of your network
++	  devices or as a leaf discipline for a classful qdisc such as HTB or
++	  CBQ (see the top of <file:net/sched/sch_esfq.c> for details and
++	  references to the SFQ algorithm).
++
++	  This is an enchanced SFQ version which allows you to control some
++	  hardcoded values in the SFQ scheduler.
++
++	  ESFQ also adds control of the hash function used to identify packet
++	  flows. The original SFQ discipline hashes by connection; ESFQ add
++	  several other hashing methods, such as by src IP or by dst IP, which
++	  can be more fair to users in some networking situations.
++
++	  To compile this code as a module, choose M here: the
++	  module will be called sch_esfq.
++
++config NET_SCH_ESFQ_NFCT
++	bool "Connection Tracking Hash Types"
++	depends on NET_SCH_ESFQ && NF_CONNTRACK
++	---help---
++	  Say Y here to enable support for hashing based on netfilter connection
++	  tracking information. This is useful for a router that is also using
++	  NAT to connect privately-addressed hosts to the Internet. If you want
++	  to provide fair distribution of upstream bandwidth, ESFQ must use
++	  connection tracking information, since all outgoing packets will share
++	  the same source address.
++
+ config NET_SCH_TEQL
+ 	tristate "True Link Equalizer (TEQL)"
+ 	---help---
+--- a/net/sched/Makefile
++++ b/net/sched/Makefile
+@@ -24,6 +24,7 @@ obj-$(CONFIG_NET_SCH_GRED)	+= sch_gred.o
+ obj-$(CONFIG_NET_SCH_INGRESS)	+= sch_ingress.o 
+ obj-$(CONFIG_NET_SCH_DSMARK)	+= sch_dsmark.o
+ obj-$(CONFIG_NET_SCH_SFQ)	+= sch_sfq.o
++obj-$(CONFIG_NET_SCH_ESFQ)	+= sch_esfq.o
+ obj-$(CONFIG_NET_SCH_TBF)	+= sch_tbf.o
+ obj-$(CONFIG_NET_SCH_TEQL)	+= sch_teql.o
+ obj-$(CONFIG_NET_SCH_PRIO)	+= sch_prio.o
+--- /dev/null
++++ b/net/sched/sch_esfq.c
+@@ -0,0 +1,702 @@
++/*
++ * net/sched/sch_esfq.c	Extended Stochastic Fairness Queueing discipline.
++ *
++ *		This program is free software; you can redistribute it and/or
++ *		modify it under the terms of the GNU General Public License
++ *		as published by the Free Software Foundation; either version
++ *		2 of the License, or (at your option) any later version.
++ *
++ * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>
++ *
++ * Changes:	Alexander Atanasov, <alex@ssi.bg>
++ *		Added dynamic depth,limit,divisor,hash_kind options.
++ *		Added dst and src hashes.
++ *
++ * 		Alexander Clouter, <alex@digriz.org.uk>
++ *		Ported ESFQ to Linux 2.6.
++ *
++ * 		Corey Hickey, <bugfood-c@fatooh.org>
++ *		Maintenance of the Linux 2.6 port.
++ *		Added fwmark hash (thanks to Robert Kurjata).
++ *		Added usage of jhash.
++ *		Added conntrack support.
++ *		Added ctnatchg hash (thanks to Ben Pfountz).
++ */
++
++#include <linux/module.h>
++#include <asm/uaccess.h>
++#include <asm/system.h>
++#include <linux/bitops.h>
++#include <linux/types.h>
++#include <linux/kernel.h>
++#include <linux/jiffies.h>
++#include <linux/string.h>
++#include <linux/mm.h>
++#include <linux/socket.h>
++#include <linux/sockios.h>
++#include <linux/in.h>
++#include <linux/errno.h>
++#include <linux/interrupt.h>
++#include <linux/if_ether.h>
++#include <linux/inet.h>
++#include <linux/netdevice.h>
++#include <linux/etherdevice.h>
++#include <linux/notifier.h>
++#include <linux/init.h>
++#include <net/ip.h>
++#include <net/netlink.h>
++#include <linux/ipv6.h>
++#include <net/route.h>
++#include <linux/skbuff.h>
++#include <net/sock.h>
++#include <net/pkt_sched.h>
++#include <linux/jhash.h>
++#ifdef CONFIG_NET_SCH_ESFQ_NFCT
++#include <net/netfilter/nf_conntrack.h>
++#endif
++
++/*	Stochastic Fairness Queuing algorithm.
++	For more comments look at sch_sfq.c.
++	The difference is that you can change limit, depth,
++	hash table size and choose alternate hash types.
++
++	classic:	same as in sch_sfq.c
++	dst:		destination IP address
++	src:		source IP address
++	fwmark:		netfilter mark value
++	ctorigdst:	original destination IP address
++	ctorigsrc:	original source IP address
++	ctrepldst:	reply destination IP address
++	ctreplsrc:	reply source IP
++
++*/
++
++#define ESFQ_HEAD 0
++#define ESFQ_TAIL 1
++
++/* This type should contain at least SFQ_DEPTH*2 values */
++typedef unsigned int esfq_index;
++
++struct esfq_head
++{
++	esfq_index	next;
++	esfq_index	prev;
++};
++
++struct esfq_sched_data
++{
++/* Parameters */
++	int		perturb_period;
++	unsigned	quantum;	/* Allotment per round: MUST BE >= MTU */
++	int		limit;
++	unsigned	depth;
++	unsigned	hash_divisor;
++	unsigned	hash_kind;
++/* Variables */
++	struct timer_list perturb_timer;
++	int		perturbation;
++	esfq_index	tail;		/* Index of current slot in round */
++	esfq_index	max_depth;	/* Maximal depth */
++
++	esfq_index	*ht;			/* Hash table */
++	esfq_index	*next;			/* Active slots link */
++	short		*allot;			/* Current allotment per slot */
++	unsigned short	*hash;			/* Hash value indexed by slots */
++	struct sk_buff_head	*qs;		/* Slot queue */
++	struct esfq_head	*dep;		/* Linked list of slots, indexed by depth */
++};
++
++/* This contains the info we will hash. */
++struct esfq_packet_info
++{
++	u32	proto;		/* protocol or port */
++	u32	src;		/* source from packet header */
++	u32	dst;		/* destination from packet header */
++	u32	ctorigsrc;	/* original source from conntrack */
++	u32	ctorigdst;	/* original destination from conntrack */
++	u32	ctreplsrc;	/* reply source from conntrack */
++	u32	ctrepldst;	/* reply destination from conntrack */
++	u32	mark;		/* netfilter mark (fwmark) */
++};
++
++static __inline__ unsigned esfq_jhash_1word(struct esfq_sched_data *q,u32 a)
++{
++	return jhash_1word(a, q->perturbation) & (q->hash_divisor-1);
++}
++
++static __inline__ unsigned esfq_jhash_2words(struct esfq_sched_data *q, u32 a, u32 b)
++{
++	return jhash_2words(a, b, q->perturbation) & (q->hash_divisor-1);
++}
++
++static __inline__ unsigned esfq_jhash_3words(struct esfq_sched_data *q, u32 a, u32 b, u32 c)
++{
++	return jhash_3words(a, b, c, q->perturbation) & (q->hash_divisor-1);
++}
++
++static unsigned esfq_hash(struct esfq_sched_data *q, struct sk_buff *skb)
++{
++	struct esfq_packet_info info;
++#ifdef CONFIG_NET_SCH_ESFQ_NFCT
++	enum ip_conntrack_info ctinfo;
++	struct nf_conn *ct = nf_ct_get(skb, &ctinfo);
++#endif
++
++	switch (skb->protocol) {
++	case __constant_htons(ETH_P_IP):
++	{
++		struct iphdr *iph = ip_hdr(skb);
++		info.dst = iph->daddr;
++		info.src = iph->saddr;
++		if (!(iph->frag_off&htons(IP_MF|IP_OFFSET)) &&
++		    (iph->protocol == IPPROTO_TCP ||
++		     iph->protocol == IPPROTO_UDP ||
++		     iph->protocol == IPPROTO_SCTP ||
++		     iph->protocol == IPPROTO_DCCP ||
++		     iph->protocol == IPPROTO_ESP))
++			info.proto = *(((u32*)iph) + iph->ihl);
++		else
++			info.proto = iph->protocol;
++		break;
++	}
++	case __constant_htons(ETH_P_IPV6):
++	{
++		struct ipv6hdr *iph = ipv6_hdr(skb);
++		/* Hash ipv6 addresses into a u32. This isn't ideal,
++		 * but the code is simple. */
++		info.dst = jhash2(iph->daddr.s6_addr32, 4, q->perturbation);
++		info.src = jhash2(iph->saddr.s6_addr32, 4, q->perturbation);
++		if (iph->nexthdr == IPPROTO_TCP ||
++		    iph->nexthdr == IPPROTO_UDP ||
++		    iph->nexthdr == IPPROTO_SCTP ||
++		    iph->nexthdr == IPPROTO_DCCP ||
++		    iph->nexthdr == IPPROTO_ESP)
++			info.proto = *(u32*)&iph[1];
++		else
++			info.proto = iph->nexthdr;
++		break;
++	}
++	default:
++		info.dst   = (u32)(unsigned long)skb_dst(skb);
++		info.src   = (u32)(unsigned long)skb->sk;
++		info.proto = skb->protocol;
++	}
++
++	info.mark = skb->mark;
++
++#ifdef CONFIG_NET_SCH_ESFQ_NFCT
++	/* defaults if there is no conntrack info */
++	info.ctorigsrc = info.src;
++	info.ctorigdst = info.dst;
++	info.ctreplsrc = info.dst;
++	info.ctrepldst = info.src;
++	/* collect conntrack info */
++	if (ct && ct != &nf_conntrack_untracked) {
++		if (skb->protocol == __constant_htons(ETH_P_IP)) {
++			info.ctorigsrc = ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple.src.u3.ip;
++			info.ctorigdst = ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple.dst.u3.ip;
++			info.ctreplsrc = ct->tuplehash[IP_CT_DIR_REPLY].tuple.src.u3.ip;
++			info.ctrepldst = ct->tuplehash[IP_CT_DIR_REPLY].tuple.dst.u3.ip;
++		}
++		else if (skb->protocol == __constant_htons(ETH_P_IPV6)) {
++			/* Again, hash ipv6 addresses into a single u32. */
++			info.ctorigsrc = jhash2(ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple.src.u3.ip6, 4, q->perturbation);
++			info.ctorigdst = jhash2(ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple.dst.u3.ip6, 4, q->perturbation);
++			info.ctreplsrc = jhash2(ct->tuplehash[IP_CT_DIR_REPLY].tuple.src.u3.ip6, 4, q->perturbation);
++			info.ctrepldst = jhash2(ct->tuplehash[IP_CT_DIR_REPLY].tuple.dst.u3.ip6, 4, q->perturbation);
++		}
++
++	}
++#endif
++
++	switch(q->hash_kind) {
++	case TCA_SFQ_HASH_CLASSIC:
++		return esfq_jhash_3words(q, info.dst, info.src, info.proto);
++	case TCA_SFQ_HASH_DST:
++		return esfq_jhash_1word(q, info.dst);
++	case TCA_SFQ_HASH_SRC:
++		return esfq_jhash_1word(q, info.src);
++	case TCA_SFQ_HASH_FWMARK:
++		return esfq_jhash_1word(q, info.mark);
++#ifdef CONFIG_NET_SCH_ESFQ_NFCT
++	case TCA_SFQ_HASH_CTORIGDST:
++		return esfq_jhash_1word(q, info.ctorigdst);
++	case TCA_SFQ_HASH_CTORIGSRC:
++		return esfq_jhash_1word(q, info.ctorigsrc);
++	case TCA_SFQ_HASH_CTREPLDST:
++		return esfq_jhash_1word(q, info.ctrepldst);
++	case TCA_SFQ_HASH_CTREPLSRC:
++		return esfq_jhash_1word(q, info.ctreplsrc);
++	case TCA_SFQ_HASH_CTNATCHG:
++	{
++		if (info.ctorigdst == info.ctreplsrc)
++			return esfq_jhash_1word(q, info.ctorigsrc);
++		return esfq_jhash_1word(q, info.ctreplsrc);
++	}
++#endif
++	default:
++		if (net_ratelimit())
++			printk(KERN_WARNING "ESFQ: Unknown hash method. Falling back to classic.\n");
++	}
++	return esfq_jhash_3words(q, info.dst, info.src, info.proto);
++}
++
++static inline void esfq_link(struct esfq_sched_data *q, esfq_index x)
++{
++	esfq_index p, n;
++	int d = q->qs[x].qlen + q->depth;
++
++	p = d;
++	n = q->dep[d].next;
++	q->dep[x].next = n;
++	q->dep[x].prev = p;
++	q->dep[p].next = q->dep[n].prev = x;
++}
++
++static inline void esfq_dec(struct esfq_sched_data *q, esfq_index x)
++{
++	esfq_index p, n;
++
++	n = q->dep[x].next;
++	p = q->dep[x].prev;
++	q->dep[p].next = n;
++	q->dep[n].prev = p;
++
++	if (n == p && q->max_depth == q->qs[x].qlen + 1)
++		q->max_depth--;
++
++	esfq_link(q, x);
++}
++
++static inline void esfq_inc(struct esfq_sched_data *q, esfq_index x)
++{
++	esfq_index p, n;
++	int d;
++
++	n = q->dep[x].next;
++	p = q->dep[x].prev;
++	q->dep[p].next = n;
++	q->dep[n].prev = p;
++	d = q->qs[x].qlen;
++	if (q->max_depth < d)
++		q->max_depth = d;
++
++	esfq_link(q, x);
++}
++
++static unsigned int esfq_drop(struct Qdisc *sch)
++{
++	struct esfq_sched_data *q = qdisc_priv(sch);
++	esfq_index d = q->max_depth;
++	struct sk_buff *skb;
++	unsigned int len;
++
++	/* Queue is full! Find the longest slot and
++	   drop a packet from it */
++
++	if (d > 1) {
++		esfq_index x = q->dep[d+q->depth].next;
++		skb = q->qs[x].prev;
++		len = skb->len;
++		__skb_unlink(skb, &q->qs[x]);
++		kfree_skb(skb);
++		esfq_dec(q, x);
++		sch->q.qlen--;
++		sch->qstats.drops++;
++		sch->qstats.backlog -= len;
++		return len;
++	}
++
++	if (d == 1) {
++		/* It is difficult to believe, but ALL THE SLOTS HAVE LENGTH 1. */
++		d = q->next[q->tail];
++		q->next[q->tail] = q->next[d];
++		q->allot[q->next[d]] += q->quantum;
++		skb = q->qs[d].prev;
++		len = skb->len;
++		__skb_unlink(skb, &q->qs[d]);
++		kfree_skb(skb);
++		esfq_dec(q, d);
++		sch->q.qlen--;
++		q->ht[q->hash[d]] = q->depth;
++		sch->qstats.drops++;
++		sch->qstats.backlog -= len;
++		return len;
++	}
++
++	return 0;
++}
++
++static void esfq_q_enqueue(struct sk_buff *skb, struct esfq_sched_data *q, unsigned int end)
++{
++	unsigned hash = esfq_hash(q, skb);
++	unsigned depth = q->depth;
++	esfq_index x;
++
++	x = q->ht[hash];
++	if (x == depth) {
++		q->ht[hash] = x = q->dep[depth].next;
++		q->hash[x] = hash;
++	}
++
++	if (end == ESFQ_TAIL)
++		__skb_queue_tail(&q->qs[x], skb);
++	else
++		__skb_queue_head(&q->qs[x], skb);
++
++	esfq_inc(q, x);
++	if (q->qs[x].qlen == 1) {		/* The flow is new */
++		if (q->tail == depth) {	/* It is the first flow */
++			q->tail = x;
++			q->next[x] = x;
++			q->allot[x] = q->quantum;
++		} else {
++			q->next[x] = q->next[q->tail];
++			q->next[q->tail] = x;
++			q->tail = x;
++		}
++	}
++}
++
++static int esfq_enqueue(struct sk_buff *skb, struct Qdisc* sch)
++{
++	struct esfq_sched_data *q = qdisc_priv(sch);
++	esfq_q_enqueue(skb, q, ESFQ_TAIL);
++	sch->qstats.backlog += skb->len;
++	if (++sch->q.qlen < q->limit-1) {
++		sch->bstats.bytes += skb->len;
++		sch->bstats.packets++;
++		return 0;
++	}
++
++	sch->qstats.drops++;
++	esfq_drop(sch);
++	return NET_XMIT_CN;
++}
++
++static struct sk_buff *esfq_peek(struct Qdisc* sch)
++{
++	struct esfq_sched_data *q = qdisc_priv(sch);
++	esfq_index a;
++
++	/* No active slots */
++	if (q->tail == q->depth)
++		return NULL;
++
++	a = q->next[q->tail];
++	return skb_peek(&q->qs[a]);
++}
++
++static struct sk_buff *esfq_q_dequeue(struct esfq_sched_data *q)
++{
++	struct sk_buff *skb;
++	unsigned depth = q->depth;
++	esfq_index a, old_a;
++
++	/* No active slots */
++	if (q->tail == depth)
++		return NULL;
++
++	a = old_a = q->next[q->tail];
++
++	/* Grab packet */
++	skb = __skb_dequeue(&q->qs[a]);
++	esfq_dec(q, a);
++
++	/* Is the slot empty? */
++	if (q->qs[a].qlen == 0) {
++		q->ht[q->hash[a]] = depth;
++		a = q->next[a];
++		if (a == old_a) {
++			q->tail = depth;
++			return skb;
++		}
++		q->next[q->tail] = a;
++		q->allot[a] += q->quantum;
++	} else if ((q->allot[a] -= skb->len) <= 0) {
++		q->tail = a;
++		a = q->next[a];
++		q->allot[a] += q->quantum;
++	}
++
++	return skb;
++}
++
++static struct sk_buff *esfq_dequeue(struct Qdisc* sch)
++{
++	struct esfq_sched_data *q = qdisc_priv(sch);
++	struct sk_buff *skb;
++
++	skb = esfq_q_dequeue(q);
++	if (skb == NULL)
++		return NULL;
++	sch->q.qlen--;
++	sch->qstats.backlog -= skb->len;
++	return skb;
++}
++
++static void esfq_q_destroy(struct esfq_sched_data *q)
++{
++	del_timer(&q->perturb_timer);
++	if(q->ht)
++		kfree(q->ht);
++	if(q->dep)
++		kfree(q->dep);
++	if(q->next)
++		kfree(q->next);
++	if(q->allot)
++		kfree(q->allot);
++	if(q->hash)
++		kfree(q->hash);
++	if(q->qs)
++		kfree(q->qs);
++}
++
++static void esfq_destroy(struct Qdisc *sch)
++{
++	struct esfq_sched_data *q = qdisc_priv(sch);
++	esfq_q_destroy(q);
++}
++
++
++static void esfq_reset(struct Qdisc* sch)
++{
++	struct sk_buff *skb;
++
++	while ((skb = esfq_dequeue(sch)) != NULL)
++		kfree_skb(skb);
++}
++
++static void esfq_perturbation(unsigned long arg)
++{
++	struct Qdisc *sch = (struct Qdisc*)arg;
++	struct esfq_sched_data *q = qdisc_priv(sch);
++
++	q->perturbation = net_random()&0x1F;
++
++	if (q->perturb_period) {
++		q->perturb_timer.expires = jiffies + q->perturb_period;
++		add_timer(&q->perturb_timer);
++	}
++}
++
++static unsigned int esfq_check_hash(unsigned int kind)
++{
++	switch (kind) {
++	case TCA_SFQ_HASH_CTORIGDST:
++	case TCA_SFQ_HASH_CTORIGSRC:
++	case TCA_SFQ_HASH_CTREPLDST:
++	case TCA_SFQ_HASH_CTREPLSRC:
++	case TCA_SFQ_HASH_CTNATCHG:
++#ifndef CONFIG_NET_SCH_ESFQ_NFCT
++	{
++		if (net_ratelimit())
++			printk(KERN_WARNING "ESFQ: Conntrack hash types disabled in kernel config. Falling back to classic.\n");
++		return TCA_SFQ_HASH_CLASSIC;
++	}
++#endif
++	case TCA_SFQ_HASH_CLASSIC:
++	case TCA_SFQ_HASH_DST:
++	case TCA_SFQ_HASH_SRC:
++	case TCA_SFQ_HASH_FWMARK:
++		return kind;
++	default:
++	{
++		if (net_ratelimit())
++			printk(KERN_WARNING "ESFQ: Unknown hash type. Falling back to classic.\n");
++		return TCA_SFQ_HASH_CLASSIC;
++	}
++	}
++}
++
++static int esfq_q_init(struct esfq_sched_data *q, struct nlattr *opt)
++{
++	struct tc_esfq_qopt *ctl = nla_data(opt);
++	esfq_index p = ~0U/2;
++	int i;
++
++	if (opt && opt->nla_len < nla_attr_size(sizeof(*ctl)))
++		return -EINVAL;
++
++	q->perturbation = 0;
++	q->hash_kind = TCA_SFQ_HASH_CLASSIC;
++	q->max_depth = 0;
++	if (opt == NULL) {
++		q->perturb_period = 0;
++		q->hash_divisor = 1024;
++		q->tail = q->limit = q->depth = 128;
++
++	} else {
++		struct tc_esfq_qopt *ctl = nla_data(opt);
++		if (ctl->quantum)
++			q->quantum = ctl->quantum;
++		q->perturb_period = ctl->perturb_period*HZ;
++		q->hash_divisor = ctl->divisor ? : 1024;
++		q->tail = q->limit = q->depth = ctl->flows ? : 128;
++
++		if ( q->depth > p - 1 )
++			return -EINVAL;
++
++		if (ctl->limit)
++			q->limit = min_t(u32, ctl->limit, q->depth);
++
++		if (ctl->hash_kind) {
++			q->hash_kind = esfq_check_hash(ctl->hash_kind);
++		}
++	}
++
++	q->ht = kmalloc(q->hash_divisor*sizeof(esfq_index), GFP_KERNEL);
++	if (!q->ht)
++		goto err_case;
++	q->dep = kmalloc((1+q->depth*2)*sizeof(struct esfq_head), GFP_KERNEL);
++	if (!q->dep)
++		goto err_case;
++	q->next = kmalloc(q->depth*sizeof(esfq_index), GFP_KERNEL);
++	if (!q->next)
++		goto err_case;
++	q->allot = kmalloc(q->depth*sizeof(short), GFP_KERNEL);
++	if (!q->allot)
++		goto err_case;
++	q->hash = kmalloc(q->depth*sizeof(unsigned short), GFP_KERNEL);
++	if (!q->hash)
++		goto err_case;
++	q->qs = kmalloc(q->depth*sizeof(struct sk_buff_head), GFP_KERNEL);
++	if (!q->qs)
++		goto err_case;
++
++	for (i=0; i< q->hash_divisor; i++)
++		q->ht[i] = q->depth;
++	for (i=0; i<q->depth; i++) {
++		skb_queue_head_init(&q->qs[i]);
++		q->dep[i+q->depth].next = i+q->depth;
++		q->dep[i+q->depth].prev = i+q->depth;
++	}
++
++	for (i=0; i<q->depth; i++)
++		esfq_link(q, i);
++	return 0;
++err_case:
++	esfq_q_destroy(q);
++	return -ENOBUFS;
++}
++
++static int esfq_init(struct Qdisc *sch, struct nlattr *opt)
++{
++	struct esfq_sched_data *q = qdisc_priv(sch);
++	int err;
++
++	q->quantum = psched_mtu(qdisc_dev(sch)); /* default */
++	if ((err = esfq_q_init(q, opt)))
++		return err;
++
++	init_timer(&q->perturb_timer);
++	q->perturb_timer.data = (unsigned long)sch;
++	q->perturb_timer.function = esfq_perturbation;
++	if (q->perturb_period) {
++		q->perturb_timer.expires = jiffies + q->perturb_period;
++		add_timer(&q->perturb_timer);
++	}
++
++	return 0;
++}
++
++static int esfq_change(struct Qdisc *sch, struct nlattr *opt)
++{
++	struct esfq_sched_data *q = qdisc_priv(sch);
++	struct esfq_sched_data new;
++	struct sk_buff *skb;
++	int err;
++
++	/* set up new queue */
++	memset(&new, 0, sizeof(struct esfq_sched_data));
++	new.quantum = psched_mtu(qdisc_dev(sch)); /* default */
++	if ((err = esfq_q_init(&new, opt)))
++		return err;
++
++	/* copy all packets from the old queue to the new queue */
++	sch_tree_lock(sch);
++	while ((skb = esfq_q_dequeue(q)) != NULL)
++		esfq_q_enqueue(skb, &new, ESFQ_TAIL);
++
++	/* clean up the old queue */
++	esfq_q_destroy(q);
++
++	/* copy elements of the new queue into the old queue */
++	q->perturb_period = new.perturb_period;
++	q->quantum        = new.quantum;
++	q->limit          = new.limit;
++	q->depth          = new.depth;
++	q->hash_divisor   = new.hash_divisor;
++	q->hash_kind      = new.hash_kind;
++	q->tail           = new.tail;
++	q->max_depth      = new.max_depth;
++	q->ht    = new.ht;
++	q->dep   = new.dep;
++	q->next  = new.next;
++	q->allot = new.allot;
++	q->hash  = new.hash;
++	q->qs    = new.qs;
++
++	/* finish up */
++	if (q->perturb_period) {
++		q->perturb_timer.expires = jiffies + q->perturb_period;
++		add_timer(&q->perturb_timer);
++	} else {
++		q->perturbation = 0;
++	}
++	sch_tree_unlock(sch);
++	return 0;
++}
++
++static int esfq_dump(struct Qdisc *sch, struct sk_buff *skb)
++{
++	struct esfq_sched_data *q = qdisc_priv(sch);
++	unsigned char *b = skb_tail_pointer(skb);
++	struct tc_esfq_qopt opt;
++
++	opt.quantum = q->quantum;
++	opt.perturb_period = q->perturb_period/HZ;
++
++	opt.limit = q->limit;
++	opt.divisor = q->hash_divisor;
++	opt.flows = q->depth;
++	opt.hash_kind = q->hash_kind;
++
++	NLA_PUT(skb, TCA_OPTIONS, sizeof(opt), &opt);
++
++	return skb->len;
++
++nla_put_failure:
++	nlmsg_trim(skb, b);
++	return -1;
++}
++
++static struct Qdisc_ops esfq_qdisc_ops =
++{
++	.next		=	NULL,
++	.cl_ops		=	NULL,
++	.id		=	"esfq",
++	.priv_size	=	sizeof(struct esfq_sched_data),
++	.enqueue	=	esfq_enqueue,
++	.dequeue	=	esfq_dequeue,
++	.peek		=	esfq_peek,
++	.drop		=	esfq_drop,
++	.init		=	esfq_init,
++	.reset		=	esfq_reset,
++	.destroy	=	esfq_destroy,
++	.change		=	esfq_change,
++	.dump		=	esfq_dump,
++	.owner		=	THIS_MODULE,
++};
++
++static int __init esfq_module_init(void)
++{
++	return register_qdisc(&esfq_qdisc_ops);
++}
++static void __exit esfq_module_exit(void)
++{
++	unregister_qdisc(&esfq_qdisc_ops);
++}
++module_init(esfq_module_init)
++module_exit(esfq_module_exit)
++MODULE_LICENSE("GPL");
diff -Nru a/target/linux/generic/patches-2.6.31/201-jhash3.patch b/target/linux/generic/patches-2.6.31/201-jhash3.patch
--- a/target/linux/generic/patches-2.6.31/201-jhash3.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/201-jhash3.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,227 @@
+--- a/include/linux/jhash.h
++++ b/include/linux/jhash.h
+@@ -3,80 +3,95 @@
+ 
+ /* jhash.h: Jenkins hash support.
+  *
+- * Copyright (C) 1996 Bob Jenkins (bob_jenkins@burtleburtle.net)
++ * Copyright (C) 2006. Bob Jenkins (bob_jenkins@burtleburtle.net)
+  *
+  * http://burtleburtle.net/bob/hash/
+  *
+  * These are the credits from Bob's sources:
+  *
+- * lookup2.c, by Bob Jenkins, December 1996, Public Domain.
+- * hash(), hash2(), hash3, and mix() are externally useful functions.
+- * Routines to test the hash are included if SELF_TEST is defined.
+- * You can use this free for any purpose.  It has no warranty.
++ * lookup3.c, by Bob Jenkins, May 2006, Public Domain.
+  *
+- * Copyright (C) 2003 David S. Miller (davem@redhat.com)
++ * These are functions for producing 32-bit hashes for hash table lookup.
++ * hashword(), hashlittle(), hashlittle2(), hashbig(), mix(), and final() 
++ * are externally useful functions.  Routines to test the hash are included 
++ * if SELF_TEST is defined.  You can use this free for any purpose.  It's in
++ * the public domain.  It has no warranty.
++ *
++ * Copyright (C) 2009 Jozsef Kadlecsik (kadlec@blackhole.kfki.hu)
+  *
+  * I've modified Bob's hash to be useful in the Linux kernel, and
+- * any bugs present are surely my fault.  -DaveM
++ * any bugs present are my fault.  Jozsef
+  */
+ 
+-/* NOTE: Arguments are modified. */
+-#define __jhash_mix(a, b, c) \
++#define __rot(x,k) (((x)<<(k)) | ((x)>>(32-(k))))
++
++/* __jhash_mix - mix 3 32-bit values reversibly. */
++#define __jhash_mix(a,b,c) \
++{ \
++  a -= c;  a ^= __rot(c, 4);  c += b; \
++  b -= a;  b ^= __rot(a, 6);  a += c; \
++  c -= b;  c ^= __rot(b, 8);  b += a; \
++  a -= c;  a ^= __rot(c,16);  c += b; \
++  b -= a;  b ^= __rot(a,19);  a += c; \
++  c -= b;  c ^= __rot(b, 4);  b += a; \
++}
++
++/* __jhash_final - final mixing of 3 32-bit values (a,b,c) into c */
++#define __jhash_final(a,b,c) \
+ { \
+-  a -= b; a -= c; a ^= (c>>13); \
+-  b -= c; b -= a; b ^= (a<<8); \
+-  c -= a; c -= b; c ^= (b>>13); \
+-  a -= b; a -= c; a ^= (c>>12);  \
+-  b -= c; b -= a; b ^= (a<<16); \
+-  c -= a; c -= b; c ^= (b>>5); \
+-  a -= b; a -= c; a ^= (c>>3);  \
+-  b -= c; b -= a; b ^= (a<<10); \
+-  c -= a; c -= b; c ^= (b>>15); \
++  c ^= b; c -= __rot(b,14); \
++  a ^= c; a -= __rot(c,11); \
++  b ^= a; b -= __rot(a,25); \
++  c ^= b; c -= __rot(b,16); \
++  a ^= c; a -= __rot(c,4);  \
++  b ^= a; b -= __rot(a,14); \
++  c ^= b; c -= __rot(b,24); \
+ }
+ 
+-/* The golden ration: an arbitrary value */
+-#define JHASH_GOLDEN_RATIO	0x9e3779b9
++/* An arbitrary initial parameter */
++#define JHASH_GOLDEN_RATIO	0xdeadbeef
+ 
+ /* The most generic version, hashes an arbitrary sequence
+  * of bytes.  No alignment or length assumptions are made about
+- * the input key.
++ * the input key. The result depends on endianness.
+  */
+ static inline u32 jhash(const void *key, u32 length, u32 initval)
+ {
+-	u32 a, b, c, len;
++	u32 a,b,c;
+ 	const u8 *k = key;
+ 
+-	len = length;
+-	a = b = JHASH_GOLDEN_RATIO;
+-	c = initval;
+-
+-	while (len >= 12) {
+-		a += (k[0] +((u32)k[1]<<8) +((u32)k[2]<<16) +((u32)k[3]<<24));
+-		b += (k[4] +((u32)k[5]<<8) +((u32)k[6]<<16) +((u32)k[7]<<24));
+-		c += (k[8] +((u32)k[9]<<8) +((u32)k[10]<<16)+((u32)k[11]<<24));
+-
+-		__jhash_mix(a,b,c);
++	/* Set up the internal state */
++	a = b = c = JHASH_GOLDEN_RATIO + length + initval;
+ 
++	/* all but the last block: affect some 32 bits of (a,b,c) */
++	while (length > 12) {
++    		a += (k[0] + ((u32)k[1]<<8) + ((u32)k[2]<<16) + ((u32)k[3]<<24));
++		b += (k[4] + ((u32)k[5]<<8) + ((u32)k[6]<<16) + ((u32)k[7]<<24));
++		c += (k[8] + ((u32)k[9]<<8) + ((u32)k[10]<<16) + ((u32)k[11]<<24));
++		__jhash_mix(a, b, c);
++		length -= 12;
+ 		k += 12;
+-		len -= 12;
+ 	}
+ 
+-	c += length;
+-	switch (len) {
+-	case 11: c += ((u32)k[10]<<24);
+-	case 10: c += ((u32)k[9]<<16);
+-	case 9 : c += ((u32)k[8]<<8);
+-	case 8 : b += ((u32)k[7]<<24);
+-	case 7 : b += ((u32)k[6]<<16);
+-	case 6 : b += ((u32)k[5]<<8);
++	/* last block: affect all 32 bits of (c) */
++	/* all the case statements fall through */
++	switch (length) {
++	case 12: c += (u32)k[11]<<24;
++	case 11: c += (u32)k[10]<<16;
++	case 10: c += (u32)k[9]<<8;
++	case 9 : c += k[8];
++	case 8 : b += (u32)k[7]<<24;
++	case 7 : b += (u32)k[6]<<16;
++	case 6 : b += (u32)k[5]<<8;
+ 	case 5 : b += k[4];
+-	case 4 : a += ((u32)k[3]<<24);
+-	case 3 : a += ((u32)k[2]<<16);
+-	case 2 : a += ((u32)k[1]<<8);
++	case 4 : a += (u32)k[3]<<24;
++	case 3 : a += (u32)k[2]<<16;
++	case 2 : a += (u32)k[1]<<8;
+ 	case 1 : a += k[0];
+-	};
+-
+-	__jhash_mix(a,b,c);
++		__jhash_final(a, b, c);
++	case 0 :
++		break;
++	}
+ 
+ 	return c;
+ }
+@@ -86,58 +101,57 @@ static inline u32 jhash(const void *key,
+  */
+ static inline u32 jhash2(const u32 *k, u32 length, u32 initval)
+ {
+-	u32 a, b, c, len;
++	u32 a, b, c;
+ 
+-	a = b = JHASH_GOLDEN_RATIO;
+-	c = initval;
+-	len = length;
++	/* Set up the internal state */
++	a = b = c = JHASH_GOLDEN_RATIO + (length<<2) + initval;
+ 
+-	while (len >= 3) {
++	/* handle most of the key */
++	while (length > 3) {
+ 		a += k[0];
+ 		b += k[1];
+ 		c += k[2];
+ 		__jhash_mix(a, b, c);
+-		k += 3; len -= 3;
++		length -= 3;
++		k += 3;
+ 	}
+ 
+-	c += length * 4;
+-
+-	switch (len) {
+-	case 2 : b += k[1];
+-	case 1 : a += k[0];
+-	};
+-
+-	__jhash_mix(a,b,c);
++	/* handle the last 3 u32's */
++	/* all the case statements fall through */ 
++	switch (length) {
++	case 3: c += k[2];
++	case 2: b += k[1];
++	case 1: a += k[0];
++		__jhash_final(a, b, c);
++	case 0:     /* case 0: nothing left to add */
++		break;
++	}
+ 
+ 	return c;
+ }
+ 
+-
+ /* A special ultra-optimized versions that knows they are hashing exactly
+  * 3, 2 or 1 word(s).
+- *
+- * NOTE: In partilar the "c += length; __jhash_mix(a,b,c);" normally
+- *       done at the end is not done here.
+  */
+ static inline u32 jhash_3words(u32 a, u32 b, u32 c, u32 initval)
+ {
+-	a += JHASH_GOLDEN_RATIO;
+-	b += JHASH_GOLDEN_RATIO;
+-	c += initval;
++	a += JHASH_GOLDEN_RATIO + initval;
++	b += JHASH_GOLDEN_RATIO + initval;
++	c += JHASH_GOLDEN_RATIO + initval;
+ 
+-	__jhash_mix(a, b, c);
++	__jhash_final(a, b, c);
+ 
+ 	return c;
+ }
+ 
+ static inline u32 jhash_2words(u32 a, u32 b, u32 initval)
+ {
+-	return jhash_3words(a, b, 0, initval);
++	return jhash_3words(0, a, b, initval);
+ }
+ 
+ static inline u32 jhash_1word(u32 a, u32 initval)
+ {
+-	return jhash_3words(a, 0, 0, initval);
++	return jhash_3words(0, 0, a, initval);
+ }
+ 
+ #endif /* _LINUX_JHASH_H */
diff -Nru a/target/linux/generic/patches-2.6.31/202-mips_mem_functions_performance.patch b/target/linux/generic/patches-2.6.31/202-mips_mem_functions_performance.patch
--- a/target/linux/generic/patches-2.6.31/202-mips_mem_functions_performance.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/202-mips_mem_functions_performance.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,83 @@
+--- a/arch/mips/include/asm/string.h
++++ b/arch/mips/include/asm/string.h
+@@ -133,11 +133,44 @@ strncmp(__const__ char *__cs, __const__
+ 
+ #define __HAVE_ARCH_MEMSET
+ extern void *memset(void *__s, int __c, size_t __count);
++#define memset(__s, __c, len)					\
++({								\
++	size_t __len = (len);					\
++	void *__ret;						\
++	if (__builtin_constant_p(len) && __len >= 64)		\
++		__ret = memset((__s), (__c), __len);		\
++	else							\
++		__ret = __builtin_memset((__s), (__c), __len);	\
++	__ret;							\
++})
+ 
+ #define __HAVE_ARCH_MEMCPY
+ extern void *memcpy(void *__to, __const__ void *__from, size_t __n);
++#define memcpy(dst, src, len)					\
++({								\
++	size_t __len = (len);					\
++	void *__ret;						\
++	if (__builtin_constant_p(len) && __len >= 64)		\
++		__ret = memcpy((dst), (src), __len);		\
++	else							\
++		__ret = __builtin_memcpy((dst), (src), __len);	\
++	__ret;							\
++})
+ 
+ #define __HAVE_ARCH_MEMMOVE
+ extern void *memmove(void *__dest, __const__ void *__src, size_t __n);
++#define memmove(dst, src, len)					\
++({								\
++	size_t __len = (len);					\
++	void *__ret;						\
++	if (__builtin_constant_p(len) && __len >= 64)		\
++		__ret = memmove((dst), (src), __len);		\
++	else							\
++		__ret = __builtin_memmove((dst), (src), __len);	\
++	__ret;							\
++})
++
++#define __HAVE_ARCH_MEMCMP
++#define memcmp(src1, src2, len) __builtin_memcmp((src1), (src2), (len))
+ 
+ #endif /* _ASM_STRING_H */
+--- a/arch/mips/lib/Makefile
++++ b/arch/mips/lib/Makefile
+@@ -3,7 +3,7 @@
+ #
+ 
+ lib-y	+= csum_partial.o delay.o memcpy.o memcpy-inatomic.o memset.o \
+-	   strlen_user.o strncpy_user.o strnlen_user.o uncached.o
++	   strlen_user.o strncpy_user.o strnlen_user.o uncached.o memcmp.o
+ 
+ obj-y			+= iomap.o
+ obj-$(CONFIG_PCI)	+= iomap-pci.o
+--- /dev/null
++++ b/arch/mips/lib/memcmp.c
+@@ -0,0 +1,22 @@
++/*
++ *  copied from linux/lib/string.c
++ *
++ *  Copyright (C) 1991, 1992  Linus Torvalds
++ */
++
++#include <linux/module.h>
++#include <linux/string.h>
++
++#undef memcmp
++int memcmp(const void *cs, const void *ct, size_t count)
++{
++	const unsigned char *su1, *su2;
++	int res = 0;
++
++	for (su1 = cs, su2 = ct; 0 < count; ++su1, ++su2, count--)
++		if ((res = *su1 - *su2) != 0)
++			break;
++	return res;
++}
++EXPORT_SYMBOL(memcmp);
++
diff -Nru a/target/linux/generic/patches-2.6.31/203-slab_maxsize.patch b/target/linux/generic/patches-2.6.31/203-slab_maxsize.patch
--- a/target/linux/generic/patches-2.6.31/203-slab_maxsize.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/203-slab_maxsize.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,13 @@
+--- a/include/linux/slab.h
++++ b/include/linux/slab.h
+@@ -124,8 +124,8 @@ int kmem_ptr_validate(struct kmem_cache
+  * to do various tricks to work around compiler limitations in order to
+  * ensure proper constant folding.
+  */
+-#define KMALLOC_SHIFT_HIGH	((MAX_ORDER + PAGE_SHIFT - 1) <= 25 ? \
+-				(MAX_ORDER + PAGE_SHIFT - 1) : 25)
++#define KMALLOC_SHIFT_HIGH	((MAX_ORDER + PAGE_SHIFT - 1) <= 17 ? \
++				(MAX_ORDER + PAGE_SHIFT - 1) : 17)
+ 
+ #define KMALLOC_MAX_SIZE	(1UL << KMALLOC_SHIFT_HIGH)
+ #define KMALLOC_MAX_ORDER	(KMALLOC_SHIFT_HIGH - PAGE_SHIFT)
diff -Nru a/target/linux/generic/patches-2.6.31/204-jffs2_eofdetect.patch b/target/linux/generic/patches-2.6.31/204-jffs2_eofdetect.patch
--- a/target/linux/generic/patches-2.6.31/204-jffs2_eofdetect.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/204-jffs2_eofdetect.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,132 @@
+--- a/fs/jffs2/build.c
++++ b/fs/jffs2/build.c
+@@ -111,6 +111,17 @@ static int jffs2_build_filesystem(struct
+ 	dbg_fsbuild("scanned flash completely\n");
+ 	jffs2_dbg_dump_block_lists_nolock(c);
+ 
++	if (c->flags & (1 << 7)) {
++		printk("%s(): unlocking the mtd device... ", __func__);
++		if (c->mtd->unlock)
++			c->mtd->unlock(c->mtd, 0, c->mtd->size);
++		printk("done.\n");
++
++		printk("%s(): erasing all blocks after the end marker... ", __func__);
++		jffs2_erase_pending_blocks(c, -1);
++		printk("done.\n");
++	}
++
+ 	dbg_fsbuild("pass 1 starting\n");
+ 	c->flags |= JFFS2_SB_FLAG_BUILDING;
+ 	/* Now scan the directory tree, increasing nlink according to every dirent found. */
+--- a/fs/jffs2/scan.c
++++ b/fs/jffs2/scan.c
+@@ -72,7 +72,7 @@ static int file_dirty(struct jffs2_sb_in
+ 		return ret;
+ 	if ((ret = jffs2_scan_dirty_space(c, jeb, jeb->free_size)))
+ 		return ret;
+-	/* Turned wasted size into dirty, since we apparently 
++	/* Turned wasted size into dirty, since we apparently
+ 	   think it's recoverable now. */
+ 	jeb->dirty_size += jeb->wasted_size;
+ 	c->dirty_size += jeb->wasted_size;
+@@ -144,8 +144,11 @@ int jffs2_scan_medium(struct jffs2_sb_in
+ 		/* reset summary info for next eraseblock scan */
+ 		jffs2_sum_reset_collected(s);
+ 
+-		ret = jffs2_scan_eraseblock(c, jeb, buf_size?flashbuf:(flashbuf+jeb->offset),
+-						buf_size, s);
++		if (c->flags & (1 << 7))
++			ret = BLK_STATE_ALLFF;
++		else
++			ret = jffs2_scan_eraseblock(c, jeb, buf_size?flashbuf:(flashbuf+jeb->offset),
++							buf_size, s);
+ 
+ 		if (ret < 0)
+ 			goto out;
+@@ -400,7 +403,7 @@ static int jffs2_scan_xref_node(struct j
+ 	if (!ref)
+ 		return -ENOMEM;
+ 
+-	/* BEFORE jffs2_build_xattr_subsystem() called, 
++	/* BEFORE jffs2_build_xattr_subsystem() called,
+ 	 * and AFTER xattr_ref is marked as a dead xref,
+ 	 * ref->xid is used to store 32bit xid, xd is not used
+ 	 * ref->ino is used to store 32bit inode-number, ic is not used
+@@ -473,7 +476,7 @@ static int jffs2_scan_eraseblock (struct
+ 		struct jffs2_sum_marker *sm;
+ 		void *sumptr = NULL;
+ 		uint32_t sumlen;
+-	      
++
+ 		if (!buf_size) {
+ 			/* XIP case. Just look, point at the summary if it's there */
+ 			sm = (void *)buf + c->sector_size - sizeof(*sm);
+@@ -489,9 +492,9 @@ static int jffs2_scan_eraseblock (struct
+ 				buf_len = sizeof(*sm);
+ 
+ 			/* Read as much as we want into the _end_ of the preallocated buffer */
+-			err = jffs2_fill_scan_buf(c, buf + buf_size - buf_len, 
++			err = jffs2_fill_scan_buf(c, buf + buf_size - buf_len,
+ 						  jeb->offset + c->sector_size - buf_len,
+-						  buf_len);				
++						  buf_len);
+ 			if (err)
+ 				return err;
+ 
+@@ -510,9 +513,9 @@ static int jffs2_scan_eraseblock (struct
+ 				}
+ 				if (buf_len < sumlen) {
+ 					/* Need to read more so that the entire summary node is present */
+-					err = jffs2_fill_scan_buf(c, sumptr, 
++					err = jffs2_fill_scan_buf(c, sumptr,
+ 								  jeb->offset + c->sector_size - sumlen,
+-								  sumlen - buf_len);				
++								  sumlen - buf_len);
+ 					if (err)
+ 						return err;
+ 				}
+@@ -525,7 +528,7 @@ static int jffs2_scan_eraseblock (struct
+ 
+ 			if (buf_size && sumlen > buf_size)
+ 				kfree(sumptr);
+-			/* If it returns with a real error, bail. 
++			/* If it returns with a real error, bail.
+ 			   If it returns positive, that's a block classification
+ 			   (i.e. BLK_STATE_xxx) so return that too.
+ 			   If it returns zero, fall through to full scan. */
+@@ -546,6 +549,17 @@ static int jffs2_scan_eraseblock (struct
+ 			return err;
+ 	}
+ 
++	if ((buf[0] == 0xde) &&
++		(buf[1] == 0xad) &&
++		(buf[2] == 0xc0) &&
++		(buf[3] == 0xde)) {
++		/* end of filesystem. erase everything after this point */
++		printk("%s(): End of filesystem marker found at 0x%x\n", __func__, jeb->offset);
++		c->flags |= (1 << 7);
++
++		return BLK_STATE_ALLFF;
++	}
++
+ 	/* We temporarily use 'ofs' as a pointer into the buffer/jeb */
+ 	ofs = 0;
+ 
+@@ -671,7 +685,7 @@ scan_more:
+ 				scan_end = buf_len;
+ 				goto more_empty;
+ 			}
+-			
++
+ 			/* See how much more there is to read in this eraseblock... */
+ 			buf_len = min_t(uint32_t, buf_size, jeb->offset + c->sector_size - ofs);
+ 			if (!buf_len) {
+@@ -907,7 +921,7 @@ scan_more:
+ 
+ 	D1(printk(KERN_DEBUG "Block at 0x%08x: free 0x%08x, dirty 0x%08x, unchecked 0x%08x, used 0x%08x, wasted 0x%08x\n",
+ 		  jeb->offset,jeb->free_size, jeb->dirty_size, jeb->unchecked_size, jeb->used_size, jeb->wasted_size));
+-	
++
+ 	/* mark_node_obsolete can add to wasted !! */
+ 	if (jeb->wasted_size) {
+ 		jeb->dirty_size += jeb->wasted_size;
diff -Nru a/target/linux/generic/patches-2.6.31/205-skb_padding.patch b/target/linux/generic/patches-2.6.31/205-skb_padding.patch
--- a/target/linux/generic/patches-2.6.31/205-skb_padding.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/205-skb_padding.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,56 @@
+--- a/include/linux/skbuff.h
++++ b/include/linux/skbuff.h
+@@ -1369,11 +1369,18 @@ static inline int skb_network_offset(con
+  *
+  * Various parts of the networking layer expect at least 32 bytes of
+  * headroom, you should not reduce this.
++ *
++ * This has been changed to 64 to acommodate for routing between ethernet
++ * and wireless, but only for new allocations
+  */
+ #ifndef NET_SKB_PAD
+ #define NET_SKB_PAD	32
+ #endif
+ 
++#ifndef NET_SKB_PAD_ALLOC
++#define NET_SKB_PAD_ALLOC	64
++#endif
++
+ extern int ___pskb_trim(struct sk_buff *skb, unsigned int len);
+ 
+ static inline void __skb_trim(struct sk_buff *skb, unsigned int len)
+@@ -1463,9 +1470,9 @@ static inline void __skb_queue_purge(str
+ static inline struct sk_buff *__dev_alloc_skb(unsigned int length,
+ 					      gfp_t gfp_mask)
+ {
+-	struct sk_buff *skb = alloc_skb(length + NET_SKB_PAD, gfp_mask);
++	struct sk_buff *skb = alloc_skb(length + NET_SKB_PAD_ALLOC, gfp_mask);
+ 	if (likely(skb))
+-		skb_reserve(skb, NET_SKB_PAD);
++		skb_reserve(skb, NET_SKB_PAD_ALLOC);
+ 	return skb;
+ }
+ 
+@@ -1538,7 +1545,7 @@ static inline int __skb_cow(struct sk_bu
+ 		delta = headroom - skb_headroom(skb);
+ 
+ 	if (delta || cloned)
+-		return pskb_expand_head(skb, ALIGN(delta, NET_SKB_PAD), 0,
++		return pskb_expand_head(skb, ALIGN(delta, NET_SKB_PAD_ALLOC), 0,
+ 					GFP_ATOMIC);
+ 	return 0;
+ }
+--- a/net/core/skbuff.c
++++ b/net/core/skbuff.c
+@@ -259,9 +259,9 @@ struct sk_buff *__netdev_alloc_skb(struc
+ 	int node = dev->dev.parent ? dev_to_node(dev->dev.parent) : -1;
+ 	struct sk_buff *skb;
+ 
+-	skb = __alloc_skb(length + NET_SKB_PAD, gfp_mask, 0, node);
++	skb = __alloc_skb(length + NET_SKB_PAD_ALLOC, gfp_mask, 0, node);
+ 	if (likely(skb)) {
+-		skb_reserve(skb, NET_SKB_PAD);
++		skb_reserve(skb, NET_SKB_PAD_ALLOC);
+ 		skb->dev = dev;
+ 	}
+ 	return skb;
diff -Nru a/target/linux/generic/patches-2.6.31/207-powerpc_asm_segment_h.patch b/target/linux/generic/patches-2.6.31/207-powerpc_asm_segment_h.patch
--- a/target/linux/generic/patches-2.6.31/207-powerpc_asm_segment_h.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/207-powerpc_asm_segment_h.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,9 @@
+--- /dev/null
++++ b/include/asm-powerpc/segment.h
+@@ -0,0 +1,6 @@
++#ifndef _ASM_SEGMENT_H
++#define _ASM_SEGMENT_H
++
++/* Only here because we have some old header files that expect it.. */
++
++#endif /* _ASM_SEGMENT_H */
diff -Nru a/target/linux/generic/patches-2.6.31/209-mini_fo.patch b/target/linux/generic/patches-2.6.31/209-mini_fo.patch
--- a/target/linux/generic/patches-2.6.31/209-mini_fo.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/209-mini_fo.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,7780 @@
+--- a/fs/Kconfig
++++ b/fs/Kconfig
+@@ -178,6 +178,7 @@ source "fs/ubifs/Kconfig"
+ source "fs/cramfs/Kconfig"
+ source "fs/squashfs/Kconfig"
+ source "fs/freevxfs/Kconfig"
++source "fs/mini_fo/Kconfig"
+ source "fs/minix/Kconfig"
+ source "fs/omfs/Kconfig"
+ source "fs/hpfs/Kconfig"
+--- a/fs/Makefile
++++ b/fs/Makefile
+@@ -77,6 +77,7 @@ obj-$(CONFIG_SQUASHFS)		+= squashfs/
+ obj-y				+= ramfs/
+ obj-$(CONFIG_HUGETLBFS)		+= hugetlbfs/
+ obj-$(CONFIG_CODA_FS)		+= coda/
++obj-$(CONFIG_MINI_FO)		+= mini_fo/
+ obj-$(CONFIG_MINIX_FS)		+= minix/
+ obj-$(CONFIG_FAT_FS)		+= fat/
+ obj-$(CONFIG_BFS_FS)		+= bfs/
+--- /dev/null
++++ b/fs/mini_fo/aux.c
+@@ -0,0 +1,577 @@
++/*
++ * Copyright (c) 1997-2003 Erez Zadok
++ * Copyright (c) 2001-2003 Stony Brook University
++ *
++ * For specific licensing information, see the COPYING file distributed with
++ * this package, or get one from ftp://ftp.filesystems.org/pub/fist/COPYING.
++ *
++ * This Copyright notice must be kept intact and distributed with all
++ * fistgen sources INCLUDING sources generated by fistgen.
++ */
++/*
++ * Copyright (C) 2004, 2005 Markus Klotzbuecher <mk@creamnet.de>
++ *
++ * This program is free software; you can redistribute it and/or
++ * modify it under the terms of the GNU General Public License
++ * as published by the Free Software Foundation; either version
++ * 2 of the License, or (at your option) any later version.
++ */
++/*
++ *  $Id$
++ */
++
++#ifdef HAVE_CONFIG_H
++# include <config.h>
++#endif
++
++#include "fist.h"
++#include "mini_fo.h"
++
++/* check if file exists in storage  */
++int exists_in_storage(dentry_t *dentry)
++{
++	check_mini_fo_dentry(dentry);
++	if(dtost(dentry) == MODIFIED || dtost(dentry) == CREATED || dtost(dentry) == DEL_REWRITTEN)
++		return 1;
++	return 0;
++}
++
++/* check if dentry is in an existing state */
++int is_mini_fo_existant(dentry_t *dentry)
++{
++	check_mini_fo_dentry(dentry);
++
++	if(dtost(dentry) == DELETED || dtost(dentry) == NON_EXISTANT)
++		return 0;
++	else
++		return 1;
++}
++
++/*
++ * This function will create a negative storage dentry for
++ * dentry, what is required for many create like options.
++ * It will create the storage structure if necessary.
++ */
++int get_neg_sto_dentry(dentry_t *dentry)
++{
++	int err = 0;
++	unsigned int len;
++	const unsigned char *name;
++
++	if(!dentry ||
++	   !dtopd(dentry) ||
++	   !(dtost(dentry) == UNMODIFIED ||
++	     dtost(dentry) == NON_EXISTANT ||
++	     dtost(dentry) == DELETED)) {
++		printk(KERN_CRIT "mini_fo: get_neg_sto_dentry: invalid dentry passed.\n");
++		err = -1;
++		goto out;
++	}
++	/* Have we got a neg. dentry already? */
++	if(dtohd2(dentry)) {
++		err = 0;
++		goto out;
++	}
++	if(dtost(dentry->d_parent) == UNMODIFIED) {
++		/* build sto struct */
++		err = build_sto_structure(dentry->d_parent->d_parent, dentry->d_parent);
++		if(err ||
++		   dtost(dentry->d_parent) != MODIFIED) {
++			printk(KERN_CRIT "mini_fo: get_neg_sto_dentry: ERROR building sto structure.\n");
++			err = -1;
++			goto out;
++		}
++	}
++
++	len = dentry->d_name.len;
++	name = dentry->d_name.name;
++
++	dtohd2(dentry) =
++		lookup_one_len(name, dtohd2(dentry->d_parent), len);
++
++ out:
++	return err;
++}
++
++int check_mini_fo_dentry(dentry_t *dentry)
++{
++ 	ASSERT(dentry != NULL);
++	ASSERT(dtopd(dentry) != NULL);
++	ASSERT((dtohd(dentry) != NULL) || (dtohd2(dentry) != NULL));
++
++/* 	if(dtost(dentry) == MODIFIED) { */
++/* 		ASSERT(dentry->d_inode != NULL); */
++/* 		ASSERT(dtohd(dentry) != NULL); */
++/* 		ASSERT(dtohd(dentry)->d_inode != NULL); */
++/* 		ASSERT(dtohd2(dentry) != NULL); */
++/* 		ASSERT(dtohd2(dentry)->d_inode != NULL); */
++/* 	} */
++/* 	else if(dtost(dentry) == UNMODIFIED) { */
++/* 		ASSERT(dentry->d_inode != NULL); */
++/* 		ASSERT( */
++/* 	} */
++	return 0;
++}
++
++int check_mini_fo_file(file_t *file)
++{
++	ASSERT(file != NULL);
++	ASSERT(ftopd(file) != NULL);
++	ASSERT(file->f_dentry != NULL);
++
++	/* violent checking, check depending of state and type
++	 *	if(S_ISDIR(file->f_dentry->d_inode->i_mode)) {}
++	 */
++	ASSERT((ftohf(file) != NULL) || (ftohf2(file) != NULL));
++	return 0;
++}
++
++int check_mini_fo_inode(inode_t *inode)
++{
++	ASSERT(inode != NULL);
++	ASSERT(itopd(inode) != NULL);
++	ASSERT((itohi(inode) != NULL) || (itohi2(inode) != NULL));
++	return 0;
++}
++
++/*
++ * will walk a base path as provided by get_mini_fo_bpath and return
++ * the (hopefully ;-) ) positive dentry of the renamed base dir.
++ *
++ * This does some work of path_init.
++ */
++dentry_t *bpath_walk(super_block_t *sb, char *bpath)
++{
++	int err;
++        struct vfsmount *mnt;
++	struct nameidata nd;
++
++	/* be paranoid */
++	if(!bpath || bpath[0] != '/') {
++		printk(KERN_CRIT "mini_fo: bpath_walk: Invalid string.\n");
++		return NULL;
++	}
++	if(!sb || !stopd(sb)) {
++		printk(KERN_CRIT "mini_fo: bpath_walk: Invalid sb.\n");
++		return NULL;
++	}
++
++	/* fix this: how do I reach this lock?
++	 * read_lock(&current->fs->lock); */
++	mnt = mntget(stopd(sb)->hidden_mnt);
++	/* read_unlock(&current->fs->lock); */
++
++	err = vfs_path_lookup(mnt->mnt_root, mnt, bpath+1, 0, &nd);
++
++	/* validate */
++	if (err || !nd.dentry || !nd.dentry->d_inode) {
++		printk(KERN_CRIT "mini_fo: bpath_walk: path_walk failed.\n");
++		return NULL;
++	}
++	return nd.dentry;
++}
++
++
++/* returns the full path of the basefile incl. its name */
++int get_mini_fo_bpath(dentry_t *dentry, char **bpath, int *bpath_len)
++{
++	char *buf_walker;
++	int len = 0;
++	dentry_t *sky_walker;
++
++	if(!dentry || !dtohd(dentry)) {
++		printk(KERN_CRIT "mini_fo: get_mini_fo_bpath: invalid dentry passed.\n");
++		return -1;
++	}
++	sky_walker = dtohd(dentry);
++
++	do {
++		len += sky_walker->d_name.len + 1 ; /* 1 for '/' */
++		sky_walker = sky_walker->d_parent;
++	} while(sky_walker != stopd(dentry->d_inode->i_sb)->base_dir_dentry);
++
++	/* 1 to oil the loop */
++	*bpath = (char*)  kmalloc(len + 1, GFP_KERNEL);
++	if(!*bpath) {
++		printk(KERN_CRIT "mini_fo: get_mini_fo_bpath: out of mem.\n");
++		return -1;
++	}
++	buf_walker = *bpath+len; /* put it on last char */
++	*buf_walker = '\n';
++	sky_walker = dtohd(dentry);
++
++	do {
++		buf_walker -= sky_walker->d_name.len;
++		strncpy(buf_walker,
++			sky_walker->d_name.name,
++			sky_walker->d_name.len);
++		*(--buf_walker) = '/';
++		sky_walker = sky_walker->d_parent;
++	} while(sky_walker != stopd(dentry->d_inode->i_sb)->base_dir_dentry);
++
++	/* bpath_len doesn't count newline! */
++	*bpath_len = len;
++ 	return 0;
++}
++
++int mini_fo_cp_cont(dentry_t *tgt_dentry, struct vfsmount *tgt_mnt,
++		    dentry_t *src_dentry, struct vfsmount *src_mnt)
++{
++	void *buf;
++	mm_segment_t old_fs;
++	file_t *tgt_file;
++	file_t *src_file;
++	int bytes, len, tmp, err;
++	err = 0;
++
++	if(!(tgt_dentry->d_inode && src_dentry->d_inode)) {
++		printk(KERN_CRIT "mini_fo_cp_cont: ERROR, neg. dentry passed.\n");
++		err = -EINVAL;
++		goto out;
++	}
++
++	dget(tgt_dentry);
++	dget(src_dentry);
++	mntget(tgt_mnt);
++	mntget(src_mnt);
++
++	/* open file write only */
++	tgt_file = dentry_open(tgt_dentry, tgt_mnt, 0x1);
++	if(!tgt_file || IS_ERR(tgt_file)) {
++		printk(KERN_CRIT "mini_fo_cp_cont: ERROR opening target file.\n");
++		err = PTR_ERR(tgt_file);
++		goto out_err;
++	}
++
++	/* open file read only */
++	src_file = dentry_open(src_dentry, src_mnt, 0x0);
++	if(!src_file || IS_ERR(src_file)) {
++		printk(KERN_CRIT "mini_fo_cp_cont: ERROR opening source file.\n");
++		err = PTR_ERR(src_file);
++
++		/* close target file */
++		fput(tgt_file);
++		goto out_err;
++	}
++
++	/* check if the filesystem(s) support read respective write */
++	if(!src_file->f_op->read || !tgt_file->f_op->write) {
++		printk(KERN_CRIT "mini_fo_cp_cont: ERROR, no fs read or write support.\n");
++		err = -EPERM;
++		goto out_close;
++	}
++
++	/* allocate a page for transfering the data */
++	buf = (void *) __get_free_page(GFP_KERNEL);
++	if(!buf) {
++		printk(KERN_CRIT "mini_fo_cp_cont: ERROR, out of kernel mem.\n");
++		goto out_err;
++	}
++
++	tgt_file->f_pos = 0;
++	src_file->f_pos = 0;
++
++	old_fs = get_fs();
++	set_fs(KERNEL_DS);
++
++	/* Doing this I assume that a read operation will return a full
++	 * buffer while there is still data to read, and a less than
++	 * full buffer when all data has been read.
++	 */
++	bytes = len = PAGE_SIZE;
++	while(bytes == len) {
++		bytes = src_file->f_op->read(src_file, buf, len,
++					     &src_file->f_pos);
++		tmp = tgt_file->f_op->write(tgt_file, buf, bytes,
++					    &tgt_file->f_pos);
++		if(tmp != bytes) {
++			printk(KERN_CRIT "mini_fo_cp_cont: ERROR writing.\n");
++			goto out_close_unset;
++		}
++	}
++
++	free_page((unsigned long) buf);
++	set_fs(old_fs);
++	fput(tgt_file);
++	fput(src_file);
++	goto out;
++
++ out_close_unset:
++	free_page((unsigned long) buf);
++	set_fs(old_fs);
++
++ out_close:
++	fput(tgt_file);
++	fput(src_file);
++
++ out_err:
++	dput(tgt_dentry);
++	dput(src_dentry);
++
++	/* mk: not sure if this need to be done */
++	mntput(tgt_mnt);
++	mntput(src_mnt);
++
++ out:
++	return err;
++}
++
++/* mk:
++ * ndl (no-duplicate list) stuff
++ * This is used in mini_fo_readdir, to save the storage directory contents
++ * and later when reading base, match them against the list in order
++ * to avoid duplicates.
++ */
++
++/* add a file specified by name and len to the ndl
++ * Return values: 0 on success, <0 on failure.
++ */
++int ndl_add_entry(struct readdir_data *rd, const char *name, int len)
++{
++	struct ndl_entry *tmp_entry;
++
++	tmp_entry = (struct ndl_entry *)
++		kmalloc(sizeof(struct ndl_entry), GFP_KERNEL);
++	if(!tmp_entry) {
++                printk(KERN_CRIT "mini_fo: ndl_add_entry: out of mem.\n");
++                return -ENOMEM;
++        }
++        tmp_entry->name = (char*) kmalloc(len, GFP_KERNEL);
++        if(!tmp_entry->name) {
++                printk(KERN_CRIT "mini_fo: ndl_add_entry: out of mem.\n");
++                return -ENOMEM;
++        }
++	strncpy(tmp_entry->name, name, len);
++        tmp_entry->len = len;
++
++        list_add(&tmp_entry->list, &rd->ndl_list);
++        rd->ndl_size++;
++        return 0;
++}
++
++/* delete all list entries and free memory */
++void ndl_put_list(struct readdir_data *rd)
++{
++	struct list_head *tmp;
++	struct ndl_entry *tmp_entry;
++
++	if(rd->ndl_size <= 0)
++		return;
++	while(!list_empty(&rd->ndl_list)) {
++		tmp = rd->ndl_list.next;
++                list_del(tmp);
++                tmp_entry = list_entry(tmp, struct ndl_entry, list);
++		kfree(tmp_entry->name);
++                kfree(tmp_entry);
++        }
++	rd->ndl_size = 0;
++}
++
++/* Check if a file specified by name and len is in the ndl
++ * Return value: 0 if not in list, 1 if file is found in ndl.
++ */
++int ndl_check_entry(struct readdir_data *rd, const char *name, int len)
++{
++	struct list_head *tmp;
++	struct ndl_entry *tmp_entry;
++
++	if(rd->ndl_size <= 0)
++		return 0;
++
++	list_for_each(tmp, &rd->ndl_list) {
++                tmp_entry = list_entry(tmp, struct ndl_entry, list);
++                if(tmp_entry->len != len)
++                        continue;
++                if(!strncmp(tmp_entry->name, name, len))
++                        return 1;
++        }
++        return 0;
++}
++
++/* mk:
++ * Recursive function to create corresponding directorys in the storage fs.
++ * The function will build the storage directorys up to dentry.
++ */
++int build_sto_structure(dentry_t *dir, dentry_t *dentry)
++{
++	int err;
++	dentry_t *hidden_sto_dentry;
++	dentry_t *hidden_sto_dir_dentry;
++
++	if(dentry->d_parent != dir) {
++		printk(KERN_CRIT "mini_fo: build_sto_structure: invalid parameter or meta data corruption [1].\n");
++		return 1;
++	}
++
++       	if(dtost(dir) != MODIFIED) {
++		err = build_sto_structure(dir->d_parent, dentry->d_parent);
++		if(err)
++			return err;
++	}
++
++	/* ok, coming back again. */
++	check_mini_fo_dentry(dentry);
++	hidden_sto_dentry = dtohd2(dentry);
++
++	if(!hidden_sto_dentry) {
++		/*
++		 * This is the case after creating the first
++		 * hidden_sto_dentry.
++		 * After one negative storage_dentry, all pointers to
++		 * hidden_storage dentries are set to NULL. We need to
++		 * create the negative dentry before we create the storage
++		 * file.
++		 */
++		unsigned int len;
++		const unsigned char *name;
++		len = dtohd(dentry)->d_name.len;
++		name = dtohd(dentry)->d_name.name;
++		hidden_sto_dentry = lookup_one_len(name, dtohd2(dir), len);
++		dtohd2(dentry) = hidden_sto_dentry;
++	}
++
++	/* was:	hidden_sto_dir_dentry = lock_parent(hidden_sto_dentry); */
++	hidden_sto_dir_dentry = dget(hidden_sto_dentry->d_parent);
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_lock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++	down(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++	/* lets be safe */
++	if(dtohd2(dir) != hidden_sto_dir_dentry) {
++		printk(KERN_CRIT "mini_fo: build_sto_structure: invalid parameter or meta data corruption [2].\n");
++		return 1;
++	}
++
++	/* check for errors in lock_parent */
++	err = PTR_ERR(hidden_sto_dir_dentry);
++	if(IS_ERR(hidden_sto_dir_dentry)) {
++		printk(KERN_CRIT "mini_fo: build_sto_structure: lock_parent failed.\n");
++		return err;
++	}
++
++	err = vfs_mkdir(hidden_sto_dir_dentry->d_inode,
++			hidden_sto_dentry,
++			dir->d_inode->i_mode);
++
++	if(err) {
++		printk(KERN_CRIT "mini_fo: build_sto_structure: failed to create storage dir [1].\n");
++		/* was: unlock_dir(dir); */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_unlock(&dir->d_inode->i_mutex);
++#else
++		up(&dir->d_inode->i_sem);
++#endif
++		dput(dir);
++		return err;
++	}
++
++	/* everything ok! */
++	if(!dtohd2(dentry)->d_inode) {
++		printk(KERN_CRIT "mini_fo: build_sto_structure: failed to create storage dir [2].\n");
++		/* was: unlock_dir(dir); */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_unlock(&dir->d_inode->i_mutex);
++#else
++		up(&dir->d_inode->i_sem);
++#endif
++		dput(dir);
++		return 1;
++	}
++
++	/* interpose the new inode and set new state */
++	itohi2(dentry->d_inode) = igrab(dtohd2(dentry)->d_inode);
++	dtopd(dentry)->state = MODIFIED;
++
++	/* initalize the wol list */
++	itopd(dentry->d_inode)->deleted_list_size = -1;
++	itopd(dentry->d_inode)->renamed_list_size = -1;
++	meta_build_lists(dentry);
++
++	fist_copy_attr_all(dentry->d_inode, itohi2(dentry->d_inode));
++	fist_copy_attr_timesizes(dir->d_inode,
++				 hidden_sto_dir_dentry->d_inode);
++	dir->d_inode->i_nlink++;
++	/* was: unlock_dir(hidden_sto_dir_dentry); */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_unlock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++	up(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++	dput(hidden_sto_dir_dentry);
++	return 0;
++}
++
++
++#if 0 /* unused */
++
++/*
++ * Read "len" bytes from "filename" into "buf".
++ * "buf" is in kernel space.
++ */
++int
++mini_fo_read_file(const char *filename, void *buf, int len)
++{
++    file_t *filp;
++    mm_segment_t oldfs;
++    int bytes;
++    /* Chroot? Maybe NULL isn't right here */
++    filp = filp_open(filename, O_RDONLY, 0);
++    if (!filp || IS_ERR(filp)) {
++	printk("mini_fo_read_file err %d\n", (int) PTR_ERR(filp));
++	return -1;  /* or do something else */
++    }
++
++    if (!filp->f_op->read)
++	return -2;  /* file(system) doesn't allow reads */
++
++    /* now read len bytes from offset 0 */
++    filp->f_pos = 0;		/* start offset */
++    oldfs = get_fs();
++    set_fs(KERNEL_DS);
++    bytes = filp->f_op->read(filp, buf, len, &filp->f_pos);
++    set_fs(oldfs);
++
++    /* close the file */
++    fput(filp);
++
++    return bytes;
++}
++
++
++
++/*
++ * Write "len" bytes from "buf" to "filename"
++ * "buf" is in kernel space.
++ */
++int
++mini_fo_write_file(const char *filename, void *buf, int len)
++{
++    file_t *filp;
++    mm_segment_t oldfs;
++    int bytes;
++				/* Chroot? Maybe NULL isn't right here */
++    filp = filp_open(filename, O_RDWR|O_CREAT, 0640);
++    if (!filp || IS_ERR(filp)) {
++	printk("mini_fo_write_file err %d\n", (int) PTR_ERR(filp));
++	return -1;  /* or do something else */
++    }
++
++    if (!filp->f_op->write)
++	return -2;  /* file(system) doesn't allow writes */
++
++    /* now write len bytes from offset 0 */
++    filp->f_pos = 0;		/* start offset */
++    oldfs = get_fs();
++    set_fs(KERNEL_DS);
++    bytes = filp->f_op->write(filp, buf, len, &filp->f_pos);
++    set_fs(oldfs);
++
++    /* close the file */
++    fput(filp);
++
++    return bytes;
++}
++
++#endif /* unused */
++
+--- /dev/null
++++ b/fs/mini_fo/ChangeLog
+@@ -0,0 +1,281 @@
++2006-01-24  Markus Klotzbuecher  <mk@mary.denx.de>
++
++	* Add tons of ugly ifdefs to Ed L. Cashin's mutex patch to
++          retain backwards compatibility.
++
++2006-01-24  Ed L. Cashin <ecashin@coraid.com>
++
++	* Support for the new mutex infrastructure
++	(7892f2f48d165a34b0b8130c8a195dfd807b8cb6)
++
++2005-10-15  Markus Klotzbuecher  <mk@localhost.localdomain>
++
++	* Bugfix for a serious memory leak in mini_fo_follow_link.
++
++2005-09-21  Markus Klotzbuecher  <mk@mary>
++
++	* new release 0.6.1
++
++	* fix of a compiler warning due to changes in 2.6.13
++
++2005-09-21  Klaus Wenninger  <klaus.wenninger@siemens.com>
++
++	* file.c: readdir: fix for a bug that caused directory entries
++          to show up twice when using storage filesystems such as
++          minixfs or pramfs.
++
++2005-06-30  Eric Lammerts <eric@lammerts.org>
++
++	* fix for an oops when overwriting a binary thats beeing
++          executed.
++
++2005-06-09    <mk@mary>
++
++	* Renamed overlay to mini_fo-overlay.
++
++	* Added mini_fo-merge script to allow merging of storage and base
++	after making modifications.
++
++2005-05-22  root  <mk@mary>
++
++	* Added overlay script that allows to easily mount mini_fo ontop
++	of a given base directory
++
++2005-05-10    <mk@mary>
++
++	* inode.c: xattr functions return -EOPNOSUPP instead of
++          -ENOSUPP, what confuses "ls -l"
++
++	* Changed license from LGPL to GPL.
++
++2005-05-08  root  <mk@mary>
++
++	* Makefile: clean it up and added make install and make
++          uninstall.
++
++2005-05-06    <mk@mary>
++
++	* merged devel branch back to main. [v0-6-0-pre3]
++
++	* removed unused files print.c and fist_ioctl. [devel-0-0-18]
++
++	* ioctl: removed fist_ioctl stuff, that is not needed for
++          now.
++
++2005-05-03    <mk@mary>
++
++	* file.c: simplified mini_fo_open and mini_fo_setattr using
++          new state changing functions. [devel-0-0-17]
++
++	* inode.c: Fixed getattr state bug (see below) in 2.4 function
++          mini_fo_inode revalidate.
++
++	* inode.c: found an other bug in mini_fo_getattr. States are not
++	  reliable in this function, as a file can be opened, unlinked and
++	  the getattr function called. This results in a deleted dentry
++	  with an inode. Fix is to ignore states and simply use the inode
++	  available.
++
++2005-04-29    <mk@mary>
++
++	* file.c: Bugfix and cleanup in fasync and fsync. [devel-0-0-16]
++
++	* file.c: do not use mini_fo_lock so the generic version is
++          used (I guess).
++
++	* inode.c: getattr, never call getattr on lower files, as this
++          will cause the inum to change.
++
++	* inode.c: rename_reg_file renamed to rename_nondir, as it
++          doesn't matter as long it't not a dir. Removed all
++          rename_dev_file etc.
++
++	* tagged as devel-0-0-15
++
++	* inode.c: added support for chosing support for extended
++          attrs at compile time by XATTR define in mini_fo.h .
++
++	* inode.c: fixed mini_fo_getattr to use mini_fo inode and not
++          lower again, what avoids inode number changes that confused
++          rm again. This is the proper solution.
++
++2005-04-24    <mk@mary>
++
++	* all files: updated Copyright notive to 2005. [devel-0-0-14]
++
++	* inode.c: fixed mini_fo_getattr to not change the inode
++          number, even if lower files change.
++
++	* super.c: fixed a bug that caused deleted base file to show
++          up suddenly after some time, or after creating a special
++          file. The problem was that after some time or after special
++          file creating sync_sb_inodes is called by the vfs, that
++          called our mini_fo_put_inode. There was (wrongly) called
++          __meta_put_lists, that nuked the lists, although the inode
++          was going to continue its life. Moving __meta_put_lists to
++          mini_fo_clear_inode, where an inode is really destroyed,
++          solved the problem.
++
++
++2005-04-23    <mk@mary>
++
++	* state.c, aux.c: more cleaning up and
++          simplifications. [devel-0-0-13]
++
++	* inode.c: implemented mini_fo_getattr, that was required for
++          2.6 because inode_revalidate has been remove there, and the
++	  old "du" bug returned.
++
++
++2005-04-20    <mk@mary>
++
++	* aux.c: get_neg_sto_dentry(): allow to be called for dentries
++          in state UNMODIFIED, NON_EXISTANT _and_ DELETED.
++
++2005-04-19    <mk@mary>
++
++	* Fixed a bug under 2.6 that caused files deleted via mini_fo
++          not to be deleted properly and therefore the fs filled up
++          untill no memory was left. [devel-0-0-12]
++
++	* Added basic hard link support. This means that creating
++          hardlinks will work, but existing ones will be treated as
++          individual files. [devel-0-0-11]
++
++2005-04-17    <mk@mary>
++
++	* Bugfixes
++
++2005-04-13  root  <mk@mary>
++
++	* Added file state.c for the state transition
++          functions. Doesn't work very well yet, though...
++
++2005-04-12    <mk@mary>
++
++	* Porting to 2.6 started, which is easier than expected, also
++          due to Olivier previous work.
++
++2005-04-08    <mk@mary>
++
++	* Fixed the bug that caused du to return invalid sizes of
++          directory trees. The problem was that
++          mini_fo_inode_revalidate didn't always copy the attributes
++          from the base inode properly.
++
++2005-04-01  Markus Klotzbuecher  <mk@chasey>
++
++	* Merged devel branch back to main trunk and updated the
++          RELEASE notes. This will be 0-6-0-pre1.
++
++2005-03-31  Markus Klotzbuecher  <mk@chasey>
++
++	* Fixed some bugs in rename_reg_file, that only showed up in
++          the kernel compile test. Kernel compiles cleanly ontop of
++          mini_fo, now also make mrproper etc. work. Seems pretty stable.
++
++2005-03-28  Markus Klotzbuecher  <mk@chasey>
++
++	* Many, many directory renaming bugfixes and a lot of other
++          cleanup. Dir renaming seems to work relatively stable.
++
++2005-03-22  Markus Klotzbuecher  <mk@chasey>
++
++	* Finished implementing lightweight directory renaming. Some
++          basic testing indicates it works fine.
++	  Next is to implement testcases for the testsuite and confirm
++          everything is really working ok.
++
++2005-03-18  Markus Klotzbuecher  <mk@chasey>
++
++	* Finished implementing meta.c stuff required for directory
++          renaming.
++
++2005-03-17  Markus Klotzbuecher  <mk@chasey>
++
++	* Fixed all compile warnings + an extremly old bug that
++          somehow crept in while reworking the wol stuff to the META
++          system. Turning on -Werror again... :-)
++
++	* Fixed some bugs in the new rename_reg_file function.
++
++	* Rewrote mini_fo rename and split it into several
++          subfunctions, that handle the different types
++          seperately. Rewrote the regular file function aswell, as it
++          was implemented somewhat inefficient.
++
++2005-03-16  Markus Klotzbuecher  <mk@chasey>
++
++	* Implemented new META subsystem, removed old WOL stuff in favor
++	  if it.
++
++	* After some basic testing everything seems ok...
++
++2005-03-11  Markus Klotzbuecher  <mk@chasey>
++
++	* Renaming a non regular file caused trouble because I always
++	  tried to copy the contents. Now I only do this for regular
++	  files. mini_fo_rename still isn't implemented properly, renaming
++	  of device files, symlinks etc. results in a empty regular file
++	  instead of the proper type.
++
++	* Directory renaming suddenly works! What a surprise! I guess
++          this is because renaming is implemented as making a copy and
++          removing the original. Still this might not work
++          everywhere...
++
++2005-03-09  Markus Klotzbuecher  <mk@chasey>
++
++	* Bugfix, when a mini_fo directory that exists in storage
++  	  (state: MODIFIED, CREATED and DEL_REWRITTEN) is deleted, a
++  	  possibly existing WOL file contained in it needs to be
++  	  deleted too.
++
++	* Starting cleanup: defined state names in order to get rid of
++          the state numbers.
++
++2005-03-08  Markus Klotzbuecher  <mk@chasey>
++
++	* Makefile fix, fist_ioctl was built against wrong sources if ARCH=um
++
++	* Fixed a bug in dentry.c, mini_fo_d_hash. In state 4 =
++          DEL_REWRITTEN the hash was calculated from the base dentry,
++          which was wrong and and caused assertions in
++          __mini_fo_hidden_dentry to fail.
++
++2005-02-21    <mk@mary>
++
++	* Implemented directory deleting (inode.c)
++
++	* main.c: made mini_fo_parse_options a little more robust.
++
++2004-12-22    <mk@mary>
++
++	* Makefile cleanup and uml stuff, removed unneccessary files
++
++	* Created a new and hopefully more informative README
++
++	* CHANGELOG: created a new CHANGELOG and added old entries reversely
++
++
++2004-10-24 Gleb Natapov <gleb@nbase.co.il>
++
++	* Fix: owner and group where not correctly copied from base to
++          storage.
++
++
++2004-10-05 Gleb Natapov <gleb@nbase.co.il>
++
++	* Implementation of fsync, fasync and lock mini_fo functions.
++
++
++2004-09-29 Bob Lee <bob@pantasys.com>
++
++	* Fix of a serious pointer bug
++
++
++2004-09-28 Gleb Natapov <gleb@nbase.co.il>
++
++	* Implementation of mini_fo_mknod and mini_fo_rename, support
++          for device files.
++
+--- /dev/null
++++ b/fs/mini_fo/dentry.c
+@@ -0,0 +1,244 @@
++/*
++ * Copyright (c) 1997-2003 Erez Zadok
++ * Copyright (c) 2001-2003 Stony Brook University
++ *
++ * For specific licensing information, see the COPYING file distributed with
++ * this package, or get one from ftp://ftp.filesystems.org/pub/fist/COPYING.
++ *
++ * This Copyright notice must be kept intact and distributed with all
++ * fistgen sources INCLUDING sources generated by fistgen.
++ */
++/*
++ * Copyright (C) 2004, 2005 Markus Klotzbuecher <mk@creamnet.de>
++ *
++ * This program is free software; you can redistribute it and/or
++ * modify it under the terms of the GNU General Public License
++ * as published by the Free Software Foundation; either version
++ * 2 of the License, or (at your option) any later version.
++ */
++
++/*
++ *  $Id$
++ */
++
++#ifdef HAVE_CONFIG_H
++# include <config.h>
++#endif
++
++#include "fist.h"
++#include "mini_fo.h"
++
++/*
++ * THIS IS A BOOLEAN FUNCTION: returns 1 if valid, 0 otherwise.
++ */
++STATIC int
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++mini_fo_d_revalidate(dentry_t *dentry, struct nameidata *nd)
++#else
++mini_fo_d_revalidate(dentry_t *dentry, int flags)
++#endif
++{
++	int err1 = 1; /* valid = 1, invalid = 0 */
++	int err2 = 1;
++	dentry_t *hidden_dentry;
++	dentry_t *hidden_sto_dentry;
++
++
++	check_mini_fo_dentry(dentry);
++
++	hidden_dentry  = dtohd(dentry);
++	hidden_sto_dentry = dtohd2(dentry);
++
++	if(hidden_dentry &&
++	   hidden_dentry->d_op &&
++	   hidden_dentry->d_op->d_revalidate) {
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++		err1 = hidden_dentry->d_op->d_revalidate(hidden_dentry, nd);
++#else
++		err1 = hidden_dentry->d_op->d_revalidate(hidden_dentry, flags);
++#endif
++	}
++	if(hidden_sto_dentry &&
++	   hidden_sto_dentry->d_op &&
++	   hidden_sto_dentry->d_op->d_revalidate) {
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++		err2 = hidden_sto_dentry->d_op->d_revalidate(hidden_sto_dentry,
++							     nd);
++#else
++		err2 = hidden_sto_dentry->d_op->d_revalidate(hidden_sto_dentry,
++							     flags);
++#endif
++	}
++
++	/* mk: if one of the lower level dentries are valid,
++	 * the mini_fo dentry is too.
++	 */
++	return (err1 || err2);
++}
++
++
++STATIC int
++mini_fo_d_hash(dentry_t *dentry, qstr_t *name)
++{
++	int err = 0;
++	dentry_t *hidden_dentry;
++	dentry_t *hidden_sto_dentry;
++
++	/* hidden_dentry = mini_fo_hidden_dentry(dentry);
++	 * hidden_sto_dentry = mini_fo_hidden_sto_dentry(dentry); */
++
++	/* state 1, 3, 4, 5: build the hash for the storage dentry */
++	if((dtopd(dentry)->state == MODIFIED) ||
++	   (dtopd(dentry)->state == CREATED) ||
++	   (dtopd(dentry)->state == DEL_REWRITTEN) ||
++	   (dtopd(dentry)->state == DELETED)) {
++		hidden_sto_dentry = dtohd2(dentry);
++		if(hidden_sto_dentry &&
++		   hidden_sto_dentry->d_op &&
++		   hidden_sto_dentry->d_op->d_hash) {
++			err = hidden_sto_dentry->d_op->d_hash(hidden_sto_dentry, name);
++		}
++		goto out;
++	}
++	/* state 2: build the hash for the base dentry */
++	if(dtopd(dentry)->state == UNMODIFIED) {
++		hidden_dentry = dtohd(dentry);
++		if(hidden_dentry &&
++		   hidden_dentry->d_op &&
++		   hidden_dentry->d_op->d_hash) {
++			err = hidden_dentry->d_op->d_hash(hidden_dentry, name);
++		}
++		goto out;
++	}
++	/* state 6: build hash for the dentry that exists */
++	if(dtopd(dentry)->state == NON_EXISTANT) {
++		hidden_sto_dentry = dtohd2(dentry);
++		if(hidden_sto_dentry &&
++		   hidden_sto_dentry->d_op &&
++		   hidden_sto_dentry->d_op->d_hash) {
++			err = hidden_sto_dentry->d_op->d_hash(hidden_sto_dentry, name);
++			goto out;
++		}
++		hidden_dentry = dtohd(dentry);
++		if(hidden_dentry &&
++		   hidden_dentry->d_op &&
++		   hidden_dentry->d_op->d_hash) {
++			err = hidden_dentry->d_op->d_hash(hidden_dentry, name);
++			goto out;
++		}
++	}
++
++	printk(KERN_CRIT "mini_fo: d_hash: invalid state detected.\n");
++
++ out:
++	return err;
++}
++
++
++STATIC int
++mini_fo_d_compare(dentry_t *dentry, qstr_t *a, qstr_t *b)
++{
++	int err;
++	dentry_t *hidden_dentry=NULL;
++
++	/* hidden_dentry = mini_fo_hidden_dentry(dentry); */
++	if(dtohd2(dentry))
++		hidden_dentry = dtohd2(dentry);
++	else if(dtohd(dentry))
++		hidden_dentry = dtohd(dentry);
++
++	if (hidden_dentry && hidden_dentry->d_op && hidden_dentry->d_op->d_compare) {
++		err = hidden_dentry->d_op->d_compare(hidden_dentry, a, b);
++	} else {
++		err = ((a->len != b->len) || memcmp(a->name, b->name, b->len));
++	}
++
++	return err;
++}
++
++
++int
++mini_fo_d_delete(dentry_t *dentry)
++{
++	dentry_t *hidden_dentry;
++	dentry_t *hidden_sto_dentry;
++	int err = 0;
++
++	/* this could be a negative dentry, so check first */
++	if (!dtopd(dentry)) {
++		printk(KERN_CRIT "mini_fo_d_delete: negative dentry passed.\n");
++		goto out;
++	}
++	hidden_dentry = dtohd(dentry);
++	hidden_sto_dentry = dtohd2(dentry);
++
++	if(hidden_dentry) {
++		if(hidden_dentry->d_op &&
++		   hidden_dentry->d_op->d_delete) {
++			err = hidden_dentry->d_op->d_delete(hidden_dentry);
++		}
++	}
++	if(hidden_sto_dentry) {
++		if(hidden_sto_dentry->d_op &&
++		   hidden_sto_dentry->d_op->d_delete) {
++			err = hidden_sto_dentry->d_op->d_delete(hidden_sto_dentry);
++		}
++	}
++
++ out:
++	return err;
++}
++
++
++void
++mini_fo_d_release(dentry_t *dentry)
++{
++	dentry_t *hidden_dentry;
++	dentry_t *hidden_sto_dentry;
++
++
++	/* this could be a negative dentry, so check first */
++	if (!dtopd(dentry)) {
++		printk(KERN_CRIT "mini_fo_d_release: no private data.\n");
++		goto out;
++	}
++	hidden_dentry = dtohd(dentry);
++	hidden_sto_dentry = dtohd2(dentry);
++
++	if(hidden_dentry) {
++		/* decrement hidden dentry's counter and free its inode */
++		dput(hidden_dentry);
++	}
++	if(hidden_sto_dentry) {
++                /* decrement hidden dentry's counter and free its inode */
++		dput(hidden_sto_dentry);
++	}
++
++	/* free private data (mini_fo_dentry_info) here */
++	kfree(dtopd(dentry));
++	__dtopd(dentry) = NULL;	/* just to be safe */
++ out:
++	return;
++}
++
++
++/*
++ * we don't really need mini_fo_d_iput, because dentry_iput will call iput() if
++ * mini_fo_d_iput is not defined. We left this implemented for ease of
++ * tracing/debugging.
++ */
++void
++mini_fo_d_iput(dentry_t *dentry, inode_t *inode)
++{
++	iput(inode);
++}
++
++
++struct dentry_operations mini_fo_dops = {
++	d_revalidate:	mini_fo_d_revalidate,
++	d_hash:		mini_fo_d_hash,
++	d_compare:		mini_fo_d_compare,
++	d_release:		mini_fo_d_release,
++	d_delete:		mini_fo_d_delete,
++	d_iput:		mini_fo_d_iput,
++};
+--- /dev/null
++++ b/fs/mini_fo/file.c
+@@ -0,0 +1,713 @@
++/*
++ * Copyright (c) 1997-2003 Erez Zadok
++ * Copyright (c) 2001-2003 Stony Brook University
++ *
++ * For specific licensing information, see the COPYING file distributed with
++ * this package, or get one from ftp://ftp.filesystems.org/pub/fist/COPYING.
++ *
++ * This Copyright notice must be kept intact and distributed with all
++ * fistgen sources INCLUDING sources generated by fistgen.
++ */
++/*
++ * Copyright (C) 2004, 2005 Markus Klotzbuecher <mk@creamnet.de>
++ *
++ * This program is free software; you can redistribute it and/or
++ * modify it under the terms of the GNU General Public License
++ * as published by the Free Software Foundation; either version
++ * 2 of the License, or (at your option) any later version.
++ */
++
++/*
++ *  $Id$
++ */
++
++#ifdef HAVE_CONFIG_H
++# include <config.h>
++#endif
++
++#include "fist.h"
++#include "mini_fo.h"
++#define ROUND_UP(x) (((x)+sizeof(long)-1) & ~(sizeof(long)-1))
++
++/*******************
++ * File Operations *
++ *******************/
++
++STATIC loff_t
++mini_fo_llseek(file_t *file, loff_t offset, int origin)
++{
++	loff_t err;
++	file_t *hidden_file = NULL;
++
++	if(S_ISDIR(file->f_dentry->d_inode->i_mode)) {
++		/* Check if trying to llseek from a directory */
++		err = -EISDIR;
++		goto out;
++	}
++	if (ftopd(file) != NULL) {
++		if(ftohf2(file)) {
++			hidden_file = ftohf2(file);
++		} else {
++			hidden_file = ftohf(file);
++		}
++	}
++
++	/* always set hidden position to this one */
++	hidden_file->f_pos = file->f_pos;
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++	memcpy(&(hidden_file->f_ra),
++	       &(file->f_ra),
++	       sizeof(struct file_ra_state));
++#else
++	if (file->f_reada) { /* update readahead information if needed */
++		hidden_file->f_reada = file->f_reada;
++		hidden_file->f_ramax = file->f_ramax;
++		hidden_file->f_raend = file->f_raend;
++		hidden_file->f_ralen = file->f_ralen;
++		hidden_file->f_rawin = file->f_rawin;
++	}
++#endif
++	if (hidden_file->f_op && hidden_file->f_op->llseek)
++		err = hidden_file->f_op->llseek(hidden_file, offset, origin);
++	else
++		err = generic_file_llseek(hidden_file, offset, origin);
++
++	if (err < 0)
++		goto out;
++
++	if (err != file->f_pos) {
++		file->f_pos = err;
++		// ION maybe this?
++		// 	file->f_pos = hidden_file->f_pos;
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
++		file->f_reada = 0;
++#endif
++		file->f_version++;
++	}
++
++ out:
++	return err;
++}
++
++
++/* mk: fanout capable */
++STATIC ssize_t
++mini_fo_read(file_t *file, char *buf, size_t count, loff_t *ppos)
++{
++	int err = -EINVAL;
++	file_t *hidden_file = NULL;
++	loff_t pos = *ppos;
++
++	if(S_ISDIR(file->f_dentry->d_inode->i_mode)) {
++		/* Check if trying to read from a directory */
++		/* printk(KERN_CRIT "mini_fo_read: ERROR: trying to read data from a directory.\n"); */
++		err = -EISDIR;
++		goto out;
++	}
++
++	if (ftopd(file) != NULL) {
++		if(ftohf2(file)) {
++			hidden_file = ftohf2(file);
++		} else {
++			hidden_file = ftohf(file);
++		}
++	}
++
++	if (!hidden_file->f_op || !hidden_file->f_op->read)
++		goto out;
++
++	err = hidden_file->f_op->read(hidden_file, buf, count, &pos);
++	*ppos = pos;
++
++	if (err >= 0) {
++		/* atime should also be updated for reads of size zero or more */
++		fist_copy_attr_atime(file->f_dentry->d_inode,
++				     hidden_file->f_dentry->d_inode);
++	}
++
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
++	/*
++	 * MAJOR HACK
++	 * because pread() does not have any way to tell us that it is
++	 * our caller, then we don't know for sure if we have to update
++	 * the file positions.  This hack relies on read() having passed us
++	 * the "real" pointer of its struct file's f_pos field.
++	 */
++	if (ppos == &file->f_pos)
++		hidden_file->f_pos = *ppos = pos;
++	if (hidden_file->f_reada) { /* update readahead information if needed */
++		file->f_reada = hidden_file->f_reada;
++		file->f_ramax = hidden_file->f_ramax;
++		file->f_raend = hidden_file->f_raend;
++		file->f_ralen = hidden_file->f_ralen;
++		file->f_rawin = hidden_file->f_rawin;
++	}
++#else
++	memcpy(&(file->f_ra),&(hidden_file->f_ra),sizeof(struct file_ra_state));
++#endif
++
++ out:
++	return err;
++}
++
++
++/* this mini_fo_write() does not modify data pages! */
++STATIC ssize_t
++mini_fo_write(file_t *file, const char *buf, size_t count, loff_t *ppos)
++{
++	int err = -EINVAL;
++	file_t *hidden_file = NULL;
++	inode_t *inode;
++	inode_t *hidden_inode;
++	loff_t pos = *ppos;
++
++	/* mk: fan out: */
++	if (ftopd(file) != NULL) {
++		if(ftohf2(file)) {
++			hidden_file = ftohf2(file);
++		} else {
++			/* This is bad! We have no storage file to write to. This
++			 * should never happen because if a file is opened for
++			 * writing, a copy should have been made earlier.
++			 */
++			printk(KERN_CRIT "mini_fo: write : ERROR, no storage file to write.\n");
++			err = -EINVAL;
++			goto out;
++		}
++	}
++
++	inode = file->f_dentry->d_inode;
++	hidden_inode = itohi2(inode);
++	if(!hidden_inode) {
++		printk(KERN_CRIT "mini_fo: write: no sto inode found, not good.\n");
++		goto out;
++	}
++
++	if (!hidden_file->f_op || !hidden_file->f_op->write)
++		goto out;
++
++	/* adjust for append -- seek to the end of the file */
++	if (file->f_flags & O_APPEND)
++		pos = inode->i_size;
++
++	err = hidden_file->f_op->write(hidden_file, buf, count, &pos);
++
++	/*
++	 * copy ctime and mtime from lower layer attributes
++	 * atime is unchanged for both layers
++	 */
++	if (err >= 0)
++		fist_copy_attr_times(inode, hidden_inode);
++
++	*ppos = pos;
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
++	/*
++	 * XXX: MAJOR HACK
++	 *
++	 * because pwrite() does not have any way to tell us that it is
++	 * our caller, then we don't know for sure if we have to update
++	 * the file positions.  This hack relies on write() having passed us
++	 * the "real" pointer of its struct file's f_pos field.
++	 */
++	if (ppos == &file->f_pos)
++		hidden_file->f_pos = *ppos = pos;
++#endif
++	/* update this inode's size */
++	if (pos > inode->i_size)
++		inode->i_size = pos;
++
++ out:
++	return err;
++}
++
++/* Global variable to hold a file_t pointer.
++ * This serves to allow mini_fo_filldir function to know which file is
++ * beeing read, which is required for two reasons:
++ *
++ *   - be able to call wol functions in order to avoid listing deleted
++ *     base files.
++ *   - if we're reading a directory which is in state 1, we need to
++ *     maintain a list (in mini_fo_filldir) of which files allready
++ *     have been copied to userspace,to detect files existing in base
++ *     and storage and not list them twice.
++ */
++filldir_t mini_fo_filldir_orig;
++file_t *mini_fo_filldir_file;
++
++/* mainly copied from fs/readdir.c */
++STATIC int
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,18)
++mini_fo_filldir(void * __buf, const char * name, int namlen, loff_t offset,
++		  u64 ino, unsigned int d_type)
++#else
++mini_fo_filldir(void * __buf, const char * name, int namlen, loff_t offset,
++		  ino_t ino, unsigned int d_type)
++#endif
++{
++	struct getdents_callback * buf = (struct getdents_callback *) __buf;
++	file_t* file = mini_fo_filldir_file;
++
++	/* In theses states we filter meta files in storage (WOL) */
++	if(file && (dtopd(file->f_dentry)->state == MODIFIED ||
++		    dtopd(file->f_dentry)->state == CREATED ||
++		    dtopd(file->f_dentry)->state == DEL_REWRITTEN)) {
++
++		int tmp = strlen(META_FILENAME);
++		if(tmp  == namlen) {
++			if(!strncmp(name, META_FILENAME, namlen))
++				return 0;
++		}
++	}
++
++	/* check if we are merging the contents of storage and base */
++	if(file && dtopd(file->f_dentry)->state == MODIFIED) {
++		/* check if we are still reading storage contents, if
++		 * yes, we just save the name of the file for duplicate
++		 * checking later. */
++
++		if(!ftopd(file)->rd.sto_done) {
++			/* put file into ndl list */
++			if(ndl_add_entry(&ftopd(file)->rd, name, namlen))
++				printk(KERN_CRIT "mini_fo_filldir: Error adding to ndl.\n");
++		} else {
++			/* check if file has been deleted */
++			if(meta_check_d_entry(file->f_dentry, name, namlen))
++				return 0;
++
++			/* do duplicate checking */
++			if(ndl_check_entry(&ftopd(file)->rd, name, namlen))
++				return 0;
++		}
++	}
++
++	return mini_fo_filldir_orig(buf, name, namlen, offset, ino, d_type);
++}
++
++
++STATIC int
++mini_fo_readdir(file_t *file, void *dirent, filldir_t filldir)
++{
++	int err = 0;/* mk: ??? -ENOTDIR; */
++	file_t *hidden_file = NULL;
++	file_t *hidden_sto_file = NULL;
++	inode_t *inode;
++	struct getdents_callback *buf;
++	int oldcount;
++
++#if defined(FIST_FILTER_NAME) || defined(FIST_FILTER_SCA)
++	struct mini_fo_getdents_callback buf;
++#endif /* FIST_FILTER_NAME || FIST_FILTER_SCA */
++
++	buf = (struct getdents_callback *) dirent;
++	oldcount = buf->count;
++	inode = file->f_dentry->d_inode;
++	mini_fo_filldir_file = file;
++	mini_fo_filldir_orig = filldir;
++
++	ftopd(file)->rd.sto_done = 0;
++	do {
++		if (ftopd(file) != NULL) {
++			if(ftohf2(file)) {
++				hidden_sto_file = ftohf2(file);
++				err = vfs_readdir(hidden_sto_file, mini_fo_filldir, dirent);
++				file->f_pos = hidden_sto_file->f_pos;
++				if (err > 0)
++					fist_copy_attr_atime(inode, hidden_sto_file->f_dentry->d_inode);
++				/* not finshed yet, we'll be called again */
++				if (buf->count != oldcount)
++					break;
++			}
++
++			ftopd(file)->rd.sto_done = 1;
++
++			if(ftohf(file)) {
++				hidden_file = ftohf(file);
++				err = vfs_readdir(hidden_file, mini_fo_filldir, dirent);
++				file->f_pos = hidden_file->f_pos;
++				if (err > 0)
++					fist_copy_attr_atime(inode, hidden_file->f_dentry->d_inode);
++			}
++
++		}
++	} while (0);
++
++	/* mk:
++	 * we need to check if all the directory data has been copied to userspace,
++	 * or if we will be called again by userspace to complete the operation.
++	 */
++	if(buf->count == oldcount) {
++		ndl_put_list(&ftopd(file)->rd);
++	}
++
++	/* unset this, safe */
++	mini_fo_filldir_file = NULL;
++	return err;
++}
++
++
++STATIC unsigned int
++mini_fo_poll(file_t *file, poll_table *wait)
++{
++	unsigned int mask = DEFAULT_POLLMASK;
++	file_t *hidden_file = NULL;
++
++	if (ftopd(file) != NULL) {
++		if(ftohf2(file)) {
++			hidden_file = ftohf2(file);
++		} else {
++			hidden_file = ftohf(file);
++		}
++	}
++
++	if (!hidden_file->f_op || !hidden_file->f_op->poll)
++		goto out;
++
++	mask = hidden_file->f_op->poll(hidden_file, wait);
++
++ out:
++	return mask;
++}
++
++/* FIST-LITE special version of mmap */
++STATIC int
++mini_fo_mmap(file_t *file, vm_area_t *vma)
++{
++	int err = 0;
++	file_t *hidden_file = NULL;
++
++	/* fanout capability */
++	if (ftopd(file) != NULL) {
++		if(ftohf2(file)) {
++			hidden_file = ftohf2(file);
++		} else {
++			hidden_file = ftohf(file);
++		}
++	}
++
++	ASSERT(hidden_file != NULL);
++	ASSERT(hidden_file->f_op != NULL);
++	ASSERT(hidden_file->f_op->mmap != NULL);
++
++	vma->vm_file = hidden_file;
++	err = hidden_file->f_op->mmap(hidden_file, vma);
++	get_file(hidden_file); /* make sure it doesn't get freed on us */
++	fput(file);	       /* no need to keep extra ref on ours */
++
++	return err;
++}
++
++
++
++STATIC int
++mini_fo_open(inode_t *inode, file_t *file)
++{
++	int err = 0;
++ 	int hidden_flags;
++	file_t *hidden_file = NULL;
++	dentry_t *hidden_dentry = NULL;
++
++	/* fanout stuff */
++	file_t *hidden_sto_file = NULL;
++	dentry_t *hidden_sto_dentry = NULL;
++
++	__ftopd(file) =
++		kmalloc(sizeof(struct mini_fo_file_info), GFP_KERNEL);
++	if (!ftopd(file)) {
++		err = -ENOMEM;
++		goto out;
++	}
++
++	/* init the readdir_helper structure */
++	INIT_LIST_HEAD(&ftopd(file)->rd.ndl_list);
++	ftopd(file)->rd.ndl_size = 0;
++
++	/* In certain paths this could stay uninitalized and cause trouble */
++	ftohf(file) = NULL;
++	ftohf2(file) = NULL;
++	hidden_flags = file->f_flags;
++
++	/* create storage files? */
++	if(dtost(file->f_dentry) == UNMODIFIED) {
++		if(!IS_WRITE_FLAG(file->f_flags)) {
++			hidden_dentry = dtohd(file->f_dentry);
++			dget(hidden_dentry);
++			/* dentry_open will decrement mnt refcnt if err.
++			 * otherwise fput() will do an mntput() for us upon file close. */
++			mntget(stopd(inode->i_sb)->hidden_mnt);
++			hidden_file = dentry_open(hidden_dentry,
++						  stopd(inode->i_sb)->hidden_mnt,
++						  hidden_flags);
++			if (IS_ERR(hidden_file)) {
++				err = PTR_ERR(hidden_file);
++				dput(hidden_dentry);
++				goto out;
++			}
++			ftohf(file) = hidden_file;	/* link two files */
++			goto out;
++		}
++		else {
++			if(S_ISDIR(file->f_dentry->d_inode->i_mode)) {
++				err = dir_unmod_to_mod(file->f_dentry);
++			} else
++				err = nondir_unmod_to_mod(file->f_dentry, 1);
++
++			if (err) {
++				printk("mini_fo_open: ERROR creating storage file.\n");
++				goto out;
++			}
++		}
++	}
++	hidden_sto_dentry = dtohd2(file->f_dentry);
++	dget(hidden_sto_dentry);
++
++	if(dtopd(file->f_dentry)->state == MODIFIED) {
++		/* Directorys are special, interpose on both lower level files */
++		if(S_ISDIR(itohi(inode)->i_mode)) {
++			/* check for invalid file types of lower level files */
++			if(!(S_ISDIR(itohi(inode)->i_mode) && S_ISDIR(itohi2(inode)->i_mode))) {
++				printk(KERN_CRIT "mini_fo_open: meta data corruption detected.\n");
++				dput(hidden_sto_dentry);
++				err = -EINVAL;
++				goto out;
++			}
++
++			/* lower level directorys are ok, open the base file */
++			hidden_dentry = dtohd(file->f_dentry);
++			dget(hidden_dentry);
++
++			mntget(stopd(inode->i_sb)->hidden_mnt);
++			hidden_file = dentry_open(hidden_dentry,
++						  stopd(inode->i_sb)->hidden_mnt,
++						  hidden_flags);
++			if (IS_ERR(hidden_file)) {
++				err = PTR_ERR(hidden_file);
++				dput(hidden_dentry);
++				dput(hidden_sto_dentry);
++				goto out;
++			}
++			ftohf(file) = hidden_file; /* link the two files */
++		}
++	}
++
++	if(!exists_in_storage(file->f_dentry)) {
++		printk(KERN_CRIT "mini_fo_open: invalid file state detected.\n");
++		err = -EINVAL;
++		dput(hidden_sto_dentry);
++
++		/* If the base file has been opened, we need to close it here */
++		if(ftohf(file)) {
++			if (hidden_file->f_op && hidden_file->f_op->flush)
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,18)
++				hidden_file->f_op->flush(hidden_file, NULL);
++#else
++				hidden_file->f_op->flush(hidden_file);
++#endif
++			dput(hidden_dentry);
++		}
++		goto out;
++	}
++
++	/* ok, now we can safely open the storage file */
++	mntget(stopd(inode->i_sb)->hidden_mnt2);
++	hidden_sto_file = dentry_open(hidden_sto_dentry,
++				      stopd(inode->i_sb)->hidden_mnt2,
++				      hidden_flags);
++
++	/* dentry_open dputs the dentry if it fails */
++	if (IS_ERR(hidden_sto_file)) {
++		err = PTR_ERR(hidden_sto_file);
++		/* close base file if open */
++		if(ftohf(file)) {
++			if (hidden_file->f_op && hidden_file->f_op->flush)
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,18)
++				hidden_file->f_op->flush(hidden_file, NULL);
++#else
++				hidden_file->f_op->flush(hidden_file);
++#endif
++			dput(hidden_dentry);
++		}
++		goto out;
++	}
++	ftohf2(file) = hidden_sto_file; /* link storage file */
++
++ out:
++	if (err < 0 && ftopd(file)) {
++		kfree(ftopd(file));
++	}
++	return err;
++}
++
++STATIC int
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,18)
++mini_fo_flush(file_t *file, fl_owner_t id)
++#else
++mini_fo_flush(file_t *file)
++#endif
++{
++	int err1 = 0;		/* assume ok (see open.c:close_fp) */
++	int err2 = 0;
++	file_t *hidden_file = NULL;
++
++	check_mini_fo_file(file);
++
++	/* mk: we don't do any state checking here, as its not worth the time.
++	 * Just flush the lower level files if they exist.
++	 */
++	if(ftopd(file) != NULL) {
++		if(ftohf(file) != NULL) {
++			hidden_file = ftohf(file);
++			if (hidden_file->f_op && hidden_file->f_op->flush)
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,18)
++				err1 = hidden_file->f_op->flush(hidden_file, id);
++#else
++				err1 = hidden_file->f_op->flush(hidden_file);
++#endif
++		}
++		if(ftohf2(file) != NULL) {
++			hidden_file = ftohf2(file);
++			if (hidden_file->f_op && hidden_file->f_op->flush)
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,18)
++				err2 = hidden_file->f_op->flush(hidden_file, id);
++#else
++				err2 = hidden_file->f_op->flush(hidden_file);
++#endif
++		}
++	}
++	return (err1 | err2);
++}
++
++
++STATIC int
++mini_fo_release(inode_t *inode, file_t *file)
++{
++	int err = 0;
++	file_t *hidden_file = NULL;
++
++	if (ftopd(file) != NULL) {
++		if(ftohf(file)) {
++			hidden_file = ftohf(file);
++			fput(hidden_file);
++		}
++		if(ftohf2(file)) {
++			hidden_file = ftohf2(file);
++			fput(hidden_file);
++		}
++		kfree(ftopd(file));
++	}
++	return err;
++}
++
++STATIC int
++mini_fo_fsync(file_t *file, dentry_t *dentry, int datasync)
++{
++	int err1 = 0;
++	int err2 = 0;
++	file_t *hidden_file = NULL;
++	dentry_t *hidden_dentry;
++
++	check_mini_fo_file(file);
++
++	if ((hidden_file = ftohf(file)) != NULL) {
++		hidden_dentry = dtohd(dentry);
++		if (hidden_file->f_op && hidden_file->f_op->fsync) {
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++			mutex_lock(&hidden_dentry->d_inode->i_mutex);
++#else
++			down(&hidden_dentry->d_inode->i_sem);
++#endif
++			err1 = hidden_file->f_op->fsync(hidden_file, hidden_dentry, datasync);
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++			mutex_unlock(&hidden_dentry->d_inode->i_mutex);
++#else
++			up(&hidden_dentry->d_inode->i_sem);
++#endif
++		}
++	}
++
++	if ((hidden_file = ftohf2(file)) != NULL) {
++		hidden_dentry = dtohd2(dentry);
++		if (hidden_file->f_op && hidden_file->f_op->fsync) {
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++			mutex_lock(&hidden_dentry->d_inode->i_mutex);
++#else
++			down(&hidden_dentry->d_inode->i_sem);
++#endif
++			err2 = hidden_file->f_op->fsync(hidden_file, hidden_dentry, datasync);
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++			mutex_unlock(&hidden_dentry->d_inode->i_mutex);
++#else
++			up(&hidden_dentry->d_inode->i_sem);
++#endif
++		}
++	}
++	else
++		goto err;
++
++err:
++	return (err1 || err2);
++}
++
++
++STATIC int
++mini_fo_fasync(int fd, file_t *file, int flag)
++{
++	int err1 = 0;
++	int err2 = 0;
++
++	file_t *hidden_file = NULL;
++
++	check_mini_fo_file(file);
++
++	if((hidden_file = ftohf(file)) != NULL) {
++		err1 = hidden_file->f_op->fasync(fd, hidden_file, flag);
++	}
++	if((hidden_file = ftohf2(file)) != NULL) {
++		err2 = hidden_file->f_op->fasync(fd, hidden_file, flag);
++	}
++
++	return (err1 || err2);
++}
++
++
++
++struct file_operations mini_fo_dir_fops =
++	{
++		read:	generic_read_dir,
++		write:	mini_fo_write,
++		readdir: mini_fo_readdir,
++		poll:	mini_fo_poll,
++		/* ioctl:	mini_fo_ioctl, */
++		mmap:	mini_fo_mmap,
++		open:	mini_fo_open,
++		flush:	mini_fo_flush,
++		release: mini_fo_release,
++		fsync:	mini_fo_fsync,
++		fasync:	mini_fo_fasync,
++		/* not needed lock:	mini_fo_lock, */
++		/* not needed: readv */
++		/* not needed: writev */
++		/* not implemented: sendpage */
++		/* not implemented: get_unmapped_area */
++	};
++
++struct file_operations mini_fo_main_fops =
++	{
++		llseek:	mini_fo_llseek,
++		read:	mini_fo_read,
++		write:	mini_fo_write,
++		readdir: mini_fo_readdir,
++		poll:	mini_fo_poll,
++		/* ioctl:	mini_fo_ioctl, */
++		mmap:	mini_fo_mmap,
++		open:	mini_fo_open,
++		flush:	mini_fo_flush,
++		release: mini_fo_release,
++		fsync:	mini_fo_fsync,
++		fasync:	mini_fo_fasync,
++		/* not needed: lock:	mini_fo_lock, */
++		/* not needed: readv */
++		/* not needed: writev */
++		/* not implemented: sendpage */
++		/* not implemented: get_unmapped_area */
++	};
+--- /dev/null
++++ b/fs/mini_fo/fist.h
+@@ -0,0 +1,252 @@
++/*
++ * Copyright (c) 1997-2003 Erez Zadok
++ * Copyright (c) 2001-2003 Stony Brook University
++ *
++ * For specific licensing information, see the COPYING file distributed with
++ * this package, or get one from ftp://ftp.filesystems.org/pub/fist/COPYING.
++ *
++ * This Copyright notice must be kept intact and distributed with all
++ * fistgen sources INCLUDING sources generated by fistgen.
++ */
++/*
++ * Copyright (C) 2004, 2005 Markus Klotzbuecher <mk@creamnet.de>
++ *
++ * This program is free software; you can redistribute it and/or
++ * modify it under the terms of the GNU General Public License
++ * as published by the Free Software Foundation; either version
++ * 2 of the License, or (at your option) any later version.
++ */
++
++
++/*
++ *  $Id$
++ */
++
++#ifndef __FIST_H_
++#define __FIST_H_
++
++/*
++ * KERNEL ONLY CODE:
++ */
++#ifdef __KERNEL__
++#include <linux/version.h>
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,19)
++#include <linux/autoconf.h>
++#else
++#include <linux/config.h>
++#endif
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
++#ifdef CONFIG_MODVERSIONS
++# define MODVERSIONS
++# include <linux/modversions.h>
++#endif /* CONFIG_MODVERSIONS */
++#endif /* KERNEL_VERSION < 2.6.0 */
++#include <linux/sched.h>
++#include <linux/kernel.h>
++#include <linux/mm.h>
++#include <linux/string.h>
++#include <linux/stat.h>
++#include <linux/errno.h>
++#include <linux/wait.h>
++#include <linux/limits.h>
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
++#include <linux/locks.h>
++#else
++#include <linux/buffer_head.h>
++#include <linux/pagemap.h>
++#include <linux/namei.h>
++#include <linux/module.h>
++#include <linux/mount.h>
++#include <linux/page-flags.h>
++#include <linux/writeback.h>
++#include <linux/statfs.h>
++#endif
++#include <linux/smp.h>
++#include <linux/smp_lock.h>
++#include <linux/file.h>
++#include <linux/slab.h>
++#include <linux/vmalloc.h>
++#include <linux/poll.h>
++#include <linux/list.h>
++#include <linux/init.h>
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,20)
++#include <linux/xattr.h>
++#endif
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++#include <linux/security.h>
++#endif
++
++#include <linux/swap.h>
++
++#include <asm/system.h>
++/* #include <asm/segment.h> */
++#include <asm/mman.h>
++#include <linux/seq_file.h>
++
++/*
++ * MACROS:
++ */
++
++/* those mapped to ATTR_* were copied from linux/fs.h */
++#define FA_MODE		ATTR_MODE
++#define FA_UID		ATTR_UID
++#define FA_GID		ATTR_GID
++#define FA_SIZE		ATTR_SIZE
++#define FA_ATIME	ATTR_ATIME
++#define FA_MTIME	ATTR_MTIME
++#define FA_CTIME	ATTR_CTIME
++#define FA_ATIME_SET	ATTR_ATIME_SET
++#define FA_MTIME_SET	ATTR_MTIME_SET
++#define FA_FORCE	ATTR_FORCE
++#define FA_ATTR_FLAGS	ATTR_ATTR_FLAG
++
++/* must be greater than all other ATTR_* flags! */
++#define FA_NLINK	2048
++#define FA_BLKSIZE	4096
++#define FA_BLOCKS	8192
++#define FA_TIMES	(FA_ATIME|FA_MTIME|FA_CTIME)
++#define FA_ALL		0
++
++/* macros to manage changes between kernels */
++#define INODE_DATA(i)	(&(i)->i_data)
++
++#define MIN(x,y) ((x < y) ? (x) : (y))
++#define MAX(x,y) ((x > y) ? (x) : (y))
++#define MAXPATHLEN PATH_MAX
++
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,4,5)
++# define lookup_one_len(a,b,c) lookup_one(a,b)
++#endif /* LINUX_VERSION_CODE < KERNEL_VERSION(2,4,5) */
++
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,4,8)
++# define generic_file_llseek default_llseek
++#endif /* LINUX_VERSION_CODE < KERNEL_VERSION(2,4,8) */
++
++#ifndef SEEK_SET
++# define SEEK_SET 0
++#endif /* not SEEK_SET */
++
++#ifndef SEEK_CUR
++# define SEEK_CUR 1
++#endif /* not SEEK_CUR */
++
++#ifndef SEEK_END
++# define SEEK_END 2
++#endif /* not SEEK_END */
++
++#ifndef DEFAULT_POLLMASK
++# define DEFAULT_POLLMASK (POLLIN | POLLOUT | POLLRDNORM | POLLWRNORM)
++#endif /* not DEFAULT_POLLMASK */
++
++/* XXX: fix this so fistgen generates kfree() code directly */
++#define kfree_s(a,b) kfree(a)
++
++/*
++ * TYPEDEFS:
++ */
++typedef struct dentry dentry_t;
++typedef struct file file_t;
++typedef struct inode inode_t;
++typedef inode_t vnode_t;
++typedef struct page page_t;
++typedef struct qstr qstr_t;
++typedef struct super_block super_block_t;
++typedef super_block_t vfs_t;
++typedef struct vm_area_struct vm_area_t;
++
++
++/*
++ * EXTERNALS:
++ */
++
++#define FPPF(str,page) printk("PPF %s 0x%x/%d: Lck:%d Err:%d Ref:%d Upd:%d Other::%d:%d:%d:%d:\n", \
++		str, \
++		(int) page, \
++		(int) page->index, \
++		(PageLocked(page) ? 1 : 0), \
++		(PageError(page) ? 1 : 0), \
++		(PageReferenced(page) ? 1 : 0), \
++		(Page_Uptodate(page) ? 1 : 0), \
++		(PageDecrAfter(page) ? 1 : 0), \
++		(PageSlab(page) ? 1 : 0), \
++		(PageSwapCache(page) ? 1 : 0), \
++		(PageReserved(page) ? 1 : 0) \
++		)
++#define EZKDBG printk("EZK %s:%d:%s\n",__FILE__,__LINE__,__FUNCTION__)
++#if 0
++# define EZKDBG1 printk("EZK %s:%d\n",__FILE__,__LINE__)
++#else
++# define EZKDBG1
++#endif
++
++extern int fist_get_debug_value(void);
++extern int fist_set_debug_value(int val);
++#if 0 /* mini_fo doesn't need these */
++extern void fist_dprint_internal(int level, char *str,...);
++extern void fist_print_dentry(char *str, const dentry_t *dentry);
++extern void fist_print_inode(char *str, const inode_t *inode);
++extern void fist_print_file(char *str, const file_t *file);
++extern void fist_print_buffer_flags(char *str, struct buffer_head *buffer);
++extern void fist_print_page_flags(char *str, page_t *page);
++extern void fist_print_page_bytes(char *str, page_t *page);
++extern void fist_print_pte_flags(char *str, const page_t *page);
++extern void fist_checkinode(inode_t *inode, char *msg);
++extern void fist_print_sb(char *str, const super_block_t *sb);
++
++/* ¬ß$% by mk: special debug functions */
++extern void fist_mk_print_dentry(char *str, const dentry_t *dentry);
++extern void fist_mk_print_inode(char *str, const inode_t *inode);
++
++extern char *add_indent(void);
++extern char *del_indent(void);
++#endif/* mini_fo doesn't need these */
++
++
++#define STATIC
++#define ASSERT(EX)	\
++do {	\
++    if (!(EX)) {	\
++	printk(KERN_CRIT "ASSERTION FAILED: %s at %s:%d (%s)\n", #EX,	\
++	       __FILE__, __LINE__, __FUNCTION__);	\
++	(*((char *)0))=0;	\
++    }	\
++} while (0)
++/* same ASSERT, but tell me who was the caller of the function */
++#define ASSERT2(EX)	\
++do {	\
++    if (!(EX)) {	\
++	printk(KERN_CRIT "ASSERTION FAILED (caller): %s at %s:%d (%s)\n", #EX,	\
++	       file, line, func);	\
++	(*((char *)0))=0;	\
++    }	\
++} while (0)
++
++#if 0 /* mini_fo doesn't need these */
++#define dprintk(format, args...) printk(KERN_DEBUG format, ##args)
++#define fist_dprint(level, str, args...) fist_dprint_internal(level, KERN_DEBUG str, ## args)
++#define print_entry_location() fist_dprint(4, "%sIN:  %s %s:%d\n", add_indent(), __FUNCTION__, __FILE__, __LINE__)
++#define print_exit_location() fist_dprint(4, "%s OUT: %s %s:%d\n", del_indent(), __FUNCTION__, __FILE__, __LINE__)
++#define print_exit_status(status) fist_dprint(4, "%s OUT: %s %s:%d, STATUS: %d\n", del_indent(), __FUNCTION__, __FILE__, __LINE__, status)
++#define print_exit_pointer(status) \
++do { \
++  if (IS_ERR(status)) \
++    fist_dprint(4, "%s OUT: %s %s:%d, RESULT: %ld\n", del_indent(), __FUNCTION__, __FILE__, __LINE__, PTR_ERR(status)); \
++  else \
++    fist_dprint(4, "%s OUT: %s %s:%d, RESULT: 0x%x\n", del_indent(), __FUNCTION__, __FILE__, __LINE__, PTR_ERR(status)); \
++} while (0)
++#endif/* mini_fo doesn't need these */
++
++#endif /* __KERNEL__ */
++
++
++/*
++ * DEFINITIONS FOR USER AND KERNEL CODE:
++ * (Note: ioctl numbers 1--9 are reserved for fistgen, the rest
++ *  are auto-generated automatically based on the user's .fist file.)
++ */
++# define FIST_IOCTL_GET_DEBUG_VALUE	_IOR(0x15, 1, int)
++# define FIST_IOCTL_SET_DEBUG_VALUE	_IOW(0x15, 2, int)
++
++#endif /* not __FIST_H_ */
+--- /dev/null
++++ b/fs/mini_fo/inode.c
+@@ -0,0 +1,1564 @@
++/*
++ * Copyright (c) 1997-2003 Erez Zadok
++ * Copyright (c) 2001-2003 Stony Brook University
++ *
++ * For specific licensing information, see the COPYING file distributed with
++ * this package, or get one from ftp://ftp.filesystems.org/pub/fist/COPYING.
++ *
++ * This Copyright notice must be kept intact and distributed with all
++ * fistgen sources INCLUDING sources generated by fistgen.
++ */
++/*
++ * Copyright (C) 2004, 2005 Markus Klotzbuecher <mk@creamnet.de>
++ *
++ * This program is free software; you can redistribute it and/or
++ * modify it under the terms of the GNU General Public License
++ * as published by the Free Software Foundation; either version
++ * 2 of the License, or (at your option) any later version.
++ */
++
++/*
++ *  $Id$
++ */
++
++#ifdef HAVE_CONFIG_H
++# include <config.h>
++#endif
++
++#include "fist.h"
++#include "mini_fo.h"
++
++STATIC int
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++mini_fo_create(inode_t *dir, dentry_t *dentry, int mode, struct nameidata *nd)
++#else
++mini_fo_create(inode_t *dir, dentry_t *dentry, int mode)
++#endif
++{
++	int err = 0;
++
++	check_mini_fo_dentry(dentry);
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++	err = create_sto_reg_file(dentry, mode, nd);
++#else
++	err = create_sto_reg_file(dentry, mode);
++#endif
++	check_mini_fo_dentry(dentry);
++	return err;
++}
++
++
++STATIC dentry_t *
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++mini_fo_lookup(inode_t *dir, dentry_t *dentry, struct nameidata* nd)
++#else
++mini_fo_lookup(inode_t *dir, dentry_t *dentry)
++#endif
++{
++	int err = 0;
++	dentry_t *hidden_dir_dentry;
++	dentry_t *hidden_dentry = NULL;
++
++	dentry_t *hidden_sto_dir_dentry;
++	dentry_t *hidden_sto_dentry = NULL;
++
++	/* whiteout flag */
++	int del_flag = 0;
++	char *bpath = NULL;
++
++	const char *name;
++	unsigned int namelen;
++
++	/* Don't allow lookups of META-files */
++	namelen = strlen(META_FILENAME);
++	if(namelen == dentry->d_name.len) {
++		if(!strncmp(dentry->d_name.name, META_FILENAME, namelen)) {
++			err = -ENOENT;
++			goto out;
++		}
++	}
++
++	hidden_dir_dentry = dtohd(dentry->d_parent);
++	hidden_sto_dir_dentry = dtohd2(dentry->d_parent);
++
++	name = dentry->d_name.name;
++	namelen = dentry->d_name.len;
++
++	/* must initialize dentry operations */
++	dentry->d_op = &mini_fo_dops;
++
++	/* setup the del_flag */
++	del_flag = __meta_check_d_entry(dir, name, namelen);
++	bpath = __meta_check_r_entry(dir, name, namelen);
++
++	/* perform the lookups of base and storage files:
++	 *
++	 * This caused some serious trouble, as a lookup_one_len passing
++	 * a negative dentry oopses. Solution is to only do the lookup
++	 * if the dentry is positive, else we set it to NULL
++	 * More trouble, who said a *_dir_dentry can't be NULL?
++	 */
++	if(bpath) {
++		/* Cross-Interposing (C), yeah! */
++		hidden_dentry = bpath_walk(dir->i_sb, bpath);
++		if(!hidden_dentry || !hidden_dentry->d_inode) {
++			printk(KERN_CRIT "mini_fo_lookup: bpath_walk failed.\n");
++			err= -EINVAL;
++			goto out;
++		}
++
++		/* this can be set up safely without fear of spaghetti
++		 * interposing as it is only used for copying times */
++		hidden_dir_dentry = hidden_dentry->d_parent;
++		kfree(bpath);
++	}
++	else if(hidden_dir_dentry && hidden_dir_dentry->d_inode)
++		hidden_dentry =
++			lookup_one_len(name, hidden_dir_dentry, namelen);
++	else
++		hidden_dentry = NULL;
++
++	if(hidden_sto_dir_dentry && hidden_sto_dir_dentry->d_inode)
++		hidden_sto_dentry =
++			lookup_one_len(name, hidden_sto_dir_dentry, namelen);
++	else
++		hidden_sto_dentry =  NULL;
++
++	/* catch error in lookup */
++	if (IS_ERR(hidden_dentry) || IS_ERR(hidden_sto_dentry)) {
++		/* mk: we need to call dput on the dentry, whose
++		 * lookup_one_len operation failed, in order to avoid
++		 * unmount trouble.
++		 */
++		if(IS_ERR(hidden_dentry)) {
++			printk(KERN_CRIT "mini_fo_lookup: ERR from base dentry, lookup failed.\n");
++			err = PTR_ERR(hidden_dentry);
++		} else {
++			dput(hidden_dentry);
++		}
++		if(IS_ERR(hidden_sto_dentry)) {
++			printk(KERN_CRIT "mini_fo_lookup: ERR from storage dentry, lookup failed.\n");
++			err = PTR_ERR(hidden_sto_dentry);
++		} else {
++			dput(hidden_sto_dentry);
++		}
++		goto out;
++	}
++
++	/* allocate dentry private data */
++	__dtopd(dentry) = (struct mini_fo_dentry_info *)
++		kmalloc(sizeof(struct mini_fo_dentry_info), GFP_KERNEL);
++
++	if (!dtopd(dentry)) {
++		err = -ENOMEM;
++		goto out_dput;
++	}
++
++	/* check for different states of the mini_fo file to be looked up. */
++
++	/* state 1, file has been modified */
++	if(hidden_dentry && hidden_sto_dentry &&
++	   hidden_dentry->d_inode && hidden_sto_dentry->d_inode && !del_flag) {
++
++		/* update parent directory's atime */
++		fist_copy_attr_atime(dir, hidden_sto_dir_dentry->d_inode);
++
++		dtopd(dentry)->state = MODIFIED;
++		dtohd(dentry) = hidden_dentry;
++		dtohd2(dentry) = hidden_sto_dentry;
++
++		err = mini_fo_tri_interpose(hidden_dentry,
++					    hidden_sto_dentry,
++					    dentry, dir->i_sb, 1);
++		if (err) {
++			printk(KERN_CRIT "mini_fo_lookup: error interposing (state1).\n");
++			goto out_free;
++		}
++		goto out;
++	}
++	/* state 2, file is unmodified */
++	if(hidden_dentry && hidden_dentry->d_inode && !del_flag) {
++
++		fist_copy_attr_atime(dir, hidden_dir_dentry->d_inode);
++
++		dtopd(dentry)->state = UNMODIFIED;
++		dtohd(dentry) = hidden_dentry;
++		dtohd2(dentry) = hidden_sto_dentry; /* could be negative */
++
++		err = mini_fo_tri_interpose(hidden_dentry,
++					    hidden_sto_dentry,
++					    dentry, dir->i_sb, 1);
++		if (err) {
++			printk(KERN_CRIT "mini_fo_lookup: error interposing (state2).\n");
++			goto out_free;
++		}
++		goto out;
++	}
++	/* state 3, file has been newly created */
++	if(hidden_sto_dentry && hidden_sto_dentry->d_inode && !del_flag) {
++
++		fist_copy_attr_atime(dir, hidden_sto_dir_dentry->d_inode);
++		dtopd(dentry)->state = CREATED;
++		dtohd(dentry) = hidden_dentry; /* could be negative */
++		dtohd2(dentry) = hidden_sto_dentry;
++
++		err = mini_fo_tri_interpose(hidden_dentry,
++					    hidden_sto_dentry,
++					    dentry, dir->i_sb, 1);
++		if (err) {
++			printk(KERN_CRIT "mini_fo_lookup: error interposing (state3).\n");
++			goto out_free;
++		}
++		goto out;
++	}
++
++	/* state 4, file has deleted and created again. */
++	if(hidden_dentry && hidden_sto_dentry &&
++	   hidden_dentry->d_inode &&
++	   hidden_sto_dentry->d_inode && del_flag) {
++
++		fist_copy_attr_atime(dir, hidden_sto_dir_dentry->d_inode);
++		dtopd(dentry)->state = DEL_REWRITTEN;
++		dtohd(dentry) = NULL;
++		dtohd2(dentry) = hidden_sto_dentry;
++
++		err = mini_fo_tri_interpose(NULL,
++					    hidden_sto_dentry,
++					    dentry, dir->i_sb, 1);
++		if (err) {
++			printk(KERN_CRIT "mini_fo_lookup: error interposing (state4).\n");
++			goto out_free;
++		}
++		/* We will never need this dentry again, as the file has been
++		 * deleted from base */
++		dput(hidden_dentry);
++		goto out;
++	}
++	/* state 5, file has been deleted in base */
++	if(hidden_dentry && hidden_sto_dentry &&
++	   hidden_dentry->d_inode &&
++	   !hidden_sto_dentry->d_inode && del_flag) {
++
++		/* check which parents atime we need for updating */
++		if(hidden_sto_dir_dentry->d_inode)
++			fist_copy_attr_atime(dir,
++					     hidden_sto_dir_dentry->d_inode);
++		else
++			fist_copy_attr_atime(dir,
++					     hidden_dir_dentry->d_inode);
++
++		dtopd(dentry)->state = DELETED;
++		dtohd(dentry) = NULL;
++		dtohd2(dentry) = hidden_sto_dentry;
++
++		/* add negative dentry to dcache to speed up lookups */
++		d_add(dentry, NULL);
++		dput(hidden_dentry);
++		goto out;
++	}
++	/* state 6, file does not exist */
++	if(((hidden_dentry && !hidden_dentry->d_inode) ||
++	    (hidden_sto_dentry && !hidden_sto_dentry->d_inode)) && !del_flag)
++		{
++			/* check which parents atime we need for updating */
++			if(hidden_sto_dir_dentry && hidden_sto_dir_dentry->d_inode)
++				fist_copy_attr_atime(dir, hidden_sto_dir_dentry->d_inode);
++			else
++				fist_copy_attr_atime(dir, hidden_dir_dentry->d_inode);
++
++			dtopd(dentry)->state = NON_EXISTANT;
++			dtohd(dentry) = hidden_dentry;
++			dtohd2(dentry) = hidden_sto_dentry;
++			d_add(dentry, NULL);
++			goto out;
++		}
++
++	/* if we get to here, were in an invalid state. bad. */
++	printk(KERN_CRIT "mini_fo_lookup: ERROR, meta data corruption detected.\n");
++
++	/* end state checking */
++ out_free:
++	d_drop(dentry);		/* so that our bad dentry will get destroyed */
++	kfree(dtopd(dentry));
++	__dtopd(dentry) = NULL;	/* be safe */
++
++ out_dput:
++	if(hidden_dentry)
++		dput(hidden_dentry);
++	if(hidden_sto_dentry)
++		dput(hidden_sto_dentry); /* drops usage count and marks for release */
++
++ out:
++	/* initalize wol if file exists and is directory */
++	if(dentry->d_inode) {
++		if(S_ISDIR(dentry->d_inode->i_mode)) {
++			itopd(dentry->d_inode)->deleted_list_size = -1;
++			itopd(dentry->d_inode)->renamed_list_size = -1;
++			meta_build_lists(dentry);
++		}
++	}
++	return ERR_PTR(err);
++}
++
++
++STATIC int
++mini_fo_link(dentry_t *old_dentry, inode_t *dir, dentry_t *new_dentry)
++{
++	int err;
++	dentry_t *hidden_old_dentry;
++	dentry_t *hidden_new_dentry;
++	dentry_t *hidden_dir_dentry;
++
++
++	check_mini_fo_dentry(old_dentry);
++	check_mini_fo_dentry(new_dentry);
++	check_mini_fo_inode(dir);
++
++	/* no links to directorys and existing targets target allowed */
++	if(S_ISDIR(old_dentry->d_inode->i_mode) ||
++	   is_mini_fo_existant(new_dentry)) {
++		err = -EPERM;
++		goto out;
++	}
++
++	/* bring it directly from unmod to del_rew */
++	if(dtost(old_dentry) == UNMODIFIED) {
++		err = nondir_unmod_to_mod(old_dentry, 1);
++		if(err) {
++			err = -EINVAL;
++			goto out;
++		}
++		err = meta_add_d_entry(old_dentry->d_parent,
++				       old_dentry->d_name.name,
++				       old_dentry->d_name.len);
++		if(err) {
++			err = -EINVAL;
++			goto out;
++		}
++		dput(dtohd(old_dentry));
++		dtohd(old_dentry) = NULL;
++		dtost(old_dentry) = DEL_REWRITTEN;
++	}
++
++	err = get_neg_sto_dentry(new_dentry);
++	if(err) {
++		err = -EINVAL;
++		goto out;
++	}
++
++	hidden_old_dentry = dtohd2(old_dentry);
++	hidden_new_dentry = dtohd2(new_dentry);
++
++	dget(hidden_old_dentry);
++	dget(hidden_new_dentry);
++
++	/* was: hidden_dir_dentry = lock_parent(hidden_new_dentry); */
++	hidden_dir_dentry = dget(hidden_new_dentry->d_parent);
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_lock(&hidden_dir_dentry->d_inode->i_mutex);
++#else
++	down(&hidden_dir_dentry->d_inode->i_sem);
++#endif
++
++	err = vfs_link(hidden_old_dentry,
++		       hidden_dir_dentry->d_inode,
++		       hidden_new_dentry);
++	if (err || !hidden_new_dentry->d_inode)
++		goto out_lock;
++
++	dtost(new_dentry) = CREATED;
++ 	err = mini_fo_tri_interpose(NULL, hidden_new_dentry, new_dentry, dir->i_sb, 0);
++	if (err)
++		goto out_lock;
++
++	fist_copy_attr_timesizes(dir, hidden_new_dentry->d_inode);
++	/* propagate number of hard-links */
++	old_dentry->d_inode->i_nlink = itohi2(old_dentry->d_inode)->i_nlink;
++
++ out_lock:
++	/* was: unlock_dir(hidden_dir_dentry); */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_unlock(&hidden_dir_dentry->d_inode->i_mutex);
++#else
++	up(&hidden_dir_dentry->d_inode->i_sem);
++#endif
++	dput(hidden_dir_dentry);
++
++	dput(hidden_new_dentry);
++	dput(hidden_old_dentry);
++	if (!new_dentry->d_inode)
++		d_drop(new_dentry);
++
++ out:
++	return err;
++}
++
++
++STATIC int
++mini_fo_unlink(inode_t *dir, dentry_t *dentry)
++{
++	int err = 0;
++
++	dget(dentry);
++	if(dtopd(dentry)->state == MODIFIED) {
++		err = nondir_mod_to_del(dentry);
++		goto out;
++	}
++	else if(dtopd(dentry)->state == UNMODIFIED) {
++		err = nondir_unmod_to_del(dentry);
++		goto out;
++	}
++	else if(dtopd(dentry)->state == CREATED) {
++		err = nondir_creat_to_del(dentry);
++		goto out;
++	}
++	else if(dtopd(dentry)->state == DEL_REWRITTEN) {
++		err = nondir_del_rew_to_del(dentry);
++		goto out;
++	}
++
++	printk(KERN_CRIT "mini_fo_unlink: ERROR, invalid state detected.\n");
++
++ out:
++	fist_copy_attr_times(dir, itohi2(dentry->d_parent->d_inode));
++
++	if(!err) {
++		/* is this causing my pain? d_delete(dentry); */
++		d_drop(dentry);
++	}
++
++	dput(dentry);
++	return err;
++}
++
++
++STATIC int
++mini_fo_symlink(inode_t *dir, dentry_t *dentry, const char *symname)
++{
++	int err=0;
++	dentry_t *hidden_sto_dentry;
++	dentry_t *hidden_sto_dir_dentry;
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++        umode_t mode;
++#endif
++
++	/* Fail if the symlink file exists */
++	if(!(dtost(dentry) == DELETED ||
++	     dtost(dentry) == NON_EXISTANT)) {
++		err = -EEXIST;
++		goto out;
++	}
++
++	err = get_neg_sto_dentry(dentry);
++	if(err) {
++		err = -EINVAL;
++		goto out;
++	}
++	hidden_sto_dentry = dtohd2(dentry);
++
++	dget(hidden_sto_dentry);
++	/* was: hidden_sto_dir_dentry = lock_parent(hidden_sto_dentry); */
++	hidden_sto_dir_dentry = dget(hidden_sto_dentry->d_parent);
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_lock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++	down(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++	mode = S_IALLUGO;
++	err = vfs_symlink(hidden_sto_dir_dentry->d_inode,
++			  hidden_sto_dentry, symname, mode);
++#else
++	err = vfs_symlink(hidden_sto_dir_dentry->d_inode,
++			  hidden_sto_dentry,
++			  symname);
++#endif
++	if (err || !hidden_sto_dentry->d_inode)
++                goto out_lock;
++
++        if(dtost(dentry) == DELETED) {
++                dtost(dentry) = DEL_REWRITTEN;
++                err = mini_fo_tri_interpose(NULL, hidden_sto_dentry, dentry, dir->i_sb, 0);
++                if(err)
++                        goto out_lock;
++        } else if(dtost(dentry) == NON_EXISTANT) {
++                dtost(dentry) = CREATED;
++                err = mini_fo_tri_interpose(dtohd(dentry), hidden_sto_dentry, dentry, dir->i_sb, 0);
++                if(err)
++                        goto out_lock;
++        }
++	fist_copy_attr_timesizes(dir, hidden_sto_dir_dentry->d_inode);
++
++ out_lock:
++        /* was: unlock_dir(hidden_sto_dir_dentry); */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_unlock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++	up(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++	dput(hidden_sto_dir_dentry);
++
++        dput(hidden_sto_dentry);
++        if (!dentry->d_inode)
++                d_drop(dentry);
++ out:
++        return err;
++}
++
++STATIC int
++mini_fo_mkdir(inode_t *dir, dentry_t *dentry, int mode)
++{
++	int err;
++
++	err = create_sto_dir(dentry, mode);
++
++	check_mini_fo_dentry(dentry);
++
++	return err;
++}
++
++
++STATIC int
++mini_fo_rmdir(inode_t *dir, dentry_t *dentry)
++{
++	int err = 0;
++
++	dentry_t *hidden_sto_dentry;
++	dentry_t *hidden_sto_dir_dentry;
++	dentry_t *meta_dentry;
++	inode_t *hidden_sto_dir = NULL;
++
++	check_mini_fo_dentry(dentry);
++	check_mini_fo_inode(dir);
++
++	dget(dentry);
++	if(dtopd(dentry)->state == MODIFIED) {
++		/* XXX: disabled, because it does not bother to check files on
++		 * the original filesystem - just a hack, but better than simply
++		 * removing it without testing */
++		err = -EINVAL;
++		goto out;
++
++		hidden_sto_dir = itohi2(dir);
++		hidden_sto_dentry = dtohd2(dentry);
++
++		/* was:hidden_sto_dir_dentry = lock_parent(hidden_sto_dentry); */
++		hidden_sto_dir_dentry = dget(hidden_sto_dentry->d_parent);
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_lock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++		down(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++
++		/* Delete an old WOL file contained in the storage dir */
++		meta_dentry = lookup_one_len(META_FILENAME,
++					     hidden_sto_dentry,
++					     strlen(META_FILENAME));
++		if(meta_dentry->d_inode) {
++			err = vfs_unlink(hidden_sto_dentry->d_inode, meta_dentry);
++			dput(meta_dentry);
++			if(!err)
++				d_delete(meta_dentry);
++		}
++
++		err = vfs_rmdir(hidden_sto_dir, hidden_sto_dentry);
++		dput(hidden_sto_dentry);
++		if(!err)
++			d_delete(hidden_sto_dentry);
++
++		/* propagate number of hard-links */
++		dentry->d_inode->i_nlink = itohi2(dentry->d_inode)->i_nlink;
++
++		dput(dtohd(dentry));
++
++		dtohd(dentry) = NULL;
++		dtopd(dentry)->state = DELETED;
++
++		/* carefull with R files */
++		if( __meta_is_r_entry(dir,
++				      dentry->d_name.name,
++				      dentry->d_name.len) == 1) {
++			err = meta_remove_r_entry(dentry->d_parent,
++						  dentry->d_name.name,
++						  dentry->d_name.len);
++			if(err) {
++				printk(KERN_CRIT "mini_fo: rmdir: meta_remove_r_entry failed.\n");
++				goto out;
++			}
++		}
++		else {
++			/* ok, add deleted file to META */
++			meta_add_d_entry(dentry->d_parent,
++					 dentry->d_name.name,
++					 dentry->d_name.len);
++		}
++		/* was: unlock_dir(hidden_sto_dir_dentry); */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_unlock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++		up(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++		dput(hidden_sto_dir_dentry);
++		goto out;
++	}
++	else if(dtopd(dentry)->state == UNMODIFIED) {
++		/* XXX: simply adding it to the delete list here is fscking dangerous!
++		 * as a temporary hack, i will disable rmdir on unmodified directories
++		 * for now.
++		 */
++		err = -EINVAL;
++		goto out;
++
++		err = get_neg_sto_dentry(dentry);
++		if(err) {
++			err = -EINVAL;
++			goto out;
++		}
++
++		/* dput base dentry, this will relase the inode and free the
++		 * dentry, as we will never need it again. */
++		dput(dtohd(dentry));
++		dtohd(dentry) = NULL;
++		dtopd(dentry)->state = DELETED;
++
++		/* add deleted file to META-file */
++		meta_add_d_entry(dentry->d_parent,
++				 dentry->d_name.name,
++				 dentry->d_name.len);
++		goto out;
++	}
++	else if(dtopd(dentry)->state == CREATED) {
++		hidden_sto_dir = itohi2(dir);
++		hidden_sto_dentry = dtohd2(dentry);
++
++		/* was: hidden_sto_dir_dentry = lock_parent(hidden_sto_dentry);*/
++		hidden_sto_dir_dentry = dget(hidden_sto_dentry->d_parent);
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_lock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++		down(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++
++		/* Delete an old WOL file contained in the storage dir */
++		meta_dentry = lookup_one_len(META_FILENAME,
++					     hidden_sto_dentry,
++					     strlen(META_FILENAME));
++		if(meta_dentry->d_inode) {
++			/* is this necessary? dget(meta_dentry); */
++			err = vfs_unlink(hidden_sto_dentry->d_inode,
++					 meta_dentry);
++			dput(meta_dentry);
++			if(!err)
++				d_delete(meta_dentry);
++		}
++
++		err = vfs_rmdir(hidden_sto_dir, hidden_sto_dentry);
++		dput(hidden_sto_dentry);
++		if(!err)
++			d_delete(hidden_sto_dentry);
++
++		/* propagate number of hard-links */
++		dentry->d_inode->i_nlink = itohi2(dentry->d_inode)->i_nlink;
++		dtopd(dentry)->state = NON_EXISTANT;
++
++		/* was: unlock_dir(hidden_sto_dir_dentry); */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_unlock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++		up(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++		dput(hidden_sto_dir_dentry);
++
++		goto out;
++	}
++	else if(dtopd(dentry)->state == DEL_REWRITTEN) {
++		hidden_sto_dir = itohi2(dir);
++		hidden_sto_dentry = dtohd2(dentry);
++
++		/* was: hidden_sto_dir_dentry = lock_parent(hidden_sto_dentry);*/
++		hidden_sto_dir_dentry = dget(hidden_sto_dentry->d_parent);
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_lock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++		down(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++
++		/* Delete an old WOL file contained in the storage dir */
++		meta_dentry = lookup_one_len(META_FILENAME,
++					     hidden_sto_dentry,
++					     strlen(META_FILENAME));
++		if(meta_dentry->d_inode) {
++			/* is this necessary? dget(meta_dentry); */
++			err = vfs_unlink(hidden_sto_dentry->d_inode,
++					 meta_dentry);
++			dput(meta_dentry);
++			if(!err)
++				d_delete(meta_dentry);
++		}
++
++		err = vfs_rmdir(hidden_sto_dir, hidden_sto_dentry);
++		dput(hidden_sto_dentry);
++		if(!err)
++			d_delete(hidden_sto_dentry);
++
++		/* propagate number of hard-links */
++		dentry->d_inode->i_nlink = itohi2(dentry->d_inode)->i_nlink;
++		dtopd(dentry)->state = DELETED;
++		/* was: unlock_dir(hidden_sto_dir_dentry); */
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_unlock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++		up(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++		dput(hidden_sto_dir_dentry);
++		goto out;
++	}
++
++	printk(KERN_CRIT "mini_fo_rmdir: ERROR, invalid state detected.\n");
++
++ out:
++	if(!err) {
++		d_drop(dentry);
++	}
++
++	fist_copy_attr_times(dir, itohi2(dentry->d_parent->d_inode));
++	dput(dentry);
++
++	return err;
++}
++
++
++STATIC int
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++mini_fo_mknod(inode_t *dir, dentry_t *dentry, int mode, dev_t dev)
++#else
++mini_fo_mknod(inode_t *dir, dentry_t *dentry, int mode, int dev)
++#endif
++{
++	int err = 0;
++
++	check_mini_fo_dentry(dentry);
++
++	err = create_sto_nod(dentry, mode, dev);
++	if(err) {
++		printk(KERN_CRIT "mini_fo_mknod: creating sto nod failed.\n");
++		err = -EINVAL;
++	}
++
++	check_mini_fo_dentry(dentry);
++	return err;
++}
++
++
++STATIC int
++mini_fo_rename(inode_t *old_dir, dentry_t *old_dentry,
++	       inode_t *new_dir, dentry_t *new_dentry)
++{
++	/* dispatch */
++	if(S_ISDIR(old_dentry->d_inode->i_mode))
++		return rename_directory(old_dir, old_dentry, new_dir, new_dentry);
++	return rename_nondir(old_dir, old_dentry, new_dir, new_dentry);
++
++}
++
++int rename_directory(inode_t *old_dir, dentry_t *old_dentry,
++		     inode_t *new_dir, dentry_t *new_dentry)
++{
++	int err, bpath_len;
++	char *bpath;
++
++	dentry_t *hidden_old_dentry;
++	dentry_t *hidden_new_dentry;
++	dentry_t *hidden_old_dir_dentry;
++	dentry_t *hidden_new_dir_dentry;
++
++	err = 0;
++	bpath = NULL;
++	bpath_len = 0;
++
++	/* this is a test, chuck out if it works */
++	if(!(dtopd(new_dentry)->state == DELETED ||
++	     dtopd(new_dentry)->state == NON_EXISTANT)) {
++		printk(KERN_CRIT "mini_fo: rename_directory: \
++                                  uh, ah, new_dentry not negative.\n");
++		/* return -1; */
++	}
++
++	/* state = UNMODIFIED */
++	if(dtopd(old_dentry)->state == UNMODIFIED) {
++		err = dir_unmod_to_mod(old_dentry);
++		if (err)
++			goto out;
++	}
++
++	/* state = MODIFIED */
++	if(dtopd(old_dentry)->state == MODIFIED) {
++		bpath = meta_check_r_entry(old_dentry->d_parent,
++					   old_dentry->d_name.name,
++					   old_dentry->d_name.len);
++		if(bpath) {
++			err = meta_remove_r_entry(old_dentry->d_parent,
++						  old_dentry->d_name.name,
++						  old_dentry->d_name.len);
++			if(err) {
++				printk(KERN_CRIT "mini_fo: rename_directory:\
++                                                   meta_remove_r_entry \
++                                                  failed.\n");
++				goto out;
++			}
++			err = meta_add_r_entry(new_dentry->d_parent,
++					       bpath,
++					       strlen(bpath),
++					       new_dentry->d_name.name,
++					       new_dentry->d_name.len);
++			kfree(bpath);
++		}
++		else {/* wol it */
++			err = meta_add_d_entry(old_dentry->d_parent,
++					       old_dentry->d_name.name,
++					       old_dentry->d_name.len);
++			if (err)
++				goto out;
++			/* put it on rename list */
++			err = get_mini_fo_bpath(old_dentry,
++						&bpath,
++						&bpath_len);
++			if (err)
++				goto out;
++			err = meta_add_r_entry(new_dentry->d_parent,
++					       bpath, bpath_len,
++					       new_dentry->d_name.name,
++					       new_dentry->d_name.len);
++			if (err)
++				goto out;
++		}
++		/* no state change, MODIFIED stays MODIFIED */
++	}
++	/* state = CREATED */
++	if(dtopd(old_dentry)->state == CREATED ||
++	   dtopd(old_dentry)->state == DEL_REWRITTEN) {
++		if(dtohd(old_dentry))
++			dput(dtohd(old_dentry));
++
++		if(dtopd(new_dentry)->state == DELETED) {
++			dtopd(old_dentry)->state = DEL_REWRITTEN;
++			dtohd(old_dentry) = NULL;
++		}
++		else if(dtopd(new_dentry)->state == NON_EXISTANT) {
++			dtopd(old_dentry)->state = CREATED;
++			/* steal new dentry's neg. base dentry */
++			dtohd(old_dentry) = dtohd(new_dentry);
++			dtohd(new_dentry) = NULL;
++		}
++	}
++	if(dtopd(new_dentry)->state == UNMODIFIED ||
++	   dtopd(new_dentry)->state == NON_EXISTANT) {
++		err = get_neg_sto_dentry(new_dentry);
++		if(err)
++			goto out;
++	}
++
++	/* now move sto file */
++	hidden_old_dentry = dtohd2(old_dentry);
++	hidden_new_dentry = dtohd2(new_dentry);
++
++	dget(hidden_old_dentry);
++	dget(hidden_new_dentry);
++
++	hidden_old_dir_dentry = dget(hidden_old_dentry->d_parent);
++	hidden_new_dir_dentry = dget(hidden_new_dentry->d_parent);
++	double_lock(hidden_old_dir_dentry, hidden_new_dir_dentry);
++
++	err = vfs_rename(hidden_old_dir_dentry->d_inode, hidden_old_dentry,
++			 hidden_new_dir_dentry->d_inode, hidden_new_dentry);
++	if(err)
++		goto out_lock;
++
++	fist_copy_attr_all(new_dir, hidden_new_dir_dentry->d_inode);
++	if (new_dir != old_dir)
++		fist_copy_attr_all(old_dir,
++				   hidden_old_dir_dentry->d_inode);
++
++ out_lock:
++	/* double_unlock will dput the new/old parent dentries
++	 * whose refcnts were incremented via get_parent above. */
++	double_unlock(hidden_old_dir_dentry, hidden_new_dir_dentry);
++	dput(hidden_new_dentry);
++	dput(hidden_old_dentry);
++
++ out:
++	return err;
++}
++
++int rename_nondir(inode_t *old_dir, dentry_t *old_dentry,
++		  inode_t *new_dir, dentry_t *new_dentry)
++{
++	int err=0;
++
++	check_mini_fo_dentry(old_dentry);
++	check_mini_fo_dentry(new_dentry);
++	check_mini_fo_inode(old_dir);
++	check_mini_fo_inode(new_dir);
++
++	/* state: UNMODIFIED */
++	if(dtost(old_dentry) == UNMODIFIED) {
++		err = nondir_unmod_to_mod(old_dentry, 1);
++		if(err) {
++			err = -EINVAL;
++			goto out;
++		}
++	}
++
++	/* the easy states */
++	if(exists_in_storage(old_dentry)) {
++
++		dentry_t *hidden_old_dentry;
++		dentry_t *hidden_new_dentry;
++		dentry_t *hidden_old_dir_dentry;
++		dentry_t *hidden_new_dir_dentry;
++
++		/* if old file is MODIFIED, add it to the deleted_list */
++		if(dtopd(old_dentry)->state == MODIFIED) {
++			meta_add_d_entry(old_dentry->d_parent,
++					 old_dentry->d_name.name,
++					 old_dentry->d_name.len);
++
++			dput(dtohd(old_dentry));
++		}
++		/* if old file is CREATED, we only release the base dentry */
++		if(dtopd(old_dentry)->state == CREATED) {
++			if(dtohd(old_dentry))
++				dput(dtohd(old_dentry));
++		}
++
++		/* now setup the new states (depends on new_dentry state) */
++		/* new dentry state =  MODIFIED */
++		if(dtopd(new_dentry)->state == MODIFIED) {
++			meta_add_d_entry(new_dentry->d_parent,
++					 new_dentry->d_name.name,
++					 new_dentry->d_name.len);
++
++			/* new dentry will be d_put'ed later by the vfs
++			 * so don't do it here
++			 * dput(dtohd(new_dentry));
++			 */
++			dtohd(old_dentry) = NULL;
++			dtopd(old_dentry)->state = DEL_REWRITTEN;
++		}
++		/* new dentry state =  UNMODIFIED */
++		else if(dtopd(new_dentry)->state == UNMODIFIED) {
++			if(get_neg_sto_dentry(new_dentry))
++				return -EINVAL;
++
++			meta_add_d_entry(new_dentry->d_parent,
++					 new_dentry->d_name.name,
++					 new_dentry->d_name.len);
++
++			/* is this right??? */
++			/*dput(dtohd(new_dentry));*/
++			dtohd(old_dentry) = NULL;
++			dtopd(old_dentry)->state = DEL_REWRITTEN;
++		}
++		/* new dentry state =  CREATED */
++		else if(dtopd(new_dentry)->state == CREATED) {
++			/* we keep the neg. base dentry (if exists) */
++			dtohd(old_dentry) = dtohd(new_dentry);
++			/* ...and set it to Null, or we'll get
++			 * dcache.c:345 if it gets dput twice... */
++			dtohd(new_dentry) = NULL;
++			dtopd(old_dentry)->state = CREATED;
++		}
++		/* new dentry state =  NON_EXISTANT */
++		else if(dtopd(new_dentry)->state == NON_EXISTANT) {
++			if(get_neg_sto_dentry(new_dentry))
++				return -EINVAL;
++
++			/* we keep the neg. base dentry (if exists) */
++			dtohd(old_dentry) = dtohd(new_dentry);
++			/* ...and set it to Null, or we'll get
++			 * Dr. dcache.c:345 if it gets dput twice... */
++			dtohd(new_dentry) = NULL;
++			dtopd(old_dentry)->state = CREATED;
++		}
++		/* new dentry state =  DEL_REWRITTEN or DELETED */
++		else if(dtopd(new_dentry)->state == DEL_REWRITTEN ||
++			dtopd(new_dentry)->state == DELETED) {
++			dtohd(old_dentry) = NULL;
++			dtopd(old_dentry)->state = DEL_REWRITTEN;
++		}
++		else { /* not possible, uhh, ahh */
++			printk(KERN_CRIT
++			       "mini_fo: rename_reg_file: invalid state detected [1].\n");
++			return -1;
++		}
++
++		/* now we definitely have a sto file */
++		hidden_old_dentry = dtohd2(old_dentry);
++		hidden_new_dentry = dtohd2(new_dentry);
++
++		dget(hidden_old_dentry);
++		dget(hidden_new_dentry);
++
++		hidden_old_dir_dentry = dget(hidden_old_dentry->d_parent);
++		hidden_new_dir_dentry = dget(hidden_new_dentry->d_parent);
++		double_lock(hidden_old_dir_dentry, hidden_new_dir_dentry);
++
++		err = vfs_rename(hidden_old_dir_dentry->d_inode,
++				 hidden_old_dentry,
++				 hidden_new_dir_dentry->d_inode,
++				 hidden_new_dentry);
++		if(err)
++			goto out_lock;
++
++		fist_copy_attr_all(new_dir, hidden_new_dir_dentry->d_inode);
++		if (new_dir != old_dir)
++			fist_copy_attr_all(old_dir, hidden_old_dir_dentry->d_inode);
++
++	out_lock:
++		/* double_unlock will dput the new/old parent dentries
++		 * whose refcnts were incremented via get_parent above.
++		 */
++		double_unlock(hidden_old_dir_dentry, hidden_new_dir_dentry);
++		dput(hidden_new_dentry);
++		dput(hidden_old_dentry);
++	out:
++		return err;
++	}
++	else { /* invalid state */
++		printk(KERN_CRIT "mini_fo: rename_reg_file: ERROR: invalid state detected [2].\n");
++		return -1;
++	}
++}
++
++
++STATIC int
++mini_fo_readlink(dentry_t *dentry, char *buf, int bufsiz)
++{
++	int err=0;
++	dentry_t *hidden_dentry = NULL;
++
++	if(dtohd2(dentry) && dtohd2(dentry)->d_inode) {
++		hidden_dentry = dtohd2(dentry);
++	} else if(dtohd(dentry) && dtohd(dentry)->d_inode) {
++		hidden_dentry = dtohd(dentry);
++	} else {
++		goto out;
++	}
++
++	if (!hidden_dentry->d_inode->i_op ||
++	    !hidden_dentry->d_inode->i_op->readlink) {
++		err = -EINVAL;		goto out;
++	}
++
++	err = hidden_dentry->d_inode->i_op->readlink(hidden_dentry,
++						     buf,
++						     bufsiz);
++	if (err > 0)
++		fist_copy_attr_atime(dentry->d_inode, hidden_dentry->d_inode);
++
++ out:
++	return err;
++}
++
++
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,13)
++static int mini_fo_follow_link(dentry_t *dentry, struct nameidata *nd)
++#else
++static void* mini_fo_follow_link(dentry_t *dentry, struct nameidata *nd)
++#endif
++{
++	char *buf;
++	int len = PAGE_SIZE, err;
++	mm_segment_t old_fs;
++
++	/* in 2.6 this is freed by mini_fo_put_link called by __do_follow_link */
++	buf = kmalloc(len, GFP_KERNEL);
++	if (!buf) {
++		err = -ENOMEM;
++		goto out;
++	}
++
++	/* read the symlink, and then we will follow it */
++	old_fs = get_fs();
++	set_fs(KERNEL_DS);
++	err = dentry->d_inode->i_op->readlink(dentry, buf, len);
++	set_fs(old_fs);
++	if (err < 0) {
++		kfree(buf);
++		buf = NULL;
++		goto out;
++	}
++	buf[err] = 0;
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++        nd_set_link(nd, buf);
++        err = 0;
++#else
++	err = vfs_follow_link(nd, buf);
++#endif
++
++ out:
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
++	kfree(buf);
++#endif
++
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,13)
++        return err;
++#else
++        return ERR_PTR(err);
++#endif
++}
++
++STATIC
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,13)
++void mini_fo_put_link(struct dentry *dentry, struct nameidata *nd)
++#else
++void mini_fo_put_link(struct dentry *dentry, struct nameidata *nd, void *cookie)
++#endif
++{
++        char *link;
++        link = nd_get_link(nd);
++        kfree(link);
++}
++#endif
++
++STATIC int
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++mini_fo_permission(inode_t *inode, int mask, struct nameidata *nd)
++#else
++mini_fo_permission(inode_t *inode, int mask)
++#endif
++{
++	inode_t *hidden_inode;
++	int mode;
++	int err;
++
++	if(itohi2(inode)) {
++		hidden_inode = itohi2(inode);
++	} else {
++		hidden_inode = itohi(inode);
++	}
++	mode = inode->i_mode;
++
++	/* not really needed, as permission handles everything:
++	 *	err = vfs_permission(inode, mask);
++	 *	if (err)
++	 *		goto out;
++	 */
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++	err = permission(hidden_inode, mask, nd);
++#else
++	err = permission(hidden_inode, mask);
++#endif
++
++	/*  out: */
++	return err;
++}
++
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
++STATIC int
++mini_fo_inode_revalidate(dentry_t *dentry)
++{
++	int err = 0;
++	dentry_t *hidden_dentry;
++	inode_t *hidden_inode;
++
++	ASSERT(dentry->d_inode);
++	ASSERT(itopd(dentry->d_inode));
++
++	if(itohi2(dentry->d_inode)) {
++                hidden_dentry = dtohd2(dentry);
++		hidden_inode = hidden_dentry->d_inode;
++	} else if(itohi(dentry->d_inode)) {
++                hidden_dentry = dtohd(dentry);
++		hidden_inode = hidden_dentry->d_inode;
++	} else {
++                printk(KERN_CRIT "mini_fo_inode_revalidate: ERROR, invalid state detected.\n");
++                err = -ENOENT;
++                goto out;
++        }
++	if (hidden_inode && hidden_inode->i_op && hidden_inode->i_op->revalidate){
++		err = hidden_inode->i_op->revalidate(hidden_dentry);
++		if (err)
++			goto out;
++	}
++	fist_copy_attr_all(dentry->d_inode, hidden_inode);
++ out:
++	return err;
++}
++#endif
++
++STATIC int
++mini_fo_setattr(dentry_t *dentry, struct iattr *ia)
++{
++	int err = 0;
++
++	check_mini_fo_dentry(dentry);
++
++	if(!is_mini_fo_existant(dentry)) {
++		printk(KERN_CRIT "mini_fo_setattr: ERROR, invalid state detected [1].\n");
++		goto out;
++	}
++
++	if(dtost(dentry) == UNMODIFIED) {
++		if(!IS_COPY_FLAG(ia->ia_valid))
++			goto out; /* we ignore these changes to base */
++
++		if(S_ISDIR(dentry->d_inode->i_mode)) {
++			err = dir_unmod_to_mod(dentry);
++		} else {
++			/* we copy contents if file is not beeing truncated */
++			if(S_ISREG(dentry->d_inode->i_mode) &&
++			   !(ia->ia_size == 0 && (ia->ia_valid & ATTR_SIZE))) {
++				err = nondir_unmod_to_mod(dentry, 1);
++			} else
++				err = nondir_unmod_to_mod(dentry, 0);
++		}
++		if(err) {
++			err = -EINVAL;
++			printk(KERN_CRIT "mini_fo_setattr: ERROR changing states.\n");
++			goto out;
++		}
++	}
++	if(!exists_in_storage(dentry)) {
++		printk(KERN_CRIT "mini_fo_setattr: ERROR, invalid state detected [2].\n");
++		err = -EINVAL;
++		goto out;
++	}
++	ASSERT(dentry->d_inode);
++	ASSERT(dtohd2(dentry));
++	ASSERT(itopd(dentry->d_inode));
++	ASSERT(itohi2(dentry->d_inode));
++
++	err = notify_change(dtohd2(dentry), ia);
++	fist_copy_attr_all(dentry->d_inode, itohi2(dentry->d_inode));
++ out:
++	return err;
++}
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++STATIC int
++mini_fo_getattr(struct vfsmount *mnt, struct dentry *dentry, struct kstat *stat)
++{
++	int err = 0;
++        dentry_t *hidden_dentry;
++
++	ASSERT(dentry->d_inode);
++	ASSERT(itopd(dentry->d_inode));
++
++	if(itohi2(dentry->d_inode)) {
++                hidden_dentry = dtohd2(dentry);
++	} else if(itohi(dentry->d_inode)) {
++                hidden_dentry = dtohd(dentry);
++	} else {
++                printk(KERN_CRIT "mini_fo_getattr: ERROR, invalid state detected.\n");
++                err = -ENOENT;
++                goto out;
++        }
++	fist_copy_attr_all(dentry->d_inode, hidden_dentry->d_inode);
++
++	ASSERT(hidden_dentry);
++	ASSERT(hidden_dentry->d_inode);
++	ASSERT(hidden_dentry->d_inode->i_op);
++
++	generic_fillattr(dentry->d_inode, stat);
++	if (!stat->blksize) {
++		struct super_block *s = hidden_dentry->d_inode->i_sb;
++		unsigned blocks;
++		blocks = (stat->size+s->s_blocksize-1) >> s->s_blocksize_bits;
++		stat->blocks = (s->s_blocksize / 512) * blocks;
++		stat->blksize = s->s_blocksize;
++	}
++ out:
++        return err;
++}
++#endif
++
++#if defined(XATTR) && (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,20))
++#if 0 /* no xattr_alloc() and xattr_free() */
++/* This is lifted from fs/xattr.c */
++static void *
++xattr_alloc(size_t size, size_t limit)
++{
++	void *ptr;
++
++	if (size > limit)
++		return ERR_PTR(-E2BIG);
++
++	if (!size)	/* size request, no buffer is needed */
++		return NULL;
++	else if (size <= PAGE_SIZE)
++		ptr = kmalloc((unsigned long) size, GFP_KERNEL);
++	else
++		ptr = vmalloc((unsigned long) size);
++	if (!ptr)
++		return ERR_PTR(-ENOMEM);
++	return ptr;
++}
++
++static void
++xattr_free(void *ptr, size_t size)
++{
++	if (!size)	/* size request, no buffer was needed */
++		return;
++	else if (size <= PAGE_SIZE)
++		kfree(ptr);
++	else
++		vfree(ptr);
++}
++#endif /* no xattr_alloc() and xattr_free() */
++
++/* BKL held by caller.
++ * dentry->d_inode->i_sem down
++ */
++STATIC int
++mini_fo_getxattr(struct dentry *dentry, const char *name, void *value, size_t size) {
++	struct dentry *hidden_dentry = NULL;
++	int err = -EOPNOTSUPP;
++	/* Define these anyway so we don't need as much ifdef'ed code. */
++	char *encoded_name = NULL;
++	char *encoded_value = NULL;
++
++	check_mini_fo_dentry(dentry);
++
++	if(exists_in_storage(dentry))
++		hidden_dentry = dtohd2(dentry);
++	else
++		hidden_dentry = dtohd(dentry);
++
++	ASSERT(hidden_dentry);
++	ASSERT(hidden_dentry->d_inode);
++	ASSERT(hidden_dentry->d_inode->i_op);
++
++	if (hidden_dentry->d_inode->i_op->getxattr) {
++		encoded_name = (char *)name;
++		encoded_value = (char *)value;
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_lock(&hidden_dentry->d_inode->i_mutex);
++#else
++		down(&hidden_dentry->d_inode->i_sem);
++#endif
++		/* lock_kernel() already done by caller. */
++		err = hidden_dentry->d_inode->i_op->getxattr(hidden_dentry, encoded_name, encoded_value, size);
++		/* unlock_kernel() will be done by caller. */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_unlock(&hidden_dentry->d_inode->i_mutex);
++#else
++		up(&hidden_dentry->d_inode->i_sem);
++#endif
++	}
++	return err;
++}
++
++/* BKL held by caller.
++ * dentry->d_inode->i_sem down
++ */
++STATIC int
++#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,21) \
++     && LINUX_VERSION_CODE <= KERNEL_VERSION(2,4,23)) \
++     || LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0))
++mini_fo_setxattr(struct dentry *dentry, const char *name,
++		 const void *value, size_t size, int flags)
++#else
++mini_fo_setxattr(struct dentry *dentry, const char *name,
++		 void *value, size_t size, int flags)
++#endif
++
++{
++	struct dentry *hidden_dentry = NULL;
++	int err = -EOPNOTSUPP;
++
++	/* Define these anyway, so we don't have as much ifdef'ed code. */
++	char *encoded_value = NULL;
++	char *encoded_name = NULL;
++
++	check_mini_fo_dentry(dentry);
++
++	if(exists_in_storage(dentry))
++		hidden_dentry = dtohd2(dentry);
++	else
++		hidden_dentry = dtohd(dentry);
++
++	ASSERT(hidden_dentry);
++	ASSERT(hidden_dentry->d_inode);
++	ASSERT(hidden_dentry->d_inode->i_op);
++
++	if (hidden_dentry->d_inode->i_op->setxattr) {
++		encoded_name = (char *)name;
++		encoded_value = (char *)value;
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_lock(&hidden_dentry->d_inode->i_mutex);
++#else
++		down(&hidden_dentry->d_inode->i_sem);
++#endif
++		/* lock_kernel() already done by caller. */
++		err = hidden_dentry->d_inode->i_op->setxattr(hidden_dentry, encoded_name, encoded_value, size, flags);
++		/* unlock_kernel() will be done by caller. */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_unlock(&hidden_dentry->d_inode->i_mutex);
++#else
++		up(&hidden_dentry->d_inode->i_sem);
++#endif
++	}
++	return err;
++}
++
++/* BKL held by caller.
++ * dentry->d_inode->i_sem down
++ */
++STATIC int
++mini_fo_removexattr(struct dentry *dentry, const char *name) {
++	struct dentry *hidden_dentry = NULL;
++	int err = -EOPNOTSUPP;
++	char *encoded_name;
++
++	check_mini_fo_dentry(dentry);
++
++	if(exists_in_storage(dentry))
++		hidden_dentry = dtohd2(dentry);
++	else
++		hidden_dentry = dtohd(dentry);
++
++	ASSERT(hidden_dentry);
++	ASSERT(hidden_dentry->d_inode);
++	ASSERT(hidden_dentry->d_inode->i_op);
++
++	if (hidden_dentry->d_inode->i_op->removexattr) {
++		encoded_name = (char *)name;
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_lock(&hidden_dentry->d_inode->i_mutex);
++#else
++		down(&hidden_dentry->d_inode->i_sem);
++#endif
++		/* lock_kernel() already done by caller. */
++		err = hidden_dentry->d_inode->i_op->removexattr(hidden_dentry, encoded_name);
++		/* unlock_kernel() will be done by caller. */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_unlock(&hidden_dentry->d_inode->i_mutex);
++#else
++		up(&hidden_dentry->d_inode->i_sem);
++#endif
++	}
++	return err;
++}
++
++/* BKL held by caller.
++ * dentry->d_inode->i_sem down
++ */
++STATIC int
++mini_fo_listxattr(struct dentry *dentry, char *list, size_t size) {
++	struct dentry *hidden_dentry = NULL;
++	int err = -EOPNOTSUPP;
++	char *encoded_list = NULL;
++
++	check_mini_fo_dentry(dentry);
++
++	if(exists_in_storage(dentry))
++		hidden_dentry = dtohd2(dentry);
++	else
++		hidden_dentry = dtohd(dentry);
++
++	ASSERT(hidden_dentry);
++	ASSERT(hidden_dentry->d_inode);
++	ASSERT(hidden_dentry->d_inode->i_op);
++
++	if (hidden_dentry->d_inode->i_op->listxattr) {
++		encoded_list = list;
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_lock(&hidden_dentry->d_inode->i_mutex);
++#else
++		down(&hidden_dentry->d_inode->i_sem);
++#endif
++		/* lock_kernel() already done by caller. */
++		err = hidden_dentry->d_inode->i_op->listxattr(hidden_dentry, encoded_list, size);
++		/* unlock_kernel() will be done by caller. */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_unlock(&hidden_dentry->d_inode->i_mutex);
++#else
++		up(&hidden_dentry->d_inode->i_sem);
++#endif
++	}
++	return err;
++}
++# endif /* defined(XATTR) && (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,20)) */
++
++struct inode_operations mini_fo_symlink_iops =
++	{
++		readlink:	mini_fo_readlink,
++		follow_link: mini_fo_follow_link,
++		/* mk: permission:	mini_fo_permission, */
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
++		revalidate:	mini_fo_inode_revalidate,
++#endif
++		setattr:	mini_fo_setattr,
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++		getattr:	mini_fo_getattr,
++		put_link:       mini_fo_put_link,
++#endif
++
++#if defined(XATTR) && (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,20))
++		setxattr:	mini_fo_setxattr,
++		getxattr:	mini_fo_getxattr,
++		listxattr:	mini_fo_listxattr,
++		removexattr: mini_fo_removexattr
++# endif /* defined(XATTR) && (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,20)) */
++	};
++
++struct inode_operations mini_fo_dir_iops =
++	{
++		create:	mini_fo_create,
++		lookup:	mini_fo_lookup,
++		link:	mini_fo_link,
++		unlink:	mini_fo_unlink,
++		symlink:	mini_fo_symlink,
++		mkdir:	mini_fo_mkdir,
++		rmdir:	mini_fo_rmdir,
++		mknod:	mini_fo_mknod,
++		rename:	mini_fo_rename,
++		/* no readlink/follow_link for non-symlinks */
++		// off because we have setattr
++		//    truncate:	mini_fo_truncate,
++		/* mk:permission:	mini_fo_permission, */
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
++		revalidate:	mini_fo_inode_revalidate,
++#endif
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++		getattr:	mini_fo_getattr,
++#endif
++		setattr:	mini_fo_setattr,
++#if defined(XATTR) && (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,20))
++		setxattr:	mini_fo_setxattr,
++		getxattr:	mini_fo_getxattr,
++		listxattr:	mini_fo_listxattr,
++		removexattr: mini_fo_removexattr
++# endif /* XATTR && LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,20) */
++	};
++
++struct inode_operations mini_fo_main_iops =
++	{
++		/* permission:	mini_fo_permission, */
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
++		revalidate:	mini_fo_inode_revalidate,
++#endif
++		setattr:	mini_fo_setattr,
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++		getattr:	mini_fo_getattr,
++#endif
++#if defined(XATTR) && (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,20))
++		setxattr:	mini_fo_setxattr,
++		getxattr:	mini_fo_getxattr,
++		listxattr:	mini_fo_listxattr,
++		removexattr:    mini_fo_removexattr
++# endif /* XATTR && LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,20) */
++	};
+--- /dev/null
++++ b/fs/mini_fo/main.c
+@@ -0,0 +1,423 @@
++/*
++ * Copyright (c) 1997-2003 Erez Zadok
++ * Copyright (c) 2001-2003 Stony Brook University
++ *
++ * For specific licensing information, see the COPYING file distributed with
++ * this package, or get one from ftp://ftp.filesystems.org/pub/fist/COPYING.
++ *
++ * This Copyright notice must be kept intact and distributed with all
++ * fistgen sources INCLUDING sources generated by fistgen.
++ */
++/*
++ * Copyright (C) 2004, 2005 Markus Klotzbuecher <mk@creamnet.de>
++ *
++ * This program is free software; you can redistribute it and/or
++ * modify it under the terms of the GNU General Public License
++ * as published by the Free Software Foundation; either version
++ * 2 of the License, or (at your option) any later version.
++ */
++
++/*
++ *  $Id$
++ */
++
++#ifdef HAVE_CONFIG_H
++# include <config.h>
++#endif
++
++#include "fist.h"
++#include "mini_fo.h"
++#include <linux/module.h>
++
++/* This definition must only appear after we include <linux/module.h> */
++#ifndef MODULE_LICENSE
++# define MODULE_LICENSE(bison)
++#endif /* not MODULE_LICENSE */
++
++/*
++ * This is the mini_fo tri interpose function, which extends the
++ * functionality of the regular interpose by interposing a higher
++ * level inode on top of two lower level ones: the base filesystem
++ * inode and the storage filesystem inode.
++ *
++ *  sb we pass is mini_fo's super_block
++ */
++int
++mini_fo_tri_interpose(dentry_t *hidden_dentry,
++		      dentry_t *hidden_sto_dentry,
++		      dentry_t *dentry, super_block_t *sb, int flag)
++{
++	inode_t *hidden_inode = NULL;
++	inode_t *hidden_sto_inode = NULL; /* store corresponding storage inode */
++	int err = 0;
++	inode_t *inode;
++
++	/* Pointer to hidden_sto_inode if exists, else to hidden_inode.
++	 * This is used to copy the attributes of the correct inode. */
++	inode_t *master_inode;
++
++	if(hidden_dentry)
++		hidden_inode = hidden_dentry->d_inode;
++	if(hidden_sto_dentry)
++		hidden_sto_inode = hidden_sto_dentry->d_inode;
++
++	ASSERT(dentry->d_inode == NULL);
++
++	/* mk: One of the inodes associated with the dentrys is likely to
++	 * be NULL, so carefull:
++	 */
++	ASSERT((hidden_inode != NULL) || (hidden_sto_inode != NULL));
++
++	if(hidden_sto_inode)
++		master_inode = hidden_sto_inode;
++	else
++		master_inode = hidden_inode;
++
++	/*
++	 * We allocate our new inode below, by calling iget.
++	 * iget will call our read_inode which will initialize some
++	 * of the new inode's fields
++	 */
++
++	/*
++	 * original: inode = iget(sb, hidden_inode->i_ino);
++	 */
++	inode = iget(sb, iunique(sb, 25));
++	if (!inode) {
++		err = -EACCES;		/* should be impossible??? */
++		goto out;
++	}
++
++	/*
++	 * interpose the inode if not already interposed
++	 *   this is possible if the inode is being reused
++	 * XXX: what happens if we get_empty_inode() but there's another already?
++	 * for now, ASSERT() that this can't happen; fix later.
++	 */
++	if (itohi(inode) != NULL) {
++		printk(KERN_CRIT "mini_fo_tri_interpose: itohi(inode) != NULL.\n");
++	}
++	if (itohi2(inode) != NULL) {
++		printk(KERN_CRIT "mini_fo_tri_interpose: itohi2(inode) != NULL.\n");
++	}
++
++	/* mk: Carefull, igrab can't handle NULL inodes (ok, why should it?), so
++	 * we need to check here:
++	 */
++	if(hidden_inode)
++		itohi(inode) = igrab(hidden_inode);
++	else
++		itohi(inode) = NULL;
++
++	if(hidden_sto_inode)
++		itohi2(inode) = igrab(hidden_sto_inode);
++	else
++		itohi2(inode) = NULL;
++
++
++	/* Use different set of inode ops for symlinks & directories*/
++	if (S_ISLNK(master_inode->i_mode))
++		inode->i_op = &mini_fo_symlink_iops;
++	else if (S_ISDIR(master_inode->i_mode))
++		inode->i_op = &mini_fo_dir_iops;
++
++	/* Use different set of file ops for directories */
++	if (S_ISDIR(master_inode->i_mode))
++		inode->i_fop = &mini_fo_dir_fops;
++
++	/* properly initialize special inodes */
++	if (S_ISBLK(master_inode->i_mode) || S_ISCHR(master_inode->i_mode) ||
++	    S_ISFIFO(master_inode->i_mode) || S_ISSOCK(master_inode->i_mode)) {
++		init_special_inode(inode, master_inode->i_mode, master_inode->i_rdev);
++	}
++
++	/* Fix our inode's address operations to that of the lower inode */
++	if (inode->i_mapping->a_ops != master_inode->i_mapping->a_ops) {
++		inode->i_mapping->a_ops = master_inode->i_mapping->a_ops;
++	}
++
++	/* only (our) lookup wants to do a d_add */
++	if (flag)
++		d_add(dentry, inode);
++	else
++		d_instantiate(dentry, inode);
++
++	ASSERT(dtopd(dentry) != NULL);
++
++	/* all well, copy inode attributes */
++	fist_copy_attr_all(inode, master_inode);
++
++ out:
++	return err;
++}
++
++/* parse mount options "base=" and "sto=" */
++dentry_t *
++mini_fo_parse_options(super_block_t *sb, char *options)
++{
++	dentry_t *hidden_root = ERR_PTR(-EINVAL);
++	dentry_t *hidden_root2 = ERR_PTR(-EINVAL);
++	struct nameidata nd, nd2;
++	char *name, *tmp, *end;
++	int err = 0;
++
++	/* We don't want to go off the end of our arguments later on. */
++	for (end = options; *end; end++);
++
++	while (options < end) {
++		tmp = options;
++		while (*tmp && *tmp != ',')
++			tmp++;
++		*tmp = '\0';
++		if (!strncmp("base=", options, 5)) {
++			name = options + 5;
++			printk(KERN_INFO "mini_fo: using base directory: %s\n", name);
++
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
++			if (path_init(name, LOOKUP_FOLLOW, &nd))
++				err = path_walk(name, &nd);
++#else
++			err = path_lookup(name, LOOKUP_FOLLOW, &nd);
++#endif
++			if (err) {
++				printk(KERN_CRIT "mini_fo: error accessing hidden directory '%s'\n", name);
++				hidden_root = ERR_PTR(err);
++				goto out;
++			}
++			hidden_root = nd.dentry;
++			stopd(sb)->base_dir_dentry = nd.dentry;
++			stopd(sb)->hidden_mnt = nd.mnt;
++
++		} else if(!strncmp("sto=", options, 4)) {
++			/* parse the storage dir */
++			name = options + 4;
++			printk(KERN_INFO "mini_fo: using storage directory: %s\n", name);
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
++			if(path_init(name, LOOKUP_FOLLOW, &nd2))
++				err = path_walk(name, &nd2);
++#else
++                        err = path_lookup(name, LOOKUP_FOLLOW, &nd2);
++#endif
++			if(err) {
++				printk(KERN_CRIT "mini_fo: error accessing hidden storage directory '%s'\n", name);
++
++				hidden_root2 = ERR_PTR(err);
++				goto out;
++			}
++			hidden_root2 = nd2.dentry;
++			stopd(sb)->storage_dir_dentry = nd2.dentry;
++			stopd(sb)->hidden_mnt2 = nd2.mnt;
++			stohs2(sb) = hidden_root2->d_sb;
++
++			/* validate storage dir, this is done in
++			 * mini_fo_read_super for the base directory.
++			 */
++			if (IS_ERR(hidden_root2)) {
++				printk(KERN_WARNING "mini_fo_parse_options: storage dentry lookup failed (err = %ld)\n", PTR_ERR(hidden_root2));
++				goto out;
++			}
++			if (!hidden_root2->d_inode) {
++				printk(KERN_WARNING "mini_fo_parse_options: no storage dir to interpose on.\n");
++				goto out;
++			}
++			stohs2(sb) = hidden_root2->d_sb;
++		} else {
++			printk(KERN_WARNING "mini_fo: unrecognized option '%s'\n", options);
++			hidden_root = ERR_PTR(-EINVAL);
++			goto out;
++		}
++		options = tmp + 1;
++	}
++
++ out:
++	if(IS_ERR(hidden_root2))
++		return hidden_root2;
++	return hidden_root;
++}
++
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++static int
++#else
++super_block_t *
++#endif
++mini_fo_read_super(super_block_t *sb, void *raw_data, int silent)
++{
++	dentry_t *hidden_root;
++	int err = 0;
++
++	if (!raw_data) {
++		printk(KERN_WARNING "mini_fo_read_super: missing argument\n");
++		err = -EINVAL;
++		goto out;
++	}
++	/*
++	 * Allocate superblock private data
++	 */
++	__stopd(sb) = kmalloc(sizeof(struct mini_fo_sb_info), GFP_KERNEL);
++	if (!stopd(sb)) {
++		printk(KERN_WARNING "%s: out of memory\n", __FUNCTION__);
++		err = -ENOMEM;
++		goto out;
++	}
++	stohs(sb) = NULL;
++
++	hidden_root = mini_fo_parse_options(sb, raw_data);
++	if (IS_ERR(hidden_root)) {
++		printk(KERN_WARNING "mini_fo_read_super: lookup_dentry failed (err = %ld)\n", PTR_ERR(hidden_root));
++		err = PTR_ERR(hidden_root);
++		goto out_free;
++	}
++	if (!hidden_root->d_inode) {
++		printk(KERN_WARNING "mini_fo_read_super: no directory to interpose on\n");
++		goto out_free;
++	}
++	stohs(sb) = hidden_root->d_sb;
++
++	/*
++	 * Linux 2.4.2-ac3 and beyond has code in
++	 * mm/filemap.c:generic_file_write() that requires sb->s_maxbytes
++	 * to be populated.  If not set, all write()s under that sb will
++	 * return 0.
++	 *
++	 * Linux 2.4.4+ automatically sets s_maxbytes to MAX_NON_LFS;
++	 * the filesystem should override it only if it supports LFS.
++	 */
++	/* non-SCA code is good to go with LFS */
++	sb->s_maxbytes = hidden_root->d_sb->s_maxbytes;
++
++	sb->s_op = &mini_fo_sops;
++	/*
++	 * we can't use d_alloc_root if we want to use
++	 * our own interpose function unchanged,
++	 * so we simply replicate *most* of the code in d_alloc_root here
++	 */
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
++	sb->s_root = d_alloc(NULL, &(const struct qstr) { "/", 1, 0 });
++#else
++	sb->s_root = d_alloc(NULL, &(const struct qstr){hash: 0, name: "/", len : 1});
++#endif
++	if (IS_ERR(sb->s_root)) {
++		printk(KERN_WARNING "mini_fo_read_super: d_alloc failed\n");
++		err = -ENOMEM;
++		goto out_dput;
++	}
++
++	sb->s_root->d_op = &mini_fo_dops;
++	sb->s_root->d_sb = sb;
++	sb->s_root->d_parent = sb->s_root;
++
++	/* link the upper and lower dentries */
++	__dtopd(sb->s_root) = (struct mini_fo_dentry_info *)
++		kmalloc(sizeof(struct mini_fo_dentry_info), GFP_KERNEL);
++	if (!dtopd(sb->s_root)) {
++		err = -ENOMEM;
++		goto out_dput2;
++	}
++	dtopd(sb->s_root)->state = MODIFIED;
++	dtohd(sb->s_root) = hidden_root;
++
++	/* fanout relevant, interpose on storage root dentry too */
++	dtohd2(sb->s_root) = stopd(sb)->storage_dir_dentry;
++
++	/* ...and call tri-interpose to interpose root dir inodes
++	 * if (mini_fo_interpose(hidden_root, sb->s_root, sb, 0))
++	 */
++	if(mini_fo_tri_interpose(hidden_root, dtohd2(sb->s_root), sb->s_root, sb, 0))
++		goto out_dput2;
++
++	/* initalize the wol list */
++	itopd(sb->s_root->d_inode)->deleted_list_size = -1;
++	itopd(sb->s_root->d_inode)->renamed_list_size = -1;
++	meta_build_lists(sb->s_root);
++
++	goto out;
++
++ out_dput2:
++	dput(sb->s_root);
++ out_dput:
++	dput(hidden_root);
++	dput(dtohd2(sb->s_root)); /* release the hidden_sto_dentry too */
++ out_free:
++	kfree(stopd(sb));
++	__stopd(sb) = NULL;
++ out:
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++        return err;
++#else
++        if (err) {
++		return ERR_PTR(err);
++        } else {
++		return sb;
++        }
++#endif
++}
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,18)
++static int mini_fo_get_sb(struct file_system_type *fs_type,
++					  int flags, const char *dev_name,
++					  void *raw_data, struct vfsmount *mnt)
++{
++	return get_sb_nodev(fs_type, flags, raw_data, mini_fo_read_super, mnt);
++}
++#else
++static struct super_block *mini_fo_get_sb(struct file_system_type *fs_type,
++					  int flags, const char *dev_name,
++					  void *raw_data)
++{
++	return get_sb_nodev(fs_type, flags, raw_data, mini_fo_read_super);
++}
++#endif
++
++void mini_fo_kill_block_super(struct super_block *sb)
++{
++	generic_shutdown_super(sb);
++	/*
++	 *      XXX: BUG: Halcrow: Things get unstable sometime after this point:
++	 *      lib/rwsem-spinlock.c:127: spin_is_locked on uninitialized
++	 *      fs/fs-writeback.c:402: spin_lock(fs/super.c:a0381828) already
++	 *      locked by fs/fs-writeback.c/402
++	 *
++	 *      Apparently, someone's not releasing a lock on sb_lock...
++	 */
++}
++
++static struct file_system_type mini_fo_fs_type = {
++	.owner          = THIS_MODULE,
++	.name           = "mini_fo",
++	.get_sb         = mini_fo_get_sb,
++	.kill_sb        = mini_fo_kill_block_super,
++	.fs_flags       = 0,
++};
++
++
++#else
++static DECLARE_FSTYPE(mini_fo_fs_type, "mini_fo", mini_fo_read_super, 0);
++#endif
++
++static int __init init_mini_fo_fs(void)
++{
++	printk("Registering mini_fo version $Id$\n");
++	return register_filesystem(&mini_fo_fs_type);
++}
++static void __exit exit_mini_fo_fs(void)
++{
++	printk("Unregistering mini_fo version $Id$\n");
++	unregister_filesystem(&mini_fo_fs_type);
++}
++
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
++EXPORT_NO_SYMBOLS;
++#endif
++
++MODULE_AUTHOR("Erez Zadok <ezk@cs.sunysb.edu>");
++MODULE_DESCRIPTION("FiST-generated mini_fo filesystem");
++MODULE_LICENSE("GPL");
++
++/* MODULE_PARM(fist_debug_var, "i"); */
++/* MODULE_PARM_DESC(fist_debug_var, "Debug level"); */
++
++module_init(init_mini_fo_fs)
++module_exit(exit_mini_fo_fs)
+--- /dev/null
++++ b/fs/mini_fo/Makefile
+@@ -0,0 +1,17 @@
++#
++# Makefile for mini_fo 2.4 and 2.6 Linux kernels
++#
++# Copyright (C) 2004, 2005 Markus Klotzbuecher <mk@creamnet.de>
++#
++# This program is free software; you can redistribute it and/or
++# modify it under the terms of the GNU General Public License
++# as published by the Free Software Foundation; either version
++# 2 of the License, or (at your option) any later version.
++#
++
++obj-$(CONFIG_MINI_FO) := mini_fo.o
++mini_fo-objs   := meta.o dentry.o file.o inode.o main.o super.o state.o aux.o
++
++# dependencies
++${mini_fo-objs}: mini_fo.h fist.h
++
+--- /dev/null
++++ b/fs/mini_fo/meta.c
+@@ -0,0 +1,1000 @@
++/*
++ * Copyright (C) 2004, 2005 Markus Klotzbuecher <mk@creamnet.de>
++ *
++ * This program is free software; you can redistribute it and/or
++ * modify it under the terms of the GNU General Public License
++ * as published by the Free Software Foundation; either version
++ * 2 of the License, or (at your option) any later version.
++ */
++
++#ifdef HAVE_CONFIG_H
++# include <config.h>
++#endif /* HAVE_CONFIG_H */
++#include "fist.h"
++#include "mini_fo.h"
++
++int meta_build_lists(dentry_t *dentry)
++{
++	struct mini_fo_inode_info *inode_info;
++
++	dentry_t *meta_dentry = 0;
++	file_t *meta_file = 0;
++	mm_segment_t old_fs;
++	void *buf;
++
++	int bytes, len;
++	struct vfsmount *meta_mnt;
++	char *entry;
++
++	inode_info = itopd(dentry->d_inode);
++	if(!(inode_info->deleted_list_size == -1 &&
++	     inode_info->renamed_list_size == -1)) {
++		printk(KERN_CRIT "mini_fo: meta_build_lists: \
++                                  Error, list(s) not virgin.\n");
++		return -1;
++	}
++
++	/* init our meta lists */
++	INIT_LIST_HEAD(&inode_info->deleted_list);
++	inode_info->deleted_list_size = 0;
++
++	INIT_LIST_HEAD(&inode_info->renamed_list);
++	inode_info->renamed_list_size = 0;
++
++  	/* might there be a META-file? */
++	if(dtohd2(dentry) && dtohd2(dentry)->d_inode) {
++		meta_dentry = lookup_one_len(META_FILENAME,
++					     dtohd2(dentry),
++					     strlen(META_FILENAME));
++		if(!meta_dentry->d_inode) {
++			dput(meta_dentry);
++			goto out_ok;
++		}
++		/* $%& err, is this correct? */
++		meta_mnt = stopd(dentry->d_inode->i_sb)->hidden_mnt2;
++		mntget(meta_mnt);
++
++
++		/* open META-file for reading */
++		meta_file = dentry_open(meta_dentry, meta_mnt, 0x0);
++		if(!meta_file || IS_ERR(meta_file)) {
++			printk(KERN_CRIT "mini_fo: meta_build_lists: \
++                                          ERROR opening META file.\n");
++			goto out_err;
++		}
++
++		/* check if fs supports reading */
++		if(!meta_file->f_op->read) {
++			printk(KERN_CRIT "mini_fo: meta_build_lists: \
++                                          ERROR, fs does not support reading.\n");
++			goto out_err_close;
++		}
++
++		/* allocate a page for transfering the data */
++		buf = (void *) __get_free_page(GFP_KERNEL);
++		if(!buf) {
++			printk(KERN_CRIT "mini_fo: meta_build_lists: \
++                                          ERROR, out of mem.\n");
++			goto out_err_close;
++		}
++		meta_file->f_pos = 0;
++		old_fs = get_fs();
++		set_fs(KERNEL_DS);
++		do {
++			char *c;
++			bytes = meta_file->f_op->read(meta_file, buf, PAGE_SIZE, &meta_file->f_pos);
++			if(bytes == PAGE_SIZE) {
++				/* trim a cut off filename and adjust f_pos to get it next time */
++				for(c = (char*) buf+PAGE_SIZE;
++				    *c != '\n';
++				    c--, bytes--, meta_file->f_pos--);
++			}
++			entry = (char *) buf;
++			while(entry < (char *) buf+bytes) {
++
++				char *old_path;
++				char *dir_name;
++				int old_len, new_len;
++
++				/* len without '\n'*/
++				len = (int) (strchr(entry, '\n') - entry);
++				switch (*entry) {
++				case 'D':
++					/* format: "D filename" */
++					meta_list_add_d_entry(dentry,
++							      entry+2,
++							      len-2);
++					break;
++				case 'R':
++					/* format: "R path/xy/dir newDir" */
++					old_path = entry+2;
++					dir_name = strchr(old_path, ' ') + 1;
++					old_len =  dir_name - old_path - 1;
++					new_len = ((int) entry) + len - ((int ) dir_name);
++					meta_list_add_r_entry(dentry,
++							      old_path,
++							      old_len,
++							      dir_name,
++							      new_len);
++					break;
++				default:
++					/* unknown entry type detected */
++					break;
++				}
++				entry += len+1;
++			}
++
++		} while(meta_file->f_pos < meta_dentry->d_inode->i_size);
++
++		free_page((unsigned long) buf);
++		set_fs(old_fs);
++		fput(meta_file);
++	}
++	goto out_ok;
++
++ out_err_close:
++	fput(meta_file);
++ out_err:
++	mntput(meta_mnt);
++	dput(meta_dentry);
++	return -1;
++ out_ok:
++	return 1; /* check this!!! inode_info->wol_size; */
++}
++
++/* cleanups up all lists and free's the mem by dentry */
++int meta_put_lists(dentry_t *dentry)
++{
++	if(!dentry || !dentry->d_inode) {
++		printk("mini_fo: meta_put_lists: invalid dentry passed.\n");
++		return -1;
++	}
++	return __meta_put_lists(dentry->d_inode);
++}
++
++/* cleanups up all lists and free's the mem by inode */
++int __meta_put_lists(inode_t *inode)
++{
++	int err = 0;
++	if(!inode || !itopd(inode)) {
++		printk("mini_fo: __meta_put_lists: invalid inode passed.\n");
++		return -1;
++	}
++	err = __meta_put_d_list(inode);
++	err |= __meta_put_r_list(inode);
++	return err;
++}
++
++int meta_sync_lists(dentry_t *dentry)
++{
++	int err = 0;
++	if(!dentry || !dentry->d_inode) {
++		printk("mini_fo: meta_sync_lists: \
++                        invalid dentry passed.\n");
++		return -1;
++	}
++	err = meta_sync_d_list(dentry, 0);
++	err |= meta_sync_r_list(dentry, 1);
++	return err;
++}
++
++
++/* remove all D entries from the renamed list and free the mem */
++int __meta_put_d_list(inode_t *inode)
++{
++	struct list_head *tmp;
++        struct deleted_entry *del_entry;
++        struct mini_fo_inode_info *inode_info;
++
++	if(!inode || !itopd(inode)) {
++		printk(KERN_CRIT "mini_fo: __meta_put_d_list: \
++                                  invalid inode passed.\n");
++		return -1;
++	}
++	inode_info = itopd(inode);
++
++        /* nuke the DELETED-list */
++        if(inode_info->deleted_list_size <= 0)
++		return 0;
++
++	while(!list_empty(&inode_info->deleted_list)) {
++		tmp = inode_info->deleted_list.next;
++		list_del(tmp);
++		del_entry = list_entry(tmp, struct deleted_entry, list);
++		kfree(del_entry->name);
++		kfree(del_entry);
++	}
++	inode_info->deleted_list_size = 0;
++
++	return 0;
++}
++
++/* remove all R entries from the renamed list and free the mem */
++int __meta_put_r_list(inode_t *inode)
++{
++	struct list_head *tmp;
++	struct renamed_entry *ren_entry;
++        struct mini_fo_inode_info *inode_info;
++
++	if(!inode || !itopd(inode)) {
++		printk(KERN_CRIT "mini_fo: meta_put_r_list: invalid inode.\n");
++		return -1;
++	}
++	inode_info = itopd(inode);
++
++        /* nuke the RENAMED-list */
++        if(inode_info->renamed_list_size <= 0)
++		return 0;
++
++	while(!list_empty(&inode_info->renamed_list)) {
++		tmp = inode_info->renamed_list.next;
++		list_del(tmp);
++		ren_entry = list_entry(tmp, struct renamed_entry, list);
++		kfree(ren_entry->new_name);
++		kfree(ren_entry->old_name);
++		kfree(ren_entry);
++	}
++	inode_info->renamed_list_size = 0;
++
++	return 0;
++}
++
++int meta_add_d_entry(dentry_t *dentry, const char *name, int len)
++{
++	int err = 0;
++	err = meta_list_add_d_entry(dentry, name, len);
++	err |= meta_write_d_entry(dentry,name,len);
++	return err;
++}
++
++/* add a D entry to the deleted list */
++int meta_list_add_d_entry(dentry_t *dentry, const char *name, int len)
++{
++        struct deleted_entry *del_entry;
++        struct mini_fo_inode_info *inode_info;
++
++	if(!dentry || !dentry->d_inode) {
++		printk(KERN_CRIT "mini_fo: meta_list_add_d_entry: \
++                                  invalid dentry passed.\n");
++		return -1;
++	}
++	inode_info = itopd(dentry->d_inode);
++
++        if(inode_info->deleted_list_size < 0)
++                return -1;
++
++        del_entry = (struct deleted_entry *)
++		kmalloc(sizeof(struct deleted_entry), GFP_KERNEL);
++        del_entry->name = (char*) kmalloc(len, GFP_KERNEL);
++        if(!del_entry || !del_entry->name) {
++                printk(KERN_CRIT "mini_fo: meta_list_add_d_entry: \
++                                  out of mem.\n");
++		kfree(del_entry->name);
++		kfree(del_entry);
++                return -ENOMEM;
++        }
++
++        strncpy(del_entry->name, name, len);
++        del_entry->len = len;
++
++        list_add(&del_entry->list, &inode_info->deleted_list);
++        inode_info->deleted_list_size++;
++        return 0;
++}
++
++int meta_add_r_entry(dentry_t *dentry,
++			  const char *old_name, int old_len,
++			  const char *new_name, int new_len)
++{
++	int err = 0;
++	err = meta_list_add_r_entry(dentry,
++				    old_name, old_len,
++				    new_name, new_len);
++	err |= meta_write_r_entry(dentry,
++				  old_name, old_len,
++				  new_name, new_len);
++	return err;
++}
++
++/* add a R entry to the renamed list */
++int meta_list_add_r_entry(dentry_t *dentry,
++			  const char *old_name, int old_len,
++			  const char *new_name, int new_len)
++{
++        struct renamed_entry *ren_entry;
++        struct mini_fo_inode_info *inode_info;
++
++	if(!dentry || !dentry->d_inode) {
++		printk(KERN_CRIT "mini_fo: meta_list_add_r_entry: \
++                                  invalid dentry passed.\n");
++		return -1;
++	}
++	inode_info = itopd(dentry->d_inode);
++
++        if(inode_info->renamed_list_size < 0)
++                return -1;
++
++        ren_entry = (struct renamed_entry *)
++		kmalloc(sizeof(struct renamed_entry), GFP_KERNEL);
++        ren_entry->old_name = (char*) kmalloc(old_len, GFP_KERNEL);
++        ren_entry->new_name = (char*) kmalloc(new_len, GFP_KERNEL);
++
++        if(!ren_entry || !ren_entry->old_name || !ren_entry->new_name) {
++                printk(KERN_CRIT "mini_fo: meta_list_add_r_entry: \
++                                  out of mem.\n");
++		kfree(ren_entry->new_name);
++		kfree(ren_entry->old_name);
++		kfree(ren_entry);
++                return -ENOMEM;
++        }
++
++        strncpy(ren_entry->old_name, old_name, old_len);
++        ren_entry->old_len = old_len;
++        strncpy(ren_entry->new_name, new_name, new_len);
++        ren_entry->new_len = new_len;
++
++        list_add(&ren_entry->list, &inode_info->renamed_list);
++        inode_info->renamed_list_size++;
++        return 0;
++}
++
++
++int meta_remove_r_entry(dentry_t *dentry, const char *name, int len)
++{
++	int err = 0;
++	if(!dentry || !dentry->d_inode) {
++		printk(KERN_CRIT
++		       "mini_fo: meta_remove_r_entry: \
++                        invalid dentry passed.\n");
++		return -1;
++	}
++
++	err = meta_list_remove_r_entry(dentry, name, len);
++	err |= meta_sync_lists(dentry);
++	return err;
++}
++
++int meta_list_remove_r_entry(dentry_t *dentry, const char *name, int len)
++{
++	if(!dentry || !dentry->d_inode) {
++		printk(KERN_CRIT
++		       "mini_fo: meta_list_remove_r_entry: \
++                        invalid dentry passed.\n");
++		return -1;
++	}
++	return __meta_list_remove_r_entry(dentry->d_inode, name, len);
++}
++
++int __meta_list_remove_r_entry(inode_t *inode, const char *name, int len)
++{
++	struct list_head *tmp;
++        struct renamed_entry *ren_entry;
++        struct mini_fo_inode_info *inode_info;
++
++	if(!inode || !itopd(inode))
++		printk(KERN_CRIT
++		       "mini_fo: __meta_list_remove_r_entry: \
++                        invalid inode passed.\n");
++	inode_info = itopd(inode);
++
++        if(inode_info->renamed_list_size < 0)
++                return -1;
++        if(inode_info->renamed_list_size == 0)
++                return 1;
++
++	list_for_each(tmp, &inode_info->renamed_list) {
++		ren_entry = list_entry(tmp, struct renamed_entry, list);
++		if(ren_entry->new_len != len)
++			continue;
++
++		if(!strncmp(ren_entry->new_name, name, len)) {
++			list_del(tmp);
++			kfree(ren_entry->new_name);
++			kfree(ren_entry->old_name);
++			kfree(ren_entry);
++			inode_info->renamed_list_size--;
++			return 0;
++		}
++	}
++	return 1;
++}
++
++
++/* append a single D entry to the meta file */
++int meta_write_d_entry(dentry_t *dentry, const char *name, int len)
++{
++	dentry_t *meta_dentry = 0;
++        file_t *meta_file = 0;
++        mm_segment_t old_fs;
++
++        int bytes, err;
++        struct vfsmount *meta_mnt = 0;
++        char *buf;
++
++	err = 0;
++
++	if(itopd(dentry->d_inode)->deleted_list_size < 0) {
++		err = -1;
++		goto out;
++	}
++
++	if(dtopd(dentry)->state == UNMODIFIED) {
++                err = build_sto_structure(dentry->d_parent, dentry);
++                if(err) {
++                        printk(KERN_CRIT "mini_fo: meta_write_d_entry: \
++                                          build_sto_structure failed.\n");
++			goto out;
++                }
++        }
++	meta_dentry = lookup_one_len(META_FILENAME,
++				     dtohd2(dentry), strlen (META_FILENAME));
++
++	/* We need to create a META-file */
++        if(!meta_dentry->d_inode) {
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++		vfs_create(dtohd2(dentry)->d_inode,
++			   meta_dentry,
++			   S_IRUSR | S_IWUSR,
++			   NULL);
++#else
++                vfs_create(dtohd2(dentry)->d_inode,
++			   meta_dentry,
++			   S_IRUSR | S_IWUSR);
++#endif
++	}
++        /* open META-file for writing */
++        meta_file = dentry_open(meta_dentry, meta_mnt, 0x1);
++        if(!meta_file || IS_ERR(meta_file)) {
++                printk(KERN_CRIT "mini_fo: meta_write_d_entry: \
++                                  ERROR opening meta file.\n");
++                mntput(meta_mnt); /* $%& is this necessary? */
++                dput(meta_dentry);
++		err = -1;
++                goto out;
++        }
++
++        /* check if fs supports writing */
++        if(!meta_file->f_op->write) {
++                printk(KERN_CRIT "mini_fo: meta_write_d_entry: \
++                                  ERROR, fs does not support writing.\n");
++                goto out_err_close;
++        }
++
++	meta_file->f_pos = meta_dentry->d_inode->i_size; /* append */
++        old_fs = get_fs();
++        set_fs(KERNEL_DS);
++
++	/* size: len for name, 1 for \n and 2 for "D " */
++	buf = (char *) kmalloc(len+3, GFP_KERNEL);
++	if (!buf) {
++		printk(KERN_CRIT "mini_fo: meta_write_d_entry: \
++                                  out of mem.\n");
++		return -ENOMEM;
++	}
++
++	buf[0] = 'D';
++	buf[1] = ' ';
++	strncpy(buf+2, name, len);
++	buf[len+2] = '\n';
++	bytes = meta_file->f_op->write(meta_file, buf, len+3,
++				       &meta_file->f_pos);
++	if(bytes != len+3) {
++		printk(KERN_CRIT "mini_fo: meta_write_d_entry: \
++                                  ERROR writing.\n");
++		err = -1;
++	}
++	kfree(buf);
++	set_fs(old_fs);
++
++ out_err_close:
++	fput(meta_file);
++ out:
++	return err;
++}
++
++/* append a single R entry to the meta file */
++int meta_write_r_entry(dentry_t *dentry,
++		       const char *old_name, int old_len,
++		       const char *new_name, int new_len)
++{
++	dentry_t *meta_dentry = 0;
++        file_t *meta_file = 0;
++        mm_segment_t old_fs;
++
++        int bytes, err, buf_len;
++	struct vfsmount *meta_mnt = 0;
++        char *buf;
++
++
++	err = 0;
++
++	if(itopd(dentry->d_inode)->renamed_list_size < 0) {
++		err = -1;
++		goto out;
++	}
++
++	/* build the storage structure? */
++	if(dtopd(dentry)->state == UNMODIFIED) {
++                err = build_sto_structure(dentry->d_parent, dentry);
++                if(err) {
++                        printk(KERN_CRIT "mini_fo: meta_write_r_entry: \
++                                          build_sto_structure failed.\n");
++			goto out;
++                }
++        }
++	meta_dentry = lookup_one_len(META_FILENAME,
++				     dtohd2(dentry),
++				     strlen (META_FILENAME));
++        if(!meta_dentry->d_inode) {
++                /* We need to create a META-file */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++                vfs_create(dtohd2(dentry)->d_inode,
++			   meta_dentry, S_IRUSR | S_IWUSR, NULL);
++#else
++                vfs_create(dtohd2(dentry)->d_inode,
++			   meta_dentry, S_IRUSR | S_IWUSR);
++#endif
++	}
++        /* open META-file for writing */
++        meta_file = dentry_open(meta_dentry, meta_mnt, 0x1);
++        if(!meta_file || IS_ERR(meta_file)) {
++                printk(KERN_CRIT "mini_fo: meta_write_r_entry: \
++                                  ERROR opening meta file.\n");
++                mntput(meta_mnt);
++                dput(meta_dentry);
++		err = -1;
++                goto out;
++        }
++
++        /* check if fs supports writing */
++        if(!meta_file->f_op->write) {
++                printk(KERN_CRIT "mini_fo: meta_write_r_entry: \
++                                  ERROR, fs does not support writing.\n");
++                goto out_err_close;
++        }
++
++	meta_file->f_pos = meta_dentry->d_inode->i_size; /* append */
++        old_fs = get_fs();
++        set_fs(KERNEL_DS);
++
++	/* size: 2 for "R ", old_len+new_len for names, 1 blank+1 \n */
++	buf_len = old_len + new_len + 4;
++	buf = (char *) kmalloc(buf_len, GFP_KERNEL);
++	if (!buf) {
++		printk(KERN_CRIT "mini_fo: meta_write_r_entry: out of mem.\n");
++		return -ENOMEM;
++	}
++
++	buf[0] = 'R';
++	buf[1] = ' ';
++	strncpy(buf + 2, old_name, old_len);
++	buf[old_len + 2] = ' ';
++	strncpy(buf + old_len + 3, new_name, new_len);
++	buf[buf_len -1] = '\n';
++	bytes = meta_file->f_op->write(meta_file, buf, buf_len, &meta_file->f_pos);
++	if(bytes != buf_len) {
++		printk(KERN_CRIT "mini_fo: meta_write_r_entry: ERROR writing.\n");
++		err = -1;
++	}
++
++	kfree(buf);
++	set_fs(old_fs);
++
++ out_err_close:
++	fput(meta_file);
++ out:
++	return err;
++}
++
++/* sync D list to disk, append data if app_flag is 1 */
++/* check the meta_mnt, which seems not to be used (properly)  */
++
++int meta_sync_d_list(dentry_t *dentry, int app_flag)
++{
++	dentry_t *meta_dentry;
++        file_t *meta_file;
++        mm_segment_t old_fs;
++
++        int bytes, err;
++        struct vfsmount *meta_mnt;
++        char *buf;
++
++	struct list_head *tmp;
++        struct deleted_entry *del_entry;
++        struct mini_fo_inode_info *inode_info;
++
++	err = 0;
++	meta_file=0;
++	meta_mnt=0;
++
++	if(!dentry || !dentry->d_inode) {
++		printk(KERN_CRIT "mini_fo: meta_sync_d_list: \
++                                  invalid inode passed.\n");
++		err = -1;
++		goto out;
++	}
++	inode_info = itopd(dentry->d_inode);
++
++        if(inode_info->deleted_list_size < 0) {
++		err = -1;
++		goto out;
++	}
++
++	/* ok, there is something to sync */
++
++	/* build the storage structure? */
++        if(!dtohd2(dentry) && !itohi2(dentry->d_inode)) {
++                err = build_sto_structure(dentry->d_parent, dentry);
++                if(err) {
++                        printk(KERN_CRIT "mini_fo: meta_sync_d_list: \
++                                          build_sto_structure failed.\n");
++			goto out;
++                }
++        }
++	meta_dentry = lookup_one_len(META_FILENAME,
++				     dtohd2(dentry),
++				     strlen(META_FILENAME));
++        if(!meta_dentry->d_inode) {
++                /* We need to create a META-file */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++                vfs_create(dtohd2(dentry)->d_inode,
++			   meta_dentry, S_IRUSR | S_IWUSR, NULL);
++#else
++                vfs_create(dtohd2(dentry)->d_inode,
++			   meta_dentry, S_IRUSR | S_IWUSR);
++#endif
++		app_flag = 0;
++	}
++	/* need we truncate the meta file? */
++	if(!app_flag) {
++		struct iattr newattrs;
++                newattrs.ia_size = 0;
++                newattrs.ia_valid = ATTR_SIZE | ATTR_CTIME;
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_lock(&meta_dentry->d_inode->i_mutex);
++#else
++                down(&meta_dentry->d_inode->i_sem);
++#endif
++                err = notify_change(meta_dentry, &newattrs);
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_unlock(&meta_dentry->d_inode->i_mutex);
++#else
++                up(&meta_dentry->d_inode->i_sem);
++#endif
++
++                if(err || meta_dentry->d_inode->i_size != 0) {
++                        printk(KERN_CRIT "mini_fo: meta_sync_d_list: \
++                                          ERROR truncating meta file.\n");
++                        goto out_err_close;
++		}
++	}
++
++        /* open META-file for writing */
++        meta_file = dentry_open(meta_dentry, meta_mnt, 0x1);
++        if(!meta_file || IS_ERR(meta_file)) {
++                printk(KERN_CRIT "mini_fo: meta_sync_d_list: \
++                                  ERROR opening meta file.\n");
++		/* we don't mntget so we dont't mntput (for now)
++		 * mntput(meta_mnt);
++		 */
++		dput(meta_dentry);
++		err = -1;
++                goto out;
++        }
++
++        /* check if fs supports writing */
++        if(!meta_file->f_op->write) {
++                printk(KERN_CRIT "mini_fo: meta_sync_d_list: \
++                                  ERROR, fs does not support writing.\n");
++                goto out_err_close;
++        }
++
++	meta_file->f_pos = meta_dentry->d_inode->i_size; /* append */
++        old_fs = get_fs();
++        set_fs(KERNEL_DS);
++
++	/* here we go... */
++        list_for_each(tmp, &inode_info->deleted_list) {
++		del_entry = list_entry(tmp, struct deleted_entry, list);
++
++		/* size: len for name, 1 for \n and 2 for "D " */
++		buf = (char *) kmalloc(del_entry->len+3, GFP_KERNEL);
++		if (!buf) {
++			printk(KERN_CRIT "mini_fo: meta_sync_d_list: \
++                                          out of mem.\n");
++			return -ENOMEM;
++		}
++
++		buf[0] = 'D';
++		buf[1] = ' ';
++		strncpy(buf+2, del_entry->name, del_entry->len);
++		buf[del_entry->len+2] = '\n';
++		bytes = meta_file->f_op->write(meta_file, buf,
++					       del_entry->len+3,
++					       &meta_file->f_pos);
++		if(bytes != del_entry->len+3) {
++			printk(KERN_CRIT "mini_fo: meta_sync_d_list: \
++                                          ERROR writing.\n");
++			err |= -1;
++		}
++		kfree(buf);
++	}
++	set_fs(old_fs);
++
++ out_err_close:
++	fput(meta_file);
++ out:
++	return err;
++
++}
++
++int meta_sync_r_list(dentry_t *dentry, int app_flag)
++{
++	dentry_t *meta_dentry;
++        file_t *meta_file;
++        mm_segment_t old_fs;
++
++        int bytes, err, buf_len;
++        struct vfsmount *meta_mnt;
++        char *buf;
++
++	struct list_head *tmp;
++        struct renamed_entry *ren_entry;
++        struct mini_fo_inode_info *inode_info;
++
++	err = 0;
++	meta_file=0;
++	meta_mnt=0;
++
++	if(!dentry || !dentry->d_inode) {
++		printk(KERN_CRIT "mini_fo: meta_sync_r_list: \
++                                  invalid dentry passed.\n");
++		err = -1;
++		goto out;
++	}
++	inode_info = itopd(dentry->d_inode);
++
++        if(inode_info->deleted_list_size < 0) {
++		err = -1;
++		goto out;
++	}
++
++	/* ok, there is something to sync */
++
++	/* build the storage structure? */
++        if(!dtohd2(dentry) && !itohi2(dentry->d_inode)) {
++                err = build_sto_structure(dentry->d_parent, dentry);
++                if(err) {
++                        printk(KERN_CRIT "mini_fo: meta_sync_r_list: \
++                                          build_sto_structure failed.\n");
++			goto out;
++                }
++        }
++	meta_dentry = lookup_one_len(META_FILENAME,
++				     dtohd2(dentry),
++				     strlen(META_FILENAME));
++        if(!meta_dentry->d_inode) {
++                /* We need to create a META-file */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++                vfs_create(dtohd2(dentry)->d_inode,
++			   meta_dentry, S_IRUSR | S_IWUSR, NULL);
++#else
++                vfs_create(dtohd2(dentry)->d_inode,
++			   meta_dentry, S_IRUSR | S_IWUSR);
++#endif
++		app_flag = 0;
++	}
++	/* need we truncate the meta file? */
++	if(!app_flag) {
++		struct iattr newattrs;
++                newattrs.ia_size = 0;
++                newattrs.ia_valid = ATTR_SIZE | ATTR_CTIME;
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_lock(&meta_dentry->d_inode->i_mutex);
++#else
++                down(&meta_dentry->d_inode->i_sem);
++#endif
++                err = notify_change(meta_dentry, &newattrs);
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_unlock(&meta_dentry->d_inode->i_mutex);
++#else
++                up(&meta_dentry->d_inode->i_sem);
++#endif
++                if(err || meta_dentry->d_inode->i_size != 0) {
++                        printk(KERN_CRIT "mini_fo: meta_sync_r_list: \
++                                          ERROR truncating meta file.\n");
++                        goto out_err_close;
++		}
++	}
++
++        /* open META-file for writing */
++        meta_file = dentry_open(meta_dentry, meta_mnt, 0x1);
++        if(!meta_file || IS_ERR(meta_file)) {
++                printk(KERN_CRIT "mini_fo: meta_sync_r_list: \
++                                  ERROR opening meta file.\n");
++		/* we don't mntget so we dont't mntput (for now)
++		 * mntput(meta_mnt);
++		 */
++		dput(meta_dentry);
++		err = -1;
++                goto out;
++        }
++
++        /* check if fs supports writing */
++        if(!meta_file->f_op->write) {
++                printk(KERN_CRIT "mini_fo: meta_sync_r_list: \
++                                  ERROR, fs does not support writing.\n");
++                goto out_err_close;
++        }
++
++	meta_file->f_pos = meta_dentry->d_inode->i_size; /* append */
++        old_fs = get_fs();
++        set_fs(KERNEL_DS);
++
++	/* here we go... */
++        list_for_each(tmp, &inode_info->renamed_list) {
++		ren_entry = list_entry(tmp, struct renamed_entry, list);
++		/* size:
++		 * 2 for "R ", old_len+new_len for names, 1 blank+1 \n */
++		buf_len = ren_entry->old_len + ren_entry->new_len + 4;
++		buf = (char *) kmalloc(buf_len, GFP_KERNEL);
++		if (!buf) {
++			printk(KERN_CRIT "mini_fo: meta_sync_r_list: \
++                                          out of mem.\n");
++			return -ENOMEM;
++		}
++		buf[0] = 'R';
++		buf[1] = ' ';
++		strncpy(buf + 2, ren_entry->old_name, ren_entry->old_len);
++		buf[ren_entry->old_len + 2] = ' ';
++		strncpy(buf + ren_entry->old_len + 3,
++			ren_entry->new_name, ren_entry->new_len);
++		buf[buf_len - 1] = '\n';
++		bytes = meta_file->f_op->write(meta_file, buf,
++					       buf_len, &meta_file->f_pos);
++		if(bytes != buf_len) {
++			printk(KERN_CRIT "mini_fo: meta_sync_r_list: \
++                                          ERROR writing.\n");
++			err |= -1;
++		}
++		kfree(buf);
++	}
++	set_fs(old_fs);
++
++ out_err_close:
++	fput(meta_file);
++ out:
++	return err;
++}
++
++int meta_check_d_entry(dentry_t *dentry, const char *name, int len)
++{
++	if(!dentry || !dentry->d_inode)
++		printk(KERN_CRIT "mini_fo: meta_check_d_dentry: \
++                                  invalid dentry passed.\n");
++	return __meta_check_d_entry(dentry->d_inode, name, len);
++}
++
++int __meta_check_d_entry(inode_t *inode, const char *name, int len)
++{
++	struct list_head *tmp;
++        struct deleted_entry *del_entry;
++        struct mini_fo_inode_info *inode_info;
++
++	if(!inode || !itopd(inode))
++		printk(KERN_CRIT "mini_fo: __meta_check_d_dentry: \
++                                  invalid inode passed.\n");
++
++        inode_info = itopd(inode);
++
++        if(inode_info->deleted_list_size <= 0)
++                return 0;
++
++        list_for_each(tmp, &inode_info->deleted_list) {
++		del_entry = list_entry(tmp, struct deleted_entry, list);
++		if(del_entry->len != len)
++			continue;
++
++		if(!strncmp(del_entry->name, name, len))
++			return 1;
++	}
++	return 0;
++}
++
++/*
++ * check if file has been renamed and return path to orig. base dir.
++ * Implements no error return values so far, what of course sucks.
++ * String is null terminated.'
++ */
++char* meta_check_r_entry(dentry_t *dentry, const char *name, int len)
++{
++	if(!dentry || !dentry->d_inode) {
++		printk(KERN_CRIT "mini_fo: meta_check_r_dentry: \
++                                  invalid dentry passed.\n");
++		return NULL;
++	}
++	return __meta_check_r_entry(dentry->d_inode, name, len);
++}
++
++char* __meta_check_r_entry(inode_t *inode, const char *name, int len)
++{
++	struct list_head *tmp;
++        struct renamed_entry *ren_entry;
++        struct mini_fo_inode_info *inode_info;
++	char *old_path;
++
++	if(!inode || !itopd(inode)) {
++		printk(KERN_CRIT "mini_fo: meta_check_r_dentry: \
++                                  invalid inode passed.\n");
++		return NULL;
++	}
++	inode_info = itopd(inode);
++
++        if(inode_info->renamed_list_size <= 0)
++                return NULL;
++
++        list_for_each(tmp, &inode_info->renamed_list) {
++		ren_entry = list_entry(tmp, struct renamed_entry, list);
++		if(ren_entry->new_len != len)
++			continue;
++
++		if(!strncmp(ren_entry->new_name, name, len)) {
++			old_path = (char *)
++				kmalloc(ren_entry->old_len+1, GFP_KERNEL);
++			strncpy(old_path,
++				ren_entry->old_name,
++				ren_entry->old_len);
++			old_path[ren_entry->old_len]='\0';
++			return old_path;
++		}
++	}
++	return NULL;
++}
++
++/*
++ * This version only checks if entry exists and return:
++ *     1 if exists,
++ *     0 if not,
++ *    -1 if error.
++ */
++int meta_is_r_entry(dentry_t *dentry, const char *name, int len)
++{
++	if(!dentry || !dentry->d_inode) {
++		printk(KERN_CRIT "mini_fo: meta_check_r_dentry [2]: \
++                                  invalid dentry passed.\n");
++		return -1;
++	}
++	return __meta_is_r_entry(dentry->d_inode, name, len);
++}
++
++int __meta_is_r_entry(inode_t *inode, const char *name, int len)
++{
++	struct list_head *tmp;
++        struct renamed_entry *ren_entry;
++        struct mini_fo_inode_info *inode_info;
++
++	if(!inode || !itopd(inode)) {
++		printk(KERN_CRIT "mini_fo: meta_check_r_dentry [2]: \
++                                  invalid inode passed.\n");
++		return -1;
++	}
++	inode_info = itopd(inode);
++
++        if(inode_info->renamed_list_size <= 0)
++                return -1;
++
++        list_for_each(tmp, &inode_info->renamed_list) {
++		ren_entry = list_entry(tmp, struct renamed_entry, list);
++		if(ren_entry->new_len != len)
++			continue;
++
++		if(!strncmp(ren_entry->new_name, name, len))
++			return 1;
++	}
++	return 0;
++}
++
+--- /dev/null
++++ b/fs/mini_fo/mini_fo.h
+@@ -0,0 +1,510 @@
++/*
++ * Copyright (c) 1997-2003 Erez Zadok
++ * Copyright (c) 2001-2003 Stony Brook University
++ *
++ * For specific licensing information, see the COPYING file distributed with
++ * this package, or get one from ftp://ftp.filesystems.org/pub/fist/COPYING.
++ *
++ * This Copyright notice must be kept intact and distributed with all
++ * fistgen sources INCLUDING sources generated by fistgen.
++ */
++/*
++ * Copyright (C) 2004, 2005 Markus Klotzbuecher <mk@creamnet.de>
++ *
++ * This program is free software; you can redistribute it and/or
++ * modify it under the terms of the GNU General Public License
++ * as published by the Free Software Foundation; either version
++ * 2 of the License, or (at your option) any later version.
++ */
++
++/*
++ *  $Id$
++ */
++
++#ifndef __MINI_FO_H_
++#define __MINI_FO_H_
++
++#ifdef __KERNEL__
++
++/* META stuff */
++#define META_FILENAME "META_dAfFgHE39ktF3HD2sr"
++
++/* use xattrs? */
++#define XATTR
++
++/* File attributes that when changed, result in a file beeing copied to storage */
++#define COPY_FLAGS ATTR_MODE | ATTR_UID | ATTR_GID | ATTR_SIZE
++
++/*
++ * mini_fo filestates
++ */
++#define MODIFIED       1
++#define UNMODIFIED     2
++#define CREATED        3
++#define DEL_REWRITTEN  4
++#define DELETED        5
++#define NON_EXISTANT   6
++
++/* fist file systems superblock magic */
++# define MINI_FO_SUPER_MAGIC 0xf15f
++
++/*
++ * STRUCTURES:
++ */
++
++/* mini_fo inode data in memory */
++struct mini_fo_inode_info {
++	inode_t *wii_inode;
++	inode_t *wii_inode2; /* pointer to storage inode */
++
++	/* META-data lists */
++	/* deleted list, ex wol */
++	struct list_head deleted_list;
++	int deleted_list_size;
++
++	/* renamed list */
++	struct list_head renamed_list;
++	int renamed_list_size;
++
++	/* add other lists here ... */
++};
++
++/* mini_fo dentry data in memory */
++struct mini_fo_dentry_info {
++	dentry_t *wdi_dentry;
++	dentry_t *wdi_dentry2; /* pointer to  storage dentry */
++	unsigned int state;  /* state of the mini_fo dentry */
++};
++
++
++/* mini_fo super-block data in memory */
++struct mini_fo_sb_info {
++	super_block_t *wsi_sb, *wsi_sb2; /* mk: might point to the same sb */
++	struct vfsmount *hidden_mnt, *hidden_mnt2;
++	dentry_t *base_dir_dentry;
++	dentry_t *storage_dir_dentry;
++	;
++};
++
++/* readdir_data, readdir helper struct */
++struct readdir_data {
++	struct list_head ndl_list; /* linked list head ptr */
++	int ndl_size; /* list size */
++	int sto_done; /* flag to show that the storage dir entries have
++		       * all been read an now follow base entries */
++};
++
++/* file private data. */
++struct mini_fo_file_info {
++	struct file *wfi_file;
++	struct file *wfi_file2; /* pointer to storage file */
++	struct readdir_data rd;
++};
++
++/* struct ndl_entry */
++struct ndl_entry {
++	struct list_head list;
++	char *name;
++	int len;
++};
++
++/********************************
++ *  META-data structures
++ ********************************/
++
++/* deleted entry */
++struct deleted_entry {
++	struct list_head list;
++	char *name;
++	int len;
++};
++
++/* renamed entry */
++struct renamed_entry {
++	struct list_head list;
++	char *old_name;     /* old directory with full path */
++	int old_len;        /* length of above string */
++	char *new_name;     /* new directory name */
++	int new_len;        /* length of above string */
++};
++
++/* attr_change entry */
++struct attr_change_entry {
++	struct list_head list;
++	char *name;
++	int len;
++};
++
++/* link entry */
++struct link_entry {
++	struct list_head list;
++	int links_moved;
++	int inum_base;
++	int inum_sto;
++	char *weird_name;
++	int weird_name_len;
++};
++
++
++/* Some other stuff required for mini_fo_filldir64, copied from
++ * fs/readdir.c
++ */
++
++#define ROUND_UP64(x) (((x)+sizeof(u64)-1) & ~(sizeof(u64)-1))
++#define NAME_OFFSET(de) ((int) ((de)->d_name - (char *) (de)))
++
++
++struct linux_dirent64 {
++        u64             d_ino;
++        s64             d_off;
++        unsigned short  d_reclen;
++        unsigned char   d_type;
++        char            d_name[0];
++};
++
++
++struct getdents_callback64 {
++        struct linux_dirent64 * current_dir;
++        struct linux_dirent64 * previous;
++        int count;
++        int error;
++};
++
++struct linux_dirent {
++	unsigned long   d_ino;
++	unsigned long   d_off;
++	unsigned short  d_reclen;
++	char            d_name[1];
++};
++
++struct getdents_callback {
++	struct linux_dirent * current_dir;
++	struct linux_dirent * previous;
++	int count;
++	int error;
++};
++
++
++/*
++ * MACROS:
++ */
++
++/* file TO private_data */
++# define ftopd(file) ((struct mini_fo_file_info *)((file)->private_data))
++# define __ftopd(file) ((file)->private_data)
++/* file TO hidden_file */
++# define ftohf(file) ((ftopd(file))->wfi_file)
++# define ftohf2(file) ((ftopd(file))->wfi_file2)
++
++/* inode TO private_data */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,18)
++# define itopd(ino) ((struct mini_fo_inode_info *)(ino)->i_private)
++# define __itopd(ino) ((ino)->i_private)
++#else
++# define itopd(ino) ((struct mini_fo_inode_info *)(ino)->u.generic_ip)
++# define __itopd(ino) ((ino)->u.generic_ip)
++#endif
++/* inode TO hidden_inode */
++# define itohi(ino) (itopd(ino)->wii_inode)
++# define itohi2(ino) (itopd(ino)->wii_inode2)
++
++/* superblock TO private_data */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++# define stopd(super) ((struct mini_fo_sb_info *)(super)->s_fs_info)
++# define __stopd(super) ((super)->s_fs_info)
++#else
++# define stopd(super) ((struct mini_fo_sb_info *)(super)->u.generic_sbp)
++# define __stopd(super) ((super)->u.generic_sbp)
++#endif
++
++/* unused? # define vfs2priv stopd */
++/* superblock TO hidden_superblock */
++
++# define stohs(super) (stopd(super)->wsi_sb)
++# define stohs2(super) (stopd(super)->wsi_sb2)
++
++/* dentry TO private_data */
++# define dtopd(dentry) ((struct mini_fo_dentry_info *)(dentry)->d_fsdata)
++# define __dtopd(dentry) ((dentry)->d_fsdata)
++/* dentry TO hidden_dentry */
++# define dtohd(dent) (dtopd(dent)->wdi_dentry)
++# define dtohd2(dent) (dtopd(dent)->wdi_dentry2)
++
++/* dentry to state */
++# define dtost(dent) (dtopd(dent)->state)
++# define sbt(sb) ((sb)->s_type->name)
++
++#define IS_WRITE_FLAG(flag) (flag & (O_RDWR | O_WRONLY | O_APPEND))
++#define IS_COPY_FLAG(flag) (flag & (COPY_FLAGS))
++
++/* macros to simplify non-SCA code */
++#  define MALLOC_PAGE_POINTERS(hidden_pages, num_hidden_pages)
++#  define MALLOC_PAGEDATA_POINTERS(hidden_pages_data, num_hidden_pages)
++#  define FREE_PAGE_POINTERS(hidden_pages, num)
++#  define FREE_PAGEDATA_POINTERS(hidden_pages_data, num)
++#  define FOR_EACH_PAGE
++#  define CURRENT_HIDDEN_PAGE hidden_page
++#  define CURRENT_HIDDEN_PAGEDATA hidden_page_data
++#  define CURRENT_HIDDEN_PAGEINDEX page->index
++
++/*
++ * EXTERNALS:
++ */
++extern struct file_operations mini_fo_main_fops;
++extern struct file_operations mini_fo_dir_fops;
++extern struct inode_operations mini_fo_main_iops;
++extern struct inode_operations mini_fo_dir_iops;
++extern struct inode_operations mini_fo_symlink_iops;
++extern struct super_operations mini_fo_sops;
++extern struct dentry_operations mini_fo_dops;
++extern struct vm_operations_struct mini_fo_shared_vmops;
++extern struct vm_operations_struct mini_fo_private_vmops;
++extern struct address_space_operations mini_fo_aops;
++
++#if 0 /* unused by mini_fo */
++extern int mini_fo_interpose(dentry_t *hidden_dentry, dentry_t *this_dentry, super_block_t *sb, int flag);
++#if defined(FIST_FILTER_DATA) || defined(FIST_FILTER_SCA)
++extern page_t *mini_fo_get1page(file_t *file, int index);
++extern int mini_fo_fill_zeros(file_t *file, page_t *page, unsigned from);
++# endif /* FIST_FILTER_DATA || FIST_FILTER_SCA */
++
++
++#  define mini_fo_hidden_dentry(d) __mini_fo_hidden_dentry(__FILE__,__FUNCTION__,__LINE__,(d))
++#  define mini_fo_hidden_sto_dentry(d) __mini_fo_hidden_sto_dentry(__FILE__,__FUNCTION__,__LINE__,(d))
++
++extern dentry_t *__mini_fo_hidden_dentry(char *file, char *func, int line, dentry_t *this_dentry);
++extern dentry_t *__mini_fo_hidden_sto_dentry(char *file, char *func, int line, dentry_t *this_dentry);
++
++extern int mini_fo_read_file(const char *filename, void *buf, int len);
++extern int mini_fo_write_file(const char *filename, void *buf, int len);
++extern dentry_t *fist_lookup(dentry_t *dir, const char *name, vnode_t **out, uid_t uid, gid_t gid);
++#endif /* unused by mini_fo */
++
++/* state transition functions */
++extern int nondir_unmod_to_mod(dentry_t *dentry, int cp_flag);
++extern int nondir_del_rew_to_del(dentry_t *dentry);
++extern int nondir_creat_to_del(dentry_t *dentry);
++extern int nondir_mod_to_del(dentry_t *dentry);
++extern int nondir_unmod_to_del(dentry_t *dentry);
++
++extern int dir_unmod_to_mod(dentry_t *dentry);
++
++/* rename specials */
++extern int rename_directory(inode_t *old_dir, dentry_t *old_dentry, inode_t *new_dir, dentry_t *new_dentry);
++extern int rename_nondir(inode_t *old_dir, dentry_t *old_dentry, inode_t *new_dir, dentry_t *new_dentry);
++
++/* misc stuff */
++extern int mini_fo_tri_interpose(dentry_t *hidden_dentry,
++				 dentry_t *hidden_sto_dentry,
++				 dentry_t *dentry,
++				 super_block_t *sb, int flag);
++
++extern int mini_fo_cp_cont(dentry_t *tgt_dentry, struct vfsmount *tgt_mnt,
++			   dentry_t *src_dentry, struct vfsmount *src_mnt);
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++extern int mini_fo_create(inode_t *dir, dentry_t *dentry, int mode, struct nameidata *nd);
++
++extern int create_sto_nod(dentry_t *dentry, int mode, dev_t dev);
++extern int create_sto_reg_file(dentry_t *dentry, int mode, struct nameidata *nd);
++#else
++extern int mini_fo_create(inode_t *dir, dentry_t *dentry, int mode);
++
++extern int create_sto_nod(dentry_t *dentry, int mode, int dev);
++extern int create_sto_reg_file(dentry_t *dentry, int mode);
++#endif
++
++extern int create_sto_dir(dentry_t *dentry, int mode);
++
++extern int exists_in_storage(dentry_t *dentry);
++extern int is_mini_fo_existant(dentry_t *dentry);
++extern int get_neg_sto_dentry(dentry_t *dentry);
++extern int build_sto_structure(dentry_t *dir, dentry_t *dentry);
++extern int get_mini_fo_bpath(dentry_t *dentry, char **bpath, int *bpath_len);
++extern dentry_t *bpath_walk(super_block_t *sb, char *bpath);
++extern int bpath_put(dentry_t *dentry);
++
++/* check_mini_fo types functions */
++extern int check_mini_fo_dentry(dentry_t *dentry);
++extern int check_mini_fo_file(file_t *file);
++extern int check_mini_fo_inode(inode_t *inode);
++
++/* General meta functions, can be called from outside of meta.c */
++extern int meta_build_lists(dentry_t *dentry);
++extern int meta_put_lists(dentry_t *dentry);
++extern int __meta_put_lists(inode_t *inode);
++
++extern int meta_add_d_entry(dentry_t *dentry, const char *name, int len);
++extern int meta_add_r_entry(dentry_t *dentry,
++			    const char *old_name, int old_len,
++			    const char *new_name, int new_len);
++
++extern int meta_remove_r_entry(dentry_t *dentry, const char *name, int len);
++
++extern int meta_check_d_entry(dentry_t *dentry, const char *name, int len);
++extern int __meta_check_d_entry(inode_t *inode, const char *name, int len);
++
++extern char* meta_check_r_entry(dentry_t *dentry, const char *name, int len);
++extern char* __meta_check_r_entry(inode_t *inode, const char *name, int len);
++extern int meta_is_r_entry(dentry_t *dentry, const char *name, int len);
++extern int __meta_is_r_entry(inode_t *inode, const char *name, int len);
++
++/* Specific meta functions, should be called only inside meta.c */
++extern int __meta_put_d_list(inode_t *inode);
++extern int __meta_put_r_list(inode_t *inode);
++
++extern int meta_list_add_d_entry(dentry_t *dentry,
++				 const char *name, int len);
++extern int meta_list_add_r_entry(dentry_t *dentry,
++				 const char *old_name, int old_len,
++				 const char *new_name, int new_len);
++
++extern int meta_list_remove_r_entry(dentry_t *dentry,
++				    const char *name, int len);
++
++extern int __meta_list_remove_r_entry(inode_t *inode,
++				      const char *name, int len);
++
++extern int meta_write_d_entry(dentry_t *dentry, const char *name, int len);
++extern int meta_write_r_entry(dentry_t *dentry,
++			      const char *old_name, int old_len,
++			      const char *new_name, int new_len);
++
++extern int meta_sync_lists(dentry_t *dentry);
++extern int meta_sync_d_list(dentry_t *dentry, int app_flag);
++extern int meta_sync_r_list(dentry_t *dentry, int app_flag);
++
++/* ndl stuff */
++extern int ndl_add_entry(struct readdir_data *rd, const char *name, int len);
++extern void ndl_put_list(struct readdir_data *rd);
++extern int ndl_check_entry(struct readdir_data *rd,
++			   const char *name, int len);
++
++
++# define copy_inode_size(dst, src) \
++    dst->i_size = src->i_size; \
++    dst->i_blocks = src->i_blocks;
++
++static inline void
++fist_copy_attr_atime(inode_t *dest, const inode_t *src)
++{
++	ASSERT(dest != NULL);
++	ASSERT(src != NULL);
++	dest->i_atime = src->i_atime;
++}
++static inline void
++fist_copy_attr_times(inode_t *dest, const inode_t *src)
++{
++	ASSERT(dest != NULL);
++	ASSERT(src != NULL);
++	dest->i_atime = src->i_atime;
++	dest->i_mtime = src->i_mtime;
++	dest->i_ctime = src->i_ctime;
++}
++static inline void
++fist_copy_attr_timesizes(inode_t *dest, const inode_t *src)
++{
++	ASSERT(dest != NULL);
++	ASSERT(src != NULL);
++	dest->i_atime = src->i_atime;
++	dest->i_mtime = src->i_mtime;
++	dest->i_ctime = src->i_ctime;
++	copy_inode_size(dest, src);
++}
++static inline void
++fist_copy_attr_all(inode_t *dest, const inode_t *src)
++{
++	ASSERT(dest != NULL);
++	ASSERT(src != NULL);
++	dest->i_mode = src->i_mode;
++	dest->i_nlink = src->i_nlink;
++	dest->i_uid = src->i_uid;
++	dest->i_gid = src->i_gid;
++	dest->i_rdev = src->i_rdev;
++	dest->i_atime = src->i_atime;
++	dest->i_mtime = src->i_mtime;
++	dest->i_ctime = src->i_ctime;
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19)
++	dest->i_blksize = src->i_blksize;
++#endif
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,12)
++	dest->i_blkbits = src->i_blkbits;
++# endif /* linux 2.4.12 and newer */
++	copy_inode_size(dest, src);
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
++	dest->i_attr_flags = src->i_attr_flags;
++#else
++	dest->i_flags = src->i_flags;
++#endif
++}
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++/* copied from linux/fs.h */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++static inline void double_lock(struct dentry *d1, struct dentry *d2)
++{
++	struct mutex *m1 = &d1->d_inode->i_mutex;
++	struct mutex *m2 = &d2->d_inode->i_mutex;
++	if (m1 != m2) {
++		if ((unsigned long) m1 < (unsigned long) m2) {
++			struct mutex *tmp = m2;
++			m2 = m1; m1 = tmp;
++		}
++		mutex_lock(m1);
++	}
++	mutex_lock(m2);
++}
++
++static inline void double_unlock(struct dentry *d1, struct dentry *d2)
++{
++	struct mutex *m1 = &d1->d_inode->i_mutex;
++	struct mutex *m2 = &d2->d_inode->i_mutex;
++	mutex_unlock(m1);
++	if (m1 != m2)
++		mutex_unlock(m2);
++	dput(d1);
++	dput(d2);
++}
++
++#else
++static inline void double_down(struct semaphore *s1, struct semaphore *s2)
++{
++        if (s1 != s2) {
++                if ((unsigned long) s1 < (unsigned long) s2) {
++                        struct semaphore *tmp = s2;
++                        s2 = s1; s1 = tmp;
++                }
++                down(s1);
++        }
++        down(s2);
++}
++
++static inline void double_up(struct semaphore *s1, struct semaphore *s2)
++{
++        up(s1);
++        if (s1 != s2)
++                up(s2);
++}
++
++static inline void double_lock(struct dentry *d1, struct dentry *d2)
++{
++        double_down(&d1->d_inode->i_sem, &d2->d_inode->i_sem);
++}
++
++static inline void double_unlock(struct dentry *d1, struct dentry *d2)
++{
++        double_up(&d1->d_inode->i_sem,&d2->d_inode->i_sem);
++        dput(d1);
++        dput(d2);
++}
++#endif   /* if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16) */
++#endif  /* if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0) */
++#endif /* __KERNEL__ */
++
++/*
++ * Definitions for user and kernel code
++ */
++
++/* ioctls */
++
++#endif	/* not __MINI_FO_H_ */
+--- /dev/null
++++ b/fs/mini_fo/mini_fo-merge
+@@ -0,0 +1,180 @@
++#!/bin/bash
++#
++# Copyright (C) 2005 Markus Klotzbuecher <mk@creamnet.de>
++# This program is free software; you can redistribute it and/or
++# modify it under the terms of the GNU General Public License
++# as published by the Free Software Foundation; either version
++# 2 of the License, or (at your option) any later version.
++#
++
++BASE=
++STO=
++HELP=
++DRYRUN=
++VERBOSE=
++TMP="/tmp/"
++META_NAME="META_dAfFgHE39ktF3HD2sr"
++SKIP_DEL_LIST="skip-delete-list.mini_fo-merge"
++
++COMMAND=
++exec_command()
++{
++    if [ x$DRYRUN == "xset" ]; then
++	echo "  would run: $COMMAND"
++    elif ! [ x$DRYRUN == "xset" ]; then
++	if [ x$VERBOSE == "xset" ]; then
++	    echo "  running: $COMMAND"
++	fi
++	eval $COMMAND
++    fi
++}
++
++usage()
++{
++cat <<EOF
++
++USAGE: $0 -b <base dir> -s <storage dir>
++Version 0.1
++
++This script merges the contents of a mini_fo storage file system back
++to the base file system.
++
++!!! Warning: This will modify the base filesystem and can destroy data
++             if used wrongly.
++
++Options:
++     -b <base dir>
++          the directory of the base file system.
++
++     -s <storage dir>
++          the directory of the storage file system.
++
++     -d   dry run, will not change anything and print the commands that
++          would be executed.
++
++     -t   tmp dir for storing temporary file. default: $TMP
++
++     -v   show what operations are performed.
++
++     -h   displays this message.
++
++EOF
++}
++
++# parse parameters
++while getopts hdvt:b:s: OPTS
++  do
++  case $OPTS in
++      h)  HELP="set";;
++      d)  DRYRUN="set";;
++      v)  VERBOSE="set";;
++      b)  BASE="$OPTARG";;
++      s)  STO="$OPTARG";;
++      t)  TMP="$OPTARG";;
++      ?)  usage
++	  exit 1;;
++  esac
++done
++
++if [ "x$HELP" == "xset" ]; then
++    usage
++    exit -1
++fi
++
++if ! [ -d "$BASE" ] || ! [ -d "$STO" ]; then
++    echo -e "$0:\n Error, -s and/or -b argument missing. type $0 -h for help."
++    exit -1;
++fi
++
++# get full paths
++pushd $STO; STO=`pwd`; popd
++pushd $BASE; BASE=`pwd`; popd
++TMP=${TMP%/}
++
++
++cat<<EOF
++###############################################################################
++# mini_fo-merge
++#
++# base dir:       $BASE
++# storage dir:    $STO
++# meta filename:  $META_NAME
++# dry run:        $DRYRUN
++# verbose:        $VERBOSE
++# tmp files:      $TMP
++###############################################################################
++
++EOF
++
++rm $TMP/$SKIP_DEL_LIST
++
++# first process all renamed dirs
++echo "Merging renamed directories..."
++pushd $STO &> /dev/null
++find . -name $META_NAME -type f -print0  | xargs -0 -e grep  -e '^R ' | tr -s ':R' ' ' | while read ENTRY; do
++    echo "entry: $ENTRY"
++    META_FILE=`echo $ENTRY | cut -d ' ' -f 1`
++    OLD_B_DIR=`echo $ENTRY | cut -d ' ' -f 2 | sed -e 's/\///'`
++    NEW_NAME=`echo $ENTRY | cut -d ' ' -f 3`
++    NEW_B_DIR=`echo $META_FILE | sed -e "s/$META_NAME/$NEW_NAME/" | sed -e 's/^\.\///'`
++    echo "META_FILE: $META_FILE"
++    echo "OLD_B_DIR: $OLD_B_DIR"
++    echo "NEW_NAME: $NEW_NAME"
++    echo  "NEW_B_DIR: $NEW_B_DIR"
++
++    pushd $BASE &> /dev/null
++    # remove an existing dir in storage
++    COMMAND="rm -rf $NEW_B_DIR"; exec_command
++    COMMAND="cp -R $OLD_B_DIR $NEW_B_DIR"; exec_command
++    echo ""
++    popd &> /dev/null
++
++    # remember this dir to exclude it from deleting later
++    echo $NEW_B_DIR >> $TMP/$SKIP_DEL_LIST
++done
++
++# delete all whiteouted files from base
++echo -e "\nDeleting whiteout'ed files from base file system..."
++find . -name $META_NAME -type f -print0  | xargs -0 -e grep  -e '^D ' | sed -e 's/:D//' | while read ENTRY; do
++    META_FILE=`echo $ENTRY | cut -d ' ' -f 1`
++    DEL_NAME=`echo $ENTRY | cut -d ' ' -f 2`
++    DEL_FILE=`echo $META_FILE | sed -e "s/$META_NAME/$DEL_NAME/" | sed -e 's/^\.\///'`
++    grep -x $DEL_FILE $TMP/$SKIP_DEL_LIST &> /dev/null
++    if [ $? -ne 0 ]; then
++	pushd $BASE &> /dev/null
++	COMMAND="rm -rf $DEL_FILE"; exec_command
++	popd &> /dev/null
++    else
++	echo "  excluding: $DEL_FILE as in skip-del-list."
++    fi
++done
++
++# create all dirs and update permissions
++echo -e "\nSetting up directory structures in base file system..."
++find . -type d | sed -e 's/^\.\///' | while read DIR; do
++    PERMS=`stat -c %a $DIR`
++    DIR_UID=`stat -c %u $DIR`
++    DIR_GID=`stat -c %g $DIR`
++    pushd $BASE &> /dev/null
++    if ! [ -d $DIR ]; then
++	COMMAND="mkdir -p $DIR"; exec_command
++    fi
++    COMMAND="chmod $PERMS $DIR"; exec_command
++    COMMAND="chown $DIR_UID:$DIR_GID $DIR"; exec_command
++    popd &> /dev/null
++done
++
++# merge all non-directory files
++echo -e "\nMerging all non-directory files...."
++for i in b c p f l s; do
++    find . -type $i | sed -e 's/^\.\///' | grep -v "$META_NAME" | while read FILE; do
++	pushd $BASE #&> /dev/null
++	COMMAND="cp -df $STO/$FILE $BASE/$FILE"; exec_command
++	popd &> /dev/null
++    done
++done
++popd &> /dev/null
++
++#rm $TMP/$SKIP_DEL_LIST
++
++echo "Done!"
+--- /dev/null
++++ b/fs/mini_fo/mini_fo-overlay
+@@ -0,0 +1,130 @@
++#!/bin/bash
++#
++# Copyright (C) 2005 Markus Klotzbuecher <mk@creamnet.de>
++# This program is free software; you can redistribute it and/or
++# modify it under the terms of the GNU General Public License
++# as published by the Free Software Foundation; either version
++# 2 of the License, or (at your option) any later version.
++#
++
++HELP=
++SUFF=
++MNTP=
++MNT_DIR="/mnt"
++STO=
++STO_DIR="/tmp"
++BASE=
++
++usage()
++{
++cat <<EOF
++
++Usage: $0 [-s suffix] [-d sto_dir_dir] [-m mount point] base_dir
++Version 0.1
++
++This script overlays the given base directory using the mini_fo file
++system. If only the base directory base_dir is given, $0
++will use a storage directory called "sto-<base_dir_name>" in $STO_DIR,
++and mount point "mini_fo-<base_dir_dir>" in $MNT_DIR.
++
++Options:
++     -s <suffix>
++          add given suffix to storage directory and the mount
++          point. This is usefull for overlaying one base directory
++          several times and avoiding conflicts with storage directory
++          names and mount points.
++
++     -d <sto_dir_dir>
++          change the directory in which the storage directory will be
++          created (default is currently "$STO_DIR".
++
++     -m <mount point>
++          use an alternative directory to create the mini_fo
++          mountpoint (default is currently "$MNT_DIR".
++
++     -h   displays this message.
++
++EOF
++exit 1;
++}
++
++while getopts hm:s:d: OPTS
++  do
++  case $OPTS in
++      s)  SUFF="$OPTARG";;
++      d)  STO_DIR="$OPTARG";;
++      m)  MNT_DIR="$OPTARG";;
++      h)  HELP="set";;
++      ?)  usage
++	  exit 1;;
++  esac
++done
++shift $(($OPTIND - 1))
++
++BASE="$1"
++
++if [ "x$HELP" == "xset" ]; then
++    usage
++    exit -1
++fi
++
++# fix suffix
++if [ "x$SUFF" != "x" ]; then
++    SUFF="-$SUFF"
++fi
++
++# kill trailing slashes
++MNT_DIR=${MNT_DIR%/}
++STO_DIR=${STO_DIR%/}
++BASE=${BASE%/}
++
++
++if ! [ -d "$BASE" ]; then
++    echo "invalid base dir $BASE, run $0 -h for help."
++    exit -1
++fi
++
++# check opts
++if ! [ -d "$MNT_DIR" ]; then
++    echo "invalid mount dir $MNT_DIR, run $0 -h for help."
++    exit -1
++fi
++
++if ! [ -d "$STO_DIR" ]; then
++    echo "invalid sto_dir_dir $STO_DIR, run $0 -h for help."
++    exit -1
++fi
++
++MNTP="$MNT_DIR/mini_fo-`basename $BASE`$SUFF"
++STO="$STO_DIR/sto-`basename $BASE`$SUFF"
++
++# create the mount point if it doesn't exist
++mkdir -p $MNTP
++if [ $? -ne 0 ]; then
++    echo "Error, failed to create mount point $MNTP"
++fi
++
++mkdir -p $STO
++if [ $? -ne 0 ]; then
++    echo "Error, failed to create storage dir $STO"
++fi
++
++# check if fs is already mounted
++mount | grep mini_fo | grep $MNTP &> /dev/null
++if [ $? -eq 0 ]; then
++    echo "Error, existing mini_fo mount at $MNTP."
++    exit -1
++fi
++
++mount | grep mini_fo | grep $STO &> /dev/null
++if [ $? -eq 0 ]; then
++    echo "Error, $STO seems to be used already."
++    exit -1
++fi
++
++# mount
++mount -t mini_fo -o base=$BASE,sto=$STO $BASE $MNTP
++
++if [ $? -ne 0 ]; then
++    echo "Error, mounting failed, maybe no permisson to mount?"
++fi
+--- /dev/null
++++ b/fs/mini_fo/mmap.c
+@@ -0,0 +1,637 @@
++/*
++ * Copyright (c) 1997-2003 Erez Zadok
++ * Copyright (c) 2001-2003 Stony Brook University
++ *
++ * For specific licensing information, see the COPYING file distributed with
++ * this package, or get one from ftp://ftp.filesystems.org/pub/fist/COPYING.
++ *
++ * This Copyright notice must be kept intact and distributed with all
++ * fistgen sources INCLUDING sources generated by fistgen.
++ */
++/*
++ * Copyright (C) 2004, 2005 Markus Klotzbuecher <mk@creamnet.de>
++ *
++ * This program is free software; you can redistribute it and/or
++ * modify it under the terms of the GNU General Public License
++ * as published by the Free Software Foundation; either version
++ * 2 of the License, or (at your option) any later version.
++ */
++
++/*
++ *  $Id$
++ */
++
++#ifdef HAVE_CONFIG_H
++# include <config.h>
++#endif /* HAVE_CONFIG_H */
++
++#include "fist.h"
++#include "mini_fo.h"
++
++
++#ifdef FIST_COUNT_WRITES
++/* for counting writes in the middle vs. regular writes */
++unsigned long count_writes = 0, count_writes_middle = 0;
++#endif /* FIST_COUNT_WRITES */
++
++/* forward declaration of commit write and prepare write */
++STATIC int mini_fo_commit_write(file_t *file, page_t *page, unsigned from, unsigned to);
++STATIC int mini_fo_prepare_write(file_t *file, page_t *page, unsigned from, unsigned to);
++
++
++/*
++ * Function for handling creation of holes when lseek-ing past the
++ * end of the file and then writing some data.
++ */
++int
++mini_fo_fill_zeros(file_t* file, page_t *page, unsigned from)
++{
++	int err = 0;
++	dentry_t *dentry = file->f_dentry;
++	inode_t *inode = dentry->d_inode;
++	page_t *tmp_page;
++	int index;
++
++	print_entry_location();
++
++	for (index = inode->i_size >> PAGE_CACHE_SHIFT; index < page->index; index++) {
++		tmp_page = mini_fo_get1page(file, index);
++		if (IS_ERR(tmp_page)) {
++			err = PTR_ERR(tmp_page);
++			goto out;
++		}
++
++		/*
++		 * zero out rest of the contents of the page between the appropriate
++		 * offsets.
++		 */
++		memset((char*)page_address(tmp_page) + (inode->i_size & ~PAGE_CACHE_MASK), 0, PAGE_CACHE_SIZE - (inode->i_size & ~PAGE_CACHE_MASK));
++
++		if (! (err = mini_fo_prepare_write(file, tmp_page, 0, PAGE_CACHE_SIZE)))
++			err = mini_fo_commit_write(file, tmp_page, 0, PAGE_CACHE_SIZE);
++
++		page_cache_release(tmp_page);
++		if (err < 0)
++			goto out;
++		if (current->need_resched)
++			schedule();
++	}
++
++	/* zero out appropriate parts of last page */
++
++	/*
++	 * if the encoding type is block, then adjust the 'from' (where the
++	 * zeroing will start) offset appropriately
++	 */
++	from = from & (~(FIST_ENCODING_BLOCKSIZE - 1));
++
++	if ((from - (inode->i_size & ~PAGE_CACHE_MASK)) > 0) {
++
++		memset((char*)page_address(page) + (inode->i_size & ~PAGE_CACHE_MASK), 0, from - (inode->i_size & ~PAGE_CACHE_MASK));
++		if (! (err = mini_fo_prepare_write(file, page, 0, PAGE_CACHE_SIZE)))
++			err = mini_fo_commit_write(file, page, 0, PAGE_CACHE_SIZE);
++
++		if (err < 0)
++			goto out;
++		if (current->need_resched)
++			schedule();
++	}
++
++ out:
++	print_exit_status(err);
++	return err;
++}
++
++
++
++STATIC int
++mini_fo_writepage(page_t *page)
++{
++	int err = -EIO;
++	inode_t *inode;
++	inode_t *hidden_inode;
++	page_t *hidden_page;
++	char *kaddr, *hidden_kaddr;
++
++	print_entry_location();
++
++	inode = page->mapping->host;
++	hidden_inode = itohi(inode);
++
++	/*
++	 * writepage is called when shared mmap'ed files need to write
++	 * their pages, while prepare/commit_write are called from the
++	 * non-paged write() interface.  (However, in 2.3 the two interfaces
++	 * share the same cache, while in 2.2 they didn't.)
++	 *
++	 * So we pretty much have to duplicate much of what commit_write does.
++	 */
++
++	/* find lower page (returns a locked page) */
++	hidden_page = grab_cache_page(hidden_inode->i_mapping, page->index);
++	if (!hidden_page)
++		goto out;
++
++	/* get page address, and encode it */
++	kaddr = (char *) kmap(page);
++	hidden_kaddr = (char*) kmap(hidden_page);
++	mini_fo_encode_block(kaddr, hidden_kaddr, PAGE_CACHE_SIZE, inode, inode->i_sb, page->index);
++	/* if encode_block could fail, then return error */
++	kunmap(page);
++	kunmap(hidden_page);
++
++	/* call lower writepage (expects locked page) */
++	err = hidden_inode->i_mapping->a_ops->writepage(hidden_page);
++
++	/*
++	 * update mtime and ctime of lower level file system
++	 * mini_fo' mtime and ctime are updated by generic_file_write
++	 */
++	hidden_inode->i_mtime = hidden_inode->i_ctime = CURRENT_TIME;
++
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,4,1)
++	UnlockPage(hidden_page);	/* b/c grab_cache_page locked it */
++# endif /* kernel older than 2.4.1 */
++	page_cache_release(hidden_page); /* b/c grab_cache_page increased refcnt */
++
++	if (err)
++		ClearPageUptodate(page);
++	else
++		SetPageUptodate(page);
++ out:
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,1)
++	UnlockPage(page);
++# endif /* kernel 2.4.1 and newer */
++	print_exit_status(err);
++	return err;
++}
++
++
++/*
++ * get one page from cache or lower f/s, return error otherwise.
++ * returns unlocked, up-to-date page (if ok), with increased refcnt.
++ */
++page_t *
++mini_fo_get1page(file_t *file, int index)
++{
++	page_t *page;
++	dentry_t *dentry;
++	inode_t *inode;
++	struct address_space *mapping;
++	int err;
++
++	print_entry_location();
++
++	dentry = file->f_dentry; /* CPW: Moved below print_entry_location */
++	inode = dentry->d_inode;
++	mapping = inode->i_mapping;
++
++	fist_dprint(8, "%s: read page index %d pid %d\n", __FUNCTION__, index, current->pid);
++	if (index < 0) {
++		printk("%s BUG: index=%d\n", __FUNCTION__, index);
++		page = ERR_PTR(-EIO);
++		goto out;
++	}
++	page = read_cache_page(mapping,
++			       index,
++			       (filler_t *) mapping->a_ops->readpage,
++			       (void *) file);
++	if (IS_ERR(page))
++		goto out;
++	wait_on_page(page);
++	if (!Page_Uptodate(page)) {
++		lock_page(page);
++		err = mapping->a_ops->readpage(file, page);
++		if (err) {
++			page = ERR_PTR(err);
++			goto out;
++		}
++		wait_on_page(page);
++		if (!Page_Uptodate(page)) {
++			page = ERR_PTR(-EIO);
++			goto out;
++		}
++	}
++
++ out:
++	print_exit_pointer(page);
++	return page;
++}
++
++
++/*
++ * get one page from cache or lower f/s, return error otherwise.
++ * similar to get1page, but doesn't guarantee that it will return
++ * an unlocked page.
++ */
++page_t *
++mini_fo_get1page_cached(file_t *file, int index)
++{
++	page_t *page;
++	dentry_t *dentry;
++	inode_t *inode;
++	struct address_space *mapping;
++	int err;
++
++	print_entry_location();
++
++	dentry = file->f_dentry; /* CPW: Moved below print_entry_location */
++	inode = dentry->d_inode;
++	mapping = inode->i_mapping;
++
++	fist_dprint(8, "%s: read page index %d pid %d\n", __FUNCTION__, index, current->pid);
++	if (index < 0) {
++		printk("%s BUG: index=%d\n", __FUNCTION__, index);
++		page = ERR_PTR(-EIO);
++		goto out;
++	}
++	page = read_cache_page(mapping,
++			       index,
++			       (filler_t *) mapping->a_ops->readpage,
++			       (void *) file);
++	if (IS_ERR(page))
++		goto out;
++
++ out:
++	print_exit_pointer(page);
++	return page;
++}
++
++
++/*
++ * readpage is called from generic_page_read and the fault handler.
++ * If your file system uses generic_page_read for the read op, it
++ * must implement readpage.
++ *
++ * Readpage expects a locked page, and must unlock it.
++ */
++STATIC int
++mini_fo_do_readpage(file_t *file, page_t *page)
++{
++	int err = -EIO;
++	dentry_t *dentry;
++	file_t *hidden_file = NULL;
++	dentry_t *hidden_dentry;
++	inode_t *inode;
++	inode_t *hidden_inode;
++	char *page_data;
++	page_t *hidden_page;
++	char *hidden_page_data;
++	int real_size;
++
++	print_entry_location();
++
++	dentry = file->f_dentry; /* CPW: Moved below print_entry_location */
++	if (ftopd(file) != NULL)
++		hidden_file = ftohf(file);
++	hidden_dentry = dtohd(dentry);
++	inode = dentry->d_inode;
++	hidden_inode = itohi(inode);
++
++	fist_dprint(7, "%s: requesting page %d from file %s\n", __FUNCTION__, page->index, dentry->d_name.name);
++
++	MALLOC_PAGE_POINTERS(hidden_pages, num_hidden_pages);
++	MALLOC_PAGEDATA_POINTERS(hidden_pages_data, num_hidden_pages);
++	FOR_EACH_PAGE
++		CURRENT_HIDDEN_PAGE = NULL;
++
++	/* find lower page (returns a locked page) */
++	FOR_EACH_PAGE {
++		fist_dprint(8, "%s: Current page index = %d\n", __FUNCTION__, CURRENT_HIDDEN_PAGEINDEX);
++		CURRENT_HIDDEN_PAGE = read_cache_page(hidden_inode->i_mapping,
++						      CURRENT_HIDDEN_PAGEINDEX,
++						      (filler_t *) hidden_inode->i_mapping->a_ops->readpage,
++						      (void *) hidden_file);
++		if (IS_ERR(CURRENT_HIDDEN_PAGE)) {
++			err = PTR_ERR(CURRENT_HIDDEN_PAGE);
++			CURRENT_HIDDEN_PAGE = NULL;
++			goto out_release;
++		}
++	}
++
++	/*
++	 * wait for the page data to show up
++	 * (signaled by readpage as unlocking the page)
++	 */
++	FOR_EACH_PAGE {
++		wait_on_page(CURRENT_HIDDEN_PAGE);
++		if (!Page_Uptodate(CURRENT_HIDDEN_PAGE)) {
++			/*
++			 * call readpage() again if we returned from wait_on_page with a
++			 * page that's not up-to-date; that can happen when a partial
++			 * page has a few buffers which are ok, but not the whole
++			 * page.
++			 */
++			lock_page(CURRENT_HIDDEN_PAGE);
++			err = hidden_inode->i_mapping->a_ops->readpage(hidden_file,
++								       CURRENT_HIDDEN_PAGE);
++			if (err) {
++				CURRENT_HIDDEN_PAGE = NULL;
++				goto out_release;
++			}
++			wait_on_page(CURRENT_HIDDEN_PAGE);
++			if (!Page_Uptodate(CURRENT_HIDDEN_PAGE)) {
++				err = -EIO;
++				goto out_release;
++			}
++		}
++	}
++
++	/* map pages, get their addresses */
++	page_data = (char *) kmap(page);
++	FOR_EACH_PAGE
++		CURRENT_HIDDEN_PAGEDATA = (char *) kmap(CURRENT_HIDDEN_PAGE);
++
++	/* if decode_block could fail, then return error */
++	err = 0;
++	real_size = hidden_inode->i_size - (page->index << PAGE_CACHE_SHIFT);
++	if (real_size <= 0)
++		memset(page_data, 0, PAGE_CACHE_SIZE);
++	else if (real_size < PAGE_CACHE_SIZE) {
++		mini_fo_decode_block(hidden_page_data, page_data, real_size, inode, inode->i_sb, page->index);
++		memset(page_data + real_size, 0, PAGE_CACHE_SIZE - real_size);
++	} else
++		mini_fo_decode_block(hidden_page_data, page_data, PAGE_CACHE_SIZE, inode, inode->i_sb, page->index);
++
++	FOR_EACH_PAGE
++		kunmap(CURRENT_HIDDEN_PAGE);
++	kunmap(page);
++
++ out_release:
++	FOR_EACH_PAGE
++		if (CURRENT_HIDDEN_PAGE)
++			page_cache_release(CURRENT_HIDDEN_PAGE); /* undo read_cache_page */
++
++	FREE_PAGE_POINTERS(hidden_pages, num_hidden_pages);
++	FREE_PAGEDATA_POINTERS(hidden_pages_data, num_hidden_pages);
++
++ out:
++	if (err == 0)
++		SetPageUptodate(page);
++	else
++		ClearPageUptodate(page);
++
++	print_exit_status(err);
++	return err;
++}
++
++
++STATIC int
++mini_fo_readpage(file_t *file, page_t *page)
++{
++	int err;
++	print_entry_location();
++
++	err = mini_fo_do_readpage(file, page);
++
++	/*
++	 * we have to unlock our page, b/c we _might_ have gotten a locked page.
++	 * but we no longer have to wakeup on our page here, b/c UnlockPage does
++	 * it
++	 */
++	UnlockPage(page);
++
++	print_exit_status(err);
++	return err;
++}
++
++
++STATIC int
++mini_fo_prepare_write(file_t *file, page_t *page, unsigned from, unsigned to)
++{
++	int err = 0;
++
++	print_entry_location();
++
++	/*
++	 * we call kmap(page) only here, and do the kunmap
++	 * and the actual downcalls, including unlockpage and uncache
++	 * in commit_write.
++	 */
++	kmap(page);
++
++	/* fast path for whole page writes */
++	if (from == 0 && to == PAGE_CACHE_SIZE)
++		goto out;
++	/* read the page to "revalidate" our data */
++	/* call the helper function which doesn't unlock the page */
++	if (!Page_Uptodate(page))
++		err = mini_fo_do_readpage(file, page);
++
++ out:
++	print_exit_status(err);
++	return err;
++}
++
++
++
++STATIC int
++mini_fo_commit_write(file_t *file, page_t *page, unsigned from, unsigned to)
++{
++	int err = -ENOMEM;
++	inode_t *inode;
++	inode_t *hidden_inode;
++	page_t *hidden_page;
++	file_t *hidden_file = NULL;
++	loff_t pos;
++	unsigned bytes = to - from;
++	unsigned hidden_from, hidden_to, hidden_bytes;
++
++	print_entry_location();
++
++	inode = page->mapping->host; /* CPW: Moved below print_entry_location */
++	hidden_inode = itohi(inode);
++
++	ASSERT(file != NULL);
++	/*
++	 * here we have a kmapped page, with data from the user copied
++	 * into it.  we need to encode_block it, and then call the lower
++	 * commit_write.  We also need to simulate same behavior of
++	 * generic_file_write, and call prepare_write on the lower f/s first.
++	 */
++#ifdef FIST_COUNT_WRITES
++	count_writes++;
++# endif /* FIST_COUNT_WRITES */
++
++	/* this is append and/or extend -- we can't have holes so fill them in */
++	if (page->index > (hidden_inode->i_size >> PAGE_CACHE_SHIFT)) {
++		page_t *tmp_page;
++		int index;
++		for (index = hidden_inode->i_size >> PAGE_CACHE_SHIFT; index < page->index; index++) {
++			tmp_page = mini_fo_get1page(file, index);
++			if (IS_ERR(tmp_page)) {
++				err = PTR_ERR(tmp_page);
++				goto out;
++			}
++			/* zero out the contents of the page at the appropriate offsets */
++			memset((char*)page_address(tmp_page) + (inode->i_size & ~PAGE_CACHE_MASK), 0, PAGE_CACHE_SIZE - (inode->i_size & ~PAGE_CACHE_MASK));
++			if (!(err = mini_fo_prepare_write(file, tmp_page, 0, PAGE_CACHE_SIZE)))
++				err = mini_fo_commit_write(file, tmp_page, 0, PAGE_CACHE_SIZE);
++			page_cache_release(tmp_page);
++			if (err < 0)
++				goto out;
++			if (current->need_resched)
++				schedule();
++		}
++	}
++
++	if (ftopd(file) != NULL)
++		hidden_file = ftohf(file);
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_lock(&hidden_inode->i_mutex);
++#else
++	down(&hidden_inode->i_sem);
++#endif
++	/* find lower page (returns a locked page) */
++	hidden_page = grab_cache_page(hidden_inode->i_mapping, page->index);
++	if (!hidden_page)
++		goto out;
++
++#if FIST_ENCODING_BLOCKSIZE > 1
++#  error encoding_blocksize greater than 1 is not yet supported
++# endif /* FIST_ENCODING_BLOCKSIZE > 1 */
++
++	hidden_from = from & (~(FIST_ENCODING_BLOCKSIZE - 1));
++	hidden_to = ((to + FIST_ENCODING_BLOCKSIZE - 1) & (~(FIST_ENCODING_BLOCKSIZE - 1)));
++	if ((page->index << PAGE_CACHE_SHIFT) + to > hidden_inode->i_size) {
++
++		/*
++		 * if this call to commit_write had introduced holes and the code
++		 * for handling holes was invoked, then the beginning of this page
++		 * must be zeroed out
++		 * zero out bytes from 'size_of_file%pagesize' to 'from'.
++		 */
++		if ((hidden_from - (inode->i_size & ~PAGE_CACHE_MASK)) > 0)
++			memset((char*)page_address(page) + (inode->i_size & ~PAGE_CACHE_MASK), 0, hidden_from - (inode->i_size & ~PAGE_CACHE_MASK));
++
++	}
++	hidden_bytes = hidden_to - hidden_from;
++
++	/* call lower prepare_write */
++	err = -EINVAL;
++	if (hidden_inode->i_mapping &&
++	    hidden_inode->i_mapping->a_ops &&
++	    hidden_inode->i_mapping->a_ops->prepare_write)
++		err = hidden_inode->i_mapping->a_ops->prepare_write(hidden_file,
++								    hidden_page,
++								    hidden_from,
++								    hidden_to);
++	if (err)
++		/* don't leave locked pages behind, esp. on an ENOSPC */
++		goto out_unlock;
++
++	fist_dprint(8, "%s: encoding %d bytes\n", __FUNCTION__, hidden_bytes);
++	mini_fo_encode_block((char *) page_address(page) + hidden_from, (char*) page_address(hidden_page) + hidden_from, hidden_bytes, inode, inode->i_sb, page->index);
++	/* if encode_block could fail, then goto unlock and return error */
++
++	/* call lower commit_write */
++	err = hidden_inode->i_mapping->a_ops->commit_write(hidden_file,
++							   hidden_page,
++							   hidden_from,
++							   hidden_to);
++
++	if (err < 0)
++		goto out_unlock;
++
++	err = bytes;	/* convert error to no. of bytes */
++
++	inode->i_blocks = hidden_inode->i_blocks;
++	/* we may have to update i_size */
++	pos = (page->index << PAGE_CACHE_SHIFT) + to;
++	if (pos > inode->i_size)
++		inode->i_size = pos;
++
++	/*
++	 * update mtime and ctime of lower level file system
++	 * mini_fo' mtime and ctime are updated by generic_file_write
++	 */
++	hidden_inode->i_mtime = hidden_inode->i_ctime = CURRENT_TIME;
++
++	mark_inode_dirty_sync(inode);
++
++ out_unlock:
++	UnlockPage(hidden_page);
++	page_cache_release(hidden_page);
++	kunmap(page);		/* kmap was done in prepare_write */
++ out:
++	/* we must set our page as up-to-date */
++	if (err < 0)
++		ClearPageUptodate(page);
++	else
++		SetPageUptodate(page);
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_unlock(&hidden_inode->i_mutex);
++#else
++	up(&hidden_inode->i_sem);
++#endif
++	print_exit_status(err);
++	return err;			/* assume all is ok */
++}
++
++
++STATIC int
++mini_fo_bmap(struct address_space *mapping, long block)
++{
++	int err = 0;
++	inode_t *inode;
++	inode_t *hidden_inode;
++
++	print_entry_location();
++
++	inode = (inode_t *) mapping->host;
++	hidden_inode = itohi(inode);
++
++	if (hidden_inode->i_mapping->a_ops->bmap)
++		err = hidden_inode->i_mapping->a_ops->bmap(hidden_inode->i_mapping, block);
++	print_exit_location();
++	return err;
++}
++
++
++/*
++ * This function is copied verbatim from mm/filemap.c.
++ * XXX: It should be simply moved to some header file instead -- bug Al about it!
++ */
++static inline int sync_page(struct page *page)
++{
++	struct address_space *mapping = page->mapping;
++
++	if (mapping && mapping->a_ops && mapping->a_ops->sync_page)
++		return mapping->a_ops->sync_page(page);
++	return 0;
++}
++
++
++/*
++ * XXX: we may not need this function if not FIST_FILTER_DATA.
++ * FIXME: for FIST_FILTER_SCA, get all lower pages and sync them each.
++ */
++STATIC int
++mini_fo_sync_page(page_t *page)
++{
++	int err = 0;
++	inode_t *inode;
++	inode_t *hidden_inode;
++	page_t *hidden_page;
++
++	print_entry_location();
++
++	inode = page->mapping->host; /* CPW: Moved below print_entry_location */
++	hidden_inode = itohi(inode);
++
++	/* find lower page (returns a locked page) */
++	hidden_page = grab_cache_page(hidden_inode->i_mapping, page->index);
++	if (!hidden_page)
++		goto out;
++
++	err = sync_page(hidden_page);
++
++	UnlockPage(hidden_page);	/* b/c grab_cache_page locked it */
++	page_cache_release(hidden_page); /* b/c grab_cache_page increased refcnt */
++
++ out:
++	print_exit_status(err);
++	return err;
++}
+--- /dev/null
++++ b/fs/mini_fo/README
+@@ -0,0 +1,163 @@
++README for the mini_fo overlay file system
++=========================================
++
++
++WHAT IS MINI_FO?
++----------------
++
++mini_fo is a virtual kernel file system that can make read-only
++file systems writable. This is done by redirecting modifying operations
++to a writeable location called "storage directory", and leaving the
++original data in the "base directory" untouched. When reading, the
++file system merges the modifed and original data so that only the
++newest versions will appear. This occurs transparently to the user,
++who can access the data like on any other read-write file system.
++
++Base and storage directories may be located on the same or on
++different partitions and may be of different file system types. While
++the storage directory obviously needs to be writable, the base may or
++may not be writable, what doesn't matter as it will no be modified
++anyway.
++
++
++WHAT IS GOOD FOR?
++-----------------
++
++The primary purpose of the mini_fo file system is to allow easy
++software updates to embedded systems, that often store their root
++file system in a read-only flash file system, but there are many
++more as for example sandboxing, or for allowing live-cds to
++permanently store information.
++
++
++BUILDING
++--------
++This should be simple. Adjust the Makefile to point to the correct
++kernel headers you want to build the module for. Then:
++
++    # make
++
++should build "mini_fo.o" for a 2.4 kernel or "mini_fo.ko" for a 2.6
++kernel.
++
++If you are building the module for you current kernel, you can install
++the module (as root):
++
++    # make install
++
++or uninstall with
++
++    # make uninstall
++
++
++USING THE FILE SYSTEM
++--------------------
++
++the general mount syntax is:
++
++   mount -t mini_fo -o base=<base directory>,sto=<storage directory>\
++                            <base directory> <mount point>
++
++Example:
++
++You have mounted a cdrom to /mnt/cdrom and want to modifiy some files
++on it:
++
++load the module (as root)
++
++    # insmod mini_fo.o for a 2.4 kernel or
++
++    # insmod mini_fo.ko for a 2.6 kernel
++
++
++create a storage dir in tmp and a mountpoint for mini_fo:
++
++    # mkdir /tmp/sto
++    # mkdir /mnt/mini_fo
++
++and mount the mini_fo file system:
++
++    # mount -t mini_fo -o base=/mnt/cdrom,sto=/tmp/sto /mnt/cdrom /mnt/mini_fo
++
++
++Now the data stored on the cd can be accessed via the mini_fo
++mountpoint just like any read-write file system, files can be modified
++and deleted, new ones can be created and so on. When done unmount the
++file system:
++
++    # unmount /mnt/mini_fo
++
++Note that if the file system is mounted again using the same storage
++file system, of course it will appear in the modified state again. If
++you remount it using an new empty storage directory, it will be
++unmodified. Therefore by executing:
++
++    # cd /tmp/sto
++    # rm -rf *
++
++you can nuke all the changes you made to the original file system. But
++ remember NEVER do this while the mini_fo file system is mounted!
++
++
++Alternatively you can use the mini_fo-overlay bash script, that
++simplifies managing mini_fo mounts. See TOOLS Section.
++
++
++TOOLS
++-----
++
++mini_fo-merge (experimental):
++
++This is a bash script that will merge changes contained in the storage
++directory back to the base directory. This allows mini_fo to function
++as a cache file system by overlaying a slow (network, ...) file system
++and using a fast (ramdisk, ...) as storage. When done, changes can be
++merged back to the (slow) base with mini_fo-merge. See "mini_fo-merge
++-h" for details.
++
++It can be usefull for merging changes back after a successfull test
++(patches, software updates...)
++
++
++mini_fo-overlay:
++
++This bash script simplifies managing one or more mini_fo mounts. For
++overlaying a directory called "basedir1", you can just call:
++
++    # mini_fo-overlay basedir1
++
++This will mount mini_fo with "basedir1" as base, "/tmp/sto-basedir1/"
++as storage to "/mnt/mini_fo-basedir1/". It has more options though,
++type "mini_fo-overlay -h" for details.
++
++
++DOCUMENTATION, REPORTING BUGS, GETTING HELP
++-------------------------------------------
++
++Please visit the mini_fo project page at:
++
++http://www.denx.de/twiki/bin/view/Know/MiniFOHome
++
++
++WARNINGS
++--------
++
++Never modify the base or the storage directorys while the mini_fo
++file system is mounted, or you might crash you system. Simply accessing
++and reading should not cause any trouble.
++
++Exporting a mini_fo mount point via NFS has not been tested, and may
++or may not work.
++
++Check the RELEASE_NOTES for details on bugs and features.
++
++
++
++Copyright (C) 2004, 2005 Markus Klotzbuecher <mk@creamnet.de>
++
++This program is free software; you can redistribute it and/or
++modify it under the terms of the GNU General Public License
++as published by the Free Software Foundation; either version
++2 of the License, or (at your option) any later version.
++
++
+--- /dev/null
++++ b/fs/mini_fo/RELEASE_NOTES
+@@ -0,0 +1,111 @@
++Release:	mini_fo-0.6.1 (v0-6-1)
++Date:		21.09.2005
++
++
++Changes:
++--------
++v0-6-1:
++
++- bugfixes (see ChangeLog)
++
++- two helper scripts "mini_fo_merge" and "mini_fo_overlay" (see
++  README for details).
++
++v0-6-0:
++
++- Support for 2.4 and 2.6 (see Makefile)
++
++- Partial hard link support (creating works as expected, but already
++  existing links in the base file system will be treated as if they
++  were individual files).
++
++- Various bugfixes and cleanups.
++
++
++v0-6-0-pre1:
++
++- This is mini_fo-0-6-0-pre1! This release is a complete rewrite of
++  many vital mini_fo parts such as the old whiteout list code which
++  has been replaced by the new META subsystem.
++
++- Light weight directory renaming implemented. This means if a
++  directory is renamed via the mini_fo filesystem this will no longer
++  result in a complete copy in storage, instead only one empty
++  directory will be created. All base filed contained in the original
++  directory stay there until modified.
++
++- Special files (creating, renaming, deleting etc.) now working.
++
++- Many bugfixes and cleanup, mini_fo is now a lot more stable.
++
++
++v0-5-10:
++
++- Final release of the 0-5-* versions. Next will be a complete rewrite
++  of many features. This release contains several bugfixes related to
++  directory renaming.
++
++
++v0-5-10-pre6:
++
++- Lots of cleanup and several bugfixes related to directory deleting
++
++- Directory renaming suddenly works, what is most likely due to the
++  fact tha that "mv" is smart: if the classic rename doesn't work it
++  will assume that source and target file are on different fs and will
++  copy the directory and try to remove the source directory. Until
++  directory removing wasn't implemented, it would fail to do this and
++  rollback.
++  So, directory renaming works for now, but it doesn't yet do what you
++  would expect from a overlay fs, so use with care.
++
++
++v0-5-10-pre5:
++
++- implemented directory deleting
++- made parsing of mount options more stable
++- New format of mount options! (See README)
++- I can't reproduce the unknown panic with 2.4.25 anymore, so I'll
++  happily assume it never existed!
++
++
++Implemented features:
++---------------------
++
++- creating hard links (see BUGS on already existing hard links)
++- lightweight directory renaming
++- renaming device files, pipes, sockets, etc.
++- creating, renaming, deleting of special files
++- deleting directorys
++- general directory reading (simple "ls" )
++- creating files in existing directorys
++- creating directorys
++- renaming files.
++- reading and writing files (involves opening)
++- appending to files (creates copy in storage)
++- deleting files
++- llseek works too, what allows editors to work
++- persistency (a deleted file stay deleted over remounts)
++- use of symbolic links
++- creating of device files
++
++
++Not (yet) implemented features:
++-------------------------------
++
++- full hard link support.
++
++
++
++BUGS:
++-----
++
++Hard links in the base file system will be treated as individual
++files, not as links to one inode.
++
++The main problem with hard links isn't allowing to create them, but
++their pure existence. If you modify a base hard link, the changes made
++will only show up on this link, the other link will remain in the
++original state. I hope to fix this someday. Please note that this does
++not effect the special hard links '.' and '..', that are handled
++seperately by the lower fs.
+--- /dev/null
++++ b/fs/mini_fo/state.c
+@@ -0,0 +1,620 @@
++/*
++ * Copyright (C) 2005 Markus Klotzbuecher <mk@creamnet.de>
++ *
++ * This program is free software; you can redistribute it and/or
++ * modify it under the terms of the GNU General Public License
++ * as published by the Free Software Foundation; either version
++ * 2 of the License, or (at your option) any later version.
++ */
++
++#ifdef HAVE_CONFIG_H
++# include <config.h>
++#endif /* HAVE_CONFIG_H */
++
++#include "fist.h"
++#include "mini_fo.h"
++
++
++/* create the storage file, setup new states */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++int create_sto_reg_file(dentry_t *dentry, int mode, struct nameidata *nd)
++#else
++int create_sto_reg_file(dentry_t *dentry, int mode)
++#endif
++{
++	int err = 0;
++	inode_t *dir;
++	dentry_t *hidden_sto_dentry;
++	dentry_t *hidden_sto_dir_dentry;
++
++	if(exists_in_storage(dentry)) {
++		printk(KERN_CRIT "mini_fo: create_sto_file: wrong type or state.\n");
++		err = -EINVAL;
++		goto out;
++	}
++	err = get_neg_sto_dentry(dentry);
++
++	if (err) {
++		printk(KERN_CRIT "mini_fo: create_sto_file: ERROR getting neg. sto dentry.\n");
++		goto out;
++	}
++
++	dir = dentry->d_parent->d_inode;
++	hidden_sto_dentry = dtohd2(dentry);
++
++	/* lock parent */
++	hidden_sto_dir_dentry = dget(hidden_sto_dentry->d_parent);
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_lock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++        down(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++
++	err = PTR_ERR(hidden_sto_dir_dentry);
++        if (IS_ERR(hidden_sto_dir_dentry))
++                goto out;
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++	err = vfs_create(hidden_sto_dir_dentry->d_inode,
++			 hidden_sto_dentry,
++			 mode, nd);
++#else
++	err = vfs_create(hidden_sto_dir_dentry->d_inode,
++			 hidden_sto_dentry,
++			 mode);
++#endif
++        if(err) {
++		printk(KERN_CRIT "mini_fo: create_sto_file: ERROR creating sto file.\n");
++                goto out_lock;
++	}
++
++	if(!dtohd2(dentry)->d_inode) {
++		printk(KERN_CRIT "mini_fo: create_sto_file: ERROR creating sto file [2].\n");
++                err = -EINVAL;
++                goto out_lock;
++        }
++
++        /* interpose the new inode */
++        if(dtost(dentry) == DELETED) {
++                dtost(dentry) = DEL_REWRITTEN;
++                err = mini_fo_tri_interpose(NULL, hidden_sto_dentry, dentry, dir->i_sb, 0);
++                if(err)
++                        goto out_lock;
++        }
++        else if(dtost(dentry) == NON_EXISTANT) {
++                dtost(dentry) = CREATED;
++                err = mini_fo_tri_interpose(dtohd(dentry), hidden_sto_dentry, dentry, dir->i_sb, 0);
++                if(err)
++                        goto out_lock;
++        }
++        else if(dtost(dentry) == UNMODIFIED) {
++                dtost(dentry) = MODIFIED;
++                /* interpose on new inode */
++                if(itohi2(dentry->d_inode) != NULL) {
++                        printk(KERN_CRIT "mini_fo: create_sto_file: invalid inode detected.\n");
++                        err = -EINVAL;
++                        goto out_lock;
++                }
++                itohi2(dentry->d_inode) = igrab(dtohd2(dentry)->d_inode);
++	}
++	fist_copy_attr_timesizes(dentry->d_parent->d_inode,
++				 hidden_sto_dir_dentry->d_inode);
++
++ out_lock:
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_unlock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++	up(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++        dput(hidden_sto_dir_dentry);
++ out:
++	return err;
++}
++
++/* create the sto dir, setup states */
++int create_sto_dir(dentry_t *dentry, int mode)
++{
++	int err = 0;
++	inode_t *dir;
++	dentry_t *hidden_sto_dentry;
++        dentry_t *hidden_sto_dir_dentry;
++
++	/* had to take the "!S_ISDIR(mode))" check out, because it failed */
++	if(exists_in_storage(dentry)) {
++                printk(KERN_CRIT "mini_fo: create_sto_dir: wrong type or state.\\
++n");
++                err = -EINVAL;
++                goto out;
++        }
++
++	err = get_neg_sto_dentry(dentry);
++	if(err) {
++		err = -EINVAL;
++		goto out;
++	}
++
++	dir = dentry->d_parent->d_inode;
++	hidden_sto_dentry = dtohd2(dentry);
++
++	/* was: hidden_sto_dir_dentry = lock_parent(hidden_sto_dentry); */
++	hidden_sto_dir_dentry = dget(hidden_sto_dentry->d_parent);
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_lock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++	down(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++
++	err = PTR_ERR(hidden_sto_dir_dentry);
++	if (IS_ERR(hidden_sto_dir_dentry))
++		goto out;
++
++	err = vfs_mkdir(hidden_sto_dir_dentry->d_inode,
++			hidden_sto_dentry,
++			mode);
++	if(err) {
++		printk(KERN_CRIT "mini_fo: create_sto_dir: ERROR creating sto dir.\n");
++		goto out_lock;
++	}
++
++	if(!dtohd2(dentry)->d_inode) {
++		printk(KERN_CRIT "mini_fo: create_sto_dir: ERROR creating sto dir [2].\n");
++		err = -EINVAL;
++		goto out_lock;
++	}
++
++	/* interpose the new inode */
++	if(dtost(dentry) == DELETED) {
++		dtost(dentry) = DEL_REWRITTEN;
++		err = mini_fo_tri_interpose(NULL, hidden_sto_dentry, dentry, dir->i_sb, 0);
++		if(err)
++			goto out_lock;
++	}
++	else if(dtopd(dentry)->state == NON_EXISTANT) {
++		dtopd(dentry)->state = CREATED;
++		err = mini_fo_tri_interpose(dtohd(dentry), hidden_sto_dentry, dentry, dir->i_sb, 0);
++		if(err)
++			goto out_lock;
++	}
++	else if(dtopd(dentry)->state == UNMODIFIED) {
++		dtopd(dentry)->state = MODIFIED;
++		/* interpose on new inode */
++		if(itohi2(dentry->d_inode) != NULL) {
++			printk(KERN_CRIT "mini_fo:  create_sto_dir: ERROR, invalid inode detected.\n");
++			err = -EINVAL;
++			goto out_lock;
++		}
++		itohi2(dentry->d_inode) = igrab(dtohd2(dentry)->d_inode);
++	}
++
++	fist_copy_attr_timesizes(dir, hidden_sto_dir_dentry->d_inode);
++
++	/* initalize the wol list */
++	itopd(dentry->d_inode)->deleted_list_size = -1;
++	itopd(dentry->d_inode)->renamed_list_size = -1;
++	meta_build_lists(dentry);
++
++
++ out_lock:
++	/* was: unlock_dir(hidden_sto_dir_dentry); */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_unlock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++	up(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++	dput(hidden_sto_dir_dentry);
++ out:
++	return err;
++}
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++int create_sto_nod(dentry_t *dentry, int mode, dev_t dev)
++#else
++int create_sto_nod(dentry_t *dentry, int mode, int dev)
++#endif
++{
++	int err = 0;
++	inode_t *dir;
++	dentry_t *hidden_sto_dentry;
++	dentry_t *hidden_sto_dir_dentry;
++
++	if(exists_in_storage(dentry)) {
++		err = -EEXIST;
++		goto out;
++	}
++	err = get_neg_sto_dentry(dentry);
++
++	if (err) {
++                printk(KERN_CRIT "mini_fo: create_sto_nod: ERROR getting neg. sto dentry.\n");
++                goto out;
++        }
++
++	dir = dentry->d_parent->d_inode;
++	hidden_sto_dentry = dtohd2(dentry);
++
++	/* lock parent */
++	hidden_sto_dir_dentry = dget(hidden_sto_dentry->d_parent);
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_lock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++	down(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++
++	err = PTR_ERR(hidden_sto_dir_dentry);
++	if (IS_ERR(hidden_sto_dir_dentry))
++		goto out;
++
++	err = vfs_mknod(hidden_sto_dir_dentry->d_inode, hidden_sto_dentry, mode, dev);
++	if(err)
++		goto out_lock;
++
++	if(!dtohd2(dentry)->d_inode) {
++		printk(KERN_CRIT "mini_fo: create_sto_nod: creating storage inode failed [1].\n");
++		err = -EINVAL; /* return something indicating failure */
++		goto out_lock;
++	}
++
++	/* interpose the new inode */
++	if(dtost(dentry) == DELETED) {
++		dtost(dentry) = DEL_REWRITTEN;
++		err = mini_fo_tri_interpose(NULL, hidden_sto_dentry, dentry, dir->i_sb, 0);
++		if(err)
++			goto out_lock;
++	}
++	else if(dtost(dentry) == NON_EXISTANT) {
++		dtost(dentry) = CREATED;
++		err = mini_fo_tri_interpose(dtohd(dentry), hidden_sto_dentry, dentry, dir->i_sb, 0);
++		if(err)
++			goto out_lock;
++	}
++	else if(dtost(dentry) == UNMODIFIED) {
++		dtost(dentry) = MODIFIED;
++		/* interpose on new inode */
++		if(itohi2(dentry->d_inode) != NULL) {
++			printk(KERN_CRIT "mini_fo: create_sto_nod: error, invalid inode detected.\n");
++			err = -EINVAL;
++			goto out_lock;
++		}
++		itohi2(dentry->d_inode) = igrab(dtohd2(dentry)->d_inode);
++	}
++
++	fist_copy_attr_timesizes(dir, hidden_sto_dir_dentry->d_inode);
++
++ out_lock:
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_unlock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++	up(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++	dput(hidden_sto_dir_dentry);
++ out:
++	return err;
++}
++
++
++/* unimplemented (and possibly not usefull):
++
++   nondir-del_to_del_rew
++   nondir-non_exist_to_creat
++
++   dir-unmod_to_del
++   dir-mod_to_del
++   dir-creat_to_del
++   dir-del_rew_to_del
++   dir-del_to_del_rew
++   dir-non_exist_to_creat
++*/
++
++
++/* bring a file of any type from state UNMODIFIED to MODIFIED */
++int nondir_unmod_to_mod(dentry_t *dentry, int cp_flag)
++{
++	int err = 0;
++	struct vfsmount *tgt_mnt;
++	struct vfsmount *src_mnt;
++	dentry_t *tgt_dentry;
++	dentry_t *src_dentry;
++	dentry_t *hidden_sto_dentry;
++	dentry_t *hidden_sto_dir_dentry;
++
++	check_mini_fo_dentry(dentry);
++
++	if((dtost(dentry) != UNMODIFIED) ||
++	   S_ISDIR(dentry->d_inode->i_mode)) {
++		printk(KERN_CRIT "mini_fo: nondir_unmod_to_mod: \
++                                  wrong type or state.\n");
++		err = -1;
++		goto out;
++	}
++	err = get_neg_sto_dentry(dentry);
++
++	if (err) {
++		printk(KERN_CRIT "mini_fo: nondir_unmod_to_mod: \
++                                  ERROR getting neg. sto dentry.\n");
++		goto out;
++	}
++
++	/* create sto file */
++	hidden_sto_dentry = dtohd2(dentry);
++
++	/* lock parent */
++	hidden_sto_dir_dentry = dget(hidden_sto_dentry->d_parent);
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_lock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++        down(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++
++	err = PTR_ERR(hidden_sto_dir_dentry);
++        if (IS_ERR(hidden_sto_dir_dentry))
++                goto out;
++
++	/* handle different types of nondirs */
++	if(S_ISCHR(dentry->d_inode->i_mode) ||
++	   S_ISBLK(dentry->d_inode->i_mode)) {
++		err = vfs_mknod(hidden_sto_dir_dentry->d_inode,
++				hidden_sto_dentry,
++				dtohd(dentry)->d_inode->i_mode,
++				dtohd(dentry)->d_inode->i_rdev);
++	}
++
++	else if(S_ISREG(dentry->d_inode->i_mode)) {
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++		err = vfs_create(hidden_sto_dir_dentry->d_inode,
++				 hidden_sto_dentry,
++				 dtohd(dentry)->d_inode->i_mode, NULL);
++#else
++		err = vfs_create(hidden_sto_dir_dentry->d_inode,
++				 hidden_sto_dentry,
++				 dtohd(dentry)->d_inode->i_mode);
++#endif
++	}
++        if(err) {
++		printk(KERN_CRIT "mini_fo: nondir_unmod_to_mod: \
++                                  ERROR creating sto file.\n");
++                goto out_lock;
++	}
++
++	/* interpose on new inode */
++	if(itohi2(dentry->d_inode) != NULL) {
++		printk(KERN_CRIT "mini_fo: nondir_unmod_to_mod: \
++                                  ERROR, invalid inode detected.\n");
++		err = -EINVAL;
++		goto out_lock;
++	}
++
++	itohi2(dentry->d_inode) = igrab(dtohd2(dentry)->d_inode);
++
++        fist_copy_attr_timesizes(dentry->d_parent->d_inode,
++				 hidden_sto_dir_dentry->d_inode);
++	dtost(dentry) = MODIFIED;
++
++	/* copy contents if regular file and cp_flag = 1 */
++	if((cp_flag == 1) && S_ISREG(dentry->d_inode->i_mode)) {
++
++		/* unlock first */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++		mutex_unlock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++		up(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++
++		dput(hidden_sto_dir_dentry);
++
++		tgt_dentry = dtohd2(dentry);
++		tgt_mnt = stopd(dentry->d_inode->i_sb)->hidden_mnt2;
++		src_dentry = dtohd(dentry);
++		src_mnt = stopd(dentry->d_inode->i_sb)->hidden_mnt;
++
++		err = mini_fo_cp_cont(tgt_dentry, tgt_mnt,
++				      src_dentry, src_mnt);
++		if(err) {
++			printk(KERN_CRIT "mini_fo: nondir_unmod_to_mod: \
++                                          ERROR copying contents.\n");
++		}
++		goto out;
++	}
++
++ out_lock:
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_unlock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++	up(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++        dput(hidden_sto_dir_dentry);
++ out:
++	return err;
++}
++
++/* this function is currently identical to nondir_creat_to_del */
++int nondir_del_rew_to_del(dentry_t *dentry)
++{
++	return nondir_creat_to_del(dentry);
++}
++
++int nondir_creat_to_del(dentry_t *dentry)
++{
++	int err = 0;
++
++	inode_t *hidden_sto_dir_inode;
++	dentry_t *hidden_sto_dir_dentry;
++	dentry_t *hidden_sto_dentry;
++
++	check_mini_fo_dentry(dentry);
++
++	/* for now this function serves for both state DEL_REWRITTEN and
++	 * CREATED */
++	if(!(dtost(dentry) == CREATED || (dtost(dentry) == DEL_REWRITTEN)) ||
++	   S_ISDIR(dentry->d_inode->i_mode)) {
++		printk(KERN_CRIT "mini_fo: nondir_mod_to_del/del_rew_to_del: \
++                                  wrong type or state.\n");
++		err = -1;
++		goto out;
++	}
++
++	hidden_sto_dir_inode = itohi2(dentry->d_parent->d_inode);
++	hidden_sto_dentry = dtohd2(dentry);
++
++	/* was: hidden_sto_dir_dentry = lock_parent(hidden_sto_dentry);*/
++	hidden_sto_dir_dentry = dget(hidden_sto_dentry->d_parent);
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_lock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++	down(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++
++	/* avoid destroying the hidden inode if the file is in use */
++	dget(hidden_sto_dentry);
++	err = vfs_unlink(hidden_sto_dir_inode, hidden_sto_dentry);
++	dput(hidden_sto_dentry);
++	if(!err)
++		d_delete(hidden_sto_dentry);
++
++	/* propagate number of hard-links */
++	dentry->d_inode->i_nlink = itohi2(dentry->d_inode)->i_nlink;
++
++	dtost(dentry) = NON_EXISTANT;
++
++	/* was: unlock_dir(hidden_sto_dir_dentry); */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_unlock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++	up(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++	dput(hidden_sto_dir_dentry);
++
++ out:
++	return err;
++}
++
++int nondir_mod_to_del(dentry_t *dentry)
++{
++	int err;
++	dentry_t *hidden_sto_dentry;
++	inode_t *hidden_sto_dir_inode;
++	dentry_t *hidden_sto_dir_dentry;
++
++	check_mini_fo_dentry(dentry);
++
++	if(dtost(dentry) != MODIFIED ||
++	   S_ISDIR(dentry->d_inode->i_mode)) {
++		printk(KERN_CRIT "mini_fo: nondir_mod_to_del: \
++                                  wrong type or state.\n");
++		err = -1;
++		goto out;
++	}
++
++	hidden_sto_dir_inode = itohi2(dentry->d_parent->d_inode);
++	hidden_sto_dentry = dtohd2(dentry);
++
++	/* was hidden_sto_dir_dentry = lock_parent(hidden_sto_dentry); */
++	hidden_sto_dir_dentry = dget(hidden_sto_dentry->d_parent);
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_lock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++	down(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++
++	/* avoid destroying the hidden inode if the file is in use */
++	dget(hidden_sto_dentry);
++	err = vfs_unlink(hidden_sto_dir_inode, hidden_sto_dentry);
++	dput(hidden_sto_dentry);
++	if(!err)
++		d_delete(hidden_sto_dentry);
++
++	/* propagate number of hard-links */
++	dentry->d_inode->i_nlink = itohi2(dentry->d_inode)->i_nlink;
++
++	/* dput base dentry, this will relase the inode and free the
++	 * dentry, as we will never need it again. */
++	dput(dtohd(dentry));
++	dtohd(dentry) = NULL;
++	dtost(dentry) = DELETED;
++
++	/* add deleted file to META-file */
++	meta_add_d_entry(dentry->d_parent,
++			 dentry->d_name.name,
++			 dentry->d_name.len);
++
++	/* was: unlock_dir(hidden_sto_dir_dentry); */
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
++	mutex_unlock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++#else
++	up(&hidden_sto_dir_dentry->d_inode->i_sem);
++#endif
++	dput(hidden_sto_dir_dentry);
++
++ out:
++	return err;
++}
++
++int nondir_unmod_to_del(dentry_t *dentry)
++{
++	int err = 0;
++
++	check_mini_fo_dentry(dentry);
++
++	if(dtost(dentry) != UNMODIFIED ||
++	   S_ISDIR(dentry->d_inode->i_mode)) {
++		printk(KERN_CRIT "mini_fo: nondir_unmod_to_del: \
++                                  wrong type or state.\n");
++		err = -1;
++		goto out;
++	}
++
++	 /* next we have to get a negative dentry for the storage file */
++	err = get_neg_sto_dentry(dentry);
++
++	if(err)
++		goto out;
++
++	/* add deleted file to META lists */
++	err = meta_add_d_entry(dentry->d_parent,
++			       dentry->d_name.name,
++			       dentry->d_name.len);
++
++	if(err)
++		goto out;
++
++	/* dput base dentry, this will relase the inode and free the
++	 * dentry, as we will never need it again. */
++	dput(dtohd(dentry));
++	dtohd(dentry) = NULL;
++	dtost(dentry) = DELETED;
++
++ out:
++	return err;
++}
++
++/* bring a dir from state UNMODIFIED to MODIFIED */
++int dir_unmod_to_mod(dentry_t *dentry)
++{
++	int err;
++
++	check_mini_fo_dentry(dentry);
++
++	if(dtost(dentry) != UNMODIFIED ||
++	   !S_ISDIR(dentry->d_inode->i_mode)) {
++		printk(KERN_CRIT "mini_fo: dir_unmod_to_mod: \
++                                  wrong type or state.\n");
++		err = -1;
++		goto out;
++	}
++
++	/* this creates our dir incl. sto. structure */
++	err = build_sto_structure(dentry->d_parent, dentry);
++	if(err) {
++		printk(KERN_CRIT "mini_fo: dir_unmod_to_mod: \
++                                  build_sto_structure failed.\n");
++		goto out;
++	}
++ out:
++	return err;
++}
++
+--- /dev/null
++++ b/fs/mini_fo/super.c
+@@ -0,0 +1,281 @@
++/*
++ * Copyright (c) 1997-2003 Erez Zadok
++ * Copyright (c) 2001-2003 Stony Brook University
++ *
++ * For specific licensing information, see the COPYING file distributed with
++ * this package, or get one from ftp://ftp.filesystems.org/pub/fist/COPYING.
++ *
++ * This Copyright notice must be kept intact and distributed with all
++ * fistgen sources INCLUDING sources generated by fistgen.
++ */
++/*
++ * Copyright (C) 2004, 2005 Markus Klotzbuecher <mk@creamnet.de>
++ *
++ * This program is free software; you can redistribute it and/or
++ * modify it under the terms of the GNU General Public License
++ * as published by the Free Software Foundation; either version
++ * 2 of the License, or (at your option) any later version.
++ */
++
++/*
++ *  $Id$
++ */
++
++#ifdef HAVE_CONFIG_H
++# include <config.h>
++#endif
++
++#include "fist.h"
++#include "mini_fo.h"
++
++
++STATIC void
++mini_fo_read_inode(inode_t *inode)
++{
++	static struct address_space_operations mini_fo_empty_aops;
++
++	__itopd(inode) = kmalloc(sizeof(struct mini_fo_inode_info), GFP_KERNEL);
++	if (!itopd(inode)) {
++		printk("<0>%s:%s:%d: No kernel memory!\n", __FILE__, __FUNCTION__, __LINE__);
++		ASSERT(NULL);
++	}
++	itohi(inode) = NULL;
++	itohi2(inode) = NULL;
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++	inode->i_version++;
++#else
++	inode->i_version = ++event;	/* increment inode version */
++#endif
++	inode->i_op = &mini_fo_main_iops;
++	inode->i_fop = &mini_fo_main_fops;
++#if 0
++	/*
++	 * XXX: To export a file system via NFS, it has to have the
++	 * FS_REQUIRES_DEV flag, so turn it on.  But should we inherit it from
++	 * the lower file system, or can we allow our file system to be exported
++	 * even if the lower one cannot be natively exported.
++	 */
++	inode->i_sb->s_type->fs_flags |= FS_REQUIRES_DEV;
++	/*
++	 * OK, the above was a hack, which is now turned off because it may
++	 * cause a panic/oops on some systems.  The correct way to export a
++	 * "nodev" filesystem is via using nfs-utils > 1.0 and the "fsid=" export
++	 * parameter, which requires 2.4.20 or later.
++	 */
++#endif
++	/* I don't think ->a_ops is ever allowed to be NULL */
++	inode->i_mapping->a_ops = &mini_fo_empty_aops;
++}
++
++
++#if defined(FIST_DEBUG) || defined(FIST_FILTER_SCA)
++/*
++ * No need to call write_inode() on the lower inode, as it
++ * will have been marked 'dirty' anyway. But we might need
++ * to write some of our own stuff to disk.
++ */
++STATIC void
++mini_fo_write_inode(inode_t *inode, int sync)
++{
++	print_entry_location();
++	print_exit_location();
++}
++#endif /* defined(FIST_DEBUG) || defined(FIST_FILTER_SCA) */
++
++
++STATIC void
++mini_fo_put_inode(inode_t *inode)
++{
++	/*
++	 * This is really funky stuff:
++	 * Basically, if i_count == 1, iput will then decrement it and this inode will be destroyed.
++	 * It is currently holding a reference to the hidden inode.
++	 * Therefore, it needs to release that reference by calling iput on the hidden inode.
++	 * iput() _will_ do it for us (by calling our clear_inode), but _only_ if i_nlink == 0.
++	 * The problem is, NFS keeps i_nlink == 1 for silly_rename'd files.
++	 * So we must for our i_nlink to 0 here to trick iput() into calling our clear_inode.
++	 */
++	if (atomic_read(&inode->i_count) == 1)
++		inode->i_nlink = 0;
++}
++
++
++#if defined(FIST_DEBUG) || defined(FIST_FILTER_SCA)
++/*
++ * we now define delete_inode, because there are two VFS paths that may
++ * destroy an inode: one of them calls clear inode before doing everything
++ * else that's needed, and the other is fine.  This way we truncate the inode
++ * size (and its pages) and then clear our own inode, which will do an iput
++ * on our and the lower inode.
++ */
++STATIC void
++mini_fo_delete_inode(inode_t *inode)
++{
++	print_entry_location();
++
++	fist_checkinode(inode, "mini_fo_delete_inode IN");
++	inode->i_size = 0;		/* every f/s seems to do that */
++	clear_inode(inode);
++
++	print_exit_location();
++}
++#endif /* defined(FIST_DEBUG) || defined(FIST_FILTER_SCA) */
++
++
++/* final actions when unmounting a file system */
++STATIC void
++mini_fo_put_super(super_block_t *sb)
++{
++	if (stopd(sb)) {
++		mntput(stopd(sb)->hidden_mnt);
++		mntput(stopd(sb)->hidden_mnt2);
++
++		/* mk: no! dput(stopd(sb)->base_dir_dentry);
++		   dput(stopd(sb)->storage_dir_dentry); */
++
++		kfree(stopd(sb));
++		__stopd(sb) = NULL;
++	}
++}
++
++
++#ifdef NOT_NEEDED
++/*
++ * This is called in do_umount before put_super.
++ * The superblock lock is not held yet.
++ * We probably do not need to define this or call write_super
++ * on the hidden_sb, because sync_supers() will get to hidden_sb
++ * sooner or later.  But it is also called from file_fsync()...
++ */
++STATIC void
++mini_fo_write_super(super_block_t *sb)
++{
++	return;
++}
++#endif /* NOT_NEEDED */
++
++
++STATIC int
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,18)
++mini_fo_statfs(struct dentry *d, struct kstatfs *buf)
++#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++mini_fo_statfs(super_block_t *sb, struct kstatfs *buf)
++#else
++mini_fo_statfs(super_block_t *sb, struct statfs *buf)
++#endif
++{
++	int err = 0;
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,18)
++	struct dentry *hidden_d;
++
++	hidden_d = dtohd(d);
++	err = vfs_statfs(hidden_d, buf);
++#else
++	super_block_t *hidden_sb;
++
++	hidden_sb = stohs(sb);
++	err = vfs_statfs(hidden_sb, buf);
++#endif
++
++	return err;
++}
++
++
++/*
++ * XXX: not implemented.  This is not allowed yet.
++ * Should we call this on the hidden_sb?  Probably not.
++ */
++STATIC int
++mini_fo_remount_fs(super_block_t *sb, int *flags, char *data)
++{
++	//printk(KERN_CRIT "mini_fo_remount_fs: WARNING, this function is umimplemented.\n");
++	return -ENOSYS;
++}
++
++
++/*
++ * Called by iput() when the inode reference count reached zero
++ * and the inode is not hashed anywhere.  Used to clear anything
++ * that needs to be, before the inode is completely destroyed and put
++ * on the inode free list.
++ */
++STATIC void
++mini_fo_clear_inode(inode_t *inode)
++{
++	/*
++	 * Decrement a reference to a hidden_inode, which was incremented
++	 * by our read_inode when it was created initially.
++	 */
++
++	/* release the wol_list */
++	if(S_ISDIR(inode->i_mode)) {
++		__meta_put_lists(inode);
++	}
++
++	/* mk: fan out fun */
++	if(itohi(inode))
++		iput(itohi(inode));
++	if(itohi2(inode))
++		iput(itohi2(inode));
++
++	// XXX: why this assertion fails?
++	// because it doesn't like us
++	// ASSERT((inode->i_state & I_DIRTY) == 0);
++	kfree(itopd(inode));
++	__itopd(inode) = NULL;
++}
++
++
++/*
++ * Called in do_umount() if the MNT_FORCE flag was used and this
++ * function is defined.  See comment in linux/fs/super.c:do_umount().
++ * Used only in nfs, to kill any pending RPC tasks, so that subsequent
++ * code can actually succeed and won't leave tasks that need handling.
++ *
++ * PS. I wonder if this is somehow useful to undo damage that was
++ * left in the kernel after a user level file server (such as amd)
++ * dies.
++ */
++STATIC void
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,18)
++mini_fo_umount_begin(struct vfsmount *mnt, int flags)
++{
++	struct vfsmount *hidden_mnt;
++
++	hidden_mnt = stopd(mnt->mnt_sb)->hidden_mnt;
++
++	if (hidden_mnt->mnt_sb->s_op->umount_begin)
++		hidden_mnt->mnt_sb->s_op->umount_begin(hidden_mnt, flags);
++
++}
++#else
++mini_fo_umount_begin(super_block_t *sb)
++{
++	super_block_t *hidden_sb;
++
++	hidden_sb = stohs(sb);
++
++	if (hidden_sb->s_op->umount_begin)
++		hidden_sb->s_op->umount_begin(hidden_sb);
++
++}
++#endif
++
++
++struct super_operations mini_fo_sops =
++{
++	read_inode:		mini_fo_read_inode,
++#if defined(FIST_DEBUG) || defined(FIST_FILTER_SCA)
++	write_inode:	mini_fo_write_inode,
++#endif /* defined(FIST_DEBUG) || defined(FIST_FILTER_SCA) */
++	put_inode:		mini_fo_put_inode,
++#if defined(FIST_DEBUG) || defined(FIST_FILTER_SCA)
++	delete_inode:	mini_fo_delete_inode,
++#endif /* defined(FIST_DEBUG) || defined(FIST_FILTER_SCA) */
++	put_super:		mini_fo_put_super,
++	statfs:		mini_fo_statfs,
++	remount_fs:		mini_fo_remount_fs,
++	clear_inode:	mini_fo_clear_inode,
++	umount_begin:	mini_fo_umount_begin,
++};
+--- /dev/null
++++ b/fs/mini_fo/Kconfig
+@@ -0,0 +1,3 @@
++config MINI_FO
++	tristate "Mini fanout overlay filesystem"
++
diff -Nru a/target/linux/generic/patches-2.6.31/210-mini_fo_2.6.25_fixes.patch b/target/linux/generic/patches-2.6.31/210-mini_fo_2.6.25_fixes.patch
--- a/target/linux/generic/patches-2.6.31/210-mini_fo_2.6.25_fixes.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/210-mini_fo_2.6.25_fixes.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,143 @@
+--- a/fs/mini_fo/main.c
++++ b/fs/mini_fo/main.c
+@@ -79,6 +79,7 @@ mini_fo_tri_interpose(dentry_t *hidden_d
+ 	 * of the new inode's fields
+ 	 */
+ 
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,25)
+ 	/*
+ 	 * original: inode = iget(sb, hidden_inode->i_ino);
+ 	 */
+@@ -87,6 +88,13 @@ mini_fo_tri_interpose(dentry_t *hidden_d
+ 		err = -EACCES;		/* should be impossible??? */
+ 		goto out;
+ 	}
++#else
++	inode = mini_fo_iget(sb, iunique(sb, 25));
++	if (IS_ERR(inode)) {
++		err = PTR_ERR(inode);
++		goto out;
++	}
++#endif
+ 
+ 	/*
+ 	 * interpose the inode if not already interposed
+@@ -184,9 +192,9 @@ mini_fo_parse_options(super_block_t *sb,
+ 				hidden_root = ERR_PTR(err);
+ 				goto out;
+ 			}
+-			hidden_root = nd.dentry;
+-			stopd(sb)->base_dir_dentry = nd.dentry;
+-			stopd(sb)->hidden_mnt = nd.mnt;
++			hidden_root = nd_get_dentry(&nd);
++			stopd(sb)->base_dir_dentry = nd_get_dentry(&nd);
++			stopd(sb)->hidden_mnt = nd_get_mnt(&nd);
+ 
+ 		} else if(!strncmp("sto=", options, 4)) {
+ 			/* parse the storage dir */
+@@ -204,9 +212,9 @@ mini_fo_parse_options(super_block_t *sb,
+ 				hidden_root2 = ERR_PTR(err);
+ 				goto out;
+ 			}
+-			hidden_root2 = nd2.dentry;
+-			stopd(sb)->storage_dir_dentry = nd2.dentry;
+-			stopd(sb)->hidden_mnt2 = nd2.mnt;
++			hidden_root2 = nd_get_dentry(&nd2);
++			stopd(sb)->storage_dir_dentry = nd_get_dentry(&nd2);
++			stopd(sb)->hidden_mnt2 = nd_get_mnt(&nd2);
+ 			stohs2(sb) = hidden_root2->d_sb;
+ 
+ 			/* validate storage dir, this is done in
+--- a/fs/mini_fo/mini_fo.h
++++ b/fs/mini_fo/mini_fo.h
+@@ -302,6 +302,10 @@ extern int mini_fo_tri_interpose(dentry_
+ extern int mini_fo_cp_cont(dentry_t *tgt_dentry, struct vfsmount *tgt_mnt,
+ 			   dentry_t *src_dentry, struct vfsmount *src_mnt);
+ 
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,25)
++extern struct inode *mini_fo_iget(struct super_block *sb, unsigned long ino);
++#endif
++
+ #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+ extern int mini_fo_create(inode_t *dir, dentry_t *dentry, int mode, struct nameidata *nd);
+ 
+@@ -501,6 +505,29 @@ static inline void double_unlock(struct
+ #endif  /* if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0) */
+ #endif /* __KERNEL__ */
+ 
++
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,25)
++static inline dentry_t *nd_get_dentry(struct nameidata *nd)
++{
++	return (nd->path.dentry);
++}
++
++static inline struct vfsmount *nd_get_mnt(struct nameidata *nd)
++{
++	return (nd->path.mnt);
++}
++#else
++static inline dentry_t *nd_get_dentry(struct nameidata *nd)
++{
++	return (nd->dentry);
++}
++
++static inline struct vfsmount *nd_get_mnt(struct nameidata *nd)
++{
++	return (nd->mnt);
++}
++#endif
++
+ /*
+  * Definitions for user and kernel code
+  */
+--- a/fs/mini_fo/super.c
++++ b/fs/mini_fo/super.c
+@@ -262,10 +262,31 @@ mini_fo_umount_begin(super_block_t *sb)
+ }
+ #endif
+ 
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,25)
++struct inode *
++mini_fo_iget(struct super_block *sb, unsigned long ino)
++{
++	struct inode *inode;
++
++	inode = iget_locked(sb, ino);
++	if (!inode)
++		return ERR_PTR(-ENOMEM);
++
++	if (!(inode->i_state & I_NEW))
++		return inode;
++
++	mini_fo_read_inode(inode);
++
++	unlock_new_inode(inode);
++	return inode;
++}
++#endif /* if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,25) */
+ 
+ struct super_operations mini_fo_sops =
+ {
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,25)
+ 	read_inode:		mini_fo_read_inode,
++#endif
+ #if defined(FIST_DEBUG) || defined(FIST_FILTER_SCA)
+ 	write_inode:	mini_fo_write_inode,
+ #endif /* defined(FIST_DEBUG) || defined(FIST_FILTER_SCA) */
+--- a/fs/mini_fo/aux.c
++++ b/fs/mini_fo/aux.c
+@@ -164,11 +164,11 @@ dentry_t *bpath_walk(super_block_t *sb,
+ 	err = vfs_path_lookup(mnt->mnt_root, mnt, bpath+1, 0, &nd);
+ 
+ 	/* validate */
+-	if (err || !nd.dentry || !nd.dentry->d_inode) {
++	if (err || !nd_get_dentry(&nd) || !nd_get_dentry(&nd)->d_inode) {
+ 		printk(KERN_CRIT "mini_fo: bpath_walk: path_walk failed.\n");
+ 		return NULL;
+ 	}
+-	return nd.dentry;
++	return nd_get_dentry(&nd);
+ }
+ 
+ 
diff -Nru a/target/linux/generic/patches-2.6.31/211-mini_fo_2.6.25_dentry_open_war.patch b/target/linux/generic/patches-2.6.31/211-mini_fo_2.6.25_dentry_open_war.patch
--- a/target/linux/generic/patches-2.6.31/211-mini_fo_2.6.25_dentry_open_war.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/211-mini_fo_2.6.25_dentry_open_war.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,66 @@
+--- a/fs/mini_fo/meta.c
++++ b/fs/mini_fo/meta.c
+@@ -442,6 +442,11 @@ int meta_write_d_entry(dentry_t *dentry,
+ 			   S_IRUSR | S_IWUSR);
+ #endif
+ 	}
++
++	/* $%& err, is this correct? */
++	meta_mnt = stopd(dentry->d_inode->i_sb)->hidden_mnt2;
++	mntget(meta_mnt);
++
+         /* open META-file for writing */
+         meta_file = dentry_open(meta_dentry, meta_mnt, 0x1);
+         if(!meta_file || IS_ERR(meta_file)) {
+@@ -535,6 +540,11 @@ int meta_write_r_entry(dentry_t *dentry,
+ 			   meta_dentry, S_IRUSR | S_IWUSR);
+ #endif
+ 	}
++
++	/* $%& err, is this correct? */
++	meta_mnt = stopd(dentry->d_inode->i_sb)->hidden_mnt2;
++	mntget(meta_mnt);
++
+         /* open META-file for writing */
+         meta_file = dentry_open(meta_dentry, meta_mnt, 0x1);
+         if(!meta_file || IS_ERR(meta_file)) {
+@@ -671,14 +681,16 @@ int meta_sync_d_list(dentry_t *dentry, i
+ 		}
+ 	}
+ 
++	/* $%& err, is this correct? */
++	meta_mnt = stopd(dentry->d_inode->i_sb)->hidden_mnt2;
++	mntget(meta_mnt);
++
+         /* open META-file for writing */
+         meta_file = dentry_open(meta_dentry, meta_mnt, 0x1);
+         if(!meta_file || IS_ERR(meta_file)) {
+                 printk(KERN_CRIT "mini_fo: meta_sync_d_list: \
+                                   ERROR opening meta file.\n");
+-		/* we don't mntget so we dont't mntput (for now)
+-		 * mntput(meta_mnt);
+-		 */
++		mntput(meta_mnt);
+ 		dput(meta_dentry);
+ 		err = -1;
+                 goto out;
+@@ -811,14 +823,16 @@ int meta_sync_r_list(dentry_t *dentry, i
+ 		}
+ 	}
+ 
++	/* $%& err, is this correct? */
++	meta_mnt = stopd(dentry->d_inode->i_sb)->hidden_mnt2;
++	mntget(meta_mnt);
++
+         /* open META-file for writing */
+         meta_file = dentry_open(meta_dentry, meta_mnt, 0x1);
+         if(!meta_file || IS_ERR(meta_file)) {
+                 printk(KERN_CRIT "mini_fo: meta_sync_r_list: \
+                                   ERROR opening meta file.\n");
+-		/* we don't mntget so we dont't mntput (for now)
+-		 * mntput(meta_mnt);
+-		 */
++		mntput(meta_mnt);
+ 		dput(meta_dentry);
+ 		err = -1;
+                 goto out;
diff -Nru a/target/linux/generic/patches-2.6.31/212-mini_fo_2.6.26_fixes.patch b/target/linux/generic/patches-2.6.31/212-mini_fo_2.6.26_fixes.patch
--- a/target/linux/generic/patches-2.6.31/212-mini_fo_2.6.26_fixes.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/212-mini_fo_2.6.26_fixes.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,37 @@
+--- a/fs/mini_fo/super.c
++++ b/fs/mini_fo/super.c
+@@ -84,6 +84,7 @@ mini_fo_write_inode(inode_t *inode, int
+ #endif /* defined(FIST_DEBUG) || defined(FIST_FILTER_SCA) */
+ 
+ 
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26)
+ STATIC void
+ mini_fo_put_inode(inode_t *inode)
+ {
+@@ -99,6 +100,7 @@ mini_fo_put_inode(inode_t *inode)
+ 	if (atomic_read(&inode->i_count) == 1)
+ 		inode->i_nlink = 0;
+ }
++#endif /* LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26) */
+ 
+ 
+ #if defined(FIST_DEBUG) || defined(FIST_FILTER_SCA)
+@@ -238,7 +240,7 @@ mini_fo_clear_inode(inode_t *inode)
+  * dies.
+  */
+ STATIC void
+-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,18)
++#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,18)) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26))
+ mini_fo_umount_begin(struct vfsmount *mnt, int flags)
+ {
+ 	struct vfsmount *hidden_mnt;
+@@ -290,7 +292,9 @@ struct super_operations mini_fo_sops =
+ #if defined(FIST_DEBUG) || defined(FIST_FILTER_SCA)
+ 	write_inode:	mini_fo_write_inode,
+ #endif /* defined(FIST_DEBUG) || defined(FIST_FILTER_SCA) */
++#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26)
+ 	put_inode:		mini_fo_put_inode,
++#endif /* LINUX_VERSION_CODE < KERNEL_VERSION(2,6,26) */
+ #if defined(FIST_DEBUG) || defined(FIST_FILTER_SCA)
+ 	delete_inode:	mini_fo_delete_inode,
+ #endif /* defined(FIST_DEBUG) || defined(FIST_FILTER_SCA) */
diff -Nru a/target/linux/generic/patches-2.6.31/213-mini_fo_2.6.27_fixes.patch b/target/linux/generic/patches-2.6.31/213-mini_fo_2.6.27_fixes.patch
--- a/target/linux/generic/patches-2.6.31/213-mini_fo_2.6.27_fixes.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/213-mini_fo_2.6.27_fixes.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,41 @@
+--- a/fs/mini_fo/inode.c
++++ b/fs/mini_fo/inode.c
+@@ -439,7 +439,7 @@ mini_fo_symlink(inode_t *dir, dentry_t *
+ 	int err=0;
+ 	dentry_t *hidden_sto_dentry;
+ 	dentry_t *hidden_sto_dir_dentry;
+-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,27))
+         umode_t mode;
+ #endif
+ 
+@@ -466,7 +466,7 @@ mini_fo_symlink(inode_t *dir, dentry_t *
+ 	down(&hidden_sto_dir_dentry->d_inode->i_sem);
+ #endif
+ 
+-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,27))
+ 	mode = S_IALLUGO;
+ 	err = vfs_symlink(hidden_sto_dir_dentry->d_inode,
+ 			  hidden_sto_dentry, symname, mode);
+@@ -1128,7 +1128,7 @@ void mini_fo_put_link(struct dentry *den
+ #endif
+ 
+ STATIC int
+-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)) && (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,27))
+ mini_fo_permission(inode_t *inode, int mask, struct nameidata *nd)
+ #else
+ mini_fo_permission(inode_t *inode, int mask)
+@@ -1150,8 +1150,9 @@ mini_fo_permission(inode_t *inode, int m
+ 	 *	if (err)
+ 	 *		goto out;
+ 	 */
+-
+-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
++#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,27)
++	err = inode_permission(hidden_inode, mask);
++#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+ 	err = permission(hidden_inode, mask, nd);
+ #else
+ 	err = permission(hidden_inode, mask);
diff -Nru a/target/linux/generic/patches-2.6.31/214-mini_fo_2.6.29.patch b/target/linux/generic/patches-2.6.31/214-mini_fo_2.6.29.patch
--- a/target/linux/generic/patches-2.6.31/214-mini_fo_2.6.29.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/214-mini_fo_2.6.29.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,96 @@
+--- a/fs/mini_fo/aux.c
++++ b/fs/mini_fo/aux.c
+@@ -236,7 +236,7 @@ int mini_fo_cp_cont(dentry_t *tgt_dentry
+ 	mntget(src_mnt);
+ 
+ 	/* open file write only */
+-	tgt_file = dentry_open(tgt_dentry, tgt_mnt, 0x1);
++	tgt_file = dentry_open(tgt_dentry, tgt_mnt, 0x1, current_cred());
+ 	if(!tgt_file || IS_ERR(tgt_file)) {
+ 		printk(KERN_CRIT "mini_fo_cp_cont: ERROR opening target file.\n");
+ 		err = PTR_ERR(tgt_file);
+@@ -244,7 +244,7 @@ int mini_fo_cp_cont(dentry_t *tgt_dentry
+ 	}
+ 
+ 	/* open file read only */
+-	src_file = dentry_open(src_dentry, src_mnt, 0x0);
++	src_file = dentry_open(src_dentry, src_mnt, 0x0, current_cred());
+ 	if(!src_file || IS_ERR(src_file)) {
+ 		printk(KERN_CRIT "mini_fo_cp_cont: ERROR opening source file.\n");
+ 		err = PTR_ERR(src_file);
+--- a/fs/mini_fo/file.c
++++ b/fs/mini_fo/file.c
+@@ -437,7 +437,7 @@ mini_fo_open(inode_t *inode, file_t *fil
+ 			mntget(stopd(inode->i_sb)->hidden_mnt);
+ 			hidden_file = dentry_open(hidden_dentry,
+ 						  stopd(inode->i_sb)->hidden_mnt,
+-						  hidden_flags);
++						  hidden_flags, file->f_cred);
+ 			if (IS_ERR(hidden_file)) {
+ 				err = PTR_ERR(hidden_file);
+ 				dput(hidden_dentry);
+@@ -479,7 +479,7 @@ mini_fo_open(inode_t *inode, file_t *fil
+ 			mntget(stopd(inode->i_sb)->hidden_mnt);
+ 			hidden_file = dentry_open(hidden_dentry,
+ 						  stopd(inode->i_sb)->hidden_mnt,
+-						  hidden_flags);
++						  hidden_flags, file->f_cred);
+ 			if (IS_ERR(hidden_file)) {
+ 				err = PTR_ERR(hidden_file);
+ 				dput(hidden_dentry);
+@@ -512,7 +512,7 @@ mini_fo_open(inode_t *inode, file_t *fil
+ 	mntget(stopd(inode->i_sb)->hidden_mnt2);
+ 	hidden_sto_file = dentry_open(hidden_sto_dentry,
+ 				      stopd(inode->i_sb)->hidden_mnt2,
+-				      hidden_flags);
++				      hidden_flags, file->f_cred);
+ 
+ 	/* dentry_open dputs the dentry if it fails */
+ 	if (IS_ERR(hidden_sto_file)) {
+--- a/fs/mini_fo/meta.c
++++ b/fs/mini_fo/meta.c
+@@ -56,7 +56,7 @@ int meta_build_lists(dentry_t *dentry)
+ 
+ 
+ 		/* open META-file for reading */
+-		meta_file = dentry_open(meta_dentry, meta_mnt, 0x0);
++		meta_file = dentry_open(meta_dentry, meta_mnt, 0x0, current_cred());
+ 		if(!meta_file || IS_ERR(meta_file)) {
+ 			printk(KERN_CRIT "mini_fo: meta_build_lists: \
+                                           ERROR opening META file.\n");
+@@ -448,7 +448,7 @@ int meta_write_d_entry(dentry_t *dentry,
+ 	mntget(meta_mnt);
+ 
+         /* open META-file for writing */
+-        meta_file = dentry_open(meta_dentry, meta_mnt, 0x1);
++        meta_file = dentry_open(meta_dentry, meta_mnt, 0x1, current_cred());
+         if(!meta_file || IS_ERR(meta_file)) {
+                 printk(KERN_CRIT "mini_fo: meta_write_d_entry: \
+                                   ERROR opening meta file.\n");
+@@ -546,7 +546,7 @@ int meta_write_r_entry(dentry_t *dentry,
+ 	mntget(meta_mnt);
+ 
+         /* open META-file for writing */
+-        meta_file = dentry_open(meta_dentry, meta_mnt, 0x1);
++        meta_file = dentry_open(meta_dentry, meta_mnt, 0x1, current_cred());
+         if(!meta_file || IS_ERR(meta_file)) {
+                 printk(KERN_CRIT "mini_fo: meta_write_r_entry: \
+                                   ERROR opening meta file.\n");
+@@ -686,7 +686,7 @@ int meta_sync_d_list(dentry_t *dentry, i
+ 	mntget(meta_mnt);
+ 
+         /* open META-file for writing */
+-        meta_file = dentry_open(meta_dentry, meta_mnt, 0x1);
++        meta_file = dentry_open(meta_dentry, meta_mnt, 0x1, current_cred());
+         if(!meta_file || IS_ERR(meta_file)) {
+                 printk(KERN_CRIT "mini_fo: meta_sync_d_list: \
+                                   ERROR opening meta file.\n");
+@@ -828,7 +828,7 @@ int meta_sync_r_list(dentry_t *dentry, i
+ 	mntget(meta_mnt);
+ 
+         /* open META-file for writing */
+-        meta_file = dentry_open(meta_dentry, meta_mnt, 0x1);
++        meta_file = dentry_open(meta_dentry, meta_mnt, 0x1, current_cred());
+         if(!meta_file || IS_ERR(meta_file)) {
+                 printk(KERN_CRIT "mini_fo: meta_sync_r_list: \
+                                   ERROR opening meta file.\n");
diff -Nru a/target/linux/generic/patches-2.6.31/215-mini_fo_2.6.30.patch b/target/linux/generic/patches-2.6.31/215-mini_fo_2.6.30.patch
--- a/target/linux/generic/patches-2.6.31/215-mini_fo_2.6.30.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/215-mini_fo_2.6.30.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,157 @@
+--- a/fs/mini_fo/aux.c
++++ b/fs/mini_fo/aux.c
+@@ -86,8 +86,10 @@ int get_neg_sto_dentry(dentry_t *dentry)
+ 	len = dentry->d_name.len;
+ 	name = dentry->d_name.name;
+ 
++	mutex_lock(&dtohd2(dentry->d_parent)->d_inode->i_mutex);
+ 	dtohd2(dentry) =
+ 		lookup_one_len(name, dtohd2(dentry->d_parent), len);
++	mutex_unlock(&dtohd2(dentry->d_parent)->d_inode->i_mutex);
+ 
+  out:
+ 	return err;
+@@ -426,7 +428,9 @@ int build_sto_structure(dentry_t *dir, d
+ 		const unsigned char *name;
+ 		len = dtohd(dentry)->d_name.len;
+ 		name = dtohd(dentry)->d_name.name;
++		mutex_lock(&dtohd2(dir)->d_inode->i_mutex);
+ 		hidden_sto_dentry = lookup_one_len(name, dtohd2(dir), len);
++		mutex_unlock(&dtohd2(dir)->d_inode->i_mutex);
+ 		dtohd2(dentry) = hidden_sto_dentry;
+ 	}
+ 
+--- a/fs/mini_fo/inode.c
++++ b/fs/mini_fo/inode.c
+@@ -113,17 +113,23 @@ mini_fo_lookup(inode_t *dir, dentry_t *d
+ 		hidden_dir_dentry = hidden_dentry->d_parent;
+ 		kfree(bpath);
+ 	}
+-	else if(hidden_dir_dentry && hidden_dir_dentry->d_inode)
++	else if(hidden_dir_dentry && hidden_dir_dentry->d_inode) {
++		mutex_lock(&hidden_dir_dentry->d_inode->i_mutex);
+ 		hidden_dentry =
+ 			lookup_one_len(name, hidden_dir_dentry, namelen);
+-	else
++		mutex_unlock(&hidden_dir_dentry->d_inode->i_mutex);
++	} else {
+ 		hidden_dentry = NULL;
++	}
+ 
+-	if(hidden_sto_dir_dentry && hidden_sto_dir_dentry->d_inode)
++	if(hidden_sto_dir_dentry && hidden_sto_dir_dentry->d_inode) {
++		mutex_lock(&hidden_sto_dir_dentry->d_inode->i_mutex);
+ 		hidden_sto_dentry =
+ 			lookup_one_len(name, hidden_sto_dir_dentry, namelen);
+-	else
++		mutex_unlock(&hidden_sto_dir_dentry->d_inode->i_mutex);
++	} else {
+ 		hidden_sto_dentry =  NULL;
++	}
+ 
+ 	/* catch error in lookup */
+ 	if (IS_ERR(hidden_dentry) || IS_ERR(hidden_sto_dentry)) {
+@@ -553,9 +559,11 @@ mini_fo_rmdir(inode_t *dir, dentry_t *de
+ #endif
+ 
+ 		/* Delete an old WOL file contained in the storage dir */
++		mutex_lock(&hidden_sto_dentry->d_inode->i_mutex);
+ 		meta_dentry = lookup_one_len(META_FILENAME,
+ 					     hidden_sto_dentry,
+ 					     strlen(META_FILENAME));
++		mutex_unlock(&hidden_sto_dentry->d_inode->i_mutex);
+ 		if(meta_dentry->d_inode) {
+ 			err = vfs_unlink(hidden_sto_dentry->d_inode, meta_dentry);
+ 			dput(meta_dentry);
+@@ -643,9 +651,11 @@ mini_fo_rmdir(inode_t *dir, dentry_t *de
+ #endif
+ 
+ 		/* Delete an old WOL file contained in the storage dir */
++		mutex_lock(&hidden_sto_dentry->d_inode->i_mutex);
+ 		meta_dentry = lookup_one_len(META_FILENAME,
+ 					     hidden_sto_dentry,
+ 					     strlen(META_FILENAME));
++		mutex_unlock(&hidden_sto_dentry->d_inode->i_mutex);
+ 		if(meta_dentry->d_inode) {
+ 			/* is this necessary? dget(meta_dentry); */
+ 			err = vfs_unlink(hidden_sto_dentry->d_inode,
+@@ -688,9 +698,11 @@ mini_fo_rmdir(inode_t *dir, dentry_t *de
+ #endif
+ 
+ 		/* Delete an old WOL file contained in the storage dir */
++		mutex_lock(&hidden_sto_dentry->d_inode->i_mutex);
+ 		meta_dentry = lookup_one_len(META_FILENAME,
+ 					     hidden_sto_dentry,
+ 					     strlen(META_FILENAME));
++		mutex_unlock(&hidden_sto_dentry->d_inode->i_mutex);
+ 		if(meta_dentry->d_inode) {
+ 			/* is this necessary? dget(meta_dentry); */
+ 			err = vfs_unlink(hidden_sto_dentry->d_inode,
+--- a/fs/mini_fo/meta.c
++++ b/fs/mini_fo/meta.c
+@@ -43,9 +43,11 @@ int meta_build_lists(dentry_t *dentry)
+ 
+   	/* might there be a META-file? */
+ 	if(dtohd2(dentry) && dtohd2(dentry)->d_inode) {
++		mutex_lock(&dtohd2(dentry)->d_inode->i_mutex);
+ 		meta_dentry = lookup_one_len(META_FILENAME,
+ 					     dtohd2(dentry),
+ 					     strlen(META_FILENAME));
++		mutex_unlock(&dtohd2(dentry)->d_inode->i_mutex);
+ 		if(!meta_dentry->d_inode) {
+ 			dput(meta_dentry);
+ 			goto out_ok;
+@@ -426,8 +428,11 @@ int meta_write_d_entry(dentry_t *dentry,
+ 			goto out;
+                 }
+         }
++
++	mutex_lock(&dtohd2(dentry)->d_inode->i_mutex);
+ 	meta_dentry = lookup_one_len(META_FILENAME,
+ 				     dtohd2(dentry), strlen (META_FILENAME));
++	mutex_unlock(&dtohd2(dentry)->d_inode->i_mutex);
+ 
+ 	/* We need to create a META-file */
+         if(!meta_dentry->d_inode) {
+@@ -527,9 +532,13 @@ int meta_write_r_entry(dentry_t *dentry,
+ 			goto out;
+                 }
+         }
++
++	mutex_lock(&dtohd2(dentry)->d_inode->i_mutex);
+ 	meta_dentry = lookup_one_len(META_FILENAME,
+ 				     dtohd2(dentry),
+ 				     strlen (META_FILENAME));
++	mutex_unlock(&dtohd2(dentry)->d_inode->i_mutex);
++
+         if(!meta_dentry->d_inode) {
+                 /* We need to create a META-file */
+ #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+@@ -641,9 +650,13 @@ int meta_sync_d_list(dentry_t *dentry, i
+ 			goto out;
+                 }
+         }
++
++	mutex_lock(&dtohd2(dentry)->d_inode->i_mutex);
+ 	meta_dentry = lookup_one_len(META_FILENAME,
+ 				     dtohd2(dentry),
+ 				     strlen(META_FILENAME));
++	mutex_unlock(&dtohd2(dentry)->d_inode->i_mutex);
++
+         if(!meta_dentry->d_inode) {
+                 /* We need to create a META-file */
+ #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+@@ -784,9 +797,13 @@ int meta_sync_r_list(dentry_t *dentry, i
+ 			goto out;
+                 }
+         }
++
++	mutex_lock(&dtohd2(dentry)->d_inode->i_mutex);
+ 	meta_dentry = lookup_one_len(META_FILENAME,
+ 				     dtohd2(dentry),
+ 				     strlen(META_FILENAME));
++	mutex_unlock(&dtohd2(dentry)->d_inode->i_mutex);
++
+         if(!meta_dentry->d_inode) {
+                 /* We need to create a META-file */
+ #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
diff -Nru a/target/linux/generic/patches-2.6.31/216-mini_fo_locking.patch b/target/linux/generic/patches-2.6.31/216-mini_fo_locking.patch
--- a/target/linux/generic/patches-2.6.31/216-mini_fo_locking.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/216-mini_fo_locking.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,25 @@
+--- a/fs/mini_fo/state.c
++++ b/fs/mini_fo/state.c
+@@ -537,17 +537,17 @@ int nondir_mod_to_del(dentry_t *dentry)
+ 	dtohd(dentry) = NULL;
+ 	dtost(dentry) = DELETED;
+ 
+-	/* add deleted file to META-file */
+-	meta_add_d_entry(dentry->d_parent,
+-			 dentry->d_name.name,
+-			 dentry->d_name.len);
+-
+ 	/* was: unlock_dir(hidden_sto_dir_dentry); */
+ #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
+ 	mutex_unlock(&hidden_sto_dir_dentry->d_inode->i_mutex);
+ #else
+ 	up(&hidden_sto_dir_dentry->d_inode->i_sem);
+ #endif
++	/* add deleted file to META-file */
++	meta_add_d_entry(dentry->d_parent,
++			 dentry->d_name.name,
++			 dentry->d_name.len);
++
+ 	dput(hidden_sto_dir_dentry);
+ 
+  out:
diff -Nru a/target/linux/generic/patches-2.6.31/219-kobject_uevent.patch b/target/linux/generic/patches-2.6.31/219-kobject_uevent.patch
--- a/target/linux/generic/patches-2.6.31/219-kobject_uevent.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/219-kobject_uevent.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,42 @@
+--- a/lib/kobject_uevent.c
++++ b/lib/kobject_uevent.c
+@@ -29,7 +29,8 @@ u64 uevent_seqnum;
+ char uevent_helper[UEVENT_HELPER_PATH_LEN] = CONFIG_UEVENT_HELPER_PATH;
+ static DEFINE_SPINLOCK(sequence_lock);
+ #if defined(CONFIG_NET)
+-static struct sock *uevent_sock;
++struct sock *uevent_sock = NULL;
++EXPORT_SYMBOL_GPL(uevent_sock);
+ #endif
+ 
+ /* the strings here must match the enum in include/linux/kobject.h */
+@@ -42,6 +43,18 @@ static const char *kobject_actions[] = {
+ 	[KOBJ_OFFLINE] =	"offline",
+ };
+ 
++u64 uevent_next_seqnum(void)
++{
++	u64 seq;
++
++	spin_lock(&sequence_lock);
++	seq = ++uevent_seqnum;
++	spin_unlock(&sequence_lock);
++
++	return seq;
++}
++EXPORT_SYMBOL_GPL(uevent_next_seqnum);
++
+ /**
+  * kobject_action_type - translate action string to numeric type
+  *
+@@ -201,9 +214,7 @@ int kobject_uevent_env(struct kobject *k
+ 		kobj->state_remove_uevent_sent = 1;
+ 
+ 	/* we will send an event, so request a new sequence number */
+-	spin_lock(&sequence_lock);
+-	seq = ++uevent_seqnum;
+-	spin_unlock(&sequence_lock);
++	seq = uevent_next_seqnum();
+ 	retval = add_uevent_var(env, "SEQNUM=%llu", (unsigned long long)seq);
+ 	if (retval)
+ 		goto exit;
diff -Nru a/target/linux/generic/patches-2.6.31/220-sound_kconfig.patch b/target/linux/generic/patches-2.6.31/220-sound_kconfig.patch
--- a/target/linux/generic/patches-2.6.31/220-sound_kconfig.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/220-sound_kconfig.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,11 @@
+--- a/sound/core/Kconfig
++++ b/sound/core/Kconfig
+@@ -7,7 +7,7 @@ config SND_PCM
+ 	select SND_TIMER
+ 
+ config SND_HWDEP
+-	tristate
++	tristate "Sound hardware support"
+ 
+ config SND_RAWMIDI
+ 	tristate
diff -Nru a/target/linux/generic/patches-2.6.31/222-partial_eraseblock_write.patch b/target/linux/generic/patches-2.6.31/222-partial_eraseblock_write.patch
--- a/target/linux/generic/patches-2.6.31/222-partial_eraseblock_write.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/222-partial_eraseblock_write.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,146 @@
+--- a/drivers/mtd/mtdpart.c
++++ b/drivers/mtd/mtdpart.c
+@@ -21,6 +21,8 @@
+ #include <linux/root_dev.h>
+ #include <linux/magic.h>
+ 
++#define MTD_ERASE_PARTIAL	0x8000 /* partition only covers parts of an erase block */
++
+ /* Our partition linked list */
+ static LIST_HEAD(mtd_partitions);
+ 
+@@ -226,13 +228,60 @@ static int part_erase(struct mtd_info *m
+ 		return -EROFS;
+ 	if (instr->addr >= mtd->size)
+ 		return -EINVAL;
++
++	instr->partial_start = false;
++	if (mtd->flags & MTD_ERASE_PARTIAL) {
++		size_t readlen = 0;
++		u64 mtd_ofs;
++
++		instr->erase_buf = kmalloc(part->master->erasesize, GFP_ATOMIC);
++		if (!instr->erase_buf)
++			return -ENOMEM;
++
++		mtd_ofs = part->offset + instr->addr;
++		instr->erase_buf_ofs = do_div(mtd_ofs, part->master->erasesize);
++
++		if (instr->erase_buf_ofs > 0) {
++			instr->addr -= instr->erase_buf_ofs;
++			ret = part->master->read(part->master,
++				instr->addr + part->offset,
++				part->master->erasesize,
++				&readlen, instr->erase_buf);
++
++			instr->partial_start = true;
++		} else {
++			mtd_ofs = part->offset + part->mtd.size;
++			instr->erase_buf_ofs = part->master->erasesize -
++				do_div(mtd_ofs, part->master->erasesize);
++
++			if (instr->erase_buf_ofs > 0) {
++				instr->len += instr->erase_buf_ofs;
++				ret = part->master->read(part->master,
++					part->offset + instr->addr +
++					instr->len - part->master->erasesize,
++					part->master->erasesize, &readlen,
++					instr->erase_buf);
++			} else {
++				ret = 0;
++			}
++		}
++		if (ret < 0) {
++			kfree(instr->erase_buf);
++			return ret;
++		}
++
++	}
++
+ 	instr->addr += part->offset;
+ 	ret = part->master->erase(part->master, instr);
+ 	if (ret) {
+ 		if (instr->fail_addr != MTD_FAIL_ADDR_UNKNOWN)
+ 			instr->fail_addr -= part->offset;
+ 		instr->addr -= part->offset;
++		if (mtd->flags & MTD_ERASE_PARTIAL)
++			kfree(instr->erase_buf);
+ 	}
++
+ 	return ret;
+ }
+ 
+@@ -240,7 +289,25 @@ void mtd_erase_callback(struct erase_inf
+ {
+ 	if (instr->mtd->erase == part_erase) {
+ 		struct mtd_part *part = PART(instr->mtd);
++		size_t wrlen = 0;
+ 
++		if (instr->mtd->flags & MTD_ERASE_PARTIAL) {
++			if (instr->partial_start) {
++				part->master->write(part->master,
++					instr->addr, instr->erase_buf_ofs,
++					&wrlen, instr->erase_buf);
++				instr->addr += instr->erase_buf_ofs;
++			} else {
++				instr->len -= instr->erase_buf_ofs;
++				part->master->write(part->master,
++					instr->addr + instr->len,
++					instr->erase_buf_ofs, &wrlen,
++					instr->erase_buf +
++					part->master->erasesize -
++					instr->erase_buf_ofs);
++			}
++			kfree(instr->erase_buf);
++		}
+ 		if (instr->fail_addr != MTD_FAIL_ADDR_UNKNOWN)
+ 			instr->fail_addr -= part->offset;
+ 		instr->addr -= part->offset;
+@@ -472,18 +539,24 @@ static struct mtd_part *add_one_partitio
+ 	if ((slave->mtd.flags & MTD_WRITEABLE) &&
+ 	    mtd_mod_by_eb(slave->offset, &slave->mtd)) {
+ 		/* Doesn't start on a boundary of major erase size */
+-		/* FIXME: Let it be writable if it is on a boundary of
+-		 * _minor_ erase size though */
+-		slave->mtd.flags &= ~MTD_WRITEABLE;
+-		printk(KERN_WARNING"mtd: partition \"%s\" doesn't start on an erase block boundary -- force read-only\n",
+-			part->name);
++		slave->mtd.flags |= MTD_ERASE_PARTIAL;
++		if (((u32) slave->mtd.size) > master->erasesize)
++			slave->mtd.flags &= ~MTD_WRITEABLE;
++		else
++			slave->mtd.erasesize = slave->mtd.size;
+ 	}
+ 	if ((slave->mtd.flags & MTD_WRITEABLE) &&
+-	    mtd_mod_by_eb(slave->mtd.size, &slave->mtd)) {
+-		slave->mtd.flags &= ~MTD_WRITEABLE;
+-		printk(KERN_WARNING"mtd: partition \"%s\" doesn't end on an erase block -- force read-only\n",
+-			part->name);
+-	}
++	    mtd_mod_by_eb(slave->offset + slave->mtd.size, &slave->mtd)) {
++		slave->mtd.flags |= MTD_ERASE_PARTIAL;
++
++		if ((u32) slave->mtd.size > master->erasesize)
++			slave->mtd.flags &= ~MTD_WRITEABLE;
++		else
++			slave->mtd.erasesize = slave->mtd.size;
++	}
++	if ((slave->mtd.flags & (MTD_ERASE_PARTIAL|MTD_WRITEABLE)) == MTD_ERASE_PARTIAL)
++		printk(KERN_WARNING"mtd: partition \"%s\" must either start or end on erase block boundary or be smaller than an erase block -- forcing read-only\n",
++				part->name);
+ 
+ 	slave->mtd.ecclayout = master->ecclayout;
+ 	if (master->block_isbad) {
+--- a/include/linux/mtd/mtd.h
++++ b/include/linux/mtd/mtd.h
+@@ -46,6 +46,10 @@ struct erase_info {
+ 	u_long priv;
+ 	u_char state;
+ 	struct erase_info *next;
++
++	u8 *erase_buf;
++	u32 erase_buf_ofs;
++	bool partial_start;
+ };
+ 
+ struct mtd_erase_region_info {
diff -Nru a/target/linux/generic/patches-2.6.31/240-packet_socket_type.patch b/target/linux/generic/patches-2.6.31/240-packet_socket_type.patch
--- a/target/linux/generic/patches-2.6.31/240-packet_socket_type.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/240-packet_socket_type.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,132 @@
+This patch allows the user to specify desired packet types (outgoing,
+broadcast, unicast, etc.) on packet sockets via setsockopt.
+This can reduce the load in situations where only a limited number
+of packet types are necessary
+
+Signed-off-by: Felix Fietkau <nbd@openwrt.org>
+
+--- a/include/linux/if_packet.h
++++ b/include/linux/if_packet.h
+@@ -31,6 +31,8 @@ struct sockaddr_ll
+ /* These ones are invisible by user level */
+ #define PACKET_LOOPBACK		5		/* MC/BRD frame looped back */
+ #define PACKET_FASTROUTE	6		/* Fastrouted frame	*/
++#define PACKET_MASK_ANY		0xffffffff	/* mask for packet type bits */
++
+ 
+ /* Packet socket options */
+ 
+@@ -48,6 +50,7 @@ struct sockaddr_ll
+ #define PACKET_RESERVE			12
+ #define PACKET_TX_RING			13
+ #define PACKET_LOSS			14
++#define PACKET_RECV_TYPE		15
+ 
+ struct tpacket_stats
+ {
+--- a/net/packet/af_packet.c
++++ b/net/packet/af_packet.c
+@@ -206,6 +206,7 @@ struct packet_sock {
+ 	unsigned int		tp_reserve;
+ 	unsigned int		tp_loss:1;
+ #endif
++	unsigned int		pkt_type;
+ };
+ 
+ struct packet_skb_cb {
+@@ -343,6 +344,7 @@ static int packet_rcv_spkt(struct sk_buf
+ {
+ 	struct sock *sk;
+ 	struct sockaddr_pkt *spkt;
++	struct packet_sock *po;
+ 
+ 	/*
+ 	 *	When we registered the protocol we saved the socket in the data
+@@ -350,6 +352,7 @@ static int packet_rcv_spkt(struct sk_buf
+ 	 */
+ 
+ 	sk = pt->af_packet_priv;
++	po = pkt_sk(sk);
+ 
+ 	/*
+ 	 *	Yank back the headers [hope the device set this
+@@ -362,7 +365,7 @@ static int packet_rcv_spkt(struct sk_buf
+ 	 *	so that this procedure is noop.
+ 	 */
+ 
+-	if (skb->pkt_type == PACKET_LOOPBACK)
++	if (!(po->pkt_type & (1 << skb->pkt_type)))
+ 		goto out;
+ 
+ 	if (dev_net(dev) != sock_net(sk))
+@@ -546,12 +549,12 @@ static int packet_rcv(struct sk_buff *sk
+ 	int skb_len = skb->len;
+ 	unsigned int snaplen, res;
+ 
+-	if (skb->pkt_type == PACKET_LOOPBACK)
+-		goto drop;
+-
+ 	sk = pt->af_packet_priv;
+ 	po = pkt_sk(sk);
+ 
++	if (!(po->pkt_type & (1 << skb->pkt_type)))
++		goto drop;
++
+ 	if (dev_net(dev) != sock_net(sk))
+ 		goto drop;
+ 
+@@ -667,12 +670,12 @@ static int tpacket_rcv(struct sk_buff *s
+ 	struct timeval tv;
+ 	struct timespec ts;
+ 
+-	if (skb->pkt_type == PACKET_LOOPBACK)
+-		goto drop;
+-
+ 	sk = pt->af_packet_priv;
+ 	po = pkt_sk(sk);
+ 
++	if (!(po->pkt_type & (1 << skb->pkt_type)))
++		goto drop;
++
+ 	if (dev_net(dev) != sock_net(sk))
+ 		goto drop;
+ 
+@@ -1387,6 +1390,7 @@ static int packet_create(struct net *net
+ 	spin_lock_init(&po->bind_lock);
+ 	mutex_init(&po->pg_vec_lock);
+ 	po->prot_hook.func = packet_rcv;
++	po->pkt_type = PACKET_MASK_ANY & ~(1 << PACKET_LOOPBACK);
+ 
+ 	if (sock->type == SOCK_PACKET)
+ 		po->prot_hook.func = packet_rcv_spkt;
+@@ -1733,6 +1737,16 @@ packet_setsockopt(struct socket *sock, i
+ 			ret = packet_mc_drop(sk, &mreq);
+ 		return ret;
+ 	}
++	case PACKET_RECV_TYPE:
++	{
++		unsigned int val;
++		if (optlen != sizeof(val))
++			return -EINVAL;
++		if (copy_from_user(&val, optval, sizeof(val)))
++			return -EFAULT;
++		po->pkt_type = val & ~PACKET_LOOPBACK;
++		return 0;
++	}
+ 
+ #ifdef CONFIG_PACKET_MMAP
+ 	case PACKET_RX_RING:
+@@ -1878,6 +1892,13 @@ static int packet_getsockopt(struct sock
+ 
+ 		data = &val;
+ 		break;
++	case PACKET_RECV_TYPE:
++		if (len > sizeof(unsigned int))
++			len = sizeof(unsigned int);
++		val = po->pkt_type;
++
++		data = &val;
++		break;
+ #ifdef CONFIG_PACKET_MMAP
+ 	case PACKET_VERSION:
+ 		if (len > sizeof(int))
diff -Nru a/target/linux/generic/patches-2.6.31/250-pppoe_header_pad.patch b/target/linux/generic/patches-2.6.31/250-pppoe_header_pad.patch
--- a/target/linux/generic/patches-2.6.31/250-pppoe_header_pad.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/250-pppoe_header_pad.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,20 @@
+--- a/drivers/net/pppoe.c
++++ b/drivers/net/pppoe.c
+@@ -863,7 +863,7 @@ static int pppoe_sendmsg(struct kiocb *i
+ 		goto end;
+ 
+ 
+-	skb = sock_wmalloc(sk, total_len + dev->hard_header_len + 32,
++	skb = sock_wmalloc(sk, total_len + dev->hard_header_len + 32 + NET_SKB_PAD,
+ 			   0, GFP_KERNEL);
+ 	if (!skb) {
+ 		error = -ENOMEM;
+@@ -871,7 +871,7 @@ static int pppoe_sendmsg(struct kiocb *i
+ 	}
+ 
+ 	/* Reserve space for headers. */
+-	skb_reserve(skb, dev->hard_header_len);
++	skb_reserve(skb, dev->hard_header_len + NET_SKB_PAD);
+ 	skb_reset_network_header(skb);
+ 
+ 	skb->dev = dev;
diff -Nru a/target/linux/generic/patches-2.6.31/260-extend_pfifo_fast.patch b/target/linux/generic/patches-2.6.31/260-extend_pfifo_fast.patch
--- a/target/linux/generic/patches-2.6.31/260-extend_pfifo_fast.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/260-extend_pfifo_fast.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,144 @@
+--- a/net/sched/sch_generic.c
++++ b/net/sched/sch_generic.c
+@@ -391,16 +391,50 @@ static const u8 prio2band[TC_PRIO_MAX+1]
+ 
+ #define PFIFO_FAST_BANDS 3
+ 
++struct pfifo_fast_sched_data {
++	struct tcf_proto *filter_list;
++	struct sk_buff_head list[PFIFO_FAST_BANDS];
++};
++
+ static inline struct sk_buff_head *prio2list(struct sk_buff *skb,
+ 					     struct Qdisc *qdisc)
+ {
+-	struct sk_buff_head *list = qdisc_priv(qdisc);
++	struct pfifo_fast_sched_data *q = qdisc_priv(qdisc);
++	struct sk_buff_head *list = q->list;
+ 	return list + prio2band[skb->priority & TC_PRIO_MAX];
+ }
+ 
++static int pfifo_fast_filter(struct sk_buff *skb, struct Qdisc* qdisc)
++{
++#ifdef CONFIG_NET_CLS_ACT
++	struct pfifo_fast_sched_data *q = qdisc_priv(qdisc);
++	int result = 0, ret = NET_XMIT_SUCCESS | __NET_XMIT_STOLEN;
++	struct tcf_result res;
++
++	if (q->filter_list != NULL)
++		result = tc_classify(skb, q->filter_list, &res);
++	if (result >= 0) {
++		switch (result) {
++		case TC_ACT_STOLEN:
++		case TC_ACT_QUEUED:
++			ret = NET_XMIT_SUCCESS | __NET_XMIT_STOLEN;
++		case TC_ACT_SHOT:
++			kfree_skb(skb);
++			return ret;
++		}
++	}
++#endif
++	return 0;
++}
++
+ static int pfifo_fast_enqueue(struct sk_buff *skb, struct Qdisc* qdisc)
+ {
+ 	struct sk_buff_head *list = prio2list(skb, qdisc);
++	int ret;
++
++	ret = pfifo_fast_filter(skb, qdisc);
++	if (ret)
++		return ret;
+ 
+ 	if (skb_queue_len(list) < qdisc_dev(qdisc)->tx_queue_len) {
+ 		qdisc->q.qlen++;
+@@ -412,8 +446,9 @@ static int pfifo_fast_enqueue(struct sk_
+ 
+ static struct sk_buff *pfifo_fast_dequeue(struct Qdisc* qdisc)
+ {
++	struct pfifo_fast_sched_data *q = qdisc_priv(qdisc);
++	struct sk_buff_head *list = q->list;
+ 	int prio;
+-	struct sk_buff_head *list = qdisc_priv(qdisc);
+ 
+ 	for (prio = 0; prio < PFIFO_FAST_BANDS; prio++) {
+ 		if (!skb_queue_empty(list + prio)) {
+@@ -440,8 +475,9 @@ static struct sk_buff *pfifo_fast_peek(s
+ 
+ static void pfifo_fast_reset(struct Qdisc* qdisc)
+ {
++	struct pfifo_fast_sched_data *q = qdisc_priv(qdisc);
++	struct sk_buff_head *list = q->list;
+ 	int prio;
+-	struct sk_buff_head *list = qdisc_priv(qdisc);
+ 
+ 	for (prio = 0; prio < PFIFO_FAST_BANDS; prio++)
+ 		__qdisc_reset_queue(qdisc, list + prio);
+@@ -464,8 +500,9 @@ nla_put_failure:
+ 
+ static int pfifo_fast_init(struct Qdisc *qdisc, struct nlattr *opt)
+ {
++	struct pfifo_fast_sched_data *q = qdisc_priv(qdisc);
++	struct sk_buff_head *list = q->list;
+ 	int prio;
+-	struct sk_buff_head *list = qdisc_priv(qdisc);
+ 
+ 	for (prio = 0; prio < PFIFO_FAST_BANDS; prio++)
+ 		skb_queue_head_init(list + prio);
+@@ -473,9 +510,36 @@ static int pfifo_fast_init(struct Qdisc
+ 	return 0;
+ }
+ 
++static int pfifo_fast_change_class(struct Qdisc *qdisc, u32 classid, u32 parentid,
++			    struct nlattr **tca, unsigned long *arg)
++{
++	return -EOPNOTSUPP;
++}
++
++static unsigned long pfifo_fast_get(struct Qdisc *qdisc, u32 classid)
++{
++	return 0;
++}
++
++static struct tcf_proto **pfifo_fast_find_tcf(struct Qdisc *qdisc, unsigned long cl)
++{
++	struct pfifo_fast_sched_data *q = qdisc_priv(qdisc);
++
++	if (cl)
++		return NULL;
++	return &q->filter_list;
++}
++
++static const struct Qdisc_class_ops pfifo_fast_class_ops = {
++	.get		=	pfifo_fast_get,
++	.change		=	pfifo_fast_change_class,
++	.tcf_chain	=	pfifo_fast_find_tcf,
++};
++
+ static struct Qdisc_ops pfifo_fast_ops __read_mostly = {
+ 	.id		=	"pfifo_fast",
+-	.priv_size	=	PFIFO_FAST_BANDS * sizeof(struct sk_buff_head),
++	.cl_ops		=	&pfifo_fast_class_ops,
++	.priv_size	=	sizeof(struct pfifo_fast_sched_data),
+ 	.enqueue	=	pfifo_fast_enqueue,
+ 	.dequeue	=	pfifo_fast_dequeue,
+ 	.peek		=	pfifo_fast_peek,
+@@ -757,3 +821,18 @@ void dev_shutdown(struct net_device *dev
+ 	shutdown_scheduler_queue(dev, &dev->rx_queue, &noop_qdisc);
+ 	WARN_ON(timer_pending(&dev->watchdog_timer));
+ }
++
++#ifdef CONFIG_NET_SCHED
++static int __init sch_generic_init(void)
++{
++	return register_qdisc(&pfifo_fast_ops);
++}
++
++static void __exit sch_generic_exit(void)
++{
++	unregister_qdisc(&pfifo_fast_ops);
++}
++
++module_init(sch_generic_init)
++module_exit(sch_generic_exit)
++#endif
diff -Nru a/target/linux/generic/patches-2.6.31/270-sched_bfs.patch b/target/linux/generic/patches-2.6.31/270-sched_bfs.patch
--- a/target/linux/generic/patches-2.6.31/270-sched_bfs.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/270-sched_bfs.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,6448 @@
+This patch adds support for bfs v230, modified for diff size reduction
+
+--- a/Documentation/sysctl/kernel.txt
++++ b/Documentation/sysctl/kernel.txt
+@@ -27,6 +27,7 @@ show up in /proc/sys/kernel:
+ - domainname
+ - hostname
+ - hotplug
++- iso_cpu
+ - java-appletviewer           [ binfmt_java, obsolete ]
+ - java-interpreter            [ binfmt_java, obsolete ]
+ - kstack_depth_to_print       [ X86 only ]
+@@ -49,6 +50,7 @@ show up in /proc/sys/kernel:
+ - randomize_va_space
+ - real-root-dev               ==> Documentation/initrd.txt
+ - reboot-cmd                  [ SPARC only ]
++- rr_interval
+ - rtsig-max
+ - rtsig-nr
+ - sem
+@@ -171,6 +173,16 @@ Default value is "/sbin/hotplug".
+ 
+ ==============================================================
+ 
++iso_cpu: (BFS only)
++
++This sets the percentage cpu that the unprivileged SCHED_ISO tasks can
++run effectively at realtime priority, averaged over a rolling five
++seconds over the -whole- system, meaning all cpus.
++
++Set to 70 (percent) by default.
++
++==============================================================
++
+ l2cr: (PPC only)
+ 
+ This flag controls the L2 cache of G3 processor boards. If
+@@ -333,6 +345,19 @@ rebooting. ???
+ 
+ ==============================================================
+ 
++rr_interval: (BFS only)
++
++This is the smallest duration that any cpu process scheduling unit
++will run for. Increasing this value can increase throughput of cpu
++bound tasks substantially but at the expense of increased latencies
++overall. This value is in milliseconds and the default value chosen
++depends on the number of cpus available at scheduler initialisation
++with a minimum of 6.
++
++Valid values are from 1-5000.
++
++==============================================================
++
+ rtsig-max & rtsig-nr:
+ 
+ The file rtsig-max can be used to tune the maximum number
+--- a/include/linux/init_task.h
++++ b/include/linux/init_task.h
+@@ -116,9 +116,10 @@ extern struct cred init_cred;
+ 	.usage		= ATOMIC_INIT(2),				\
+ 	.flags		= PF_KTHREAD,					\
+ 	.lock_depth	= -1,						\
+-	.prio		= MAX_PRIO-20,					\
++	.prio		= NORMAL_PRIO,					\
+ 	.static_prio	= MAX_PRIO-20,					\
+-	.normal_prio	= MAX_PRIO-20,					\
++	.normal_prio	= NORMAL_PRIO,					\
++	.deadline	= 0,						\
+ 	.policy		= SCHED_NORMAL,					\
+ 	.cpus_allowed	= CPU_MASK_ALL,					\
+ 	.mm		= NULL,						\
+--- a/include/linux/sched.h
++++ b/include/linux/sched.h
+@@ -36,9 +36,12 @@
+ #define SCHED_FIFO		1
+ #define SCHED_RR		2
+ #define SCHED_BATCH		3
+-/* SCHED_ISO: reserved but not implemented yet */
++#define SCHED_ISO		4
+ #define SCHED_IDLE		5
+ 
++#define SCHED_MAX		(SCHED_IDLE)
++#define SCHED_RANGE(policy)	((policy) <= SCHED_MAX)
++
+ #ifdef __KERNEL__
+ 
+ struct sched_param {
+@@ -1090,10 +1093,13 @@ struct sched_entity {
+ 	struct load_weight	load;		/* for load-balancing */
+ 	struct rb_node		run_node;
+ 	struct list_head	group_node;
++#ifdef CONFIG_SCHED_CFS
+ 	unsigned int		on_rq;
+ 
+ 	u64			exec_start;
++#endif
+ 	u64			sum_exec_runtime;
++#ifdef CONFIG_SCHED_CFS
+ 	u64			vruntime;
+ 	u64			prev_sum_exec_runtime;
+ 
+@@ -1145,6 +1151,7 @@ struct sched_entity {
+ 	/* rq "owned" by this entity/group: */
+ 	struct cfs_rq		*my_q;
+ #endif
++#endif
+ };
+ 
+ struct sched_rt_entity {
+@@ -1172,17 +1179,19 @@ struct task_struct {
+ 
+ 	int lock_depth;		/* BKL lock depth */
+ 
+-#ifdef CONFIG_SMP
+-#ifdef __ARCH_WANT_UNLOCKED_CTXSW
+ 	int oncpu;
+-#endif
+-#endif
+-
+ 	int prio, static_prio, normal_prio;
+ 	unsigned int rt_priority;
+ 	const struct sched_class *sched_class;
+ 	struct sched_entity se;
+ 	struct sched_rt_entity rt;
++	unsigned long deadline;
++#ifdef CONFIG_SCHED_BFS
++	int load_weight;	/* for niceness load balancing purposes */
++	int first_time_slice;
++	unsigned long long timestamp, last_ran;
++	unsigned long utime_pc, stime_pc;
++#endif
+ 
+ #ifdef CONFIG_PREEMPT_NOTIFIERS
+ 	/* list of struct preempt_notifier: */
+@@ -1205,6 +1214,9 @@ struct task_struct {
+ 
+ 	unsigned int policy;
+ 	cpumask_t cpus_allowed;
++#ifdef CONFIG_HOTPLUG_CPU
++	cpumask_t unplugged_mask;
++#endif
+ 
+ #ifdef CONFIG_PREEMPT_RCU
+ 	int rcu_read_lock_nesting;
+@@ -1497,11 +1509,19 @@ struct task_struct {
+  * priority to a value higher than any user task. Note:
+  * MAX_RT_PRIO must not be smaller than MAX_USER_RT_PRIO.
+  */
+-
++#define PRIO_RANGE		(40)
+ #define MAX_USER_RT_PRIO	100
+ #define MAX_RT_PRIO		MAX_USER_RT_PRIO
+-
++#ifdef CONFIG_SCHED_BFS
++#define MAX_PRIO		(MAX_RT_PRIO + PRIO_RANGE)
++#define ISO_PRIO		(MAX_RT_PRIO)
++#define NORMAL_PRIO		(MAX_RT_PRIO + 1)
++#define IDLE_PRIO		(MAX_RT_PRIO + 2)
++#define PRIO_LIMIT		((IDLE_PRIO) + 1)
++#else
+ #define MAX_PRIO		(MAX_RT_PRIO + 40)
++#define NORMAL_PRIO	(MAX_RT_PRIO - 20)
++#endif
+ #define DEFAULT_PRIO		(MAX_RT_PRIO + 20)
+ 
+ static inline int rt_prio(int prio)
+@@ -1785,7 +1805,7 @@ task_sched_runtime(struct task_struct *t
+ extern unsigned long long thread_group_sched_runtime(struct task_struct *task);
+ 
+ /* sched_exec is called by processes performing an exec */
+-#ifdef CONFIG_SMP
++#if defined(CONFIG_SMP) && defined(CONFIG_SCHED_CFS)
+ extern void sched_exec(void);
+ #else
+ #define sched_exec()   {}
+--- a/init/Kconfig
++++ b/init/Kconfig
+@@ -451,9 +451,22 @@ config LOG_BUF_SHIFT
+ config HAVE_UNSTABLE_SCHED_CLOCK
+ 	bool
+ 
++choice
++	prompt "Scheduler"
++	default SCHED_CFS
++
++	config SCHED_CFS
++		bool "CFS"
++
++	config SCHED_BFS
++		bool "BFS"
++
++endchoice
++
+ config GROUP_SCHED
+ 	bool "Group CPU scheduler"
+ 	depends on EXPERIMENTAL
++	depends on SCHED_CFS
+ 	default n
+ 	help
+ 	  This feature lets CPU scheduler recognize task groups and control CPU
+@@ -504,6 +517,7 @@ endchoice
+ 
+ menuconfig CGROUPS
+ 	boolean "Control Group support"
++	depends on SCHED_CFS
+ 	help
+ 	  This option adds support for grouping sets of processes together, for
+ 	  use with process control subsystems such as Cpusets, CFS, memory
+--- a/kernel/Makefile
++++ b/kernel/Makefile
+@@ -2,7 +2,7 @@
+ # Makefile for the linux kernel.
+ #
+ 
+-obj-y     = sched.o fork.o exec_domain.o panic.o printk.o \
++obj-y     = $(if $(CONFIG_SCHED_CFS),sched.o,sched_bfs.o) fork.o exec_domain.o panic.o printk.o \
+ 	    cpu.o exit.o itimer.o time.o softirq.o resource.o \
+ 	    sysctl.o capability.o ptrace.o timer.o user.o \
+ 	    signal.o sys.o kmod.o workqueue.o pid.o \
+@@ -108,6 +108,7 @@ ifneq ($(CONFIG_SCHED_OMIT_FRAME_POINTER
+ # I turn this off for IA-64 only.  Andreas Schwab says it's also needed on m68k
+ # to get a correct value for the wait-channel (WCHAN in ps). --davidm
+ CFLAGS_sched.o := $(PROFILING) -fno-omit-frame-pointer
++CFLAGS_sched_bfs.o := $(PROFILING) -fno-omit-frame-pointer
+ endif
+ 
+ $(obj)/configs.o: $(obj)/config_data.h
+--- a/kernel/kthread.c
++++ b/kernel/kthread.c
+@@ -16,7 +16,11 @@
+ #include <linux/mutex.h>
+ #include <trace/events/sched.h>
+ 
++#ifdef CONFIG_SCHED_BFS
++#define KTHREAD_NICE_LEVEL (0)
++#else
+ #define KTHREAD_NICE_LEVEL (-5)
++#endif
+ 
+ static DEFINE_SPINLOCK(kthread_create_lock);
+ static LIST_HEAD(kthread_create_list);
+--- /dev/null
++++ b/kernel/sched_bfs.c
+@@ -0,0 +1,6105 @@
++/*
++ *  kernel/sched_bfs.c, was sched.c
++ *
++ *  Kernel scheduler and related syscalls
++ *
++ *  Copyright (C) 1991-2002  Linus Torvalds
++ *
++ *  1996-12-23  Modified by Dave Grothe to fix bugs in semaphores and
++ *		make semaphores SMP safe
++ *  1998-11-19	Implemented schedule_timeout() and related stuff
++ *		by Andrea Arcangeli
++ *  2002-01-04	New ultra-scalable O(1) scheduler by Ingo Molnar:
++ *		hybrid priority-list and round-robin design with
++ *		an array-switch method of distributing timeslices
++ *		and per-CPU runqueues.  Cleanups and useful suggestions
++ *		by Davide Libenzi, preemptible kernel bits by Robert Love.
++ *  2003-09-03	Interactivity tuning by Con Kolivas.
++ *  2004-04-02	Scheduler domains code by Nick Piggin
++ *  2007-04-15  Work begun on replacing all interactivity tuning with a
++ *              fair scheduling design by Con Kolivas.
++ *  2007-05-05  Load balancing (smp-nice) and other improvements
++ *              by Peter Williams
++ *  2007-05-06  Interactivity improvements to CFS by Mike Galbraith
++ *  2007-07-01  Group scheduling enhancements by Srivatsa Vaddagiri
++ *  2007-11-29  RT balancing improvements by Steven Rostedt, Gregory Haskins,
++ *              Thomas Gleixner, Mike Kravetz
++ *  now		Brainfuck deadline scheduling policy by Con Kolivas deletes
++ *              a whole lot of those previous things.
++ */
++
++#include <linux/mm.h>
++#include <linux/module.h>
++#include <linux/nmi.h>
++#include <linux/init.h>
++#include <asm/uaccess.h>
++#include <linux/highmem.h>
++#include <linux/smp_lock.h>
++#include <asm/mmu_context.h>
++#include <linux/interrupt.h>
++#include <linux/capability.h>
++#include <linux/completion.h>
++#include <linux/kernel_stat.h>
++#include <linux/debug_locks.h>
++#include <linux/perf_counter.h>
++#include <linux/security.h>
++#include <linux/notifier.h>
++#include <linux/profile.h>
++#include <linux/freezer.h>
++#include <linux/vmalloc.h>
++#include <linux/blkdev.h>
++#include <linux/delay.h>
++#include <linux/smp.h>
++#include <linux/threads.h>
++#include <linux/timer.h>
++#include <linux/rcupdate.h>
++#include <linux/cpu.h>
++#include <linux/cpuset.h>
++#include <linux/cpumask.h>
++#include <linux/percpu.h>
++#include <linux/kthread.h>
++#include <linux/proc_fs.h>
++#include <linux/seq_file.h>
++#include <linux/syscalls.h>
++#include <linux/times.h>
++#include <linux/tsacct_kern.h>
++#include <linux/kprobes.h>
++#include <linux/delayacct.h>
++#include <linux/reciprocal_div.h>
++#include <linux/log2.h>
++#include <linux/bootmem.h>
++#include <linux/ftrace.h>
++
++#include <asm/tlb.h>
++#include <asm/unistd.h>
++
++#define CREATE_TRACE_POINTS
++#include <trace/events/sched.h>
++
++#define rt_prio(prio)		unlikely((prio) < MAX_RT_PRIO)
++#define rt_task(p)		rt_prio((p)->prio)
++#define rt_queue(rq)		rt_prio((rq)->rq_prio)
++#define batch_task(p)		(unlikely((p)->policy == SCHED_BATCH))
++#define is_rt_policy(policy)	((policy) == SCHED_FIFO || \
++					(policy) == SCHED_RR)
++#define has_rt_policy(p)	unlikely(is_rt_policy((p)->policy))
++#define idleprio_task(p)	unlikely((p)->policy == SCHED_IDLE)
++#define iso_task(p)		unlikely((p)->policy == SCHED_ISO)
++#define iso_queue(rq)		unlikely((rq)->rq_policy == SCHED_ISO)
++#define ISO_PERIOD		((5 * HZ * num_online_cpus()) + 1)
++
++/*
++ * Convert user-nice values [ -20 ... 0 ... 19 ]
++ * to static priority [ MAX_RT_PRIO..MAX_PRIO-1 ],
++ * and back.
++ */
++#define NICE_TO_PRIO(nice)	(MAX_RT_PRIO + (nice) + 20)
++#define PRIO_TO_NICE(prio)	((prio) - MAX_RT_PRIO - 20)
++#define TASK_NICE(p)		PRIO_TO_NICE((p)->static_prio)
++
++/*
++ * 'User priority' is the nice value converted to something we
++ * can work with better when scaling various scheduler parameters,
++ * it's a [ 0 ... 39 ] range.
++ */
++#define USER_PRIO(p)		((p)-MAX_RT_PRIO)
++#define TASK_USER_PRIO(p)	USER_PRIO((p)->static_prio)
++#define MAX_USER_PRIO		(USER_PRIO(MAX_PRIO))
++#define SCHED_PRIO(p)		((p)+MAX_RT_PRIO)
++
++/* Some helpers for converting to/from various scales.*/
++#define JIFFIES_TO_NS(TIME)	((TIME) * (1000000000 / HZ))
++#define MS_TO_NS(TIME)		((TIME) * 1000000)
++#define MS_TO_US(TIME)		((TIME) * 1000)
++
++#ifdef CONFIG_SMP
++/*
++ * Divide a load by a sched group cpu_power : (load / sg->__cpu_power)
++ * Since cpu_power is a 'constant', we can use a reciprocal divide.
++ */
++static inline u32 sg_div_cpu_power(const struct sched_group *sg, u32 load)
++{
++	return reciprocal_divide(load, sg->reciprocal_cpu_power);
++}
++
++/*
++ * Each time a sched group cpu_power is changed,
++ * we must compute its reciprocal value
++ */
++static inline void sg_inc_cpu_power(struct sched_group *sg, u32 val)
++{
++	sg->__cpu_power += val;
++	sg->reciprocal_cpu_power = reciprocal_value(sg->__cpu_power);
++}
++#endif
++
++/*
++ * This is the time all tasks within the same priority round robin.
++ * Value is in ms and set to a minimum of 6ms. Scales with number of cpus.
++ * Tunable via /proc interface.
++ */
++int rr_interval __read_mostly = 6;
++
++/*
++ * sched_iso_cpu - sysctl which determines the cpu percentage SCHED_ISO tasks
++ * are allowed to run five seconds as real time tasks. This is the total over
++ * all online cpus.
++ */
++int sched_iso_cpu __read_mostly = 70;
++
++int prio_ratios[PRIO_RANGE] __read_mostly;
++
++static inline unsigned long timeslice(void)
++{
++	return MS_TO_US(rr_interval);
++}
++
++struct global_rq {
++	spinlock_t lock;
++	unsigned long nr_running;
++	unsigned long nr_uninterruptible;
++	unsigned long long nr_switches;
++	struct list_head queue[PRIO_LIMIT];
++	DECLARE_BITMAP(prio_bitmap, PRIO_LIMIT + 1);
++	unsigned long iso_ticks;
++	unsigned short iso_refractory;
++#ifdef CONFIG_SMP
++	unsigned long qnr; /* queued not running */
++	cpumask_t cpu_idle_map;
++#endif
++};
++
++static struct global_rq grq;
++
++/*
++ * This is the main, per-CPU runqueue data structure.
++ * All this is protected by the global_rq lock.
++ */
++struct rq {
++#ifdef CONFIG_SMP
++#ifdef CONFIG_NO_HZ
++	unsigned char in_nohz_recently;
++#endif
++#endif
++
++	struct task_struct *curr, *idle;
++	struct mm_struct *prev_mm;
++	struct list_head queue; /* Place to store currently running task */
++
++	/* Stored data about rq->curr to work outside grq lock */
++	unsigned long rq_deadline;
++	unsigned int rq_policy;
++	int rq_time_slice;
++	int rq_prio;
++
++	/* Accurate timekeeping data */
++	u64 timekeep_clock;
++	unsigned long user_pc, nice_pc, irq_pc, softirq_pc, system_pc,
++			iowait_pc, idle_pc;
++	atomic_t nr_iowait;
++
++	int cpu;		/* cpu of this runqueue */
++	int online;
++
++#ifdef CONFIG_SMP
++	struct root_domain *rd;
++	struct sched_domain *sd;
++
++	struct list_head migration_queue;
++#endif
++
++	u64 clock;
++#ifdef CONFIG_SCHEDSTATS
++
++	/* latency stats */
++	struct sched_info rq_sched_info;
++	unsigned long long rq_cpu_time;
++	/* could above be rq->cfs_rq.exec_clock + rq->rt_rq.rt_runtime ? */
++
++	/* sys_sched_yield() stats */
++	unsigned int yld_count;
++
++	/* schedule() stats */
++	unsigned int sched_switch;
++	unsigned int sched_count;
++	unsigned int sched_goidle;
++
++	/* try_to_wake_up() stats */
++	unsigned int ttwu_count;
++	unsigned int ttwu_local;
++
++	/* BKL stats */
++	unsigned int bkl_count;
++#endif
++};
++
++static DEFINE_PER_CPU(struct rq, runqueues) ____cacheline_aligned_in_smp;
++static DEFINE_MUTEX(sched_hotcpu_mutex);
++
++#ifdef CONFIG_SMP
++
++/*
++ * We add the notion of a root-domain which will be used to define per-domain
++ * variables. Each exclusive cpuset essentially defines an island domain by
++ * fully partitioning the member cpus from any other cpuset. Whenever a new
++ * exclusive cpuset is created, we also create and attach a new root-domain
++ * object.
++ *
++ */
++struct root_domain {
++	atomic_t refcount;
++	cpumask_var_t span;
++	cpumask_var_t online;
++
++	/*
++	 * The "RT overload" flag: it gets set if a CPU has more than
++	 * one runnable RT task.
++	 */
++	cpumask_var_t rto_mask;
++	atomic_t rto_count;
++#if defined(CONFIG_SCHED_MC) || defined(CONFIG_SCHED_SMT)
++	/*
++	 * Preferred wake up cpu nominated by sched_mc balance that will be
++	 * used when most cpus are idle in the system indicating overall very
++	 * low system utilisation. Triggered at POWERSAVINGS_BALANCE_WAKEUP(2)
++	 */
++	unsigned int sched_mc_preferred_wakeup_cpu;
++#endif
++};
++
++/*
++ * By default the system creates a single root-domain with all cpus as
++ * members (mimicking the global state we have today).
++ */
++static struct root_domain def_root_domain;
++
++#endif
++
++static inline int cpu_of(struct rq *rq)
++{
++#ifdef CONFIG_SMP
++	return rq->cpu;
++#else
++	return 0;
++#endif
++}
++
++/*
++ * The domain tree (rq->sd) is protected by RCU's quiescent state transition.
++ * See detach_destroy_domains: synchronize_sched for details.
++ *
++ * The domain tree of any CPU may only be accessed from within
++ * preempt-disabled sections.
++ */
++#define for_each_domain(cpu, __sd) \
++	for (__sd = rcu_dereference(cpu_rq(cpu)->sd); __sd; __sd = __sd->parent)
++
++#define cpu_rq(cpu)		(&per_cpu(runqueues, (cpu)))
++#define this_rq()		(&__get_cpu_var(runqueues))
++#define task_rq(p)		cpu_rq(task_cpu(p))
++#define cpu_curr(cpu)		(cpu_rq(cpu)->curr)
++
++#include "sched_stats.h"
++
++#ifndef prepare_arch_switch
++# define prepare_arch_switch(next)	do { } while (0)
++#endif
++#ifndef finish_arch_switch
++# define finish_arch_switch(prev)	do { } while (0)
++#endif
++
++inline void update_rq_clock(struct rq *rq)
++{
++	rq->clock = sched_clock_cpu(cpu_of(rq));
++}
++
++static inline int task_running(struct task_struct *p)
++{
++	return (!!p->oncpu);
++}
++
++static inline void grq_lock(void)
++	__acquires(grq.lock)
++{
++	smp_mb();
++	spin_lock(&grq.lock);
++}
++
++static inline void grq_unlock(void)
++	__releases(grq.lock)
++{
++	spin_unlock(&grq.lock);
++}
++
++static inline void grq_lock_irq(void)
++	__acquires(grq.lock)
++{
++	smp_mb();
++	spin_lock_irq(&grq.lock);
++}
++
++static inline void time_lock_grq(struct rq *rq)
++	__acquires(grq.lock)
++{
++	grq_lock();
++	update_rq_clock(rq);
++}
++
++static inline void grq_unlock_irq(void)
++	__releases(grq.lock)
++{
++	spin_unlock_irq(&grq.lock);
++}
++
++static inline void grq_lock_irqsave(unsigned long *flags)
++	__acquires(grq.lock)
++{
++	smp_mb();
++	spin_lock_irqsave(&grq.lock, *flags);
++}
++
++static inline void grq_unlock_irqrestore(unsigned long *flags)
++	__releases(grq.lock)
++{
++	spin_unlock_irqrestore(&grq.lock, *flags);
++}
++
++static inline struct rq
++*task_grq_lock(struct task_struct *p, unsigned long *flags)
++	__acquires(grq.lock)
++{
++	grq_lock_irqsave(flags);
++	return task_rq(p);
++}
++
++static inline struct rq
++*time_task_grq_lock(struct task_struct *p, unsigned long *flags)
++	__acquires(grq.lock)
++{
++	struct rq *rq = task_grq_lock(p, flags);
++	update_rq_clock(rq);
++	return rq;
++}
++
++static inline void task_grq_unlock(unsigned long *flags)
++	__releases(grq.lock)
++{
++	grq_unlock_irqrestore(flags);
++}
++
++/**
++ * runqueue_is_locked
++ *
++ * Returns true if the global runqueue is locked.
++ * This interface allows printk to be called with the runqueue lock
++ * held and know whether or not it is OK to wake up the klogd.
++ */
++int runqueue_is_locked(void)
++{
++	return spin_is_locked(&grq.lock);
++}
++
++void task_rq_unlock_wait(struct task_struct *p)
++	__releases(grq.lock)
++{
++	smp_mb(); /* spin-unlock-wait is not a full memory barrier */
++	spin_unlock_wait(&grq.lock);
++}
++
++static inline void time_grq_lock(struct rq *rq, unsigned long *flags)
++	__acquires(grq.lock)
++{
++	spin_lock_irqsave(&grq.lock, *flags);
++	update_rq_clock(rq);
++}
++
++static inline struct rq *__task_grq_lock(struct task_struct *p)
++	__acquires(grq.lock)
++{
++	grq_lock();
++	return task_rq(p);
++}
++
++static inline void __task_grq_unlock(void)
++	__releases(grq.lock)
++{
++	grq_unlock();
++}
++
++#ifndef __ARCH_WANT_UNLOCKED_CTXSW
++static inline void prepare_lock_switch(struct rq *rq, struct task_struct *next)
++{
++}
++
++static inline void finish_lock_switch(struct rq *rq, struct task_struct *prev)
++{
++#ifdef CONFIG_DEBUG_SPINLOCK
++	/* this is a valid case when another task releases the spinlock */
++	grq.lock.owner = current;
++#endif
++	/*
++	 * If we are tracking spinlock dependencies then we have to
++	 * fix up the runqueue lock - which gets 'carried over' from
++	 * prev into current:
++	 */
++	spin_acquire(&grq.lock.dep_map, 0, 0, _THIS_IP_);
++
++	grq_unlock_irq();
++}
++
++#else /* __ARCH_WANT_UNLOCKED_CTXSW */
++
++static inline void prepare_lock_switch(struct rq *rq, struct task_struct *next)
++{
++#ifdef __ARCH_WANT_INTERRUPTS_ON_CTXSW
++	grq_unlock_irq();
++#else
++	grq_unlock();
++#endif
++}
++
++static inline void finish_lock_switch(struct rq *rq, struct task_struct *prev)
++{
++	smp_wmb();
++#ifndef __ARCH_WANT_INTERRUPTS_ON_CTXSW
++	local_irq_enable();
++#endif
++}
++#endif /* __ARCH_WANT_UNLOCKED_CTXSW */
++
++/*
++ * A task that is queued will be on the grq run list.
++ * A task that is not running or queued will not be on the grq run list.
++ * A task that is currently running will have ->oncpu set and be queued
++ * temporarily in its own rq queue.
++ * A task that is running and no longer queued will be seen only on
++ * context switch exit.
++ */
++
++static inline int task_queued(struct task_struct *p)
++{
++	return (!list_empty(&p->rt.run_list));
++}
++
++static inline int task_queued_only(struct task_struct *p)
++{
++	return (!list_empty(&p->rt.run_list) && !task_running(p));
++}
++
++/*
++ * Removing from the global runqueue. Enter with grq locked.
++ */
++static void dequeue_task(struct task_struct *p)
++{
++	list_del_init(&p->rt.run_list);
++	if (list_empty(grq.queue + p->prio))
++		__clear_bit(p->prio, grq.prio_bitmap);
++}
++
++static inline void reset_first_time_slice(struct task_struct *p)
++{
++	if (unlikely(p->first_time_slice))
++		p->first_time_slice = 0;
++}
++
++static int idleprio_suitable(struct task_struct *p)
++{
++	return (!freezing(p) && !signal_pending(p) &&
++		!(task_contributes_to_load(p)) && !(p->flags & (PF_EXITING)));
++}
++
++static int isoprio_suitable(void)
++{
++	return !grq.iso_refractory;
++}
++
++/*
++ * Adding to the global runqueue. Enter with grq locked.
++ */
++static void enqueue_task(struct task_struct *p)
++{
++	if (!rt_task(p)) {
++		/* Check it hasn't gotten rt from PI */
++		if ((idleprio_task(p) && idleprio_suitable(p)) ||
++		   (iso_task(p) && isoprio_suitable()))
++			p->prio = p->normal_prio;
++		else
++			p->prio = NORMAL_PRIO;
++	}
++	__set_bit(p->prio, grq.prio_bitmap);
++	list_add_tail(&p->rt.run_list, grq.queue + p->prio);
++	sched_info_queued(p);
++}
++
++/* Only idle task does this as a real time task*/
++static inline void enqueue_task_head(struct task_struct *p)
++{
++	__set_bit(p->prio, grq.prio_bitmap);
++	list_add(&p->rt.run_list, grq.queue + p->prio);
++	sched_info_queued(p);
++}
++
++static inline void requeue_task(struct task_struct *p)
++{
++	sched_info_queued(p);
++}
++
++static inline int pratio(struct task_struct *p)
++{
++	return prio_ratios[TASK_USER_PRIO(p)];
++}
++
++/*
++ * task_timeslice - all tasks of all priorities get the exact same timeslice
++ * length. CPU distribution is handled by giving different deadlines to
++ * tasks of different priorities.
++ */
++static inline int task_timeslice(struct task_struct *p)
++{
++	return (rr_interval * pratio(p) / 100);
++}
++
++#ifdef CONFIG_SMP
++static inline void inc_qnr(void)
++{
++	grq.qnr++;
++}
++
++static inline void dec_qnr(void)
++{
++	grq.qnr--;
++}
++
++static inline int queued_notrunning(void)
++{
++	return grq.qnr;
++}
++#else
++static inline void inc_qnr(void)
++{
++}
++
++static inline void dec_qnr(void)
++{
++}
++
++static inline int queued_notrunning(void)
++{
++	return grq.nr_running;
++}
++#endif
++
++/*
++ * activate_idle_task - move idle task to the _front_ of runqueue.
++ */
++static inline void activate_idle_task(struct task_struct *p)
++{
++	enqueue_task_head(p);
++	grq.nr_running++;
++	inc_qnr();
++}
++
++static inline int normal_prio(struct task_struct *p)
++{
++	if (has_rt_policy(p))
++		return MAX_RT_PRIO - 1 - p->rt_priority;
++	if (idleprio_task(p))
++		return IDLE_PRIO;
++	if (iso_task(p))
++		return ISO_PRIO;
++	return NORMAL_PRIO;
++}
++
++/*
++ * Calculate the current priority, i.e. the priority
++ * taken into account by the scheduler. This value might
++ * be boosted by RT tasks as it will be RT if the task got
++ * RT-boosted. If not then it returns p->normal_prio.
++ */
++static int effective_prio(struct task_struct *p)
++{
++	p->normal_prio = normal_prio(p);
++	/*
++	 * If we are RT tasks or we were boosted to RT priority,
++	 * keep the priority unchanged. Otherwise, update priority
++	 * to the normal priority:
++	 */
++	if (!rt_prio(p->prio))
++		return p->normal_prio;
++	return p->prio;
++}
++
++/*
++ * activate_task - move a task to the runqueue. Enter with grq locked. The rq
++ * doesn't really matter but gives us the local clock.
++ */
++static void activate_task(struct task_struct *p, struct rq *rq)
++{
++	u64 now = rq->clock;
++
++	/*
++	 * Sleep time is in units of nanosecs, so shift by 20 to get a
++	 * milliseconds-range estimation of the amount of time that the task
++	 * spent sleeping:
++	 */
++	if (unlikely(prof_on == SLEEP_PROFILING)) {
++		if (p->state == TASK_UNINTERRUPTIBLE)
++			profile_hits(SLEEP_PROFILING, (void *)get_wchan(p),
++				     (now - p->timestamp) >> 20);
++	}
++
++	p->prio = effective_prio(p);
++	p->timestamp = now;
++	if (task_contributes_to_load(p))
++		grq.nr_uninterruptible--;
++	enqueue_task(p);
++	grq.nr_running++;
++	inc_qnr();
++}
++
++/*
++ * deactivate_task - If it's running, it's not on the grq and we can just
++ * decrement the nr_running.
++ */
++static inline void deactivate_task(struct task_struct *p)
++{
++	if (task_contributes_to_load(p))
++		grq.nr_uninterruptible++;
++	grq.nr_running--;
++}
++
++#ifdef CONFIG_SMP
++void set_task_cpu(struct task_struct *p, unsigned int cpu)
++{
++	trace_sched_migrate_task(p, cpu);
++	/*
++	 * After ->cpu is set up to a new value, task_grq_lock(p, ...) can be
++	 * successfuly executed on another CPU. We must ensure that updates of
++	 * per-task data have been completed by this moment.
++	 */
++	smp_wmb();
++	task_thread_info(p)->cpu = cpu;
++}
++#endif
++
++/*
++ * Move a task off the global queue and take it to a cpu for it will
++ * become the running task.
++ */
++static inline void take_task(struct rq *rq, struct task_struct *p)
++{
++	set_task_cpu(p, rq->cpu);
++	dequeue_task(p);
++	list_add(&p->rt.run_list, &rq->queue);
++	dec_qnr();
++}
++
++/*
++ * Returns a descheduling task to the grq runqueue unless it is being
++ * deactivated.
++ */
++static inline void return_task(struct task_struct *p, int deactivate)
++{
++	list_del_init(&p->rt.run_list);
++	if (deactivate)
++		deactivate_task(p);
++	else {
++		inc_qnr();
++		enqueue_task(p);
++	}
++}
++
++/*
++ * resched_task - mark a task 'to be rescheduled now'.
++ *
++ * On UP this means the setting of the need_resched flag, on SMP it
++ * might also involve a cross-CPU call to trigger the scheduler on
++ * the target CPU.
++ */
++#ifdef CONFIG_SMP
++
++#ifndef tsk_is_polling
++#define tsk_is_polling(t) test_tsk_thread_flag(t, TIF_POLLING_NRFLAG)
++#endif
++
++static void resched_task(struct task_struct *p)
++{
++	int cpu;
++
++	assert_spin_locked(&grq.lock);
++
++	if (unlikely(test_tsk_thread_flag(p, TIF_NEED_RESCHED)))
++		return;
++
++	set_tsk_thread_flag(p, TIF_NEED_RESCHED);
++
++	cpu = task_cpu(p);
++	if (cpu == smp_processor_id())
++		return;
++
++	/* NEED_RESCHED must be visible before we test polling */
++	smp_mb();
++	if (!tsk_is_polling(p))
++		smp_send_reschedule(cpu);
++}
++
++#else
++static inline void resched_task(struct task_struct *p)
++{
++	assert_spin_locked(&grq.lock);
++	set_tsk_need_resched(p);
++}
++#endif
++
++/**
++ * task_curr - is this task currently executing on a CPU?
++ * @p: the task in question.
++ */
++inline int task_curr(const struct task_struct *p)
++{
++	return cpu_curr(task_cpu(p)) == p;
++}
++
++#ifdef CONFIG_SMP
++struct migration_req {
++	struct list_head list;
++
++	struct task_struct *task;
++	int dest_cpu;
++
++	struct completion done;
++};
++
++/*
++ * wait_task_context_switch -	wait for a thread to complete at least one
++ *				context switch.
++ *
++ * @p must not be current.
++ */
++void wait_task_context_switch(struct task_struct *p)
++{
++	unsigned long nvcsw, nivcsw, flags;
++	int running;
++	struct rq *rq;
++
++	nvcsw	= p->nvcsw;
++	nivcsw	= p->nivcsw;
++	for (;;) {
++		/*
++		 * The runqueue is assigned before the actual context
++		 * switch. We need to take the runqueue lock.
++		 *
++		 * We could check initially without the lock but it is
++		 * very likely that we need to take the lock in every
++		 * iteration.
++		 */
++		rq = task_grq_lock(p, &flags);
++		running = task_running(p);
++		task_grq_unlock(&flags);
++
++		if (likely(!running))
++			break;
++		/*
++		 * The switch count is incremented before the actual
++		 * context switch. We thus wait for two switches to be
++		 * sure at least one completed.
++		 */
++		if ((p->nvcsw - nvcsw) > 1)
++			break;
++		if ((p->nivcsw - nivcsw) > 1)
++			break;
++
++		cpu_relax();
++	}
++}
++
++/*
++ * wait_task_inactive - wait for a thread to unschedule.
++ *
++ * If @match_state is nonzero, it's the @p->state value just checked and
++ * not expected to change.  If it changes, i.e. @p might have woken up,
++ * then return zero.  When we succeed in waiting for @p to be off its CPU,
++ * we return a positive number (its total switch count).  If a second call
++ * a short while later returns the same number, the caller can be sure that
++ * @p has remained unscheduled the whole time.
++ *
++ * The caller must ensure that the task *will* unschedule sometime soon,
++ * else this function might spin for a *long* time. This function can't
++ * be called with interrupts off, or it may introduce deadlock with
++ * smp_call_function() if an IPI is sent by the same process we are
++ * waiting to become inactive.
++ */
++unsigned long wait_task_inactive(struct task_struct *p, long match_state)
++{
++	unsigned long flags;
++	int running, on_rq;
++	unsigned long ncsw;
++	struct rq *rq;
++
++	for (;;) {
++		/*
++		 * We do the initial early heuristics without holding
++		 * any task-queue locks at all. We'll only try to get
++		 * the runqueue lock when things look like they will
++		 * work out!
++		 */
++		rq = task_rq(p);
++
++		/*
++		 * If the task is actively running on another CPU
++		 * still, just relax and busy-wait without holding
++		 * any locks.
++		 *
++		 * NOTE! Since we don't hold any locks, it's not
++		 * even sure that "rq" stays as the right runqueue!
++		 * But we don't care, since this will
++		 * return false if the runqueue has changed and p
++		 * is actually now running somewhere else!
++		 */
++		while (task_running(p) && p == rq->curr) {
++			if (match_state && unlikely(p->state != match_state))
++				return 0;
++			cpu_relax();
++		}
++
++		/*
++		 * Ok, time to look more closely! We need the grq
++		 * lock now, to be *sure*. If we're wrong, we'll
++		 * just go back and repeat.
++		 */
++		rq = task_grq_lock(p, &flags);
++		trace_sched_wait_task(rq, p);
++		running = task_running(p);
++		on_rq = task_queued(p);
++		ncsw = 0;
++		if (!match_state || p->state == match_state)
++			ncsw = p->nvcsw | LONG_MIN; /* sets MSB */
++		task_grq_unlock(&flags);
++
++		/*
++		 * If it changed from the expected state, bail out now.
++		 */
++		if (unlikely(!ncsw))
++			break;
++
++		/*
++		 * Was it really running after all now that we
++		 * checked with the proper locks actually held?
++		 *
++		 * Oops. Go back and try again..
++		 */
++		if (unlikely(running)) {
++			cpu_relax();
++			continue;
++		}
++
++		/*
++		 * It's not enough that it's not actively running,
++		 * it must be off the runqueue _entirely_, and not
++		 * preempted!
++		 *
++		 * So if it was still runnable (but just not actively
++		 * running right now), it's preempted, and we should
++		 * yield - it could be a while.
++		 */
++		if (unlikely(on_rq)) {
++			schedule_timeout_uninterruptible(1);
++			continue;
++		}
++
++		/*
++		 * Ahh, all good. It wasn't running, and it wasn't
++		 * runnable, which means that it will never become
++		 * running in the future either. We're all done!
++		 */
++		break;
++	}
++
++	return ncsw;
++}
++
++/***
++ * kick_process - kick a running thread to enter/exit the kernel
++ * @p: the to-be-kicked thread
++ *
++ * Cause a process which is running on another CPU to enter
++ * kernel-mode, without any delay. (to get signals handled.)
++ *
++ * NOTE: this function doesnt have to take the runqueue lock,
++ * because all it wants to ensure is that the remote task enters
++ * the kernel. If the IPI races and the task has been migrated
++ * to another CPU then no harm is done and the purpose has been
++ * achieved as well.
++ */
++void kick_process(struct task_struct *p)
++{
++	int cpu;
++
++	preempt_disable();
++	cpu = task_cpu(p);
++	if ((cpu != smp_processor_id()) && task_curr(p))
++		smp_send_reschedule(cpu);
++	preempt_enable();
++}
++EXPORT_SYMBOL_GPL(kick_process);
++#endif
++
++#define rq_idle(rq)	((rq)->rq_prio == PRIO_LIMIT)
++
++/*
++ * RT tasks preempt purely on priority. SCHED_NORMAL tasks preempt on the
++ * basis of earlier deadlines. SCHED_BATCH and SCHED_IDLE don't preempt,
++ * they cooperatively multitask.
++ */
++static inline int task_preempts_curr(struct task_struct *p, struct rq *rq)
++{
++	int preempts = 0;
++
++	if (p->prio < rq->rq_prio)
++		preempts = 1;
++	else if (p->policy == SCHED_NORMAL && (p->prio == rq->rq_prio &&
++		 time_before(p->deadline, rq->rq_deadline)))
++			preempts = 1;
++	return preempts;
++}
++
++/*
++ * Wake up *any* suitable cpu to schedule this task.
++ */
++static void try_preempt(struct task_struct *p)
++{
++	struct rq *highest_prio_rq, *this_rq;
++	unsigned long latest_deadline, cpu;
++	int highest_prio;
++	cpumask_t tmp;
++
++	/* Try the task's previous rq first and as a fallback */
++	this_rq = task_rq(p);
++
++	if (cpu_isset(this_rq->cpu, p->cpus_allowed)) {
++		highest_prio_rq = this_rq;
++		/* If this_rq is idle, use that. */
++		if (rq_idle(this_rq))
++			goto found_rq;
++	} else
++		highest_prio_rq = cpu_rq(any_online_cpu(p->cpus_allowed));
++	latest_deadline = this_rq->rq_deadline;
++	highest_prio = this_rq->rq_prio;
++
++	cpus_and(tmp, cpu_online_map, p->cpus_allowed);
++
++	for_each_cpu_mask(cpu, tmp) {
++		struct rq *rq;
++		int rq_prio;
++
++		rq = cpu_rq(cpu);
++
++		if (rq_idle(rq)) {
++			/* found an idle rq, use that one */
++			highest_prio_rq = rq;
++			goto found_rq;
++		}
++
++		rq_prio = rq->rq_prio;
++		if (rq_prio > highest_prio ||
++			(rq_prio == highest_prio &&
++			time_after(rq->rq_deadline, latest_deadline))) {
++				highest_prio = rq_prio;
++				latest_deadline = rq->rq_deadline;
++				highest_prio_rq = rq;
++		}
++	}
++
++	if (!task_preempts_curr(p, highest_prio_rq))
++		return;
++found_rq:
++	resched_task(highest_prio_rq->curr);
++	return;
++}
++
++/**
++ * task_oncpu_function_call - call a function on the cpu on which a task runs
++ * @p:		the task to evaluate
++ * @func:	the function to be called
++ * @info:	the function call argument
++ *
++ * Calls the function @func when the task is currently running. This might
++ * be on the current CPU, which just calls the function directly
++ */
++void task_oncpu_function_call(struct task_struct *p,
++			      void (*func) (void *info), void *info)
++{
++	int cpu;
++
++	preempt_disable();
++	cpu = task_cpu(p);
++	if (task_curr(p))
++		smp_call_function_single(cpu, func, info, 1);
++	preempt_enable();
++}
++
++#ifdef CONFIG_SMP
++static int suitable_idle_cpus(struct task_struct *p)
++{
++	return (cpus_intersects(p->cpus_allowed, grq.cpu_idle_map));
++}
++#else
++static int suitable_idle_cpus(struct task_struct *p)
++{
++	return 0;
++}
++#endif
++
++/***
++ * try_to_wake_up - wake up a thread
++ * @p: the to-be-woken-up thread
++ * @state: the mask of task states that can be woken
++ * @sync: do a synchronous wakeup?
++ *
++ * Put it on the run-queue if it's not already there. The "current"
++ * thread is always on the run-queue (except when the actual
++ * re-schedule is in progress), and as such you're allowed to do
++ * the simpler "current->state = TASK_RUNNING" to mark yourself
++ * runnable without the overhead of this.
++ *
++ * returns failure only if the task is already active.
++ */
++static int try_to_wake_up(struct task_struct *p, unsigned int state, int sync)
++{
++	unsigned long flags;
++	int success = 0;
++	long old_state;
++	struct rq *rq;
++
++	rq = time_task_grq_lock(p, &flags);
++	old_state = p->state;
++	if (!(old_state & state))
++		goto out_unlock;
++
++	/*
++	 * Note this catches tasks that are running and queued, but returns
++	 * false during the context switch when they're running and no
++	 * longer queued.
++	 */
++	if (task_queued(p))
++		goto out_running;
++
++	activate_task(p, rq);
++	/*
++	 * Sync wakeups (i.e. those types of wakeups where the waker
++	 * has indicated that it will leave the CPU in short order)
++	 * don't trigger a preemption if there are no idle cpus,
++	 * instead waiting for current to deschedule.
++	 */
++	if (!sync || (sync && suitable_idle_cpus(p)))
++		try_preempt(p);
++	success = 1;
++
++out_running:
++	trace_sched_wakeup(rq, p, success);
++	p->state = TASK_RUNNING;
++out_unlock:
++	task_grq_unlock(&flags);
++	return success;
++}
++
++/**
++ * wake_up_process - Wake up a specific process
++ * @p: The process to be woken up.
++ *
++ * Attempt to wake up the nominated process and move it to the set of runnable
++ * processes.  Returns 1 if the process was woken up, 0 if it was already
++ * running.
++ *
++ * It may be assumed that this function implies a write memory barrier before
++ * changing the task state if and only if any tasks are woken up.
++ */
++int wake_up_process(struct task_struct *p)
++{
++	return try_to_wake_up(p, TASK_ALL, 0);
++}
++EXPORT_SYMBOL(wake_up_process);
++
++int wake_up_state(struct task_struct *p, unsigned int state)
++{
++	return try_to_wake_up(p, state, 0);
++}
++
++/*
++ * Perform scheduler related setup for a newly forked process p.
++ * p is forked by current.
++ */
++void sched_fork(struct task_struct *p, int clone_flags)
++{
++	int cpu = get_cpu();
++	struct rq *rq;
++
++#ifdef CONFIG_PREEMPT_NOTIFIERS
++	INIT_HLIST_HEAD(&p->preempt_notifiers);
++#endif
++	/*
++	 * We mark the process as running here, but have not actually
++	 * inserted it onto the runqueue yet. This guarantees that
++	 * nobody will actually run it, and a signal or other external
++	 * event cannot wake it up and insert it on the runqueue either.
++	 */
++	p->state = TASK_RUNNING;
++	set_task_cpu(p, cpu);
++
++	/* Should be reset in fork.c but done here for ease of bfs patching */
++	p->se.sum_exec_runtime = p->stime_pc = p->utime_pc = 0;
++
++	/*
++	 * Make sure we do not leak PI boosting priority to the child:
++	 */
++	p->prio = current->normal_prio;
++
++	INIT_LIST_HEAD(&p->rt.run_list);
++#if defined(CONFIG_SCHEDSTATS) || defined(CONFIG_TASK_DELAY_ACCT)
++	if (unlikely(sched_info_on()))
++		memset(&p->sched_info, 0, sizeof(p->sched_info));
++#endif
++
++	p->oncpu = 0;
++
++#ifdef CONFIG_PREEMPT
++	/* Want to start with kernel preemption disabled. */
++	task_thread_info(p)->preempt_count = 1;
++#endif
++	if (unlikely(p->policy == SCHED_FIFO))
++		goto out;
++	/*
++	 * Share the timeslice between parent and child, thus the
++	 * total amount of pending timeslices in the system doesn't change,
++	 * resulting in more scheduling fairness. If it's negative, it won't
++	 * matter since that's the same as being 0. current's time_slice is
++	 * actually in rq_time_slice when it's running.
++	 */
++	local_irq_disable();
++	rq = task_rq(current);
++	if (likely(rq->rq_time_slice > 0)) {
++		rq->rq_time_slice /= 2;
++		/*
++		 * The remainder of the first timeslice might be recovered by
++		 * the parent if the child exits early enough.
++		 */
++		p->first_time_slice = 1;
++	}
++	p->rt.time_slice = rq->rq_time_slice;
++	local_irq_enable();
++out:
++	put_cpu();
++}
++
++/*
++ * wake_up_new_task - wake up a newly created task for the first time.
++ *
++ * This function will do some initial scheduler statistics housekeeping
++ * that must be done for every newly created context, then puts the task
++ * on the runqueue and wakes it.
++ */
++void wake_up_new_task(struct task_struct *p, unsigned long clone_flags)
++{
++	struct task_struct *parent;
++	unsigned long flags;
++	struct rq *rq;
++
++	rq = time_task_grq_lock(p, &flags); ;
++	parent = p->parent;
++	BUG_ON(p->state != TASK_RUNNING);
++	set_task_cpu(p, task_cpu(parent));
++
++	activate_task(p, rq);
++	trace_sched_wakeup_new(rq, p, 1);
++	if (!(clone_flags & CLONE_VM) && rq->curr == parent &&
++		!suitable_idle_cpus(p)) {
++		/*
++		 * The VM isn't cloned, so we're in a good position to
++		 * do child-runs-first in anticipation of an exec. This
++		 * usually avoids a lot of COW overhead.
++		 */
++			resched_task(parent);
++	} else
++		try_preempt(p);
++	task_grq_unlock(&flags);
++}
++
++/*
++ * Potentially available exiting-child timeslices are
++ * retrieved here - this way the parent does not get
++ * penalized for creating too many threads.
++ *
++ * (this cannot be used to 'generate' timeslices
++ * artificially, because any timeslice recovered here
++ * was given away by the parent in the first place.)
++ */
++void sched_exit(struct task_struct *p)
++{
++	struct task_struct *parent;
++	unsigned long flags;
++	struct rq *rq;
++
++	if (p->first_time_slice) {
++		parent = p->parent;
++		rq = task_grq_lock(parent, &flags);
++		parent->rt.time_slice += p->rt.time_slice;
++		if (unlikely(parent->rt.time_slice > timeslice()))
++			parent->rt.time_slice = timeslice();
++		task_grq_unlock(&flags);
++	}
++}
++
++#ifdef CONFIG_PREEMPT_NOTIFIERS
++
++/**
++ * preempt_notifier_register - tell me when current is being preempted & rescheduled
++ * @notifier: notifier struct to register
++ */
++void preempt_notifier_register(struct preempt_notifier *notifier)
++{
++	hlist_add_head(&notifier->link, &current->preempt_notifiers);
++}
++EXPORT_SYMBOL_GPL(preempt_notifier_register);
++
++/**
++ * preempt_notifier_unregister - no longer interested in preemption notifications
++ * @notifier: notifier struct to unregister
++ *
++ * This is safe to call from within a preemption notifier.
++ */
++void preempt_notifier_unregister(struct preempt_notifier *notifier)
++{
++	hlist_del(&notifier->link);
++}
++EXPORT_SYMBOL_GPL(preempt_notifier_unregister);
++
++static void fire_sched_in_preempt_notifiers(struct task_struct *curr)
++{
++	struct preempt_notifier *notifier;
++	struct hlist_node *node;
++
++	hlist_for_each_entry(notifier, node, &curr->preempt_notifiers, link)
++		notifier->ops->sched_in(notifier, raw_smp_processor_id());
++}
++
++static void
++fire_sched_out_preempt_notifiers(struct task_struct *curr,
++				 struct task_struct *next)
++{
++	struct preempt_notifier *notifier;
++	struct hlist_node *node;
++
++	hlist_for_each_entry(notifier, node, &curr->preempt_notifiers, link)
++		notifier->ops->sched_out(notifier, next);
++}
++
++#else /* !CONFIG_PREEMPT_NOTIFIERS */
++
++static void fire_sched_in_preempt_notifiers(struct task_struct *curr)
++{
++}
++
++static void
++fire_sched_out_preempt_notifiers(struct task_struct *curr,
++				 struct task_struct *next)
++{
++}
++
++#endif /* CONFIG_PREEMPT_NOTIFIERS */
++
++/**
++ * prepare_task_switch - prepare to switch tasks
++ * @rq: the runqueue preparing to switch
++ * @next: the task we are going to switch to.
++ *
++ * This is called with the rq lock held and interrupts off. It must
++ * be paired with a subsequent finish_task_switch after the context
++ * switch.
++ *
++ * prepare_task_switch sets up locking and calls architecture specific
++ * hooks.
++ */
++static inline void
++prepare_task_switch(struct rq *rq, struct task_struct *prev,
++		    struct task_struct *next)
++{
++	fire_sched_out_preempt_notifiers(prev, next);
++	prepare_lock_switch(rq, next);
++	prepare_arch_switch(next);
++}
++
++/**
++ * finish_task_switch - clean up after a task-switch
++ * @rq: runqueue associated with task-switch
++ * @prev: the thread we just switched away from.
++ *
++ * finish_task_switch must be called after the context switch, paired
++ * with a prepare_task_switch call before the context switch.
++ * finish_task_switch will reconcile locking set up by prepare_task_switch,
++ * and do any other architecture-specific cleanup actions.
++ *
++ * Note that we may have delayed dropping an mm in context_switch(). If
++ * so, we finish that here outside of the runqueue lock.  (Doing it
++ * with the lock held can cause deadlocks; see schedule() for
++ * details.)
++ */
++static inline void finish_task_switch(struct rq *rq, struct task_struct *prev)
++	__releases(grq.lock)
++{
++	struct mm_struct *mm = rq->prev_mm;
++	long prev_state;
++
++	rq->prev_mm = NULL;
++
++	/*
++	 * A task struct has one reference for the use as "current".
++	 * If a task dies, then it sets TASK_DEAD in tsk->state and calls
++	 * schedule one last time. The schedule call will never return, and
++	 * the scheduled task must drop that reference.
++	 * The test for TASK_DEAD must occur while the runqueue locks are
++	 * still held, otherwise prev could be scheduled on another cpu, die
++	 * there before we look at prev->state, and then the reference would
++	 * be dropped twice.
++	 *		Manfred Spraul <manfred@colorfullife.com>
++	 */
++	prev_state = prev->state;
++	finish_arch_switch(prev);
++	perf_counter_task_sched_in(current, cpu_of(rq));
++	finish_lock_switch(rq, prev);
++
++	fire_sched_in_preempt_notifiers(current);
++	if (mm)
++		mmdrop(mm);
++	if (unlikely(prev_state == TASK_DEAD)) {
++		/*
++		 * Remove function-return probe instances associated with this
++		 * task and put them back on the free list.
++	 	 */
++		kprobe_flush_task(prev);
++		put_task_struct(prev);
++	}
++}
++
++/**
++ * schedule_tail - first thing a freshly forked thread must call.
++ * @prev: the thread we just switched away from.
++ */
++asmlinkage void schedule_tail(struct task_struct *prev)
++	__releases(grq.lock)
++{
++	struct rq *rq = this_rq();
++
++	finish_task_switch(rq, prev);
++#ifdef __ARCH_WANT_UNLOCKED_CTXSW
++	/* In this case, finish_task_switch does not reenable preemption */
++	preempt_enable();
++#endif
++	if (current->set_child_tid)
++		put_user(current->pid, current->set_child_tid);
++}
++
++/*
++ * context_switch - switch to the new MM and the new
++ * thread's register state.
++ */
++static inline void
++context_switch(struct rq *rq, struct task_struct *prev,
++	       struct task_struct *next)
++{
++	struct mm_struct *mm, *oldmm;
++
++	prepare_task_switch(rq, prev, next);
++	trace_sched_switch(rq, prev, next);
++	mm = next->mm;
++	oldmm = prev->active_mm;
++	/*
++	 * For paravirt, this is coupled with an exit in switch_to to
++	 * combine the page table reload and the switch backend into
++	 * one hypercall.
++	 */
++	arch_start_context_switch(prev);
++
++	if (unlikely(!mm)) {
++		next->active_mm = oldmm;
++		atomic_inc(&oldmm->mm_count);
++		enter_lazy_tlb(oldmm, next);
++	} else
++		switch_mm(oldmm, mm, next);
++
++	if (unlikely(!prev->mm)) {
++		prev->active_mm = NULL;
++		rq->prev_mm = oldmm;
++	}
++	/*
++	 * Since the runqueue lock will be released by the next
++	 * task (which is an invalid locking op but in the case
++	 * of the scheduler it's an obvious special-case), so we
++	 * do an early lockdep release here:
++	 */
++#ifndef __ARCH_WANT_UNLOCKED_CTXSW
++	spin_release(&grq.lock.dep_map, 1, _THIS_IP_);
++#endif
++
++	/* Here we just switch the register state and the stack. */
++	switch_to(prev, next, prev);
++
++	barrier();
++	/*
++	 * this_rq must be evaluated again because prev may have moved
++	 * CPUs since it called schedule(), thus the 'rq' on its stack
++	 * frame will be invalid.
++	 */
++	finish_task_switch(this_rq(), prev);
++}
++
++/*
++ * nr_running, nr_uninterruptible and nr_context_switches:
++ *
++ * externally visible scheduler statistics: current number of runnable
++ * threads, current number of uninterruptible-sleeping threads, total
++ * number of context switches performed since bootup. All are measured
++ * without grabbing the grq lock but the occasional inaccurate result
++ * doesn't matter so long as it's positive.
++ */
++unsigned long nr_running(void)
++{
++	long nr = grq.nr_running;
++
++	if (unlikely(nr < 0))
++		nr = 0;
++	return (unsigned long)nr;
++}
++
++unsigned long nr_uninterruptible(void)
++{
++	unsigned long nu = grq.nr_uninterruptible;
++
++	if (unlikely(nu < 0))
++		nu = 0;
++	return nu;
++}
++
++unsigned long long nr_context_switches(void)
++{
++	long long ns = grq.nr_switches;
++
++	/* This is of course impossible */
++	if (unlikely(ns < 0))
++		ns = 1;
++	return (long long)ns;
++}
++
++unsigned long nr_iowait(void)
++{
++	unsigned long i, sum = 0;
++
++	for_each_possible_cpu(i)
++		sum += atomic_read(&cpu_rq(i)->nr_iowait);
++
++	return sum;
++}
++
++unsigned long nr_active(void)
++{
++	return nr_running() + nr_uninterruptible();
++}
++
++/* Variables and functions for calc_load */
++static unsigned long calc_load_update;
++unsigned long avenrun[3];
++EXPORT_SYMBOL(avenrun);
++
++/**
++ * get_avenrun - get the load average array
++ * @loads:	pointer to dest load array
++ * @offset:	offset to add
++ * @shift:	shift count to shift the result left
++ *
++ * These values are estimates at best, so no need for locking.
++ */
++void get_avenrun(unsigned long *loads, unsigned long offset, int shift)
++{
++	loads[0] = (avenrun[0] + offset) << shift;
++	loads[1] = (avenrun[1] + offset) << shift;
++	loads[2] = (avenrun[2] + offset) << shift;
++}
++
++static unsigned long
++calc_load(unsigned long load, unsigned long exp, unsigned long active)
++{
++	load *= exp;
++	load += active * (FIXED_1 - exp);
++	return load >> FSHIFT;
++}
++
++/*
++ * calc_load - update the avenrun load estimates every LOAD_FREQ seconds.
++ */
++void calc_global_load(void)
++{
++	long active;
++
++	if (time_before(jiffies, calc_load_update))
++		return;
++	active = nr_active() * FIXED_1;
++
++	avenrun[0] = calc_load(avenrun[0], EXP_1, active);
++	avenrun[1] = calc_load(avenrun[1], EXP_5, active);
++	avenrun[2] = calc_load(avenrun[2], EXP_15, active);
++
++	calc_load_update = jiffies + LOAD_FREQ;
++}
++
++DEFINE_PER_CPU(struct kernel_stat, kstat);
++
++EXPORT_PER_CPU_SYMBOL(kstat);
++
++/*
++ * On each tick, see what percentage of that tick was attributed to each
++ * component and add the percentage to the _pc values. Once a _pc value has
++ * accumulated one tick's worth, account for that. This means the total
++ * percentage of load components will always be 100 per tick.
++ */
++static void pc_idle_time(struct rq *rq, unsigned long pc)
++{
++	struct cpu_usage_stat *cpustat = &kstat_this_cpu.cpustat;
++	cputime64_t tmp = cputime_to_cputime64(jiffies_to_cputime(1));
++
++	if (atomic_read(&rq->nr_iowait) > 0) {
++		rq->iowait_pc += pc;
++		if (rq->iowait_pc >= 100) {
++			rq->iowait_pc %= 100;
++			cpustat->iowait = cputime64_add(cpustat->iowait, tmp);
++		}
++	} else {
++		rq->idle_pc += pc;
++		if (rq->idle_pc >= 100) {
++			rq->idle_pc %= 100;
++			cpustat->idle = cputime64_add(cpustat->idle, tmp);
++		}
++	}
++}
++
++static void
++pc_system_time(struct rq *rq, struct task_struct *p, int hardirq_offset,
++	       unsigned long pc, unsigned long ns)
++{
++	struct cpu_usage_stat *cpustat = &kstat_this_cpu.cpustat;
++	cputime_t one_jiffy = jiffies_to_cputime(1);
++	cputime_t one_jiffy_scaled = cputime_to_scaled(one_jiffy);
++	cputime64_t tmp = cputime_to_cputime64(one_jiffy);
++
++	p->stime_pc += pc;
++	if (p->stime_pc >= 100) {
++		p->stime_pc -= 100;
++		p->stime = cputime_add(p->stime, one_jiffy);
++		p->stimescaled = cputime_add(p->stimescaled, one_jiffy_scaled);
++		account_group_system_time(p, one_jiffy);
++		acct_update_integrals(p);
++	}
++	p->se.sum_exec_runtime += ns;
++
++	if (hardirq_count() - hardirq_offset)
++		rq->irq_pc += pc;
++	else if (softirq_count()) {
++		rq->softirq_pc += pc;
++		if (rq->softirq_pc >= 100) {
++			rq->softirq_pc %= 100;
++			cpustat->softirq = cputime64_add(cpustat->softirq, tmp);
++		}
++	} else {
++		rq->system_pc += pc;
++		if (rq->system_pc >= 100) {
++			rq->system_pc %= 100;
++			cpustat->system = cputime64_add(cpustat->system, tmp);
++		}
++	}
++}
++
++static void pc_user_time(struct rq *rq, struct task_struct *p,
++			 unsigned long pc, unsigned long ns)
++{
++	struct cpu_usage_stat *cpustat = &kstat_this_cpu.cpustat;
++	cputime_t one_jiffy = jiffies_to_cputime(1);
++	cputime_t one_jiffy_scaled = cputime_to_scaled(one_jiffy);
++	cputime64_t tmp = cputime_to_cputime64(one_jiffy);
++
++	p->utime_pc += pc;
++	if (p->utime_pc >= 100) {
++		p->utime_pc -= 100;
++		p->utime = cputime_add(p->utime, one_jiffy);
++		p->utimescaled = cputime_add(p->utimescaled, one_jiffy_scaled);
++		account_group_user_time(p, one_jiffy);
++		acct_update_integrals(p);
++	}
++	p->se.sum_exec_runtime += ns;
++
++	if (TASK_NICE(p) > 0 || idleprio_task(p)) {
++		rq->nice_pc += pc;
++		if (rq->nice_pc >= 100) {
++			rq->nice_pc %= 100;
++			cpustat->nice = cputime64_add(cpustat->nice, tmp);
++		}
++	} else {
++		rq->user_pc += pc;
++		if (rq->user_pc >= 100) {
++			rq->user_pc %= 100;
++			cpustat->user = cputime64_add(cpustat->user, tmp);
++		}
++	}
++}
++
++/* Convert nanoseconds to percentage of one tick. */
++#define NS_TO_PC(NS)	(NS * 100 / JIFFIES_TO_NS(1))
++
++/*
++ * This is called on clock ticks and on context switches.
++ * Bank in p->se.sum_exec_runtime the ns elapsed since the last tick or switch.
++ * CPU scheduler quota accounting is also performed here in microseconds.
++ * The value returned from sched_clock() occasionally gives bogus values so
++ * some sanity checking is required. Time is supposed to be banked all the
++ * time so default to half a tick to make up for when sched_clock reverts
++ * to just returning jiffies, and for hardware that can't do tsc.
++ */
++static void
++update_cpu_clock(struct rq *rq, struct task_struct *p, int tick)
++{
++	long time_diff = rq->clock - p->last_ran;
++	long account_ns = rq->clock - rq->timekeep_clock;
++	struct task_struct *idle = rq->idle;
++	unsigned long account_pc;
++
++	/*
++	 * There should be less than or equal to one jiffy worth, and not
++	 * negative/overflow. time_diff is only used for internal scheduler
++	 * time_slice accounting.
++	 */
++	if (time_diff <= 0)
++		time_diff = JIFFIES_TO_NS(1) / 2;
++	else if (time_diff > JIFFIES_TO_NS(1))
++		time_diff = JIFFIES_TO_NS(1);
++
++	if (unlikely(account_ns < 0))
++		account_ns = 0;
++
++	account_pc = NS_TO_PC(account_ns);
++
++	if (tick) {
++		int user_tick = user_mode(get_irq_regs());
++
++		/* Accurate tick timekeeping */
++		if (user_tick)
++			pc_user_time(rq, p, account_pc, account_ns);
++		else if (p != idle || (irq_count() != HARDIRQ_OFFSET))
++			pc_system_time(rq, p, HARDIRQ_OFFSET,
++				       account_pc, account_ns);
++		else
++			pc_idle_time(rq, account_pc);
++	} else {
++		/* Accurate subtick timekeeping */
++		if (p == idle)
++			pc_idle_time(rq, account_pc);
++		else
++			pc_user_time(rq, p, account_pc, account_ns);
++	}
++
++	/* time_slice accounting is done in usecs to avoid overflow on 32bit */
++	if (rq->rq_policy != SCHED_FIFO && p != idle)
++		rq->rq_time_slice -= time_diff / 1000;
++	p->last_ran = rq->timekeep_clock = rq->clock;
++}
++
++/*
++ * Return any ns on the sched_clock that have not yet been accounted in
++ * @p in case that task is currently running.
++ *
++ * Called with task_grq_lock() held on @rq.
++ */
++static u64 do_task_delta_exec(struct task_struct *p, struct rq *rq)
++{
++	u64 ns = 0;
++
++	if (p == rq->curr) {
++		update_rq_clock(rq);
++		ns = rq->clock - p->last_ran;
++		if ((s64)ns < 0)
++			ns = 0;
++	}
++
++	return ns;
++}
++
++unsigned long long task_delta_exec(struct task_struct *p)
++{
++	unsigned long flags;
++	struct rq *rq;
++	u64 ns = 0;
++
++	rq = task_grq_lock(p, &flags);
++	ns = do_task_delta_exec(p, rq);
++	task_grq_unlock(&flags);
++
++	return ns;
++}
++
++/*
++ * Return accounted runtime for the task.
++ * In case the task is currently running, return the runtime plus current's
++ * pending runtime that have not been accounted yet.
++ */
++unsigned long long task_sched_runtime(struct task_struct *p)
++{
++	unsigned long flags;
++	struct rq *rq;
++	u64 ns = 0;
++
++	rq = task_grq_lock(p, &flags);
++	ns = p->se.sum_exec_runtime + do_task_delta_exec(p, rq);
++	task_grq_unlock(&flags);
++
++	return ns;
++}
++
++/*
++ * Return sum_exec_runtime for the thread group.
++ * In case the task is currently running, return the sum plus current's
++ * pending runtime that have not been accounted yet.
++ *
++ * Note that the thread group might have other running tasks as well,
++ * so the return value not includes other pending runtime that other
++ * running tasks might have.
++ */
++unsigned long long thread_group_sched_runtime(struct task_struct *p)
++{
++	struct task_cputime totals;
++	unsigned long flags;
++	struct rq *rq;
++	u64 ns;
++
++	rq = task_grq_lock(p, &flags);
++	thread_group_cputime(p, &totals);
++	ns = totals.sum_exec_runtime + do_task_delta_exec(p, rq);
++	task_grq_unlock(&flags);
++
++	return ns;
++}
++
++/* Compatibility crap for removal */
++void account_user_time(struct task_struct *p, cputime_t cputime,
++		       cputime_t cputime_scaled)
++{
++}
++
++void account_idle_time(cputime_t cputime)
++{
++}
++
++/*
++ * Account guest cpu time to a process.
++ * @p: the process that the cpu time gets accounted to
++ * @cputime: the cpu time spent in virtual machine since the last update
++ * @cputime_scaled: cputime scaled by cpu frequency
++ */
++static void account_guest_time(struct task_struct *p, cputime_t cputime,
++			       cputime_t cputime_scaled)
++{
++	cputime64_t tmp;
++	struct cpu_usage_stat *cpustat = &kstat_this_cpu.cpustat;
++
++	tmp = cputime_to_cputime64(cputime);
++
++	/* Add guest time to process. */
++	p->utime = cputime_add(p->utime, cputime);
++	p->utimescaled = cputime_add(p->utimescaled, cputime_scaled);
++	account_group_user_time(p, cputime);
++	p->gtime = cputime_add(p->gtime, cputime);
++
++	/* Add guest time to cpustat. */
++	cpustat->user = cputime64_add(cpustat->user, tmp);
++	cpustat->guest = cputime64_add(cpustat->guest, tmp);
++}
++
++/*
++ * Account system cpu time to a process.
++ * @p: the process that the cpu time gets accounted to
++ * @hardirq_offset: the offset to subtract from hardirq_count()
++ * @cputime: the cpu time spent in kernel space since the last update
++ * @cputime_scaled: cputime scaled by cpu frequency
++ * This is for guest only now.
++ */
++void account_system_time(struct task_struct *p, int hardirq_offset,
++			 cputime_t cputime, cputime_t cputime_scaled)
++{
++
++	if ((p->flags & PF_VCPU) && (irq_count() - hardirq_offset == 0))
++		account_guest_time(p, cputime, cputime_scaled);
++}
++
++/*
++ * Account for involuntary wait time.
++ * @steal: the cpu time spent in involuntary wait
++ */
++void account_steal_time(cputime_t cputime)
++{
++	struct cpu_usage_stat *cpustat = &kstat_this_cpu.cpustat;
++	cputime64_t cputime64 = cputime_to_cputime64(cputime);
++
++	cpustat->steal = cputime64_add(cpustat->steal, cputime64);
++}
++
++/*
++ * Account for idle time.
++ * @cputime: the cpu time spent in idle wait
++ */
++static void account_idle_times(cputime_t cputime)
++{
++	struct cpu_usage_stat *cpustat = &kstat_this_cpu.cpustat;
++	cputime64_t cputime64 = cputime_to_cputime64(cputime);
++	struct rq *rq = this_rq();
++
++	if (atomic_read(&rq->nr_iowait) > 0)
++		cpustat->iowait = cputime64_add(cpustat->iowait, cputime64);
++	else
++		cpustat->idle = cputime64_add(cpustat->idle, cputime64);
++}
++
++#ifndef CONFIG_VIRT_CPU_ACCOUNTING
++
++void account_process_tick(struct task_struct *p, int user_tick)
++{
++}
++
++/*
++ * Account multiple ticks of steal time.
++ * @p: the process from which the cpu time has been stolen
++ * @ticks: number of stolen ticks
++ */
++void account_steal_ticks(unsigned long ticks)
++{
++	account_steal_time(jiffies_to_cputime(ticks));
++}
++
++/*
++ * Account multiple ticks of idle time.
++ * @ticks: number of stolen ticks
++ */
++void account_idle_ticks(unsigned long ticks)
++{
++	account_idle_times(jiffies_to_cputime(ticks));
++}
++#endif
++
++/*
++ * Functions to test for when SCHED_ISO tasks have used their allocated
++ * quota as real time scheduling and convert them back to SCHED_NORMAL.
++ * Where possible, the data is tested lockless, to avoid grabbing grq_lock
++ * because the occasional inaccurate result won't matter. However the
++ * data is only ever modified under lock.
++ */
++static void set_iso_refractory(void)
++{
++	grq_lock();
++	grq.iso_refractory = 1;
++	grq_unlock();
++}
++
++static void clear_iso_refractory(void)
++{
++	grq_lock();
++	grq.iso_refractory = 0;
++	grq_unlock();
++}
++
++/*
++ * Test if SCHED_ISO tasks have run longer than their alloted period as RT
++ * tasks and set the refractory flag if necessary. There is 10% hysteresis
++ * for unsetting the flag.
++ */
++static unsigned int test_ret_isorefractory(struct rq *rq)
++{
++	if (likely(!grq.iso_refractory)) {
++		if (grq.iso_ticks / ISO_PERIOD > sched_iso_cpu)
++			set_iso_refractory();
++	} else {
++		if (grq.iso_ticks / ISO_PERIOD < (sched_iso_cpu * 90 / 100))
++			clear_iso_refractory();
++	}
++	return grq.iso_refractory;
++}
++
++static void iso_tick(void)
++{
++	grq_lock();
++	grq.iso_ticks += 100;
++	grq_unlock();
++}
++
++/* No SCHED_ISO task was running so decrease rq->iso_ticks */
++static inline void no_iso_tick(void)
++{
++	if (grq.iso_ticks) {
++		grq_lock();
++		grq.iso_ticks = grq.iso_ticks * (ISO_PERIOD - 1) / ISO_PERIOD;
++		grq_unlock();
++	}
++}
++
++static int rq_running_iso(struct rq *rq)
++{
++	return rq->rq_prio == ISO_PRIO;
++}
++
++/* This manages tasks that have run out of timeslice during a scheduler_tick */
++static void task_running_tick(struct rq *rq)
++{
++	struct task_struct *p;
++
++	/*
++	 * If a SCHED_ISO task is running we increment the iso_ticks. In
++	 * order to prevent SCHED_ISO tasks from causing starvation in the
++	 * presence of true RT tasks we account those as iso_ticks as well.
++	 */
++	if ((rt_queue(rq) || (iso_queue(rq) && !grq.iso_refractory))) {
++		if (grq.iso_ticks <= (ISO_PERIOD * 100) - 100)
++			iso_tick();
++	} else
++		no_iso_tick();
++
++	if (iso_queue(rq)) {
++		if (unlikely(test_ret_isorefractory(rq))) {
++			if (rq_running_iso(rq)) {
++				/*
++				 * SCHED_ISO task is running as RT and limit
++				 * has been hit. Force it to reschedule as
++				 * SCHED_NORMAL by zeroing its time_slice
++				 */
++				rq->rq_time_slice = 0;
++			}
++		}
++	}
++
++	/* SCHED_FIFO tasks never run out of timeslice. */
++	if (rq_idle(rq) || rq->rq_time_slice > 0 || rq->rq_policy == SCHED_FIFO)
++		return;
++
++	/* p->rt.time_slice <= 0. We only modify task_struct under grq lock */
++	grq_lock();
++	p = rq->curr;
++	if (likely(task_running(p))) {
++		requeue_task(p);
++		set_tsk_need_resched(p);
++	}
++	grq_unlock();
++}
++
++void wake_up_idle_cpu(int cpu);
++
++/*
++ * This function gets called by the timer code, with HZ frequency.
++ * We call it with interrupts disabled. The data modified is all
++ * local to struct rq so we don't need to grab grq lock.
++ */
++void scheduler_tick(void)
++{
++	int cpu = smp_processor_id();
++	struct rq *rq = cpu_rq(cpu);
++
++	sched_clock_tick();
++	update_rq_clock(rq);
++	update_cpu_clock(rq, rq->curr, 1);
++	if (!rq_idle(rq))
++		task_running_tick(rq);
++	else {
++		no_iso_tick();
++		if (unlikely(queued_notrunning()))
++			set_tsk_need_resched(rq->idle);
++	}
++}
++
++notrace unsigned long get_parent_ip(unsigned long addr)
++{
++	if (in_lock_functions(addr)) {
++		addr = CALLER_ADDR2;
++		if (in_lock_functions(addr))
++			addr = CALLER_ADDR3;
++	}
++	return addr;
++}
++
++#if defined(CONFIG_PREEMPT) && (defined(CONFIG_DEBUG_PREEMPT) || \
++				defined(CONFIG_PREEMPT_TRACER))
++void __kprobes add_preempt_count(int val)
++{
++#ifdef CONFIG_DEBUG_PREEMPT
++	/*
++	 * Underflow?
++	 */
++	if (DEBUG_LOCKS_WARN_ON((preempt_count() < 0)))
++		return;
++#endif
++	preempt_count() += val;
++#ifdef CONFIG_DEBUG_PREEMPT
++	/*
++	 * Spinlock count overflowing soon?
++	 */
++	DEBUG_LOCKS_WARN_ON((preempt_count() & PREEMPT_MASK) >=
++				PREEMPT_MASK - 10);
++#endif
++	if (preempt_count() == val)
++		trace_preempt_off(CALLER_ADDR0, get_parent_ip(CALLER_ADDR1));
++}
++EXPORT_SYMBOL(add_preempt_count);
++
++void __kprobes sub_preempt_count(int val)
++{
++#ifdef CONFIG_DEBUG_PREEMPT
++	/*
++	 * Underflow?
++	 */
++	if (DEBUG_LOCKS_WARN_ON(val > preempt_count()))
++		return;
++	/*
++	 * Is the spinlock portion underflowing?
++	 */
++	if (DEBUG_LOCKS_WARN_ON((val < PREEMPT_MASK) &&
++			!(preempt_count() & PREEMPT_MASK)))
++		return;
++#endif
++
++	if (preempt_count() == val)
++		trace_preempt_on(CALLER_ADDR0, get_parent_ip(CALLER_ADDR1));
++	preempt_count() -= val;
++}
++EXPORT_SYMBOL(sub_preempt_count);
++#endif
++
++/*
++ * Deadline is "now" in jiffies + (offset by priority). Setting the deadline
++ * is the key to everything. It distributes cpu fairly amongst tasks of the
++ * same nice value, it proportions cpu according to nice level, it means the
++ * task that last woke up the longest ago has the earliest deadline, thus
++ * ensuring that interactive tasks get low latency on wake up.
++ */
++static inline int prio_deadline_diff(struct task_struct *p)
++{
++	return (pratio(p) * rr_interval * HZ / 1000 / 100) ? : 1;
++}
++
++static inline int longest_deadline(void)
++{
++	return (prio_ratios[39] * rr_interval * HZ / 1000 / 100);
++}
++
++/*
++ * SCHED_IDLE tasks still have a deadline set, but offset by to nice +19.
++ * This allows nice levels to work between IDLEPRIO tasks and gives a
++ * deadline longer than nice +19 for when they're scheduled as SCHED_NORMAL
++ * tasks.
++ */
++static inline void time_slice_expired(struct task_struct *p)
++{
++	reset_first_time_slice(p);
++	p->rt.time_slice = timeslice();
++	p->deadline = jiffies + prio_deadline_diff(p);
++	if (idleprio_task(p))
++		p->deadline += longest_deadline();
++}
++
++static inline void check_deadline(struct task_struct *p)
++{
++	if (p->rt.time_slice <= 0)
++		time_slice_expired(p);
++}
++
++/*
++ * O(n) lookup of all tasks in the global runqueue. The real brainfuck
++ * of lock contention and O(n). It's not really O(n) as only the queued,
++ * but not running tasks are scanned, and is O(n) queued in the worst case
++ * scenario only because the right task can be found before scanning all of
++ * them.
++ * Tasks are selected in this order:
++ * Real time tasks are selected purely by their static priority and in the
++ * order they were queued, so the lowest value idx, and the first queued task
++ * of that priority value is chosen.
++ * If no real time tasks are found, the SCHED_ISO priority is checked, and
++ * all SCHED_ISO tasks have the same priority value, so they're selected by
++ * the earliest deadline value.
++ * If no SCHED_ISO tasks are found, SCHED_NORMAL tasks are selected by the
++ * earliest deadline.
++ * Finally if no SCHED_NORMAL tasks are found, SCHED_IDLEPRIO tasks are
++ * selected by the earliest deadline.
++ */
++static inline struct
++task_struct *earliest_deadline_task(struct rq *rq, struct task_struct *idle)
++{
++	unsigned long dl, earliest_deadline = 0; /* Initialise to silence compiler */
++	struct task_struct *p, *edt;
++	unsigned int cpu = rq->cpu;
++	struct list_head *queue;
++	int idx = 0;
++
++	edt = idle;
++retry:
++	idx = find_next_bit(grq.prio_bitmap, PRIO_LIMIT, idx);
++	if (idx >= PRIO_LIMIT)
++		goto out;
++	queue = &grq.queue[idx];
++	list_for_each_entry(p, queue, rt.run_list) {
++		/* Make sure cpu affinity is ok */
++		if (!cpu_isset(cpu, p->cpus_allowed))
++			continue;
++		if (idx < MAX_RT_PRIO) {
++			/* We found an rt task */
++			edt = p;
++			goto out_take;
++		}
++
++		/*
++		 * No rt task, select the earliest deadline task now.
++		 * On the 1st run the 2nd condition is never used, so
++		 * there is no need to initialise earliest_deadline
++		 * before. Normalise all old deadlines to now.
++		 */
++		if (time_before(p->deadline, jiffies))
++			dl = jiffies;
++		else
++			dl = p->deadline;
++
++		if (edt == idle ||
++		    time_before(dl, earliest_deadline)) {
++			earliest_deadline = dl;
++			edt = p;
++		}
++	}
++	if (edt == idle) {
++		if (++idx < PRIO_LIMIT)
++			goto retry;
++		goto out;
++	}
++out_take:
++	take_task(rq, edt);
++out:
++	return edt;
++}
++
++#ifdef CONFIG_SMP
++static inline void set_cpuidle_map(unsigned long cpu)
++{
++	cpu_set(cpu, grq.cpu_idle_map);
++}
++
++static inline void clear_cpuidle_map(unsigned long cpu)
++{
++	cpu_clear(cpu, grq.cpu_idle_map);
++}
++
++#else /* CONFIG_SMP */
++static inline void set_cpuidle_map(unsigned long cpu)
++{
++}
++
++static inline void clear_cpuidle_map(unsigned long cpu)
++{
++}
++#endif /* !CONFIG_SMP */
++
++/*
++ * Print scheduling while atomic bug:
++ */
++static noinline void __schedule_bug(struct task_struct *prev)
++{
++	struct pt_regs *regs = get_irq_regs();
++
++	printk(KERN_ERR "BUG: scheduling while atomic: %s/%d/0x%08x\n",
++		prev->comm, prev->pid, preempt_count());
++
++	debug_show_held_locks(prev);
++	print_modules();
++	if (irqs_disabled())
++		print_irqtrace_events(prev);
++
++	if (regs)
++		show_regs(regs);
++	else
++		dump_stack();
++}
++
++/*
++ * Various schedule()-time debugging checks and statistics:
++ */
++static inline void schedule_debug(struct task_struct *prev)
++{
++	/*
++	 * Test if we are atomic. Since do_exit() needs to call into
++	 * schedule() atomically, we ignore that path for now.
++	 * Otherwise, whine if we are scheduling when we should not be.
++	 */
++	if (unlikely(in_atomic_preempt_off() && !prev->exit_state))
++		__schedule_bug(prev);
++
++	profile_hit(SCHED_PROFILING, __builtin_return_address(0));
++
++	schedstat_inc(this_rq(), sched_count);
++#ifdef CONFIG_SCHEDSTATS
++	if (unlikely(prev->lock_depth >= 0)) {
++		schedstat_inc(this_rq(), bkl_count);
++		schedstat_inc(prev, sched_info.bkl_count);
++	}
++#endif
++}
++
++/*
++ * schedule() is the main scheduler function.
++ */
++asmlinkage void __sched __schedule(void)
++{
++	struct task_struct *prev, *next, *idle;
++	int deactivate = 0, cpu;
++	long *switch_count;
++	struct rq *rq;
++	u64 now;
++
++	cpu = smp_processor_id();
++	rq = this_rq();
++	rcu_qsctr_inc(cpu);
++	prev = rq->curr;
++	switch_count = &prev->nivcsw;
++
++	release_kernel_lock(prev);
++need_resched_nonpreemptible:
++
++	schedule_debug(prev);
++	idle = rq->idle;
++	/*
++	 * The idle thread is not allowed to schedule!
++	 * Remove this check after it has been exercised a bit.
++	 */
++	if (unlikely(prev == idle) && prev->state != TASK_RUNNING) {
++		printk(KERN_ERR "bad: scheduling from the idle thread!\n");
++		dump_stack();
++	}
++
++	grq_lock_irq();
++	update_rq_clock(rq);
++	now = rq->clock;
++	update_cpu_clock(rq, prev, 0);
++
++	clear_tsk_need_resched(prev);
++
++	if (prev->state && !(preempt_count() & PREEMPT_ACTIVE)) {
++		if (unlikely(signal_pending_state(prev->state, prev)))
++			prev->state = TASK_RUNNING;
++		else
++			deactivate = 1;
++		switch_count = &prev->nvcsw;
++	}
++
++	if (prev != idle) {
++		/* Update all the information stored on struct rq */
++		prev->rt.time_slice = rq->rq_time_slice;
++		prev->deadline = rq->rq_deadline;
++		check_deadline(prev);
++		return_task(prev, deactivate);
++	}
++
++	if (likely(queued_notrunning())) {
++		next = earliest_deadline_task(rq, idle);
++	} else {
++		next = idle;
++		schedstat_inc(rq, sched_goidle);
++	}
++
++	if (next == rq->idle)
++		set_cpuidle_map(cpu);
++	else
++		clear_cpuidle_map(cpu);
++
++	prefetch(next);
++	prefetch_stack(next);
++
++	prev->timestamp = prev->last_ran = now;
++
++	if (likely(prev != next)) {
++		rq->rq_time_slice = next->rt.time_slice;
++		rq->rq_deadline = next->deadline;
++		rq->rq_prio = next->prio;
++
++		sched_info_switch(prev, next);
++		grq.nr_switches++;
++		next->oncpu = 1;
++		prev->oncpu = 0;
++		rq->curr = next;
++		++*switch_count;
++
++		context_switch(rq, prev, next); /* unlocks the rq */
++		/*
++		 * the context switch might have flipped the stack from under
++		 * us, hence refresh the local variables.
++		 */
++		cpu = smp_processor_id();
++		rq = cpu_rq(cpu);
++	} else
++		grq_unlock_irq();
++
++	if (unlikely(reacquire_kernel_lock(current) < 0))
++		goto need_resched_nonpreemptible;
++}
++
++asmlinkage void __sched schedule(void)
++{
++need_resched:
++	preempt_disable();
++	__schedule();
++	preempt_enable_no_resched();
++	if (unlikely(test_thread_flag(TIF_NEED_RESCHED)))
++		goto need_resched;
++}
++EXPORT_SYMBOL(schedule);
++
++#ifdef CONFIG_SMP
++int mutex_spin_on_owner(struct mutex *lock, struct thread_info *owner)
++{
++	return 0;
++}
++#endif
++
++#ifdef CONFIG_PREEMPT
++/*
++ * this is the entry point to schedule() from in-kernel preemption
++ * off of preempt_enable. Kernel preemptions off return from interrupt
++ * occur there and call schedule directly.
++ */
++asmlinkage void __sched preempt_schedule(void)
++{
++	struct thread_info *ti = current_thread_info();
++
++	/*
++	 * If there is a non-zero preempt_count or interrupts are disabled,
++	 * we do not want to preempt the current task. Just return..
++	 */
++	if (likely(ti->preempt_count || irqs_disabled()))
++		return;
++
++	do {
++		add_preempt_count(PREEMPT_ACTIVE);
++		schedule();
++		sub_preempt_count(PREEMPT_ACTIVE);
++
++		/*
++		 * Check again in case we missed a preemption opportunity
++		 * between schedule and now.
++		 */
++		barrier();
++	} while (need_resched());
++}
++EXPORT_SYMBOL(preempt_schedule);
++
++/*
++ * this is the entry point to schedule() from kernel preemption
++ * off of irq context.
++ * Note, that this is called and return with irqs disabled. This will
++ * protect us against recursive calling from irq.
++ */
++asmlinkage void __sched preempt_schedule_irq(void)
++{
++	struct thread_info *ti = current_thread_info();
++
++	/* Catch callers which need to be fixed */
++	BUG_ON(ti->preempt_count || !irqs_disabled());
++
++	do {
++		add_preempt_count(PREEMPT_ACTIVE);
++		local_irq_enable();
++		schedule();
++		local_irq_disable();
++		sub_preempt_count(PREEMPT_ACTIVE);
++
++		/*
++		 * Check again in case we missed a preemption opportunity
++		 * between schedule and now.
++		 */
++		barrier();
++	} while (need_resched());
++}
++
++#endif /* CONFIG_PREEMPT */
++
++int default_wake_function(wait_queue_t *curr, unsigned mode, int sync,
++			  void *key)
++{
++	return try_to_wake_up(curr->private, mode, sync);
++}
++EXPORT_SYMBOL(default_wake_function);
++
++/*
++ * The core wakeup function.  Non-exclusive wakeups (nr_exclusive == 0) just
++ * wake everything up.  If it's an exclusive wakeup (nr_exclusive == small +ve
++ * number) then we wake all the non-exclusive tasks and one exclusive task.
++ *
++ * There are circumstances in which we can try to wake a task which has already
++ * started to run but is not in state TASK_RUNNING.  try_to_wake_up() returns
++ * zero in this (rare) case, and we handle it by continuing to scan the queue.
++ */
++void __wake_up_common(wait_queue_head_t *q, unsigned int mode,
++		      int nr_exclusive, int sync, void *key)
++{
++	struct list_head *tmp, *next;
++
++	list_for_each_safe(tmp, next, &q->task_list) {
++		wait_queue_t *curr = list_entry(tmp, wait_queue_t, task_list);
++		unsigned flags = curr->flags;
++
++		if (curr->func(curr, mode, sync, key) &&
++				(flags & WQ_FLAG_EXCLUSIVE) && !--nr_exclusive)
++			break;
++	}
++}
++
++/**
++ * __wake_up - wake up threads blocked on a waitqueue.
++ * @q: the waitqueue
++ * @mode: which threads
++ * @nr_exclusive: how many wake-one or wake-many threads to wake up
++ * @key: is directly passed to the wakeup function
++ *
++ * It may be assumed that this function implies a write memory barrier before
++ * changing the task state if and only if any tasks are woken up.
++ */
++void __wake_up(wait_queue_head_t *q, unsigned int mode,
++			int nr_exclusive, void *key)
++{
++	unsigned long flags;
++
++	spin_lock_irqsave(&q->lock, flags);
++	__wake_up_common(q, mode, nr_exclusive, 0, key);
++	spin_unlock_irqrestore(&q->lock, flags);
++}
++EXPORT_SYMBOL(__wake_up);
++
++/*
++ * Same as __wake_up but called with the spinlock in wait_queue_head_t held.
++ */
++void __wake_up_locked(wait_queue_head_t *q, unsigned int mode)
++{
++	__wake_up_common(q, mode, 1, 0, NULL);
++}
++
++void __wake_up_locked_key(wait_queue_head_t *q, unsigned int mode, void *key)
++{
++	__wake_up_common(q, mode, 1, 0, key);
++}
++
++/**
++ * __wake_up_sync_key - wake up threads blocked on a waitqueue.
++ * @q: the waitqueue
++ * @mode: which threads
++ * @nr_exclusive: how many wake-one or wake-many threads to wake up
++ * @key: opaque value to be passed to wakeup targets
++ *
++ * The sync wakeup differs that the waker knows that it will schedule
++ * away soon, so while the target thread will be woken up, it will not
++ * be migrated to another CPU - ie. the two threads are 'synchronized'
++ * with each other. This can prevent needless bouncing between CPUs.
++ *
++ * On UP it can prevent extra preemption.
++ *
++ * It may be assumed that this function implies a write memory barrier before
++ * changing the task state if and only if any tasks are woken up.
++ */
++void __wake_up_sync_key(wait_queue_head_t *q, unsigned int mode,
++			int nr_exclusive, void *key)
++{
++	unsigned long flags;
++	int sync = 1;
++
++	if (unlikely(!q))
++		return;
++
++	if (unlikely(!nr_exclusive))
++		sync = 0;
++
++	spin_lock_irqsave(&q->lock, flags);
++	__wake_up_common(q, mode, nr_exclusive, sync, key);
++	spin_unlock_irqrestore(&q->lock, flags);
++}
++EXPORT_SYMBOL_GPL(__wake_up_sync_key);
++
++/**
++ * __wake_up_sync - wake up threads blocked on a waitqueue.
++ * @q: the waitqueue
++ * @mode: which threads
++ * @nr_exclusive: how many wake-one or wake-many threads to wake up
++ *
++ * The sync wakeup differs that the waker knows that it will schedule
++ * away soon, so while the target thread will be woken up, it will not
++ * be migrated to another CPU - ie. the two threads are 'synchronized'
++ * with each other. This can prevent needless bouncing between CPUs.
++ *
++ * On UP it can prevent extra preemption.
++ */
++void __wake_up_sync(wait_queue_head_t *q, unsigned int mode, int nr_exclusive)
++{
++	unsigned long flags;
++	int sync = 1;
++
++	if (unlikely(!q))
++		return;
++
++	if (unlikely(!nr_exclusive))
++		sync = 0;
++
++	spin_lock_irqsave(&q->lock, flags);
++	__wake_up_common(q, mode, nr_exclusive, sync, NULL);
++	spin_unlock_irqrestore(&q->lock, flags);
++}
++EXPORT_SYMBOL_GPL(__wake_up_sync);	/* For internal use only */
++
++/**
++ * complete: - signals a single thread waiting on this completion
++ * @x:  holds the state of this particular completion
++ *
++ * This will wake up a single thread waiting on this completion. Threads will be
++ * awakened in the same order in which they were queued.
++ *
++ * See also complete_all(), wait_for_completion() and related routines.
++ *
++ * It may be assumed that this function implies a write memory barrier before
++ * changing the task state if and only if any tasks are woken up.
++ */
++void complete(struct completion *x)
++{
++	unsigned long flags;
++
++	spin_lock_irqsave(&x->wait.lock, flags);
++	x->done++;
++	__wake_up_common(&x->wait, TASK_NORMAL, 1, 0, NULL);
++	spin_unlock_irqrestore(&x->wait.lock, flags);
++}
++EXPORT_SYMBOL(complete);
++
++/**
++ * complete_all: - signals all threads waiting on this completion
++ * @x:  holds the state of this particular completion
++ *
++ * This will wake up all threads waiting on this particular completion event.
++ *
++ * It may be assumed that this function implies a write memory barrier before
++ * changing the task state if and only if any tasks are woken up.
++ */
++void complete_all(struct completion *x)
++{
++	unsigned long flags;
++
++	spin_lock_irqsave(&x->wait.lock, flags);
++	x->done += UINT_MAX/2;
++	__wake_up_common(&x->wait, TASK_NORMAL, 0, 0, NULL);
++	spin_unlock_irqrestore(&x->wait.lock, flags);
++}
++EXPORT_SYMBOL(complete_all);
++
++static inline long __sched
++do_wait_for_common(struct completion *x, long timeout, int state)
++{
++	if (!x->done) {
++		DECLARE_WAITQUEUE(wait, current);
++
++		wait.flags |= WQ_FLAG_EXCLUSIVE;
++		__add_wait_queue_tail(&x->wait, &wait);
++		do {
++			if (signal_pending_state(state, current)) {
++				timeout = -ERESTARTSYS;
++				break;
++			}
++			__set_current_state(state);
++			spin_unlock_irq(&x->wait.lock);
++			timeout = schedule_timeout(timeout);
++			spin_lock_irq(&x->wait.lock);
++		} while (!x->done && timeout);
++		__remove_wait_queue(&x->wait, &wait);
++		if (!x->done)
++			return timeout;
++	}
++	x->done--;
++	return timeout ?: 1;
++}
++
++static long __sched
++wait_for_common(struct completion *x, long timeout, int state)
++{
++	might_sleep();
++
++	spin_lock_irq(&x->wait.lock);
++	timeout = do_wait_for_common(x, timeout, state);
++	spin_unlock_irq(&x->wait.lock);
++	return timeout;
++}
++
++/**
++ * wait_for_completion: - waits for completion of a task
++ * @x:  holds the state of this particular completion
++ *
++ * This waits to be signaled for completion of a specific task. It is NOT
++ * interruptible and there is no timeout.
++ *
++ * See also similar routines (i.e. wait_for_completion_timeout()) with timeout
++ * and interrupt capability. Also see complete().
++ */
++void __sched wait_for_completion(struct completion *x)
++{
++	wait_for_common(x, MAX_SCHEDULE_TIMEOUT, TASK_UNINTERRUPTIBLE);
++}
++EXPORT_SYMBOL(wait_for_completion);
++
++/**
++ * wait_for_completion_timeout: - waits for completion of a task (w/timeout)
++ * @x:  holds the state of this particular completion
++ * @timeout:  timeout value in jiffies
++ *
++ * This waits for either a completion of a specific task to be signaled or for a
++ * specified timeout to expire. The timeout is in jiffies. It is not
++ * interruptible.
++ */
++unsigned long __sched
++wait_for_completion_timeout(struct completion *x, unsigned long timeout)
++{
++	return wait_for_common(x, timeout, TASK_UNINTERRUPTIBLE);
++}
++EXPORT_SYMBOL(wait_for_completion_timeout);
++
++/**
++ * wait_for_completion_interruptible: - waits for completion of a task (w/intr)
++ * @x:  holds the state of this particular completion
++ *
++ * This waits for completion of a specific task to be signaled. It is
++ * interruptible.
++ */
++int __sched wait_for_completion_interruptible(struct completion *x)
++{
++	long t = wait_for_common(x, MAX_SCHEDULE_TIMEOUT, TASK_INTERRUPTIBLE);
++	if (t == -ERESTARTSYS)
++		return t;
++	return 0;
++}
++EXPORT_SYMBOL(wait_for_completion_interruptible);
++
++/**
++ * wait_for_completion_interruptible_timeout: - waits for completion (w/(to,intr))
++ * @x:  holds the state of this particular completion
++ * @timeout:  timeout value in jiffies
++ *
++ * This waits for either a completion of a specific task to be signaled or for a
++ * specified timeout to expire. It is interruptible. The timeout is in jiffies.
++ */
++unsigned long __sched
++wait_for_completion_interruptible_timeout(struct completion *x,
++					  unsigned long timeout)
++{
++	return wait_for_common(x, timeout, TASK_INTERRUPTIBLE);
++}
++EXPORT_SYMBOL(wait_for_completion_interruptible_timeout);
++
++/**
++ * wait_for_completion_killable: - waits for completion of a task (killable)
++ * @x:  holds the state of this particular completion
++ *
++ * This waits to be signaled for completion of a specific task. It can be
++ * interrupted by a kill signal.
++ */
++int __sched wait_for_completion_killable(struct completion *x)
++{
++	long t = wait_for_common(x, MAX_SCHEDULE_TIMEOUT, TASK_KILLABLE);
++	if (t == -ERESTARTSYS)
++		return t;
++	return 0;
++}
++EXPORT_SYMBOL(wait_for_completion_killable);
++
++/**
++ *	try_wait_for_completion - try to decrement a completion without blocking
++ *	@x:	completion structure
++ *
++ *	Returns: 0 if a decrement cannot be done without blocking
++ *		 1 if a decrement succeeded.
++ *
++ *	If a completion is being used as a counting completion,
++ *	attempt to decrement the counter without blocking. This
++ *	enables us to avoid waiting if the resource the completion
++ *	is protecting is not available.
++ */
++bool try_wait_for_completion(struct completion *x)
++{
++	int ret = 1;
++
++	spin_lock_irq(&x->wait.lock);
++	if (!x->done)
++		ret = 0;
++	else
++		x->done--;
++	spin_unlock_irq(&x->wait.lock);
++	return ret;
++}
++EXPORT_SYMBOL(try_wait_for_completion);
++
++/**
++ *	completion_done - Test to see if a completion has any waiters
++ *	@x:	completion structure
++ *
++ *	Returns: 0 if there are waiters (wait_for_completion() in progress)
++ *		 1 if there are no waiters.
++ *
++ */
++bool completion_done(struct completion *x)
++{
++	int ret = 1;
++
++	spin_lock_irq(&x->wait.lock);
++	if (!x->done)
++		ret = 0;
++	spin_unlock_irq(&x->wait.lock);
++	return ret;
++}
++EXPORT_SYMBOL(completion_done);
++
++static long __sched
++sleep_on_common(wait_queue_head_t *q, int state, long timeout)
++{
++	unsigned long flags;
++	wait_queue_t wait;
++
++	init_waitqueue_entry(&wait, current);
++
++	__set_current_state(state);
++
++	spin_lock_irqsave(&q->lock, flags);
++	__add_wait_queue(q, &wait);
++	spin_unlock(&q->lock);
++	timeout = schedule_timeout(timeout);
++	spin_lock_irq(&q->lock);
++	__remove_wait_queue(q, &wait);
++	spin_unlock_irqrestore(&q->lock, flags);
++
++	return timeout;
++}
++
++void __sched interruptible_sleep_on(wait_queue_head_t *q)
++{
++	sleep_on_common(q, TASK_INTERRUPTIBLE, MAX_SCHEDULE_TIMEOUT);
++}
++EXPORT_SYMBOL(interruptible_sleep_on);
++
++long __sched
++interruptible_sleep_on_timeout(wait_queue_head_t *q, long timeout)
++{
++	return sleep_on_common(q, TASK_INTERRUPTIBLE, timeout);
++}
++EXPORT_SYMBOL(interruptible_sleep_on_timeout);
++
++void __sched sleep_on(wait_queue_head_t *q)
++{
++	sleep_on_common(q, TASK_UNINTERRUPTIBLE, MAX_SCHEDULE_TIMEOUT);
++}
++EXPORT_SYMBOL(sleep_on);
++
++long __sched sleep_on_timeout(wait_queue_head_t *q, long timeout)
++{
++	return sleep_on_common(q, TASK_UNINTERRUPTIBLE, timeout);
++}
++EXPORT_SYMBOL(sleep_on_timeout);
++
++#ifdef CONFIG_RT_MUTEXES
++
++/*
++ * rt_mutex_setprio - set the current priority of a task
++ * @p: task
++ * @prio: prio value (kernel-internal form)
++ *
++ * This function changes the 'effective' priority of a task. It does
++ * not touch ->normal_prio like __setscheduler().
++ *
++ * Used by the rt_mutex code to implement priority inheritance logic.
++ */
++void rt_mutex_setprio(struct task_struct *p, int prio)
++{
++	unsigned long flags;
++	int queued, oldprio;
++	struct rq *rq;
++
++	BUG_ON(prio < 0 || prio > MAX_PRIO);
++
++	rq = time_task_grq_lock(p, &flags);
++
++	oldprio = p->prio;
++	queued = task_queued_only(p);
++	if (queued)
++		dequeue_task(p);
++	p->prio = prio;
++	if (task_running(p) && prio > oldprio)
++		resched_task(p);
++	if (queued) {
++		enqueue_task(p);
++		try_preempt(p);
++	}
++
++	task_grq_unlock(&flags);
++}
++
++#endif
++
++/*
++ * Adjust the deadline for when the priority is to change, before it's
++ * changed.
++ */
++static void adjust_deadline(struct task_struct *p, int new_prio)
++{
++	p->deadline += (prio_ratios[USER_PRIO(new_prio)] - pratio(p)) *
++			rr_interval * HZ / 1000 / 100;
++}
++
++void set_user_nice(struct task_struct *p, long nice)
++{
++	int queued, new_static;
++	unsigned long flags;
++	struct rq *rq;
++
++	if (TASK_NICE(p) == nice || nice < -20 || nice > 19)
++		return;
++	new_static = NICE_TO_PRIO(nice);
++	/*
++	 * We have to be careful, if called from sys_setpriority(),
++	 * the task might be in the middle of scheduling on another CPU.
++	 */
++	rq = time_task_grq_lock(p, &flags);
++	/*
++	 * The RT priorities are set via sched_setscheduler(), but we still
++	 * allow the 'normal' nice value to be set - but as expected
++	 * it wont have any effect on scheduling until the task is
++	 * not SCHED_NORMAL/SCHED_BATCH:
++	 */
++	if (has_rt_policy(p)) {
++		p->static_prio = new_static;
++		goto out_unlock;
++	}
++	queued = task_queued_only(p);
++	/*
++	 * If p is actually running, we don't need to do anything when
++	 * changing the priority because the grq is unaffected.
++	 */
++	if (queued)
++		dequeue_task(p);
++
++	adjust_deadline(p, new_static);
++	p->static_prio = new_static;
++	p->prio = effective_prio(p);
++
++	if (queued) {
++		enqueue_task(p);
++		try_preempt(p);
++	}
++
++	/* Just resched the task, schedule() will know what to do. */
++	if (task_running(p))
++		resched_task(p);
++out_unlock:
++	task_grq_unlock(&flags);
++}
++EXPORT_SYMBOL(set_user_nice);
++
++/*
++ * can_nice - check if a task can reduce its nice value
++ * @p: task
++ * @nice: nice value
++ */
++int can_nice(const struct task_struct *p, const int nice)
++{
++	/* convert nice value [19,-20] to rlimit style value [1,40] */
++	int nice_rlim = 20 - nice;
++
++	return (nice_rlim <= p->signal->rlim[RLIMIT_NICE].rlim_cur ||
++		capable(CAP_SYS_NICE));
++}
++
++#ifdef __ARCH_WANT_SYS_NICE
++
++/*
++ * sys_nice - change the priority of the current process.
++ * @increment: priority increment
++ *
++ * sys_setpriority is a more generic, but much slower function that
++ * does similar things.
++ */
++SYSCALL_DEFINE1(nice, int, increment)
++{
++	long nice, retval;
++
++	/*
++	 * Setpriority might change our priority at the same moment.
++	 * We don't have to worry. Conceptually one call occurs first
++	 * and we have a single winner.
++	 */
++	if (increment < -40)
++		increment = -40;
++	if (increment > 40)
++		increment = 40;
++
++	nice = TASK_NICE(current) + increment;
++	if (nice < -20)
++		nice = -20;
++	if (nice > 19)
++		nice = 19;
++
++	if (increment < 0 && !can_nice(current, nice))
++		return -EPERM;
++
++	retval = security_task_setnice(current, nice);
++	if (retval)
++		return retval;
++
++	set_user_nice(current, nice);
++	return 0;
++}
++
++#endif
++
++/**
++ * task_prio - return the priority value of a given task.
++ * @p: the task in question.
++ *
++ * This is the priority value as seen by users in /proc.
++ * RT tasks are offset by -100. Normal tasks are centered
++ * around 1, value goes from 0 (SCHED_ISO) up to 82 (nice +19
++ * SCHED_IDLE).
++ */
++int task_prio(const struct task_struct *p)
++{
++	int delta, prio = p->prio - MAX_RT_PRIO;
++
++	/* rt tasks and iso tasks */
++	if (prio <= 0)
++		goto out;
++
++	delta = (p->deadline - jiffies) * 40 / longest_deadline();
++	if (delta > 0 && delta <= 80)
++		prio += delta;
++out:
++	return prio;
++}
++
++/**
++ * task_nice - return the nice value of a given task.
++ * @p: the task in question.
++ */
++int task_nice(const struct task_struct *p)
++{
++	return TASK_NICE(p);
++}
++EXPORT_SYMBOL_GPL(task_nice);
++
++/**
++ * idle_cpu - is a given cpu idle currently?
++ * @cpu: the processor in question.
++ */
++int idle_cpu(int cpu)
++{
++	return cpu_curr(cpu) == cpu_rq(cpu)->idle;
++}
++
++/**
++ * idle_task - return the idle task for a given cpu.
++ * @cpu: the processor in question.
++ */
++struct task_struct *idle_task(int cpu)
++{
++	return cpu_rq(cpu)->idle;
++}
++
++/**
++ * find_process_by_pid - find a process with a matching PID value.
++ * @pid: the pid in question.
++ */
++static inline struct task_struct *find_process_by_pid(pid_t pid)
++{
++	return pid ? find_task_by_vpid(pid) : current;
++}
++
++/* Actually do priority change: must hold grq lock. */
++static void __setscheduler(struct task_struct *p, int policy, int prio)
++{
++	BUG_ON(task_queued_only(p));
++
++	p->policy = policy;
++	p->rt_priority = prio;
++	p->normal_prio = normal_prio(p);
++	/* we are holding p->pi_lock already */
++	p->prio = rt_mutex_getprio(p);
++	/*
++	 * Reschedule if running. schedule() will know if it can continue
++	 * running or not.
++	 */
++	if (task_running(p))
++		resched_task(p);
++}
++
++/*
++ * check the target process has a UID that matches the current process's
++ */
++static bool check_same_owner(struct task_struct *p)
++{
++	const struct cred *cred = current_cred(), *pcred;
++	bool match;
++
++	rcu_read_lock();
++	pcred = __task_cred(p);
++	match = (cred->euid == pcred->euid ||
++		 cred->euid == pcred->uid);
++	rcu_read_unlock();
++	return match;
++}
++
++static int __sched_setscheduler(struct task_struct *p, int policy,
++		       struct sched_param *param, bool user)
++{
++	struct sched_param zero_param = { .sched_priority = 0 };
++	int queued, retval, oldprio, oldpolicy = -1;
++	unsigned long flags, rlim_rtprio = 0;
++	struct rq *rq;
++
++	/* may grab non-irq protected spin_locks */
++	BUG_ON(in_interrupt());
++
++	if (is_rt_policy(policy) && !capable(CAP_SYS_NICE)) {
++		unsigned long lflags;
++
++		if (!lock_task_sighand(p, &lflags))
++			return -ESRCH;
++		rlim_rtprio = p->signal->rlim[RLIMIT_RTPRIO].rlim_cur;
++		unlock_task_sighand(p, &lflags);
++		if (rlim_rtprio)
++			goto recheck;
++		/*
++		 * If the caller requested an RT policy without having the
++		 * necessary rights, we downgrade the policy to SCHED_ISO.
++		 * We also set the parameter to zero to pass the checks.
++		 */
++		policy = SCHED_ISO;
++		param = &zero_param;
++	}
++recheck:
++	/* double check policy once rq lock held */
++	if (policy < 0)
++		policy = oldpolicy = p->policy;
++	else if (!SCHED_RANGE(policy))
++		return -EINVAL;
++	/*
++	 * Valid priorities for SCHED_FIFO and SCHED_RR are
++	 * 1..MAX_USER_RT_PRIO-1, valid priority for SCHED_NORMAL and
++	 * SCHED_BATCH is 0.
++	 */
++	if (param->sched_priority < 0 ||
++	    (p->mm && param->sched_priority > MAX_USER_RT_PRIO-1) ||
++	    (!p->mm && param->sched_priority > MAX_RT_PRIO-1))
++		return -EINVAL;
++	if (is_rt_policy(policy) != (param->sched_priority != 0))
++		return -EINVAL;
++
++	/*
++	 * Allow unprivileged RT tasks to decrease priority:
++	 */
++	if (user && !capable(CAP_SYS_NICE)) {
++		if (is_rt_policy(policy)) {
++			/* can't set/change the rt policy */
++			if (policy != p->policy && !rlim_rtprio)
++				return -EPERM;
++
++			/* can't increase priority */
++			if (param->sched_priority > p->rt_priority &&
++			    param->sched_priority > rlim_rtprio)
++				return -EPERM;
++		} else {
++			switch (p->policy) {
++				/*
++				 * Can only downgrade policies but not back to
++				 * SCHED_NORMAL
++				 */
++				case SCHED_ISO:
++					if (policy == SCHED_ISO)
++						goto out;
++					if (policy == SCHED_NORMAL)
++						return -EPERM;
++					break;
++				case SCHED_BATCH:
++					if (policy == SCHED_BATCH)
++						goto out;
++					if (policy != SCHED_IDLE)
++					    	return -EPERM;
++					break;
++				case SCHED_IDLE:
++					if (policy == SCHED_IDLE)
++						goto out;
++					return -EPERM;
++				default:
++					break;
++			}
++		}
++
++		/* can't change other user's priorities */
++		if (!check_same_owner(p))
++			return -EPERM;
++	}
++
++	retval = security_task_setscheduler(p, policy, param);
++	if (retval)
++		return retval;
++	/*
++	 * make sure no PI-waiters arrive (or leave) while we are
++	 * changing the priority of the task:
++	 */
++	spin_lock_irqsave(&p->pi_lock, flags);
++	/*
++	 * To be able to change p->policy safely, the apropriate
++	 * runqueue lock must be held.
++	 */
++	rq = __task_grq_lock(p);
++	/* recheck policy now with rq lock held */
++	if (unlikely(oldpolicy != -1 && oldpolicy != p->policy)) {
++		__task_grq_unlock();
++		spin_unlock_irqrestore(&p->pi_lock, flags);
++		policy = oldpolicy = -1;
++		goto recheck;
++	}
++	update_rq_clock(rq);
++	queued = task_queued_only(p);
++	if (queued)
++		dequeue_task(p);
++	oldprio = p->prio;
++	__setscheduler(p, policy, param->sched_priority);
++	if (queued) {
++		enqueue_task(p);
++		try_preempt(p);
++	}
++	__task_grq_unlock();
++	spin_unlock_irqrestore(&p->pi_lock, flags);
++
++	rt_mutex_adjust_pi(p);
++out:
++	return 0;
++}
++
++/**
++ * sched_setscheduler - change the scheduling policy and/or RT priority of a thread.
++ * @p: the task in question.
++ * @policy: new policy.
++ * @param: structure containing the new RT priority.
++ *
++ * NOTE that the task may be already dead.
++ */
++int sched_setscheduler(struct task_struct *p, int policy,
++		       struct sched_param *param)
++{
++	return __sched_setscheduler(p, policy, param, true);
++}
++
++EXPORT_SYMBOL_GPL(sched_setscheduler);
++
++/**
++ * sched_setscheduler_nocheck - change the scheduling policy and/or RT priority of a thread from kernelspace.
++ * @p: the task in question.
++ * @policy: new policy.
++ * @param: structure containing the new RT priority.
++ *
++ * Just like sched_setscheduler, only don't bother checking if the
++ * current context has permission.  For example, this is needed in
++ * stop_machine(): we create temporary high priority worker threads,
++ * but our caller might not have that capability.
++ */
++int sched_setscheduler_nocheck(struct task_struct *p, int policy,
++			       struct sched_param *param)
++{
++	return __sched_setscheduler(p, policy, param, false);
++}
++
++static int
++do_sched_setscheduler(pid_t pid, int policy, struct sched_param __user *param)
++{
++	struct sched_param lparam;
++	struct task_struct *p;
++	int retval;
++
++	if (!param || pid < 0)
++		return -EINVAL;
++	if (copy_from_user(&lparam, param, sizeof(struct sched_param)))
++		return -EFAULT;
++
++	rcu_read_lock();
++	retval = -ESRCH;
++	p = find_process_by_pid(pid);
++	if (p != NULL)
++		retval = sched_setscheduler(p, policy, &lparam);
++	rcu_read_unlock();
++
++	return retval;
++}
++
++/**
++ * sys_sched_setscheduler - set/change the scheduler policy and RT priority
++ * @pid: the pid in question.
++ * @policy: new policy.
++ * @param: structure containing the new RT priority.
++ */
++asmlinkage long sys_sched_setscheduler(pid_t pid, int policy,
++				       struct sched_param __user *param)
++{
++	/* negative values for policy are not valid */
++	if (policy < 0)
++		return -EINVAL;
++
++	return do_sched_setscheduler(pid, policy, param);
++}
++
++/**
++ * sys_sched_setparam - set/change the RT priority of a thread
++ * @pid: the pid in question.
++ * @param: structure containing the new RT priority.
++ */
++SYSCALL_DEFINE2(sched_setparam, pid_t, pid, struct sched_param __user *, param)
++{
++	return do_sched_setscheduler(pid, -1, param);
++}
++
++/**
++ * sys_sched_getscheduler - get the policy (scheduling class) of a thread
++ * @pid: the pid in question.
++ */
++SYSCALL_DEFINE1(sched_getscheduler, pid_t, pid)
++{
++	struct task_struct *p;
++	int retval = -EINVAL;
++
++	if (pid < 0)
++		goto out_nounlock;
++
++	retval = -ESRCH;
++	read_lock(&tasklist_lock);
++	p = find_process_by_pid(pid);
++	if (p) {
++		retval = security_task_getscheduler(p);
++		if (!retval)
++			retval = p->policy;
++	}
++	read_unlock(&tasklist_lock);
++
++out_nounlock:
++	return retval;
++}
++
++/**
++ * sys_sched_getscheduler - get the RT priority of a thread
++ * @pid: the pid in question.
++ * @param: structure containing the RT priority.
++ */
++SYSCALL_DEFINE2(sched_getparam, pid_t, pid, struct sched_param __user *, param)
++{
++	struct sched_param lp;
++	struct task_struct *p;
++	int retval = -EINVAL;
++
++	if (!param || pid < 0)
++		goto out_nounlock;
++
++	read_lock(&tasklist_lock);
++	p = find_process_by_pid(pid);
++	retval = -ESRCH;
++	if (!p)
++		goto out_unlock;
++
++	retval = security_task_getscheduler(p);
++	if (retval)
++		goto out_unlock;
++
++	lp.sched_priority = p->rt_priority;
++	read_unlock(&tasklist_lock);
++
++	/*
++	 * This one might sleep, we cannot do it with a spinlock held ...
++	 */
++	retval = copy_to_user(param, &lp, sizeof(*param)) ? -EFAULT : 0;
++
++out_nounlock:
++	return retval;
++
++out_unlock:
++	read_unlock(&tasklist_lock);
++	return retval;
++}
++
++long sched_setaffinity(pid_t pid, const struct cpumask *in_mask)
++{
++	cpumask_var_t cpus_allowed, new_mask;
++	struct task_struct *p;
++	int retval;
++
++	get_online_cpus();
++	read_lock(&tasklist_lock);
++
++	p = find_process_by_pid(pid);
++	if (!p) {
++		read_unlock(&tasklist_lock);
++		put_online_cpus();
++		return -ESRCH;
++	}
++
++	/*
++	 * It is not safe to call set_cpus_allowed with the
++	 * tasklist_lock held. We will bump the task_struct's
++	 * usage count and then drop tasklist_lock.
++	 */
++	get_task_struct(p);
++	read_unlock(&tasklist_lock);
++
++	if (!alloc_cpumask_var(&cpus_allowed, GFP_KERNEL)) {
++		retval = -ENOMEM;
++		goto out_put_task;
++	}
++	if (!alloc_cpumask_var(&new_mask, GFP_KERNEL)) {
++		retval = -ENOMEM;
++		goto out_free_cpus_allowed;
++	}
++	retval = -EPERM;
++	if (!check_same_owner(p) && !capable(CAP_SYS_NICE))
++		goto out_unlock;
++
++	retval = security_task_setscheduler(p, 0, NULL);
++	if (retval)
++		goto out_unlock;
++
++	cpuset_cpus_allowed(p, cpus_allowed);
++	cpumask_and(new_mask, in_mask, cpus_allowed);
++again:
++	retval = set_cpus_allowed_ptr(p, new_mask);
++
++	if (!retval) {
++		cpuset_cpus_allowed(p, cpus_allowed);
++		if (!cpumask_subset(new_mask, cpus_allowed)) {
++			/*
++			 * We must have raced with a concurrent cpuset
++			 * update. Just reset the cpus_allowed to the
++			 * cpuset's cpus_allowed
++			 */
++			cpumask_copy(new_mask, cpus_allowed);
++			goto again;
++		}
++	}
++out_unlock:
++	free_cpumask_var(new_mask);
++out_free_cpus_allowed:
++	free_cpumask_var(cpus_allowed);
++out_put_task:
++	put_task_struct(p);
++	put_online_cpus();
++	return retval;
++}
++
++static int get_user_cpu_mask(unsigned long __user *user_mask_ptr, unsigned len,
++			     cpumask_t *new_mask)
++{
++	if (len < sizeof(cpumask_t)) {
++		memset(new_mask, 0, sizeof(cpumask_t));
++	} else if (len > sizeof(cpumask_t)) {
++		len = sizeof(cpumask_t);
++	}
++	return copy_from_user(new_mask, user_mask_ptr, len) ? -EFAULT : 0;
++}
++
++
++/**
++ * sys_sched_setaffinity - set the cpu affinity of a process
++ * @pid: pid of the process
++ * @len: length in bytes of the bitmask pointed to by user_mask_ptr
++ * @user_mask_ptr: user-space pointer to the new cpu mask
++ */
++SYSCALL_DEFINE3(sched_setaffinity, pid_t, pid, unsigned int, len,
++		unsigned long __user *, user_mask_ptr)
++{
++	cpumask_var_t new_mask;
++	int retval;
++
++	if (!alloc_cpumask_var(&new_mask, GFP_KERNEL))
++		return -ENOMEM;
++
++	retval = get_user_cpu_mask(user_mask_ptr, len, new_mask);
++	if (retval == 0)
++		retval = sched_setaffinity(pid, new_mask);
++	free_cpumask_var(new_mask);
++	return retval;
++}
++
++long sched_getaffinity(pid_t pid, cpumask_t *mask)
++{
++	struct task_struct *p;
++	int retval;
++
++	mutex_lock(&sched_hotcpu_mutex);
++	read_lock(&tasklist_lock);
++
++	retval = -ESRCH;
++	p = find_process_by_pid(pid);
++	if (!p)
++		goto out_unlock;
++
++	retval = security_task_getscheduler(p);
++	if (retval)
++		goto out_unlock;
++
++	cpus_and(*mask, p->cpus_allowed, cpu_online_map);
++
++out_unlock:
++	read_unlock(&tasklist_lock);
++	mutex_unlock(&sched_hotcpu_mutex);
++	if (retval)
++		return retval;
++
++	return 0;
++}
++
++/**
++ * sys_sched_getaffinity - get the cpu affinity of a process
++ * @pid: pid of the process
++ * @len: length in bytes of the bitmask pointed to by user_mask_ptr
++ * @user_mask_ptr: user-space pointer to hold the current cpu mask
++ */
++SYSCALL_DEFINE3(sched_getaffinity, pid_t, pid, unsigned int, len,
++		unsigned long __user *, user_mask_ptr)
++{
++	int ret;
++	cpumask_var_t mask;
++
++	if (len < cpumask_size())
++		return -EINVAL;
++
++	if (!alloc_cpumask_var(&mask, GFP_KERNEL))
++		return -ENOMEM;
++
++	ret = sched_getaffinity(pid, mask);
++	if (ret == 0) {
++		if (copy_to_user(user_mask_ptr, mask, cpumask_size()))
++			ret = -EFAULT;
++		else
++			ret = cpumask_size();
++	}
++	free_cpumask_var(mask);
++
++	return ret;
++}
++
++/**
++ * sys_sched_yield - yield the current processor to other threads.
++ *
++ * This function yields the current CPU to other tasks. It does this by
++ * refilling the timeslice, resetting the deadline and scheduling away.
++ */
++SYSCALL_DEFINE0(sched_yield)
++{
++	struct task_struct *p;
++
++	grq_lock_irq();
++	p = current;
++	schedstat_inc(this_rq(), yld_count);
++	update_rq_clock(task_rq(p));
++	time_slice_expired(p);
++	requeue_task(p);
++
++	/*
++	 * Since we are going to call schedule() anyway, there's
++	 * no need to preempt or enable interrupts:
++	 */
++	__release(grq.lock);
++	spin_release(&grq.lock.dep_map, 1, _THIS_IP_);
++	_raw_spin_unlock(&grq.lock);
++	preempt_enable_no_resched();
++
++	schedule();
++
++	return 0;
++}
++
++static inline int should_resched(void)
++{
++	return need_resched() && !(preempt_count() & PREEMPT_ACTIVE);
++}
++
++static void __cond_resched(void)
++{
++#ifdef CONFIG_DEBUG_SPINLOCK_SLEEP
++	__might_sleep(__FILE__, __LINE__);
++#endif
++	/*
++	 * The BKS might be reacquired before we have dropped
++	 * PREEMPT_ACTIVE, which could trigger a second
++	 * cond_resched() call.
++	 */
++	do {
++		add_preempt_count(PREEMPT_ACTIVE);
++		schedule();
++		sub_preempt_count(PREEMPT_ACTIVE);
++	} while (need_resched());
++}
++
++int __sched _cond_resched(void)
++{
++	if (should_resched()) {
++		__cond_resched();
++		return 1;
++	}
++	return 0;
++}
++EXPORT_SYMBOL(_cond_resched);
++
++/*
++ * cond_resched_lock() - if a reschedule is pending, drop the given lock,
++ * call schedule, and on return reacquire the lock.
++ *
++ * This works OK both with and without CONFIG_PREEMPT.  We do strange low-level
++ * operations here to prevent schedule() from being called twice (once via
++ * spin_unlock(), once by hand).
++ */
++int cond_resched_lock(spinlock_t *lock)
++{
++	int resched = should_resched();
++	int ret = 0;
++
++	if (spin_needbreak(lock) || resched) {
++		spin_unlock(lock);
++		if (resched)
++			__cond_resched();
++		else
++			cpu_relax();
++		ret = 1;
++		spin_lock(lock);
++	}
++	return ret;
++}
++EXPORT_SYMBOL(cond_resched_lock);
++
++int __sched cond_resched_softirq(void)
++{
++	BUG_ON(!in_softirq());
++
++	if (should_resched()) {
++		local_bh_enable();
++		__cond_resched();
++		local_bh_disable();
++		return 1;
++	}
++	return 0;
++}
++EXPORT_SYMBOL(cond_resched_softirq);
++
++/**
++ * yield - yield the current processor to other threads.
++ *
++ * This is a shortcut for kernel-space yielding - it marks the
++ * thread runnable and calls sys_sched_yield().
++ */
++void __sched yield(void)
++{
++	set_current_state(TASK_RUNNING);
++	sys_sched_yield();
++}
++EXPORT_SYMBOL(yield);
++
++/*
++ * This task is about to go to sleep on IO.  Increment rq->nr_iowait so
++ * that process accounting knows that this is a task in IO wait state.
++ *
++ * But don't do that if it is a deliberate, throttling IO wait (this task
++ * has set its backing_dev_info: the queue against which it should throttle)
++ */
++void __sched io_schedule(void)
++{
++	struct rq *rq = &__raw_get_cpu_var(runqueues);
++
++	delayacct_blkio_start();
++	atomic_inc(&rq->nr_iowait);
++	schedule();
++	atomic_dec(&rq->nr_iowait);
++	delayacct_blkio_end();
++}
++EXPORT_SYMBOL(io_schedule);
++
++long __sched io_schedule_timeout(long timeout)
++{
++	struct rq *rq = &__raw_get_cpu_var(runqueues);
++	long ret;
++
++	delayacct_blkio_start();
++	atomic_inc(&rq->nr_iowait);
++	ret = schedule_timeout(timeout);
++	atomic_dec(&rq->nr_iowait);
++	delayacct_blkio_end();
++	return ret;
++}
++
++/**
++ * sys_sched_get_priority_max - return maximum RT priority.
++ * @policy: scheduling class.
++ *
++ * this syscall returns the maximum rt_priority that can be used
++ * by a given scheduling class.
++ */
++SYSCALL_DEFINE1(sched_get_priority_max, int, policy)
++{
++	int ret = -EINVAL;
++
++	switch (policy) {
++	case SCHED_FIFO:
++	case SCHED_RR:
++		ret = MAX_USER_RT_PRIO-1;
++		break;
++	case SCHED_NORMAL:
++	case SCHED_BATCH:
++	case SCHED_ISO:
++	case SCHED_IDLE:
++		ret = 0;
++		break;
++	}
++	return ret;
++}
++
++/**
++ * sys_sched_get_priority_min - return minimum RT priority.
++ * @policy: scheduling class.
++ *
++ * this syscall returns the minimum rt_priority that can be used
++ * by a given scheduling class.
++ */
++SYSCALL_DEFINE1(sched_get_priority_min, int, policy)
++{
++	int ret = -EINVAL;
++
++	switch (policy) {
++	case SCHED_FIFO:
++	case SCHED_RR:
++		ret = 1;
++		break;
++	case SCHED_NORMAL:
++	case SCHED_BATCH:
++	case SCHED_ISO:
++	case SCHED_IDLE:
++		ret = 0;
++		break;
++	}
++	return ret;
++}
++
++/**
++ * sys_sched_rr_get_interval - return the default timeslice of a process.
++ * @pid: pid of the process.
++ * @interval: userspace pointer to the timeslice value.
++ *
++ * this syscall writes the default timeslice value of a given process
++ * into the user-space timespec buffer. A value of '0' means infinity.
++ */
++SYSCALL_DEFINE2(sched_rr_get_interval, pid_t, pid,
++		struct timespec __user *, interval)
++{
++	struct task_struct *p;
++	int retval = -EINVAL;
++	struct timespec t;
++
++	if (pid < 0)
++		goto out_nounlock;
++
++	retval = -ESRCH;
++	read_lock(&tasklist_lock);
++	p = find_process_by_pid(pid);
++	if (!p)
++		goto out_unlock;
++
++	retval = security_task_getscheduler(p);
++	if (retval)
++		goto out_unlock;
++
++	t = ns_to_timespec(p->policy == SCHED_FIFO ? 0 :
++			   MS_TO_NS(task_timeslice(p)));
++	read_unlock(&tasklist_lock);
++	retval = copy_to_user(interval, &t, sizeof(t)) ? -EFAULT : 0;
++out_nounlock:
++	return retval;
++out_unlock:
++	read_unlock(&tasklist_lock);
++	return retval;
++}
++
++static const char stat_nam[] = TASK_STATE_TO_CHAR_STR;
++
++void sched_show_task(struct task_struct *p)
++{
++	unsigned long free = 0;
++	unsigned state;
++
++	state = p->state ? __ffs(p->state) + 1 : 0;
++	printk(KERN_INFO "%-13.13s %c", p->comm,
++		state < sizeof(stat_nam) - 1 ? stat_nam[state] : '?');
++#if BITS_PER_LONG == 32
++	if (state == TASK_RUNNING)
++		printk(KERN_CONT " running  ");
++	else
++		printk(KERN_CONT " %08lx ", thread_saved_pc(p));
++#else
++	if (state == TASK_RUNNING)
++		printk(KERN_CONT "  running task    ");
++	else
++		printk(KERN_CONT " %016lx ", thread_saved_pc(p));
++#endif
++#ifdef CONFIG_DEBUG_STACK_USAGE
++	free = stack_not_used(p);
++#endif
++	printk(KERN_CONT "%5lu %5d %6d 0x%08lx\n", free,
++		task_pid_nr(p), task_pid_nr(p->real_parent),
++		(unsigned long)task_thread_info(p)->flags);
++
++	show_stack(p, NULL);
++}
++
++void show_state_filter(unsigned long state_filter)
++{
++	struct task_struct *g, *p;
++
++#if BITS_PER_LONG == 32
++	printk(KERN_INFO
++		"  task                PC stack   pid father\n");
++#else
++	printk(KERN_INFO
++		"  task                        PC stack   pid father\n");
++#endif
++	read_lock(&tasklist_lock);
++	do_each_thread(g, p) {
++		/*
++		 * reset the NMI-timeout, listing all files on a slow
++		 * console might take alot of time:
++		 */
++		touch_nmi_watchdog();
++		if (!state_filter || (p->state & state_filter))
++			sched_show_task(p);
++	} while_each_thread(g, p);
++
++	touch_all_softlockup_watchdogs();
++
++	read_unlock(&tasklist_lock);
++	/*
++	 * Only show locks if all tasks are dumped:
++	 */
++	if (state_filter == -1)
++		debug_show_all_locks();
++}
++
++/**
++ * init_idle - set up an idle thread for a given CPU
++ * @idle: task in question
++ * @cpu: cpu the idle task belongs to
++ *
++ * NOTE: this function does not set the idle thread's NEED_RESCHED
++ * flag, to make booting more robust.
++ */
++void __cpuinit init_idle(struct task_struct *idle, int cpu)
++{
++	struct rq *rq = cpu_rq(cpu);
++	unsigned long flags;
++
++	time_grq_lock(rq, &flags);
++	idle->timestamp = idle->last_ran = rq->clock;
++	idle->state = TASK_RUNNING;
++	/* Setting prio to illegal value shouldn't matter when never queued */
++	idle->prio = rq->rq_prio = PRIO_LIMIT;
++	rq->rq_deadline = idle->deadline;
++	rq->rq_policy = idle->policy;
++	rq->rq_time_slice = idle->rt.time_slice;
++	idle->cpus_allowed = cpumask_of_cpu(cpu);
++	set_task_cpu(idle, cpu);
++	rq->curr = rq->idle = idle;
++	idle->oncpu = 1;
++	set_cpuidle_map(cpu);
++#ifdef CONFIG_HOTPLUG_CPU
++	idle->unplugged_mask = CPU_MASK_NONE;
++#endif
++	grq_unlock_irqrestore(&flags);
++
++	/* Set the preempt count _outside_ the spinlocks! */
++#if defined(CONFIG_PREEMPT) && !defined(CONFIG_PREEMPT_BKL)
++	task_thread_info(idle)->preempt_count = (idle->lock_depth >= 0);
++#else
++	task_thread_info(idle)->preempt_count = 0;
++#endif
++	ftrace_graph_init_task(idle);
++}
++
++/*
++ * In a system that switches off the HZ timer nohz_cpu_mask
++ * indicates which cpus entered this state. This is used
++ * in the rcu update to wait only for active cpus. For system
++ * which do not switch off the HZ timer nohz_cpu_mask should
++ * always be CPU_BITS_NONE.
++ */
++cpumask_var_t nohz_cpu_mask;
++
++#ifdef CONFIG_SMP
++#ifdef CONFIG_NO_HZ
++static struct {
++	atomic_t load_balancer;
++	cpumask_var_t cpu_mask;
++	cpumask_var_t ilb_grp_nohz_mask;
++} nohz ____cacheline_aligned = {
++	.load_balancer = ATOMIC_INIT(-1),
++};
++
++int get_nohz_load_balancer(void)
++{
++	return atomic_read(&nohz.load_balancer);
++}
++
++/*
++ * This routine will try to nominate the ilb (idle load balancing)
++ * owner among the cpus whose ticks are stopped. ilb owner will do the idle
++ * load balancing on behalf of all those cpus. If all the cpus in the system
++ * go into this tickless mode, then there will be no ilb owner (as there is
++ * no need for one) and all the cpus will sleep till the next wakeup event
++ * arrives...
++ *
++ * For the ilb owner, tick is not stopped. And this tick will be used
++ * for idle load balancing. ilb owner will still be part of
++ * nohz.cpu_mask..
++ *
++ * While stopping the tick, this cpu will become the ilb owner if there
++ * is no other owner. And will be the owner till that cpu becomes busy
++ * or if all cpus in the system stop their ticks at which point
++ * there is no need for ilb owner.
++ *
++ * When the ilb owner becomes busy, it nominates another owner, during the
++ * next busy scheduler_tick()
++ */
++int select_nohz_load_balancer(int stop_tick)
++{
++	int cpu = smp_processor_id();
++
++	if (stop_tick) {
++		cpu_rq(cpu)->in_nohz_recently = 1;
++
++		if (!cpu_active(cpu)) {
++			if (atomic_read(&nohz.load_balancer) != cpu)
++				return 0;
++
++			/*
++			 * If we are going offline and still the leader,
++			 * give up!
++			 */
++			if (atomic_cmpxchg(&nohz.load_balancer, cpu, -1) != cpu)
++				BUG();
++
++			return 0;
++		}
++
++		cpumask_set_cpu(cpu, nohz.cpu_mask);
++
++		/* time for ilb owner also to sleep */
++		if (cpumask_weight(nohz.cpu_mask) == num_online_cpus()) {
++			if (atomic_read(&nohz.load_balancer) == cpu)
++				atomic_set(&nohz.load_balancer, -1);
++			return 0;
++		}
++
++		if (atomic_read(&nohz.load_balancer) == -1) {
++			/* make me the ilb owner */
++			if (atomic_cmpxchg(&nohz.load_balancer, -1, cpu) == -1)
++				return 1;
++		} else if (atomic_read(&nohz.load_balancer) == cpu)
++			return 1;
++	} else {
++		if (!cpumask_test_cpu(cpu, nohz.cpu_mask))
++			return 0;
++
++		cpumask_clear_cpu(cpu, nohz.cpu_mask);
++
++		if (atomic_read(&nohz.load_balancer) == cpu)
++			if (atomic_cmpxchg(&nohz.load_balancer, cpu, -1) != cpu)
++				BUG();
++	}
++	return 0;
++}
++
++/*
++ * When add_timer_on() enqueues a timer into the timer wheel of an
++ * idle CPU then this timer might expire before the next timer event
++ * which is scheduled to wake up that CPU. In case of a completely
++ * idle system the next event might even be infinite time into the
++ * future. wake_up_idle_cpu() ensures that the CPU is woken up and
++ * leaves the inner idle loop so the newly added timer is taken into
++ * account when the CPU goes back to idle and evaluates the timer
++ * wheel for the next timer event.
++ */
++void wake_up_idle_cpu(int cpu)
++{
++	struct task_struct *idle;
++	struct rq *rq;
++
++	if (cpu == smp_processor_id())
++		return;
++
++	rq = cpu_rq(cpu);
++	idle = rq->idle;
++
++	/*
++	 * This is safe, as this function is called with the timer
++	 * wheel base lock of (cpu) held. When the CPU is on the way
++	 * to idle and has not yet set rq->curr to idle then it will
++	 * be serialized on the timer wheel base lock and take the new
++	 * timer into account automatically.
++	 */
++	if (unlikely(rq->curr != idle))
++		return;
++
++	/*
++	 * We can set TIF_RESCHED on the idle task of the other CPU
++	 * lockless. The worst case is that the other CPU runs the
++	 * idle task through an additional NOOP schedule()
++	 */
++	set_tsk_need_resched(idle);
++
++	/* NEED_RESCHED must be visible before we test polling */
++	smp_mb();
++	if (!tsk_is_polling(idle))
++		smp_send_reschedule(cpu);
++}
++
++#endif /* CONFIG_NO_HZ */
++
++/*
++ * Change a given task's CPU affinity. Migrate the thread to a
++ * proper CPU and schedule it away if the CPU it's executing on
++ * is removed from the allowed bitmask.
++ *
++ * NOTE: the caller must have a valid reference to the task, the
++ * task must not exit() & deallocate itself prematurely. The
++ * call is not atomic; no spinlocks may be held.
++ */
++int set_cpus_allowed_ptr(struct task_struct *p, const struct cpumask *new_mask)
++{
++	unsigned long flags;
++	int running = 0;
++	int queued = 0;
++	struct rq *rq;
++	int ret = 0;
++
++	rq = task_grq_lock(p, &flags);
++	if (!cpumask_intersects(new_mask, cpu_online_mask)) {
++		ret = -EINVAL;
++		goto out;
++	}
++
++	if (unlikely((p->flags & PF_THREAD_BOUND) && p != current &&
++		     !cpumask_equal(&p->cpus_allowed, new_mask))) {
++		ret = -EINVAL;
++		goto out;
++	}
++
++	queued = task_queued_only(p);
++
++	cpumask_copy(&p->cpus_allowed, new_mask);
++	p->rt.nr_cpus_allowed = cpumask_weight(new_mask);
++
++	/* Can the task run on the task's current CPU? If so, we're done */
++	if (cpumask_test_cpu(task_cpu(p), new_mask))
++		goto out;
++
++	/* Reschedule the task, schedule() will know if it can keep running */
++	if (task_running(p))
++		running = 1;
++	else
++		set_task_cpu(p, cpumask_any_and(cpu_online_mask, new_mask));
++
++out:
++	if (queued)
++		try_preempt(p);
++	task_grq_unlock(&flags);
++
++	/* This might be a flaky way of changing cpus! */
++	if (running)
++		schedule();
++	return ret;
++}
++EXPORT_SYMBOL_GPL(set_cpus_allowed_ptr);
++
++#ifdef CONFIG_HOTPLUG_CPU
++/* Schedules idle task to be the next runnable task on current CPU.
++ * It does so by boosting its priority to highest possible.
++ * Used by CPU offline code.
++ */
++void sched_idle_next(void)
++{
++	int this_cpu = smp_processor_id();
++	struct rq *rq = cpu_rq(this_cpu);
++	struct task_struct *idle = rq->idle;
++	unsigned long flags;
++
++	/* cpu has to be offline */
++	BUG_ON(cpu_online(this_cpu));
++
++	/*
++	 * Strictly not necessary since rest of the CPUs are stopped by now
++	 * and interrupts disabled on the current cpu.
++	 */
++	time_grq_lock(rq, &flags);
++
++	__setscheduler(idle, SCHED_FIFO, MAX_RT_PRIO - 1);
++
++	activate_idle_task(idle);
++	set_tsk_need_resched(rq->curr);
++
++	grq_unlock_irqrestore(&flags);
++}
++
++/*
++ * Ensures that the idle task is using init_mm right before its cpu goes
++ * offline.
++ */
++void idle_task_exit(void)
++{
++	struct mm_struct *mm = current->active_mm;
++
++	BUG_ON(cpu_online(smp_processor_id()));
++
++	if (mm != &init_mm)
++		switch_mm(mm, &init_mm, current);
++	mmdrop(mm);
++}
++
++#endif /* CONFIG_HOTPLUG_CPU */
++
++#if defined(CONFIG_SCHED_DEBUG) && defined(CONFIG_SYSCTL)
++
++static struct ctl_table sd_ctl_dir[] = {
++	{
++		.procname	= "sched_domain",
++		.mode		= 0555,
++	},
++	{0, },
++};
++
++static struct ctl_table sd_ctl_root[] = {
++	{
++		.ctl_name	= CTL_KERN,
++		.procname	= "kernel",
++		.mode		= 0555,
++		.child		= sd_ctl_dir,
++	},
++	{0, },
++};
++
++static struct ctl_table *sd_alloc_ctl_entry(int n)
++{
++	struct ctl_table *entry =
++		kcalloc(n, sizeof(struct ctl_table), GFP_KERNEL);
++
++	return entry;
++}
++
++static void sd_free_ctl_entry(struct ctl_table **tablep)
++{
++	struct ctl_table *entry;
++
++	/*
++	 * In the intermediate directories, both the child directory and
++	 * procname are dynamically allocated and could fail but the mode
++	 * will always be set. In the lowest directory the names are
++	 * static strings and all have proc handlers.
++	 */
++	for (entry = *tablep; entry->mode; entry++) {
++		if (entry->child)
++			sd_free_ctl_entry(&entry->child);
++		if (entry->proc_handler == NULL)
++			kfree(entry->procname);
++	}
++
++	kfree(*tablep);
++	*tablep = NULL;
++}
++
++static void
++set_table_entry(struct ctl_table *entry,
++		const char *procname, void *data, int maxlen,
++		mode_t mode, proc_handler *proc_handler)
++{
++	entry->procname = procname;
++	entry->data = data;
++	entry->maxlen = maxlen;
++	entry->mode = mode;
++	entry->proc_handler = proc_handler;
++}
++
++static struct ctl_table *
++sd_alloc_ctl_domain_table(struct sched_domain *sd)
++{
++	struct ctl_table *table = sd_alloc_ctl_entry(13);
++
++	if (table == NULL)
++		return NULL;
++
++	set_table_entry(&table[0], "min_interval", &sd->min_interval,
++		sizeof(long), 0644, proc_doulongvec_minmax);
++	set_table_entry(&table[1], "max_interval", &sd->max_interval,
++		sizeof(long), 0644, proc_doulongvec_minmax);
++	set_table_entry(&table[2], "busy_idx", &sd->busy_idx,
++		sizeof(int), 0644, proc_dointvec_minmax);
++	set_table_entry(&table[3], "idle_idx", &sd->idle_idx,
++		sizeof(int), 0644, proc_dointvec_minmax);
++	set_table_entry(&table[4], "newidle_idx", &sd->newidle_idx,
++		sizeof(int), 0644, proc_dointvec_minmax);
++	set_table_entry(&table[5], "wake_idx", &sd->wake_idx,
++		sizeof(int), 0644, proc_dointvec_minmax);
++	set_table_entry(&table[6], "forkexec_idx", &sd->forkexec_idx,
++		sizeof(int), 0644, proc_dointvec_minmax);
++	set_table_entry(&table[7], "busy_factor", &sd->busy_factor,
++		sizeof(int), 0644, proc_dointvec_minmax);
++	set_table_entry(&table[8], "imbalance_pct", &sd->imbalance_pct,
++		sizeof(int), 0644, proc_dointvec_minmax);
++	set_table_entry(&table[9], "cache_nice_tries",
++		&sd->cache_nice_tries,
++		sizeof(int), 0644, proc_dointvec_minmax);
++	set_table_entry(&table[10], "flags", &sd->flags,
++		sizeof(int), 0644, proc_dointvec_minmax);
++	set_table_entry(&table[11], "name", sd->name,
++		CORENAME_MAX_SIZE, 0444, proc_dostring);
++	/* &table[12] is terminator */
++
++	return table;
++}
++
++static ctl_table *sd_alloc_ctl_cpu_table(int cpu)
++{
++	struct ctl_table *entry, *table;
++	struct sched_domain *sd;
++	int domain_num = 0, i;
++	char buf[32];
++
++	for_each_domain(cpu, sd)
++		domain_num++;
++	entry = table = sd_alloc_ctl_entry(domain_num + 1);
++	if (table == NULL)
++		return NULL;
++
++	i = 0;
++	for_each_domain(cpu, sd) {
++		snprintf(buf, 32, "domain%d", i);
++		entry->procname = kstrdup(buf, GFP_KERNEL);
++		entry->mode = 0555;
++		entry->child = sd_alloc_ctl_domain_table(sd);
++		entry++;
++		i++;
++	}
++	return table;
++}
++
++static struct ctl_table_header *sd_sysctl_header;
++static void register_sched_domain_sysctl(void)
++{
++	int i, cpu_num = num_online_cpus();
++	struct ctl_table *entry = sd_alloc_ctl_entry(cpu_num + 1);
++	char buf[32];
++
++	WARN_ON(sd_ctl_dir[0].child);
++	sd_ctl_dir[0].child = entry;
++
++	if (entry == NULL)
++		return;
++
++	for_each_online_cpu(i) {
++		snprintf(buf, 32, "cpu%d", i);
++		entry->procname = kstrdup(buf, GFP_KERNEL);
++		entry->mode = 0555;
++		entry->child = sd_alloc_ctl_cpu_table(i);
++		entry++;
++	}
++
++	WARN_ON(sd_sysctl_header);
++	sd_sysctl_header = register_sysctl_table(sd_ctl_root);
++}
++
++/* may be called multiple times per register */
++static void unregister_sched_domain_sysctl(void)
++{
++	if (sd_sysctl_header)
++		unregister_sysctl_table(sd_sysctl_header);
++	sd_sysctl_header = NULL;
++	if (sd_ctl_dir[0].child)
++		sd_free_ctl_entry(&sd_ctl_dir[0].child);
++}
++#else
++static void register_sched_domain_sysctl(void)
++{
++}
++static void unregister_sched_domain_sysctl(void)
++{
++}
++#endif
++
++static void set_rq_online(struct rq *rq)
++{
++	if (!rq->online) {
++		cpumask_set_cpu(rq->cpu, rq->rd->online);
++		rq->online = 1;
++	}
++}
++
++static void set_rq_offline(struct rq *rq)
++{
++	if (rq->online) {
++		cpumask_clear_cpu(rq->cpu, rq->rd->online);
++		rq->online = 0;
++	}
++}
++
++#ifdef CONFIG_HOTPLUG_CPU
++/*
++ * This cpu is going down, so walk over the tasklist and find tasks that can
++ * only run on this cpu and remove their affinity. Store their value in
++ * unplugged_mask so it can be restored once their correct cpu is online. No
++ * need to do anything special since they'll just move on next reschedule if
++ * they're running.
++ */
++static void remove_cpu(unsigned long cpu)
++{
++	struct task_struct *p, *t;
++
++	read_lock(&tasklist_lock);
++
++	do_each_thread(t, p) {
++		cpumask_t cpus_remaining;
++
++		cpus_and(cpus_remaining, p->cpus_allowed, cpu_online_map);
++		cpu_clear(cpu, cpus_remaining);
++		if (cpus_empty(cpus_remaining)) {
++			p->unplugged_mask = p->cpus_allowed;
++			p->cpus_allowed = cpu_possible_map;
++		}
++	} while_each_thread(t, p);
++
++	read_unlock(&tasklist_lock);
++}
++
++/*
++ * This cpu is coming up so add it to the cpus_allowed.
++ */
++static void add_cpu(unsigned long cpu)
++{
++	struct task_struct *p, *t;
++
++	read_lock(&tasklist_lock);
++
++	do_each_thread(t, p) {
++		/* Have we taken all the cpus from the unplugged_mask back */
++		if (cpus_empty(p->unplugged_mask))
++			continue;
++
++		/* Was this cpu in the unplugged_mask mask */
++		if (cpu_isset(cpu, p->unplugged_mask)) {
++			cpu_set(cpu, p->cpus_allowed);
++			if (cpus_subset(p->unplugged_mask, p->cpus_allowed)) {
++				/*
++				 * Have we set more than the unplugged_mask?
++				 * If so, that means we have remnants set from
++				 * the unplug/plug cycle and need to remove
++				 * them. Then clear the unplugged_mask as we've
++				 * set all the cpus back.
++				 */
++				p->cpus_allowed = p->unplugged_mask;
++				cpus_clear(p->unplugged_mask);
++			}
++		}
++	} while_each_thread(t, p);
++
++	read_unlock(&tasklist_lock);
++}
++#else
++static void add_cpu(unsigned long cpu)
++{
++}
++#endif
++
++/*
++ * migration_call - callback that gets triggered when a CPU is added.
++ */
++static int __cpuinit
++migration_call(struct notifier_block *nfb, unsigned long action, void *hcpu)
++{
++	int cpu = (long)hcpu;
++	unsigned long flags;
++	struct rq *rq;
++
++	switch (action) {
++
++	case CPU_UP_PREPARE:
++	case CPU_UP_PREPARE_FROZEN:
++		break;
++
++	case CPU_ONLINE:
++	case CPU_ONLINE_FROZEN:
++		/* Update our root-domain */
++		rq = cpu_rq(cpu);
++		grq_lock_irqsave(&flags);
++		if (rq->rd) {
++			BUG_ON(!cpumask_test_cpu(cpu, rq->rd->span));
++
++			set_rq_online(rq);
++		}
++		add_cpu(cpu);
++		grq_unlock_irqrestore(&flags);
++		break;
++
++#ifdef CONFIG_HOTPLUG_CPU
++	case CPU_UP_CANCELED:
++	case CPU_UP_CANCELED_FROZEN:
++		break;
++
++	case CPU_DEAD:
++	case CPU_DEAD_FROZEN:
++		cpuset_lock(); /* around calls to cpuset_cpus_allowed_lock() */
++		rq = cpu_rq(cpu);
++		/* Idle task back to normal (off runqueue, low prio) */
++		grq_lock_irq();
++		remove_cpu(cpu);
++		deactivate_task(rq->idle);
++		rq->idle->static_prio = MAX_PRIO;
++		__setscheduler(rq->idle, SCHED_NORMAL, 0);
++		rq->idle->prio = PRIO_LIMIT;
++		update_rq_clock(rq);
++		grq_unlock_irq();
++		cpuset_unlock();
++		break;
++
++	case CPU_DYING:
++	case CPU_DYING_FROZEN:
++		rq = cpu_rq(cpu);
++		grq_lock_irqsave(&flags);
++		if (rq->rd) {
++			BUG_ON(!cpumask_test_cpu(cpu, rq->rd->span));
++			set_rq_offline(rq);
++		}
++		grq_unlock_irqrestore(&flags);
++		break;
++#endif
++	}
++	return NOTIFY_OK;
++}
++
++/*
++ * Register at high priority so that task migration (migrate_all_tasks)
++ * happens before everything else.  This has to be lower priority than
++ * the notifier in the perf_counter subsystem, though.
++ */
++static struct notifier_block __cpuinitdata migration_notifier = {
++	.notifier_call = migration_call,
++	.priority = 10
++};
++
++int __init migration_init(void)
++{
++	void *cpu = (void *)(long)smp_processor_id();
++	int err;
++
++	/* Start one for the boot CPU: */
++	err = migration_call(&migration_notifier, CPU_UP_PREPARE, cpu);
++	BUG_ON(err == NOTIFY_BAD);
++	migration_call(&migration_notifier, CPU_ONLINE, cpu);
++	register_cpu_notifier(&migration_notifier);
++
++	return 0;
++}
++early_initcall(migration_init);
++#endif
++
++/*
++ * sched_domains_mutex serializes calls to arch_init_sched_domains,
++ * detach_destroy_domains and partition_sched_domains.
++ */
++static DEFINE_MUTEX(sched_domains_mutex);
++
++#ifdef CONFIG_SMP
++
++#ifdef CONFIG_SCHED_DEBUG
++
++static int sched_domain_debug_one(struct sched_domain *sd, int cpu, int level,
++				  struct cpumask *groupmask)
++{
++	struct sched_group *group = sd->groups;
++	char str[256];
++
++	cpulist_scnprintf(str, sizeof(str), sched_domain_span(sd));
++	cpumask_clear(groupmask);
++
++	printk(KERN_DEBUG "%*s domain %d: ", level, "", level);
++
++	if (!(sd->flags & SD_LOAD_BALANCE)) {
++		printk("does not load-balance\n");
++		if (sd->parent)
++			printk(KERN_ERR "ERROR: !SD_LOAD_BALANCE domain"
++					" has parent");
++		return -1;
++	}
++
++	printk(KERN_CONT "span %s level %s\n", str, sd->name);
++
++	if (!cpumask_test_cpu(cpu, sched_domain_span(sd))) {
++		printk(KERN_ERR "ERROR: domain->span does not contain "
++				"CPU%d\n", cpu);
++	}
++	if (!cpumask_test_cpu(cpu, sched_group_cpus(group))) {
++		printk(KERN_ERR "ERROR: domain->groups does not contain"
++				" CPU%d\n", cpu);
++	}
++
++	printk(KERN_DEBUG "%*s groups:", level + 1, "");
++	do {
++		if (!group) {
++			printk("\n");
++			printk(KERN_ERR "ERROR: group is NULL\n");
++			break;
++		}
++
++		if (!group->__cpu_power) {
++			printk(KERN_CONT "\n");
++			printk(KERN_ERR "ERROR: domain->cpu_power not "
++					"set\n");
++			break;
++		}
++
++		if (!cpumask_weight(sched_group_cpus(group))) {
++			printk(KERN_CONT "\n");
++			printk(KERN_ERR "ERROR: empty group\n");
++			break;
++		}
++
++		if (cpumask_intersects(groupmask, sched_group_cpus(group))) {
++			printk(KERN_CONT "\n");
++			printk(KERN_ERR "ERROR: repeated CPUs\n");
++			break;
++		}
++
++		cpumask_or(groupmask, groupmask, sched_group_cpus(group));
++
++		cpulist_scnprintf(str, sizeof(str), sched_group_cpus(group));
++
++		printk(KERN_CONT " %s", str);
++		if (group->__cpu_power != SCHED_LOAD_SCALE) {
++			printk(KERN_CONT " (__cpu_power = %d)",
++				group->__cpu_power);
++		}
++
++		group = group->next;
++	} while (group != sd->groups);
++	printk(KERN_CONT "\n");
++
++	if (!cpumask_equal(sched_domain_span(sd), groupmask))
++		printk(KERN_ERR "ERROR: groups don't span domain->span\n");
++
++	if (sd->parent &&
++	    !cpumask_subset(groupmask, sched_domain_span(sd->parent)))
++		printk(KERN_ERR "ERROR: parent span is not a superset "
++			"of domain->span\n");
++	return 0;
++}
++
++static void sched_domain_debug(struct sched_domain *sd, int cpu)
++{
++	cpumask_var_t groupmask;
++	int level = 0;
++
++	if (!sd) {
++		printk(KERN_DEBUG "CPU%d attaching NULL sched-domain.\n", cpu);
++		return;
++	}
++
++	printk(KERN_DEBUG "CPU%d attaching sched-domain:\n", cpu);
++
++	if (!alloc_cpumask_var(&groupmask, GFP_KERNEL)) {
++		printk(KERN_DEBUG "Cannot load-balance (out of memory)\n");
++		return;
++	}
++
++	for (;;) {
++		if (sched_domain_debug_one(sd, cpu, level, groupmask))
++			break;
++		level++;
++		sd = sd->parent;
++		if (!sd)
++			break;
++	}
++	free_cpumask_var(groupmask);
++}
++#else /* !CONFIG_SCHED_DEBUG */
++# define sched_domain_debug(sd, cpu) do { } while (0)
++#endif /* CONFIG_SCHED_DEBUG */
++
++static int sd_degenerate(struct sched_domain *sd)
++{
++	if (cpumask_weight(sched_domain_span(sd)) == 1)
++		return 1;
++
++	/* Following flags need at least 2 groups */
++	if (sd->flags & (SD_LOAD_BALANCE |
++			 SD_BALANCE_NEWIDLE |
++			 SD_BALANCE_FORK |
++			 SD_BALANCE_EXEC |
++			 SD_SHARE_CPUPOWER |
++			 SD_SHARE_PKG_RESOURCES)) {
++		if (sd->groups != sd->groups->next)
++			return 0;
++	}
++
++	/* Following flags don't use groups */
++	if (sd->flags & (SD_WAKE_IDLE |
++			 SD_WAKE_AFFINE |
++			 SD_WAKE_BALANCE))
++		return 0;
++
++	return 1;
++}
++
++static int
++sd_parent_degenerate(struct sched_domain *sd, struct sched_domain *parent)
++{
++	unsigned long cflags = sd->flags, pflags = parent->flags;
++
++	if (sd_degenerate(parent))
++		return 1;
++
++	if (!cpumask_equal(sched_domain_span(sd), sched_domain_span(parent)))
++		return 0;
++
++	/* Does parent contain flags not in child? */
++	/* WAKE_BALANCE is a subset of WAKE_AFFINE */
++	if (cflags & SD_WAKE_AFFINE)
++		pflags &= ~SD_WAKE_BALANCE;
++	/* Flags needing groups don't count if only 1 group in parent */
++	if (parent->groups == parent->groups->next) {
++		pflags &= ~(SD_LOAD_BALANCE |
++				SD_BALANCE_NEWIDLE |
++				SD_BALANCE_FORK |
++				SD_BALANCE_EXEC |
++				SD_SHARE_CPUPOWER |
++				SD_SHARE_PKG_RESOURCES);
++		if (nr_node_ids == 1)
++			pflags &= ~SD_SERIALIZE;
++	}
++	if (~cflags & pflags)
++		return 0;
++
++	return 1;
++}
++
++static void free_rootdomain(struct root_domain *rd)
++{
++	free_cpumask_var(rd->rto_mask);
++	free_cpumask_var(rd->online);
++	free_cpumask_var(rd->span);
++	kfree(rd);
++}
++
++static void rq_attach_root(struct rq *rq, struct root_domain *rd)
++{
++	struct root_domain *old_rd = NULL;
++	unsigned long flags;
++
++	grq_lock_irqsave(&flags);
++
++	if (rq->rd) {
++		old_rd = rq->rd;
++
++		if (cpumask_test_cpu(rq->cpu, old_rd->online))
++			set_rq_offline(rq);
++
++		cpumask_clear_cpu(rq->cpu, old_rd->span);
++
++		/*
++		 * If we dont want to free the old_rt yet then
++		 * set old_rd to NULL to skip the freeing later
++		 * in this function:
++		 */
++		if (!atomic_dec_and_test(&old_rd->refcount))
++			old_rd = NULL;
++	}
++
++	atomic_inc(&rd->refcount);
++	rq->rd = rd;
++
++	cpumask_set_cpu(rq->cpu, rd->span);
++	if (cpumask_test_cpu(rq->cpu, cpu_online_mask))
++		set_rq_online(rq);
++
++	grq_unlock_irqrestore(&flags);
++
++	if (old_rd)
++		free_rootdomain(old_rd);
++}
++
++static int init_rootdomain(struct root_domain *rd, bool bootmem)
++{
++	gfp_t gfp = GFP_KERNEL;
++
++	memset(rd, 0, sizeof(*rd));
++
++	if (bootmem)
++		gfp = GFP_NOWAIT;
++
++	if (!alloc_cpumask_var(&rd->span, gfp))
++		goto out;
++	if (!alloc_cpumask_var(&rd->online, gfp))
++		goto free_span;
++	if (!alloc_cpumask_var(&rd->rto_mask, gfp))
++		goto free_online;
++
++	return 0;
++
++free_online:
++	free_cpumask_var(rd->online);
++free_span:
++	free_cpumask_var(rd->span);
++out:
++	return -ENOMEM;
++}
++
++static void init_defrootdomain(void)
++{
++	init_rootdomain(&def_root_domain, true);
++
++	atomic_set(&def_root_domain.refcount, 1);
++}
++
++static struct root_domain *alloc_rootdomain(void)
++{
++	struct root_domain *rd;
++
++	rd = kmalloc(sizeof(*rd), GFP_KERNEL);
++	if (!rd)
++		return NULL;
++
++	if (init_rootdomain(rd, false) != 0) {
++		kfree(rd);
++		return NULL;
++	}
++
++	return rd;
++}
++
++/*
++ * Attach the domain 'sd' to 'cpu' as its base domain. Callers must
++ * hold the hotplug lock.
++ */
++static void
++cpu_attach_domain(struct sched_domain *sd, struct root_domain *rd, int cpu)
++{
++	struct rq *rq = cpu_rq(cpu);
++	struct sched_domain *tmp;
++
++	/* Remove the sched domains which do not contribute to scheduling. */
++	for (tmp = sd; tmp; ) {
++		struct sched_domain *parent = tmp->parent;
++		if (!parent)
++			break;
++
++		if (sd_parent_degenerate(tmp, parent)) {
++			tmp->parent = parent->parent;
++			if (parent->parent)
++				parent->parent->child = tmp;
++		} else
++			tmp = tmp->parent;
++	}
++
++	if (sd && sd_degenerate(sd)) {
++		sd = sd->parent;
++		if (sd)
++			sd->child = NULL;
++	}
++
++	sched_domain_debug(sd, cpu);
++
++	rq_attach_root(rq, rd);
++	rcu_assign_pointer(rq->sd, sd);
++}
++
++/* cpus with isolated domains */
++static cpumask_var_t cpu_isolated_map;
++
++/* Setup the mask of cpus configured for isolated domains */
++static int __init isolated_cpu_setup(char *str)
++{
++	cpulist_parse(str, cpu_isolated_map);
++	return 1;
++}
++
++__setup("isolcpus=", isolated_cpu_setup);
++
++/*
++ * init_sched_build_groups takes the cpumask we wish to span, and a pointer
++ * to a function which identifies what group(along with sched group) a CPU
++ * belongs to. The return value of group_fn must be a >= 0 and < nr_cpu_ids
++ * (due to the fact that we keep track of groups covered with a struct cpumask).
++ *
++ * init_sched_build_groups will build a circular linked list of the groups
++ * covered by the given span, and will set each group's ->cpumask correctly,
++ * and ->cpu_power to 0.
++ */
++static void
++init_sched_build_groups(const struct cpumask *span,
++			const struct cpumask *cpu_map,
++			int (*group_fn)(int cpu, const struct cpumask *cpu_map,
++					struct sched_group **sg,
++					struct cpumask *tmpmask),
++			struct cpumask *covered, struct cpumask *tmpmask)
++{
++	struct sched_group *first = NULL, *last = NULL;
++	int i;
++
++	cpumask_clear(covered);
++
++	for_each_cpu(i, span) {
++		struct sched_group *sg;
++		int group = group_fn(i, cpu_map, &sg, tmpmask);
++		int j;
++
++		if (cpumask_test_cpu(i, covered))
++			continue;
++
++		cpumask_clear(sched_group_cpus(sg));
++		sg->__cpu_power = 0;
++
++		for_each_cpu(j, span) {
++			if (group_fn(j, cpu_map, NULL, tmpmask) != group)
++				continue;
++
++			cpumask_set_cpu(j, covered);
++			cpumask_set_cpu(j, sched_group_cpus(sg));
++		}
++		if (!first)
++			first = sg;
++		if (last)
++			last->next = sg;
++		last = sg;
++	}
++	last->next = first;
++}
++
++#define SD_NODES_PER_DOMAIN 16
++
++#ifdef CONFIG_NUMA
++
++/**
++ * find_next_best_node - find the next node to include in a sched_domain
++ * @node: node whose sched_domain we're building
++ * @used_nodes: nodes already in the sched_domain
++ *
++ * Find the next node to include in a given scheduling domain. Simply
++ * finds the closest node not already in the @used_nodes map.
++ *
++ * Should use nodemask_t.
++ */
++static int find_next_best_node(int node, nodemask_t *used_nodes)
++{
++	int i, n, val, min_val, best_node = 0;
++
++	min_val = INT_MAX;
++
++	for (i = 0; i < nr_node_ids; i++) {
++		/* Start at @node */
++		n = (node + i) % nr_node_ids;
++
++		if (!nr_cpus_node(n))
++			continue;
++
++		/* Skip already used nodes */
++		if (node_isset(n, *used_nodes))
++			continue;
++
++		/* Simple min distance search */
++		val = node_distance(node, n);
++
++		if (val < min_val) {
++			min_val = val;
++			best_node = n;
++		}
++	}
++
++	node_set(best_node, *used_nodes);
++	return best_node;
++}
++
++/**
++ * sched_domain_node_span - get a cpumask for a node's sched_domain
++ * @node: node whose cpumask we're constructing
++ * @span: resulting cpumask
++ *
++ * Given a node, construct a good cpumask for its sched_domain to span. It
++ * should be one that prevents unnecessary balancing, but also spreads tasks
++ * out optimally.
++ */
++static void sched_domain_node_span(int node, struct cpumask *span)
++{
++	nodemask_t used_nodes;
++	int i;
++
++	cpumask_clear(span);
++	nodes_clear(used_nodes);
++
++	cpumask_or(span, span, cpumask_of_node(node));
++	node_set(node, used_nodes);
++
++	for (i = 1; i < SD_NODES_PER_DOMAIN; i++) {
++		int next_node = find_next_best_node(node, &used_nodes);
++
++		cpumask_or(span, span, cpumask_of_node(next_node));
++	}
++}
++#endif /* CONFIG_NUMA */
++
++int sched_smt_power_savings = 0, sched_mc_power_savings = 0;
++
++/*
++ * The cpus mask in sched_group and sched_domain hangs off the end.
++ *
++ * ( See the the comments in include/linux/sched.h:struct sched_group
++ *   and struct sched_domain. )
++ */
++struct static_sched_group {
++	struct sched_group sg;
++	DECLARE_BITMAP(cpus, CONFIG_NR_CPUS);
++};
++
++struct static_sched_domain {
++	struct sched_domain sd;
++	DECLARE_BITMAP(span, CONFIG_NR_CPUS);
++};
++
++/*
++ * SMT sched-domains:
++ */
++#ifdef CONFIG_SCHED_SMT
++static DEFINE_PER_CPU(struct static_sched_domain, cpu_domains);
++static DEFINE_PER_CPU(struct static_sched_group, sched_group_cpus);
++
++static int
++cpu_to_cpu_group(int cpu, const struct cpumask *cpu_map,
++		 struct sched_group **sg, struct cpumask *unused)
++{
++	if (sg)
++		*sg = &per_cpu(sched_group_cpus, cpu).sg;
++	return cpu;
++}
++#endif /* CONFIG_SCHED_SMT */
++
++/*
++ * multi-core sched-domains:
++ */
++#ifdef CONFIG_SCHED_MC
++static DEFINE_PER_CPU(struct static_sched_domain, core_domains);
++static DEFINE_PER_CPU(struct static_sched_group, sched_group_core);
++#endif /* CONFIG_SCHED_MC */
++
++#if defined(CONFIG_SCHED_MC) && defined(CONFIG_SCHED_SMT)
++static int
++cpu_to_core_group(int cpu, const struct cpumask *cpu_map,
++		  struct sched_group **sg, struct cpumask *mask)
++{
++	int group;
++
++	cpumask_and(mask, topology_thread_cpumask(cpu), cpu_map);
++	group = cpumask_first(mask);
++	if (sg)
++		*sg = &per_cpu(sched_group_core, group).sg;
++	return group;
++}
++#elif defined(CONFIG_SCHED_MC)
++static int
++cpu_to_core_group(int cpu, const struct cpumask *cpu_map,
++		  struct sched_group **sg, struct cpumask *unused)
++{
++	if (sg)
++		*sg = &per_cpu(sched_group_core, cpu).sg;
++	return cpu;
++}
++#endif
++
++static DEFINE_PER_CPU(struct static_sched_domain, phys_domains);
++static DEFINE_PER_CPU(struct static_sched_group, sched_group_phys);
++
++static int
++cpu_to_phys_group(int cpu, const struct cpumask *cpu_map,
++		  struct sched_group **sg, struct cpumask *mask)
++{
++	int group;
++#ifdef CONFIG_SCHED_MC
++	cpumask_and(mask, cpu_coregroup_mask(cpu), cpu_map);
++	group = cpumask_first(mask);
++#elif defined(CONFIG_SCHED_SMT)
++	cpumask_and(mask, topology_thread_cpumask(cpu), cpu_map);
++	group = cpumask_first(mask);
++#else
++	group = cpu;
++#endif
++	if (sg)
++		*sg = &per_cpu(sched_group_phys, group).sg;
++	return group;
++}
++
++/**
++ * group_first_cpu - Returns the first cpu in the cpumask of a sched_group.
++ * @group: The group whose first cpu is to be returned.
++ */
++static inline unsigned int group_first_cpu(struct sched_group *group)
++{
++	return cpumask_first(sched_group_cpus(group));
++}
++
++#ifdef CONFIG_NUMA
++/*
++ * The init_sched_build_groups can't handle what we want to do with node
++ * groups, so roll our own. Now each node has its own list of groups which
++ * gets dynamically allocated.
++ */
++static DEFINE_PER_CPU(struct static_sched_domain, node_domains);
++static struct sched_group ***sched_group_nodes_bycpu;
++
++static DEFINE_PER_CPU(struct static_sched_domain, allnodes_domains);
++static DEFINE_PER_CPU(struct static_sched_group, sched_group_allnodes);
++
++static int cpu_to_allnodes_group(int cpu, const struct cpumask *cpu_map,
++				 struct sched_group **sg,
++				 struct cpumask *nodemask)
++{
++	int group;
++
++	cpumask_and(nodemask, cpumask_of_node(cpu_to_node(cpu)), cpu_map);
++	group = cpumask_first(nodemask);
++
++	if (sg)
++		*sg = &per_cpu(sched_group_allnodes, group).sg;
++	return group;
++}
++
++static void init_numa_sched_groups_power(struct sched_group *group_head)
++{
++	struct sched_group *sg = group_head;
++	int j;
++
++	if (!sg)
++		return;
++	do {
++		for_each_cpu(j, sched_group_cpus(sg)) {
++			struct sched_domain *sd;
++
++			sd = &per_cpu(phys_domains, j).sd;
++			if (j != group_first_cpu(sd->groups)) {
++				/*
++				 * Only add "power" once for each
++				 * physical package.
++				 */
++				continue;
++			}
++
++			sg_inc_cpu_power(sg, sd->groups->__cpu_power);
++		}
++		sg = sg->next;
++	} while (sg != group_head);
++}
++#endif /* CONFIG_NUMA */
++
++#ifdef CONFIG_NUMA
++/* Free memory allocated for various sched_group structures */
++static void free_sched_groups(const struct cpumask *cpu_map,
++			      struct cpumask *nodemask)
++{
++	int cpu, i;
++
++	for_each_cpu(cpu, cpu_map) {
++		struct sched_group **sched_group_nodes
++			= sched_group_nodes_bycpu[cpu];
++
++		if (!sched_group_nodes)
++			continue;
++
++		for (i = 0; i < nr_node_ids; i++) {
++			struct sched_group *oldsg, *sg = sched_group_nodes[i];
++
++			cpumask_and(nodemask, cpumask_of_node(i), cpu_map);
++			if (cpumask_empty(nodemask))
++				continue;
++
++			if (sg == NULL)
++				continue;
++			sg = sg->next;
++next_sg:
++			oldsg = sg;
++			sg = sg->next;
++			kfree(oldsg);
++			if (oldsg != sched_group_nodes[i])
++				goto next_sg;
++		}
++		kfree(sched_group_nodes);
++		sched_group_nodes_bycpu[cpu] = NULL;
++	}
++}
++#else /* !CONFIG_NUMA */
++static void free_sched_groups(const struct cpumask *cpu_map,
++			      struct cpumask *nodemask)
++{
++}
++#endif /* CONFIG_NUMA */
++
++/*
++ * Initialize sched groups cpu_power.
++ *
++ * cpu_power indicates the capacity of sched group, which is used while
++ * distributing the load between different sched groups in a sched domain.
++ * Typically cpu_power for all the groups in a sched domain will be same unless
++ * there are asymmetries in the topology. If there are asymmetries, group
++ * having more cpu_power will pickup more load compared to the group having
++ * less cpu_power.
++ *
++ * cpu_power will be a multiple of SCHED_LOAD_SCALE. This multiple represents
++ * the maximum number of tasks a group can handle in the presence of other idle
++ * or lightly loaded groups in the same sched domain.
++ */
++static void init_sched_groups_power(int cpu, struct sched_domain *sd)
++{
++	struct sched_domain *child;
++	struct sched_group *group;
++
++	WARN_ON(!sd || !sd->groups);
++
++	if (cpu != group_first_cpu(sd->groups))
++		return;
++
++	child = sd->child;
++
++	sd->groups->__cpu_power = 0;
++
++	/*
++	 * For perf policy, if the groups in child domain share resources
++	 * (for example cores sharing some portions of the cache hierarchy
++	 * or SMT), then set this domain groups cpu_power such that each group
++	 * can handle only one task, when there are other idle groups in the
++	 * same sched domain.
++	 */
++	if (!child || (!(sd->flags & SD_POWERSAVINGS_BALANCE) &&
++		       (child->flags &
++			(SD_SHARE_CPUPOWER | SD_SHARE_PKG_RESOURCES)))) {
++		sg_inc_cpu_power(sd->groups, SCHED_LOAD_SCALE);
++		return;
++	}
++
++	/*
++	 * add cpu_power of each child group to this groups cpu_power
++	 */
++	group = child->groups;
++	do {
++		sg_inc_cpu_power(sd->groups, group->__cpu_power);
++		group = group->next;
++	} while (group != child->groups);
++}
++
++/*
++ * Initializers for schedule domains
++ * Non-inlined to reduce accumulated stack pressure in build_sched_domains()
++ */
++
++#ifdef CONFIG_SCHED_DEBUG
++# define SD_INIT_NAME(sd, type)		sd->name = #type
++#else
++# define SD_INIT_NAME(sd, type)		do { } while (0)
++#endif
++
++#define	SD_INIT(sd, type)	sd_init_##type(sd)
++
++#define SD_INIT_FUNC(type)	\
++static noinline void sd_init_##type(struct sched_domain *sd)	\
++{								\
++	memset(sd, 0, sizeof(*sd));				\
++	*sd = SD_##type##_INIT;					\
++	sd->level = SD_LV_##type;				\
++	SD_INIT_NAME(sd, type);					\
++}
++
++SD_INIT_FUNC(CPU)
++#ifdef CONFIG_NUMA
++ SD_INIT_FUNC(ALLNODES)
++ SD_INIT_FUNC(NODE)
++#endif
++#ifdef CONFIG_SCHED_SMT
++ SD_INIT_FUNC(SIBLING)
++#endif
++#ifdef CONFIG_SCHED_MC
++ SD_INIT_FUNC(MC)
++#endif
++
++static int default_relax_domain_level = -1;
++
++static int __init setup_relax_domain_level(char *str)
++{
++	unsigned long val;
++
++	val = simple_strtoul(str, NULL, 0);
++	if (val < SD_LV_MAX)
++		default_relax_domain_level = val;
++
++	return 1;
++}
++__setup("relax_domain_level=", setup_relax_domain_level);
++
++static void set_domain_attribute(struct sched_domain *sd,
++				 struct sched_domain_attr *attr)
++{
++	int request;
++
++	if (!attr || attr->relax_domain_level < 0) {
++		if (default_relax_domain_level < 0)
++			return;
++		else
++			request = default_relax_domain_level;
++	} else
++		request = attr->relax_domain_level;
++	if (request < sd->level) {
++		/* turn off idle balance on this domain */
++		sd->flags &= ~(SD_WAKE_IDLE|SD_BALANCE_NEWIDLE);
++	} else {
++		/* turn on idle balance on this domain */
++		sd->flags |= (SD_WAKE_IDLE_FAR|SD_BALANCE_NEWIDLE);
++	}
++}
++
++/*
++ * Build sched domains for a given set of cpus and attach the sched domains
++ * to the individual cpus
++ */
++static int __build_sched_domains(const struct cpumask *cpu_map,
++				 struct sched_domain_attr *attr)
++{
++	int i, err = -ENOMEM;
++	struct root_domain *rd;
++	cpumask_var_t nodemask, this_sibling_map, this_core_map, send_covered,
++		tmpmask;
++#ifdef CONFIG_NUMA
++	cpumask_var_t domainspan, covered, notcovered;
++	struct sched_group **sched_group_nodes = NULL;
++	int sd_allnodes = 0;
++
++	if (!alloc_cpumask_var(&domainspan, GFP_KERNEL))
++		goto out;
++	if (!alloc_cpumask_var(&covered, GFP_KERNEL))
++		goto free_domainspan;
++	if (!alloc_cpumask_var(&notcovered, GFP_KERNEL))
++		goto free_covered;
++#endif
++
++	if (!alloc_cpumask_var(&nodemask, GFP_KERNEL))
++		goto free_notcovered;
++	if (!alloc_cpumask_var(&this_sibling_map, GFP_KERNEL))
++		goto free_nodemask;
++	if (!alloc_cpumask_var(&this_core_map, GFP_KERNEL))
++		goto free_this_sibling_map;
++	if (!alloc_cpumask_var(&send_covered, GFP_KERNEL))
++		goto free_this_core_map;
++	if (!alloc_cpumask_var(&tmpmask, GFP_KERNEL))
++		goto free_send_covered;
++
++#ifdef CONFIG_NUMA
++	/*
++	 * Allocate the per-node list of sched groups
++	 */
++	sched_group_nodes = kcalloc(nr_node_ids, sizeof(struct sched_group *),
++				    GFP_KERNEL);
++	if (!sched_group_nodes) {
++		printk(KERN_WARNING "Can not alloc sched group node list\n");
++		goto free_tmpmask;
++	}
++#endif
++
++	rd = alloc_rootdomain();
++	if (!rd) {
++		printk(KERN_WARNING "Cannot alloc root domain\n");
++		goto free_sched_groups;
++	}
++
++#ifdef CONFIG_NUMA
++	sched_group_nodes_bycpu[cpumask_first(cpu_map)] = sched_group_nodes;
++#endif
++
++	/*
++	 * Set up domains for cpus specified by the cpu_map.
++	 */
++	for_each_cpu(i, cpu_map) {
++		struct sched_domain *sd = NULL, *p;
++
++		cpumask_and(nodemask, cpumask_of_node(cpu_to_node(i)), cpu_map);
++
++#ifdef CONFIG_NUMA
++		if (cpumask_weight(cpu_map) >
++				SD_NODES_PER_DOMAIN*cpumask_weight(nodemask)) {
++			sd = &per_cpu(allnodes_domains, i).sd;
++			SD_INIT(sd, ALLNODES);
++			set_domain_attribute(sd, attr);
++			cpumask_copy(sched_domain_span(sd), cpu_map);
++			cpu_to_allnodes_group(i, cpu_map, &sd->groups, tmpmask);
++			p = sd;
++			sd_allnodes = 1;
++		} else
++			p = NULL;
++
++		sd = &per_cpu(node_domains, i).sd;
++		SD_INIT(sd, NODE);
++		set_domain_attribute(sd, attr);
++		sched_domain_node_span(cpu_to_node(i), sched_domain_span(sd));
++		sd->parent = p;
++		if (p)
++			p->child = sd;
++		cpumask_and(sched_domain_span(sd),
++			    sched_domain_span(sd), cpu_map);
++#endif
++
++		p = sd;
++		sd = &per_cpu(phys_domains, i).sd;
++		SD_INIT(sd, CPU);
++		set_domain_attribute(sd, attr);
++		cpumask_copy(sched_domain_span(sd), nodemask);
++		sd->parent = p;
++		if (p)
++			p->child = sd;
++		cpu_to_phys_group(i, cpu_map, &sd->groups, tmpmask);
++
++#ifdef CONFIG_SCHED_MC
++		p = sd;
++		sd = &per_cpu(core_domains, i).sd;
++		SD_INIT(sd, MC);
++		set_domain_attribute(sd, attr);
++		cpumask_and(sched_domain_span(sd), cpu_map,
++						   cpu_coregroup_mask(i));
++		sd->parent = p;
++		p->child = sd;
++		cpu_to_core_group(i, cpu_map, &sd->groups, tmpmask);
++#endif
++
++#ifdef CONFIG_SCHED_SMT
++		p = sd;
++		sd = &per_cpu(cpu_domains, i).sd;
++		SD_INIT(sd, SIBLING);
++		set_domain_attribute(sd, attr);
++		cpumask_and(sched_domain_span(sd),
++			    topology_thread_cpumask(i), cpu_map);
++		sd->parent = p;
++		p->child = sd;
++		cpu_to_cpu_group(i, cpu_map, &sd->groups, tmpmask);
++#endif
++	}
++
++#ifdef CONFIG_SCHED_SMT
++	/* Set up CPU (sibling) groups */
++	for_each_cpu(i, cpu_map) {
++		cpumask_and(this_sibling_map,
++			    topology_thread_cpumask(i), cpu_map);
++		if (i != cpumask_first(this_sibling_map))
++			continue;
++
++		init_sched_build_groups(this_sibling_map, cpu_map,
++					&cpu_to_cpu_group,
++					send_covered, tmpmask);
++	}
++#endif
++
++#ifdef CONFIG_SCHED_MC
++	/* Set up multi-core groups */
++	for_each_cpu(i, cpu_map) {
++		cpumask_and(this_core_map, cpu_coregroup_mask(i), cpu_map);
++		if (i != cpumask_first(this_core_map))
++			continue;
++
++		init_sched_build_groups(this_core_map, cpu_map,
++					&cpu_to_core_group,
++					send_covered, tmpmask);
++	}
++#endif
++
++	/* Set up physical groups */
++	for (i = 0; i < nr_node_ids; i++) {
++		cpumask_and(nodemask, cpumask_of_node(i), cpu_map);
++		if (cpumask_empty(nodemask))
++			continue;
++
++		init_sched_build_groups(nodemask, cpu_map,
++					&cpu_to_phys_group,
++					send_covered, tmpmask);
++	}
++
++#ifdef CONFIG_NUMA
++	/* Set up node groups */
++	if (sd_allnodes) {
++		init_sched_build_groups(cpu_map, cpu_map,
++					&cpu_to_allnodes_group,
++					send_covered, tmpmask);
++	}
++
++	for (i = 0; i < nr_node_ids; i++) {
++		/* Set up node groups */
++		struct sched_group *sg, *prev;
++		int j;
++
++		cpumask_clear(covered);
++		cpumask_and(nodemask, cpumask_of_node(i), cpu_map);
++		if (cpumask_empty(nodemask)) {
++			sched_group_nodes[i] = NULL;
++			continue;
++		}
++
++		sched_domain_node_span(i, domainspan);
++		cpumask_and(domainspan, domainspan, cpu_map);
++
++		sg = kmalloc_node(sizeof(struct sched_group) + cpumask_size(),
++				  GFP_KERNEL, i);
++		if (!sg) {
++			printk(KERN_WARNING "Can not alloc domain group for "
++				"node %d\n", i);
++			goto error;
++		}
++		sched_group_nodes[i] = sg;
++		for_each_cpu(j, nodemask) {
++			struct sched_domain *sd;
++
++			sd = &per_cpu(node_domains, j).sd;
++			sd->groups = sg;
++		}
++		sg->__cpu_power = 0;
++		cpumask_copy(sched_group_cpus(sg), nodemask);
++		sg->next = sg;
++		cpumask_or(covered, covered, nodemask);
++		prev = sg;
++
++		for (j = 0; j < nr_node_ids; j++) {
++			int n = (i + j) % nr_node_ids;
++
++			cpumask_complement(notcovered, covered);
++			cpumask_and(tmpmask, notcovered, cpu_map);
++			cpumask_and(tmpmask, tmpmask, domainspan);
++			if (cpumask_empty(tmpmask))
++				break;
++
++			cpumask_and(tmpmask, tmpmask, cpumask_of_node(n));
++			if (cpumask_empty(tmpmask))
++				continue;
++
++			sg = kmalloc_node(sizeof(struct sched_group) +
++					  cpumask_size(),
++					  GFP_KERNEL, i);
++			if (!sg) {
++				printk(KERN_WARNING
++				"Can not alloc domain group for node %d\n", j);
++				goto error;
++			}
++			sg->__cpu_power = 0;
++			cpumask_copy(sched_group_cpus(sg), tmpmask);
++			sg->next = prev->next;
++			cpumask_or(covered, covered, tmpmask);
++			prev->next = sg;
++			prev = sg;
++		}
++	}
++#endif
++
++	/* Calculate CPU power for physical packages and nodes */
++#ifdef CONFIG_SCHED_SMT
++	for_each_cpu(i, cpu_map) {
++		struct sched_domain *sd = &per_cpu(cpu_domains, i).sd;
++
++		init_sched_groups_power(i, sd);
++	}
++#endif
++#ifdef CONFIG_SCHED_MC
++	for_each_cpu(i, cpu_map) {
++		struct sched_domain *sd = &per_cpu(core_domains, i).sd;
++
++		init_sched_groups_power(i, sd);
++	}
++#endif
++
++	for_each_cpu(i, cpu_map) {
++		struct sched_domain *sd = &per_cpu(phys_domains, i).sd;
++
++		init_sched_groups_power(i, sd);
++	}
++
++#ifdef CONFIG_NUMA
++	for (i = 0; i < nr_node_ids; i++)
++		init_numa_sched_groups_power(sched_group_nodes[i]);
++
++	if (sd_allnodes) {
++		struct sched_group *sg;
++
++		cpu_to_allnodes_group(cpumask_first(cpu_map), cpu_map, &sg,
++								tmpmask);
++		init_numa_sched_groups_power(sg);
++	}
++#endif
++
++	/* Attach the domains */
++	for_each_cpu(i, cpu_map) {
++		struct sched_domain *sd;
++#ifdef CONFIG_SCHED_SMT
++		sd = &per_cpu(cpu_domains, i).sd;
++#elif defined(CONFIG_SCHED_MC)
++		sd = &per_cpu(core_domains, i).sd;
++#else
++		sd = &per_cpu(phys_domains, i).sd;
++#endif
++		cpu_attach_domain(sd, rd, i);
++	}
++
++	err = 0;
++
++free_tmpmask:
++	free_cpumask_var(tmpmask);
++free_send_covered:
++	free_cpumask_var(send_covered);
++free_this_core_map:
++	free_cpumask_var(this_core_map);
++free_this_sibling_map:
++	free_cpumask_var(this_sibling_map);
++free_nodemask:
++	free_cpumask_var(nodemask);
++free_notcovered:
++#ifdef CONFIG_NUMA
++	free_cpumask_var(notcovered);
++free_covered:
++	free_cpumask_var(covered);
++free_domainspan:
++	free_cpumask_var(domainspan);
++out:
++#endif
++	return err;
++
++free_sched_groups:
++#ifdef CONFIG_NUMA
++	kfree(sched_group_nodes);
++#endif
++	goto free_tmpmask;
++
++#ifdef CONFIG_NUMA
++error:
++	free_sched_groups(cpu_map, tmpmask);
++	free_rootdomain(rd);
++	goto free_tmpmask;
++#endif
++}
++
++static int build_sched_domains(const struct cpumask *cpu_map)
++{
++	return __build_sched_domains(cpu_map, NULL);
++}
++
++static struct cpumask *doms_cur;	/* current sched domains */
++static int ndoms_cur;		/* number of sched domains in 'doms_cur' */
++static struct sched_domain_attr *dattr_cur;
++				/* attribues of custom domains in 'doms_cur' */
++
++/*
++ * Special case: If a kmalloc of a doms_cur partition (array of
++ * cpumask) fails, then fallback to a single sched domain,
++ * as determined by the single cpumask fallback_doms.
++ */
++static cpumask_var_t fallback_doms;
++
++/*
++ * arch_update_cpu_topology lets virtualized architectures update the
++ * cpu core maps. It is supposed to return 1 if the topology changed
++ * or 0 if it stayed the same.
++ */
++int __attribute__((weak)) arch_update_cpu_topology(void)
++{
++	return 0;
++}
++
++/*
++ * Set up scheduler domains and groups. Callers must hold the hotplug lock.
++ * For now this just excludes isolated cpus, but could be used to
++ * exclude other special cases in the future.
++ */
++static int arch_init_sched_domains(const struct cpumask *cpu_map)
++{
++	int err;
++
++	arch_update_cpu_topology();
++	ndoms_cur = 1;
++	doms_cur = kmalloc(cpumask_size(), GFP_KERNEL);
++	if (!doms_cur)
++		doms_cur = fallback_doms;
++	cpumask_andnot(doms_cur, cpu_map, cpu_isolated_map);
++	dattr_cur = NULL;
++	err = build_sched_domains(doms_cur);
++	register_sched_domain_sysctl();
++
++	return err;
++}
++
++static void arch_destroy_sched_domains(const struct cpumask *cpu_map,
++				       struct cpumask *tmpmask)
++{
++	free_sched_groups(cpu_map, tmpmask);
++}
++
++/*
++ * Detach sched domains from a group of cpus specified in cpu_map
++ * These cpus will now be attached to the NULL domain
++ */
++static void detach_destroy_domains(const struct cpumask *cpu_map)
++{
++	/* Save because hotplug lock held. */
++	static DECLARE_BITMAP(tmpmask, CONFIG_NR_CPUS);
++	int i;
++
++	for_each_cpu(i, cpu_map)
++		cpu_attach_domain(NULL, &def_root_domain, i);
++	synchronize_sched();
++	arch_destroy_sched_domains(cpu_map, to_cpumask(tmpmask));
++}
++
++/* handle null as "default" */
++static int dattrs_equal(struct sched_domain_attr *cur, int idx_cur,
++			struct sched_domain_attr *new, int idx_new)
++{
++	struct sched_domain_attr tmp;
++
++	/* fast path */
++	if (!new && !cur)
++		return 1;
++
++	tmp = SD_ATTR_INIT;
++	return !memcmp(cur ? (cur + idx_cur) : &tmp,
++			new ? (new + idx_new) : &tmp,
++			sizeof(struct sched_domain_attr));
++}
++
++/*
++ * Partition sched domains as specified by the 'ndoms_new'
++ * cpumasks in the array doms_new[] of cpumasks. This compares
++ * doms_new[] to the current sched domain partitioning, doms_cur[].
++ * It destroys each deleted domain and builds each new domain.
++ *
++ * 'doms_new' is an array of cpumask's of length 'ndoms_new'.
++ * The masks don't intersect (don't overlap.) We should setup one
++ * sched domain for each mask. CPUs not in any of the cpumasks will
++ * not be load balanced. If the same cpumask appears both in the
++ * current 'doms_cur' domains and in the new 'doms_new', we can leave
++ * it as it is.
++ *
++ * The passed in 'doms_new' should be kmalloc'd. This routine takes
++ * ownership of it and will kfree it when done with it. If the caller
++ * failed the kmalloc call, then it can pass in doms_new == NULL &&
++ * ndoms_new == 1, and partition_sched_domains() will fallback to
++ * the single partition 'fallback_doms', it also forces the domains
++ * to be rebuilt.
++ *
++ * If doms_new == NULL it will be replaced with cpu_online_mask.
++ * ndoms_new == 0 is a special case for destroying existing domains,
++ * and it will not create the default domain.
++ *
++ * Call with hotplug lock held
++ */
++/* FIXME: Change to struct cpumask *doms_new[] */
++void partition_sched_domains(int ndoms_new, struct cpumask *doms_new,
++			     struct sched_domain_attr *dattr_new)
++{
++	int i, j, n;
++	int new_topology;
++
++	mutex_lock(&sched_domains_mutex);
++
++	/* always unregister in case we don't destroy any domains */
++	unregister_sched_domain_sysctl();
++
++	/* Let architecture update cpu core mappings. */
++	new_topology = arch_update_cpu_topology();
++
++	n = doms_new ? ndoms_new : 0;
++
++	/* Destroy deleted domains */
++	for (i = 0; i < ndoms_cur; i++) {
++		for (j = 0; j < n && !new_topology; j++) {
++			if (cpumask_equal(&doms_cur[i], &doms_new[j])
++			    && dattrs_equal(dattr_cur, i, dattr_new, j))
++				goto match1;
++		}
++		/* no match - a current sched domain not in new doms_new[] */
++		detach_destroy_domains(doms_cur + i);
++match1:
++		;
++	}
++
++	if (doms_new == NULL) {
++		ndoms_cur = 0;
++		doms_new = fallback_doms;
++		cpumask_andnot(&doms_new[0], cpu_online_mask, cpu_isolated_map);
++		WARN_ON_ONCE(dattr_new);
++	}
++
++	/* Build new domains */
++	for (i = 0; i < ndoms_new; i++) {
++		for (j = 0; j < ndoms_cur && !new_topology; j++) {
++			if (cpumask_equal(&doms_new[i], &doms_cur[j])
++			    && dattrs_equal(dattr_new, i, dattr_cur, j))
++				goto match2;
++		}
++		/* no match - add a new doms_new */
++		__build_sched_domains(doms_new + i,
++					dattr_new ? dattr_new + i : NULL);
++match2:
++		;
++	}
++
++	/* Remember the new sched domains */
++	if (doms_cur != fallback_doms)
++		kfree(doms_cur);
++	kfree(dattr_cur);	/* kfree(NULL) is safe */
++	doms_cur = doms_new;
++	dattr_cur = dattr_new;
++	ndoms_cur = ndoms_new;
++
++	register_sched_domain_sysctl();
++
++	mutex_unlock(&sched_domains_mutex);
++}
++
++#if defined(CONFIG_SCHED_MC) || defined(CONFIG_SCHED_SMT)
++static void arch_reinit_sched_domains(void)
++{
++	get_online_cpus();
++
++	/* Destroy domains first to force the rebuild */
++	partition_sched_domains(0, NULL, NULL);
++
++	rebuild_sched_domains();
++	put_online_cpus();
++}
++
++static ssize_t sched_power_savings_store(const char *buf, size_t count, int smt)
++{
++	unsigned int level = 0;
++
++	if (sscanf(buf, "%u", &level) != 1)
++		return -EINVAL;
++
++	/*
++	 * level is always be positive so don't check for
++	 * level < POWERSAVINGS_BALANCE_NONE which is 0
++	 * What happens on 0 or 1 byte write,
++	 * need to check for count as well?
++	 */
++
++	if (level >= MAX_POWERSAVINGS_BALANCE_LEVELS)
++		return -EINVAL;
++
++	if (smt)
++		sched_smt_power_savings = level;
++	else
++		sched_mc_power_savings = level;
++
++	arch_reinit_sched_domains();
++
++	return count;
++}
++
++#ifdef CONFIG_SCHED_MC
++static ssize_t sched_mc_power_savings_show(struct sysdev_class *class,
++					   char *page)
++{
++	return sprintf(page, "%u\n", sched_mc_power_savings);
++}
++static ssize_t sched_mc_power_savings_store(struct sysdev_class *class,
++					    const char *buf, size_t count)
++{
++	return sched_power_savings_store(buf, count, 0);
++}
++static SYSDEV_CLASS_ATTR(sched_mc_power_savings, 0644,
++			 sched_mc_power_savings_show,
++			 sched_mc_power_savings_store);
++#endif
++
++#ifdef CONFIG_SCHED_SMT
++static ssize_t sched_smt_power_savings_show(struct sysdev_class *dev,
++					    char *page)
++{
++	return sprintf(page, "%u\n", sched_smt_power_savings);
++}
++static ssize_t sched_smt_power_savings_store(struct sysdev_class *dev,
++					     const char *buf, size_t count)
++{
++	return sched_power_savings_store(buf, count, 1);
++}
++static SYSDEV_CLASS_ATTR(sched_smt_power_savings, 0644,
++		   sched_smt_power_savings_show,
++		   sched_smt_power_savings_store);
++#endif
++
++int __init sched_create_sysfs_power_savings_entries(struct sysdev_class *cls)
++{
++	int err = 0;
++
++#ifdef CONFIG_SCHED_SMT
++	if (smt_capable())
++		err = sysfs_create_file(&cls->kset.kobj,
++					&attr_sched_smt_power_savings.attr);
++#endif
++#ifdef CONFIG_SCHED_MC
++	if (!err && mc_capable())
++		err = sysfs_create_file(&cls->kset.kobj,
++					&attr_sched_mc_power_savings.attr);
++#endif
++	return err;
++}
++#endif /* CONFIG_SCHED_MC || CONFIG_SCHED_SMT */
++
++#ifndef CONFIG_CPUSETS
++/*
++ * Add online and remove offline CPUs from the scheduler domains.
++ * When cpusets are enabled they take over this function.
++ */
++static int update_sched_domains(struct notifier_block *nfb,
++				unsigned long action, void *hcpu)
++{
++	switch (action) {
++	case CPU_ONLINE:
++	case CPU_ONLINE_FROZEN:
++	case CPU_DEAD:
++	case CPU_DEAD_FROZEN:
++		partition_sched_domains(1, NULL, NULL);
++		return NOTIFY_OK;
++
++	default:
++		return NOTIFY_DONE;
++	}
++}
++#endif
++
++static int update_runtime(struct notifier_block *nfb,
++				unsigned long action, void *hcpu)
++{
++	switch (action) {
++	case CPU_DOWN_PREPARE:
++	case CPU_DOWN_PREPARE_FROZEN:
++		return NOTIFY_OK;
++
++	case CPU_DOWN_FAILED:
++	case CPU_DOWN_FAILED_FROZEN:
++	case CPU_ONLINE:
++	case CPU_ONLINE_FROZEN:
++		return NOTIFY_OK;
++
++	default:
++		return NOTIFY_DONE;
++	}
++}
++
++void __init sched_init_smp(void)
++{
++	cpumask_var_t non_isolated_cpus;
++
++	alloc_cpumask_var(&non_isolated_cpus, GFP_KERNEL);
++
++#if defined(CONFIG_NUMA)
++	sched_group_nodes_bycpu = kzalloc(nr_cpu_ids * sizeof(void **),
++								GFP_KERNEL);
++	BUG_ON(sched_group_nodes_bycpu == NULL);
++#endif
++	get_online_cpus();
++	mutex_lock(&sched_domains_mutex);
++	arch_init_sched_domains(cpu_online_mask);
++	cpumask_andnot(non_isolated_cpus, cpu_possible_mask, cpu_isolated_map);
++	if (cpumask_empty(non_isolated_cpus))
++		cpumask_set_cpu(smp_processor_id(), non_isolated_cpus);
++	mutex_unlock(&sched_domains_mutex);
++	put_online_cpus();
++
++#ifndef CONFIG_CPUSETS
++	/* XXX: Theoretical race here - CPU may be hotplugged now */
++	hotcpu_notifier(update_sched_domains, 0);
++#endif
++
++	/* RT runtime code needs to handle some hotplug events */
++	hotcpu_notifier(update_runtime, 0);
++
++	/* Move init over to a non-isolated CPU */
++	if (set_cpus_allowed_ptr(current, non_isolated_cpus) < 0)
++		BUG();
++	free_cpumask_var(non_isolated_cpus);
++
++	alloc_cpumask_var(&fallback_doms, GFP_KERNEL);
++
++	/*
++	 * Assume that every added cpu gives us slightly less overall latency
++	 * allowing us to increase the base rr_interval, but in a non linear
++	 * fashion.
++	 */
++	rr_interval *= 1 + ilog2(num_online_cpus());
++}
++#else
++void __init sched_init_smp(void)
++{
++}
++#endif /* CONFIG_SMP */
++
++unsigned int sysctl_timer_migration = 1;
++
++int in_sched_functions(unsigned long addr)
++{
++	return in_lock_functions(addr) ||
++		(addr >= (unsigned long)__sched_text_start
++		&& addr < (unsigned long)__sched_text_end);
++}
++
++void __init sched_init(void)
++{
++	int i;
++	int highest_cpu = 0;
++
++	prio_ratios[0] = 100;
++	for (i = 1 ; i < PRIO_RANGE ; i++)
++		prio_ratios[i] = prio_ratios[i - 1] * 11 / 10;
++
++#ifdef CONFIG_SMP
++	init_defrootdomain();
++	cpus_clear(grq.cpu_idle_map);
++#endif
++	spin_lock_init(&grq.lock);
++	for_each_possible_cpu(i) {
++		struct rq *rq;
++
++		rq = cpu_rq(i);
++		INIT_LIST_HEAD(&rq->queue);
++		rq->rq_deadline = 0;
++		rq->rq_prio = 0;
++		rq->cpu = i;
++		rq->user_pc = rq->nice_pc = rq->softirq_pc = rq->system_pc =
++			      rq->iowait_pc = rq->idle_pc = 0;
++#ifdef CONFIG_SMP
++		rq->sd = NULL;
++		rq->rd = NULL;
++		rq->online = 0;
++		INIT_LIST_HEAD(&rq->migration_queue);
++		rq_attach_root(rq, &def_root_domain);
++#endif
++		atomic_set(&rq->nr_iowait, 0);
++		highest_cpu = i;
++	}
++	grq.iso_ticks = grq.nr_running = grq.nr_uninterruptible = 0;
++	for (i = 0; i < PRIO_LIMIT; i++)
++		INIT_LIST_HEAD(grq.queue + i);
++	bitmap_zero(grq.prio_bitmap, PRIO_LIMIT);
++	/* delimiter for bitsearch */
++	__set_bit(PRIO_LIMIT, grq.prio_bitmap);
++
++#ifdef CONFIG_SMP
++	nr_cpu_ids = highest_cpu + 1;
++#endif
++
++#ifdef CONFIG_PREEMPT_NOTIFIERS
++	INIT_HLIST_HEAD(&init_task.preempt_notifiers);
++#endif
++
++#ifdef CONFIG_RT_MUTEXES
++	plist_head_init(&init_task.pi_waiters, &init_task.pi_lock);
++#endif
++
++	/*
++	 * The boot idle thread does lazy MMU switching as well:
++	 */
++	atomic_inc(&init_mm.mm_count);
++	enter_lazy_tlb(&init_mm, current);
++
++	/*
++	 * Make us the idle thread. Technically, schedule() should not be
++	 * called from this thread, however somewhere below it might be,
++	 * but because we are the idle thread, we just pick up running again
++	 * when this runqueue becomes "idle".
++	 */
++	init_idle(current, smp_processor_id());
++
++	/* Allocate the nohz_cpu_mask if CONFIG_CPUMASK_OFFSTACK */
++	alloc_cpumask_var(&nohz_cpu_mask, GFP_NOWAIT);
++#ifdef CONFIG_SMP
++#ifdef CONFIG_NO_HZ
++	alloc_cpumask_var(&nohz.cpu_mask, GFP_NOWAIT);
++	alloc_cpumask_var(&nohz.ilb_grp_nohz_mask, GFP_NOWAIT);
++#endif
++	alloc_cpumask_var(&cpu_isolated_map, GFP_NOWAIT);
++#endif /* SMP */
++	perf_counter_init();
++}
++
++#ifdef CONFIG_DEBUG_SPINLOCK_SLEEP
++void __might_sleep(char *file, int line)
++{
++#ifdef in_atomic
++	static unsigned long prev_jiffy;	/* ratelimiting */
++
++	if ((in_atomic() || irqs_disabled()) &&
++	    system_state == SYSTEM_RUNNING && !oops_in_progress) {
++		if (time_before(jiffies, prev_jiffy + HZ) && prev_jiffy)
++			return;
++		prev_jiffy = jiffies;
++		printk(KERN_ERR "BUG: sleeping function called from invalid"
++				" context at %s:%d\n", file, line);
++		printk("in_atomic():%d, irqs_disabled():%d\n",
++			in_atomic(), irqs_disabled());
++		debug_show_held_locks(current);
++		if (irqs_disabled())
++			print_irqtrace_events(current);
++		dump_stack();
++	}
++#endif
++}
++EXPORT_SYMBOL(__might_sleep);
++#endif
++
++#ifdef CONFIG_MAGIC_SYSRQ
++void normalize_rt_tasks(void)
++{
++	struct task_struct *g, *p;
++	unsigned long flags;
++	struct rq *rq;
++	int queued;
++
++	read_lock_irq(&tasklist_lock);
++
++	do_each_thread(g, p) {
++		if (!rt_task(p) && !iso_task(p))
++			continue;
++
++		spin_lock_irqsave(&p->pi_lock, flags);
++		rq = __task_grq_lock(p);
++		update_rq_clock(rq);
++
++		queued = task_queued_only(p);
++		if (queued)
++			dequeue_task(p);
++		__setscheduler(p, SCHED_NORMAL, 0);
++		if (task_running(p))
++			resched_task(p);
++		if (queued) {
++			enqueue_task(p);
++			try_preempt(p);
++		}
++
++		__task_grq_unlock();
++		spin_unlock_irqrestore(&p->pi_lock, flags);
++	} while_each_thread(g, p);
++
++	read_unlock_irq(&tasklist_lock);
++}
++#endif /* CONFIG_MAGIC_SYSRQ */
++
++#ifdef CONFIG_IA64
++/*
++ * These functions are only useful for the IA64 MCA handling.
++ *
++ * They can only be called when the whole system has been
++ * stopped - every CPU needs to be quiescent, and no scheduling
++ * activity can take place. Using them for anything else would
++ * be a serious bug, and as a result, they aren't even visible
++ * under any other configuration.
++ */
++
++/**
++ * curr_task - return the current task for a given cpu.
++ * @cpu: the processor in question.
++ *
++ * ONLY VALID WHEN THE WHOLE SYSTEM IS STOPPED!
++ */
++struct task_struct *curr_task(int cpu)
++{
++	return cpu_curr(cpu);
++}
++
++/**
++ * set_curr_task - set the current task for a given cpu.
++ * @cpu: the processor in question.
++ * @p: the task pointer to set.
++ *
++ * Description: This function must only be used when non-maskable interrupts
++ * are serviced on a separate stack.  It allows the architecture to switch the
++ * notion of the current task on a cpu in a non-blocking manner.  This function
++ * must be called with all CPU's synchronized, and interrupts disabled, the
++ * and caller must save the original value of the current task (see
++ * curr_task() above) and restore that value before reenabling interrupts and
++ * re-starting the system.
++ *
++ * ONLY VALID WHEN THE WHOLE SYSTEM IS STOPPED!
++ */
++void set_curr_task(int cpu, struct task_struct *p)
++{
++	cpu_curr(cpu) = p;
++}
++
++#endif
++
++/*
++ * Use precise platform statistics if available:
++ */
++#ifdef CONFIG_VIRT_CPU_ACCOUNTING
++cputime_t task_utime(struct task_struct *p)
++{
++	return p->utime;
++}
++
++cputime_t task_stime(struct task_struct *p)
++{
++	return p->stime;
++}
++#else
++cputime_t task_utime(struct task_struct *p)
++{
++	clock_t utime = cputime_to_clock_t(p->utime),
++		total = utime + cputime_to_clock_t(p->stime);
++	u64 temp;
++
++	temp = (u64)nsec_to_clock_t(p->se.sum_exec_runtime);
++
++	if (total) {
++		temp *= utime;
++		do_div(temp, total);
++	}
++	utime = (clock_t)temp;
++
++	p->prev_utime = max(p->prev_utime, clock_t_to_cputime(utime));
++	return p->prev_utime;
++}
++
++cputime_t task_stime(struct task_struct *p)
++{
++	clock_t stime;
++
++	stime = nsec_to_clock_t(p->se.sum_exec_runtime) -
++			cputime_to_clock_t(task_utime(p));
++
++	if (stime >= 0)
++		p->prev_stime = max(p->prev_stime, clock_t_to_cputime(stime));
++
++	return p->prev_stime;
++}
++#endif
++
++inline cputime_t task_gtime(struct task_struct *p)
++{
++	return p->gtime;
++}
++
++void __cpuinit init_idle_bootup_task(struct task_struct *idle)
++{}
++
++#ifdef CONFIG_SCHED_DEBUG
++void proc_sched_show_task(struct task_struct *p, struct seq_file *m)
++{}
++
++void proc_sched_set_task(struct task_struct *p)
++{}
++#endif
+--- a/kernel/sysctl.c
++++ b/kernel/sysctl.c
+@@ -86,6 +86,8 @@ extern int percpu_pagelist_fraction;
+ extern int compat_log;
+ extern int latencytop_enabled;
+ extern int sysctl_nr_open_min, sysctl_nr_open_max;
++extern int rr_interval;
++extern int sched_iso_cpu;
+ #ifndef CONFIG_MMU
+ extern int sysctl_nr_trim_pages;
+ #endif
+@@ -103,7 +105,8 @@ static int zero;
+ static int __maybe_unused one = 1;
+ static int __maybe_unused two = 2;
+ static unsigned long one_ul = 1;
+-static int one_hundred = 100;
++static int __read_mostly one_hundred = 100;
++static int __maybe_unused __read_mostly five_thousand = 5000;
+ 
+ /* this is needed for the proc_doulongvec_minmax of vm_dirty_bytes */
+ static unsigned long dirty_bytes_min = 2 * PAGE_SIZE;
+@@ -238,7 +241,7 @@ static struct ctl_table root_table[] = {
+ 	{ .ctl_name = 0 }
+ };
+ 
+-#ifdef CONFIG_SCHED_DEBUG
++#if defined(CONFIG_SCHED_DEBUG) && defined(CONFIG_SCHED_CFS)
+ static int min_sched_granularity_ns = 100000;		/* 100 usecs */
+ static int max_sched_granularity_ns = NSEC_PER_SEC;	/* 1 second */
+ static int min_wakeup_granularity_ns;			/* 0 usecs */
+@@ -246,7 +249,7 @@ static int max_wakeup_granularity_ns = N
+ #endif
+ 
+ static struct ctl_table kern_table[] = {
+-#ifdef CONFIG_SCHED_DEBUG
++#if defined(CONFIG_SCHED_DEBUG) && defined(CONFIG_SCHED_CFS)
+ 	{
+ 		.ctl_name	= CTL_UNNUMBERED,
+ 		.procname	= "sched_min_granularity_ns",
+@@ -342,6 +345,7 @@ static struct ctl_table kern_table[] = {
+ 		.extra2		= &one,
+ 	},
+ #endif
++#ifdef CONFIG_SCHED_CFS
+ 	{
+ 		.ctl_name	= CTL_UNNUMBERED,
+ 		.procname	= "sched_rt_period_us",
+@@ -366,6 +370,7 @@ static struct ctl_table kern_table[] = {
+ 		.mode		= 0644,
+ 		.proc_handler	= &proc_dointvec,
+ 	},
++#endif
+ #ifdef CONFIG_PROVE_LOCKING
+ 	{
+ 		.ctl_name	= CTL_UNNUMBERED,
+@@ -798,6 +803,30 @@ static struct ctl_table kern_table[] = {
+ 		.proc_handler	= &proc_dointvec,
+ 	},
+ #endif
++#ifdef CONFIG_SCHED_BFS
++	{
++		.ctl_name	= CTL_UNNUMBERED,
++		.procname	= "rr_interval",
++		.data		= &rr_interval,
++		.maxlen		= sizeof (int),
++		.mode		= 0644,
++		.proc_handler	= &proc_dointvec_minmax,
++		.strategy	= &sysctl_intvec,
++		.extra1		= &one,
++		.extra2		= &five_thousand,
++	},
++	{
++		.ctl_name	= CTL_UNNUMBERED,
++		.procname	= "iso_cpu",
++		.data		= &sched_iso_cpu,
++		.maxlen		= sizeof (int),
++		.mode		= 0644,
++		.proc_handler	= &proc_dointvec_minmax,
++		.strategy	= &sysctl_intvec,
++		.extra1		= &zero,
++		.extra2		= &one_hundred,
++	},
++#endif
+ #if defined(CONFIG_S390) && defined(CONFIG_SMP)
+ 	{
+ 		.ctl_name	= KERN_SPIN_RETRY,
+--- a/kernel/workqueue.c
++++ b/kernel/workqueue.c
+@@ -317,7 +317,9 @@ static int worker_thread(void *__cwq)
+ 	if (cwq->wq->freezeable)
+ 		set_freezable();
+ 
++#ifdef CONFIG_SCHED_CFS
+ 	set_user_nice(current, -5);
++#endif
+ 
+ 	for (;;) {
+ 		prepare_to_wait(&cwq->more_work, &wait, TASK_INTERRUPTIBLE);
diff -Nru a/target/linux/generic/patches-2.6.31/300-ipv6_accept_ra_when_forwarding.patch b/target/linux/generic/patches-2.6.31/300-ipv6_accept_ra_when_forwarding.patch
--- a/target/linux/generic/patches-2.6.31/300-ipv6_accept_ra_when_forwarding.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/300-ipv6_accept_ra_when_forwarding.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,30 @@
+--- a/net/ipv6/ndisc.c
++++ b/net/ipv6/ndisc.c
+@@ -1106,6 +1106,18 @@ errout:
+ 	rtnl_set_sk_err(net, RTNLGRP_ND_USEROPT, err);
+ }
+ 
++static inline int accept_ra(struct inet6_dev *in6_dev)
++{
++	/*
++	 * If forwarding is enabled, RA are not accepted unless the special
++	 * hybrid mode (accept_ra=2) is enabled.
++	 */
++	if (in6_dev->cnf.forwarding && in6_dev->cnf.accept_ra < 2)
++		return 0;
++
++	return in6_dev->cnf.accept_ra;
++}
++
+ static void ndisc_router_discovery(struct sk_buff *skb)
+ {
+ 	struct ra_msg *ra_msg = (struct ra_msg *)skb_transport_header(skb);
+@@ -1151,7 +1163,7 @@ static void ndisc_router_discovery(struc
+ 			   skb->dev->name);
+ 		return;
+ 	}
+-	if (in6_dev->cnf.forwarding || !in6_dev->cnf.accept_ra) {
++	if (!accept_ra(in6_dev)) {
+ 		in6_dev_put(in6_dev);
+ 		return;
+ 	}
diff -Nru a/target/linux/generic/patches-2.6.31/301-ipv6_send_rs_when_forwarding.patch b/target/linux/generic/patches-2.6.31/301-ipv6_send_rs_when_forwarding.patch
--- a/target/linux/generic/patches-2.6.31/301-ipv6_send_rs_when_forwarding.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/301-ipv6_send_rs_when_forwarding.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,12 @@
+--- a/net/ipv6/addrconf.c
++++ b/net/ipv6/addrconf.c
+@@ -2864,7 +2864,8 @@ static void addrconf_dad_completed(struc
+ 	   start sending router solicitations.
+ 	 */
+ 
+-	if (ifp->idev->cnf.forwarding == 0 &&
++	if ((ifp->idev->cnf.forwarding == 0 ||
++	     ifp->idev->cnf.forwarding == 2) &&
+ 	    ifp->idev->cnf.rtr_solicits > 0 &&
+ 	    (dev->flags&IFF_LOOPBACK) == 0 &&
+ 	    (ipv6_addr_type(&ifp->addr) & IPV6_ADDR_LINKLOCAL)) {
diff -Nru a/target/linux/generic/patches-2.6.31/400-ledtrig_morse.patch b/target/linux/generic/patches-2.6.31/400-ledtrig_morse.patch
--- a/target/linux/generic/patches-2.6.31/400-ledtrig_morse.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/400-ledtrig_morse.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,18 @@
+--- a/drivers/leds/Kconfig
++++ b/drivers/leds/Kconfig
+@@ -297,4 +297,8 @@ config LEDS_TRIGGER_DEFAULT_ON
+ comment "iptables trigger is under Netfilter config (LED target)"
+ 	depends on LEDS_TRIGGERS
+ 
++config LEDS_TRIGGER_MORSE
++	tristate "LED Morse Trigger"
++	depends on LEDS_TRIGGERS
++
+ endif # NEW_LEDS
+--- a/drivers/leds/Makefile
++++ b/drivers/leds/Makefile
+@@ -39,3 +39,4 @@ obj-$(CONFIG_LEDS_TRIGGER_HEARTBEAT)	+=
+ obj-$(CONFIG_LEDS_TRIGGER_BACKLIGHT)	+= ledtrig-backlight.o
+ obj-$(CONFIG_LEDS_TRIGGER_GPIO)		+= ledtrig-gpio.o
+ obj-$(CONFIG_LEDS_TRIGGER_DEFAULT_ON)	+= ledtrig-default-on.o
++obj-$(CONFIG_LEDS_TRIGGER_MORSE)	+= ledtrig-morse.o
diff -Nru a/target/linux/generic/patches-2.6.31/402-ledtrig_netdev.patch b/target/linux/generic/patches-2.6.31/402-ledtrig_netdev.patch
--- a/target/linux/generic/patches-2.6.31/402-ledtrig_netdev.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/402-ledtrig_netdev.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,21 @@
+--- a/drivers/leds/Kconfig
++++ b/drivers/leds/Kconfig
+@@ -301,4 +301,11 @@ config LEDS_TRIGGER_MORSE
+ 	tristate "LED Morse Trigger"
+ 	depends on LEDS_TRIGGERS
+ 
++config LEDS_TRIGGER_NETDEV
++	tristate "LED Netdev Trigger"
++	depends on NET && LEDS_TRIGGERS
++	help
++	  This allows LEDs to be controlled by network device activity.
++	  If unsure, say Y.
++
+ endif # NEW_LEDS
+--- a/drivers/leds/Makefile
++++ b/drivers/leds/Makefile
+@@ -40,3 +40,4 @@ obj-$(CONFIG_LEDS_TRIGGER_BACKLIGHT)	+=
+ obj-$(CONFIG_LEDS_TRIGGER_GPIO)		+= ledtrig-gpio.o
+ obj-$(CONFIG_LEDS_TRIGGER_DEFAULT_ON)	+= ledtrig-default-on.o
+ obj-$(CONFIG_LEDS_TRIGGER_MORSE)	+= ledtrig-morse.o
++obj-$(CONFIG_LEDS_TRIGGER_NETDEV)	+= ledtrig-netdev.o
diff -Nru a/target/linux/generic/patches-2.6.31/410-gpio_buttons.patch b/target/linux/generic/patches-2.6.31/410-gpio_buttons.patch
--- a/target/linux/generic/patches-2.6.31/410-gpio_buttons.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/410-gpio_buttons.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,31 @@
+--- a/drivers/input/misc/Kconfig
++++ b/drivers/input/misc/Kconfig
+@@ -269,4 +269,21 @@ config INPUT_DM355EVM
+ 
+ 	  To compile this driver as a module, choose M here: the
+ 	  module will be called dm355evm_keys.
++
++config INPUT_GPIO_BUTTONS
++	tristate "Polled GPIO buttons interface"
++	depends on GENERIC_GPIO
++	select INPUT_POLLDEV
++	help
++	  This driver implements support for buttons connected
++	  to GPIO pins of various CPUs (and some other chips).
++
++	  Say Y here if your device has buttons connected
++	  directly to such GPIO pins.  Your board-specific
++	  setup logic must also provide a platform device,
++	  with configuration data saying which GPIOs are used.
++
++	  To compile this driver as a module, choose M here: the
++	  module will be called gpio-buttons.
++
+ endif
+--- a/drivers/input/misc/Makefile
++++ b/drivers/input/misc/Makefile
+@@ -26,3 +26,4 @@ obj-$(CONFIG_INPUT_TWL4030_PWRBUTTON)	+=
+ obj-$(CONFIG_INPUT_UINPUT)		+= uinput.o
+ obj-$(CONFIG_INPUT_WISTRON_BTNS)	+= wistron_btns.o
+ obj-$(CONFIG_INPUT_YEALINK)		+= yealink.o
++obj-$(CONFIG_INPUT_GPIO_BUTTONS)	+= gpio_buttons.o
diff -Nru a/target/linux/generic/patches-2.6.31/420-gpiodev.patch b/target/linux/generic/patches-2.6.31/420-gpiodev.patch
--- a/target/linux/generic/patches-2.6.31/420-gpiodev.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/420-gpiodev.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,27 @@
+--- a/drivers/char/Kconfig
++++ b/drivers/char/Kconfig
+@@ -1029,6 +1029,14 @@ config CS5535_GPIO
+ 
+ 	  If compiled as a module, it will be called cs5535_gpio.
+ 
++config GPIO_DEVICE
++	tristate "GPIO device support"
++	depends on GENERIC_GPIO
++	help
++	  Say Y to enable Linux GPIO device support.  This allows control of
++	  GPIO pins using a character device
++
++
+ config RAW_DRIVER
+ 	tristate "RAW driver (/dev/raw/rawN)"
+ 	depends on BLOCK
+--- a/drivers/char/Makefile
++++ b/drivers/char/Makefile
+@@ -95,6 +95,7 @@ obj-$(CONFIG_SCx200_GPIO)	+= scx200_gpio
+ obj-$(CONFIG_PC8736x_GPIO)	+= pc8736x_gpio.o
+ obj-$(CONFIG_NSC_GPIO)		+= nsc_gpio.o
+ obj-$(CONFIG_CS5535_GPIO)	+= cs5535_gpio.o
++obj-$(CONFIG_GPIO_DEVICE)	+= gpio_dev.o
+ obj-$(CONFIG_GPIO_TB0219)	+= tb0219.o
+ obj-$(CONFIG_TELCLOCK)		+= tlclk.o
+ 
diff -Nru a/target/linux/generic/patches-2.6.31/430-scsi_header_fix.patch b/target/linux/generic/patches-2.6.31/430-scsi_header_fix.patch
--- a/target/linux/generic/patches-2.6.31/430-scsi_header_fix.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/430-scsi_header_fix.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,17 @@
+--- a/include/scsi/scsi.h
++++ b/include/scsi/scsi.h
+@@ -142,10 +142,10 @@ struct scsi_cmnd;
+ 
+ /* defined in T10 SCSI Primary Commands-2 (SPC2) */
+ struct scsi_varlen_cdb_hdr {
+-	u8 opcode;        /* opcode always == VARIABLE_LENGTH_CMD */
+-	u8 control;
+-	u8 misc[5];
+-	u8 additional_cdb_length;         /* total cdb length - 8 */
++	__u8 opcode;        /* opcode always == VARIABLE_LENGTH_CMD */
++	__u8 control;
++	__u8 misc[5];
++	__u8 additional_cdb_length;         /* total cdb length - 8 */
+ 	__be16 service_action;
+ 	/* service specific data follows */
+ };
diff -Nru a/target/linux/generic/patches-2.6.31/510-yaffs_support.patch b/target/linux/generic/patches-2.6.31/510-yaffs_support.patch
--- a/target/linux/generic/patches-2.6.31/510-yaffs_support.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/510-yaffs_support.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,17 @@
+--- a/fs/Kconfig
++++ b/fs/Kconfig
+@@ -188,6 +188,7 @@ source "fs/sysv/Kconfig"
+ source "fs/ufs/Kconfig"
+ source "fs/exofs/Kconfig"
+ source "fs/nilfs2/Kconfig"
++source "fs/yaffs2/Kconfig"
+ 
+ endif # MISC_FILESYSTEMS
+ 
+--- a/fs/Makefile
++++ b/fs/Makefile
+@@ -125,3 +125,4 @@ obj-$(CONFIG_OCFS2_FS)		+= ocfs2/
+ obj-$(CONFIG_BTRFS_FS)		+= btrfs/
+ obj-$(CONFIG_GFS2_FS)           += gfs2/
+ obj-$(CONFIG_EXOFS_FS)          += exofs/
++obj-$(CONFIG_YAFFS_FS)		+= yaffs2/
diff -Nru a/target/linux/generic/patches-2.6.31/600-phy_extension.patch b/target/linux/generic/patches-2.6.31/600-phy_extension.patch
--- a/target/linux/generic/patches-2.6.31/600-phy_extension.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/600-phy_extension.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,83 @@
+--- a/drivers/net/phy/phy.c
++++ b/drivers/net/phy/phy.c
+@@ -299,6 +299,50 @@ int phy_ethtool_gset(struct phy_device *
+ }
+ EXPORT_SYMBOL(phy_ethtool_gset);
+ 
++int phy_ethtool_ioctl(struct phy_device *phydev, void *useraddr)
++{
++	u32 cmd;
++	int tmp;
++	struct ethtool_cmd ecmd = { ETHTOOL_GSET };
++	struct ethtool_value edata = { ETHTOOL_GLINK };
++
++	if (get_user(cmd, (u32 *) useraddr))
++		return -EFAULT;
++
++	switch (cmd) {
++	case ETHTOOL_GSET:
++		phy_ethtool_gset(phydev, &ecmd);
++		if (copy_to_user(useraddr, &ecmd, sizeof(ecmd)))
++			return -EFAULT;
++		return 0;
++
++	case ETHTOOL_SSET:
++		if (copy_from_user(&ecmd, useraddr, sizeof(ecmd)))
++			return -EFAULT;
++		return phy_ethtool_sset(phydev, &ecmd);
++
++	case ETHTOOL_NWAY_RST:
++		/* if autoneg is off, it's an error */
++		tmp = phy_read(phydev, MII_BMCR);
++		if (tmp & BMCR_ANENABLE) {
++			tmp |= (BMCR_ANRESTART);
++			phy_write(phydev, MII_BMCR, tmp);
++			return 0;
++		}
++		return -EINVAL;
++
++	case ETHTOOL_GLINK:
++		edata.data = (phy_read(phydev,
++				MII_BMSR) & BMSR_LSTATUS) ? 1 : 0;
++		if (copy_to_user(useraddr, &edata, sizeof(edata)))
++			return -EFAULT;
++		return 0;
++	}
++
++	return -EOPNOTSUPP;
++}
++EXPORT_SYMBOL(phy_ethtool_ioctl);
++
+ /**
+  * phy_mii_ioctl - generic PHY MII ioctl interface
+  * @phydev: the phy_device struct
+@@ -355,8 +399,8 @@ int phy_mii_ioctl(struct phy_device *phy
+ 		}
+ 
+ 		phy_write(phydev, mii_data->reg_num, val);
+-		
+-		if (mii_data->reg_num == MII_BMCR 
++
++		if (mii_data->reg_num == MII_BMCR
+ 				&& val & BMCR_RESET
+ 				&& phydev->drv->config_init) {
+ 			phy_scan_fixups(phydev);
+@@ -471,7 +515,7 @@ static void phy_force_reduction(struct p
+ 	int idx;
+ 
+ 	idx = phy_find_setting(phydev->speed, phydev->duplex);
+-	
++
+ 	idx++;
+ 
+ 	idx = phy_find_valid(idx, phydev->supported);
+--- a/include/linux/phy.h
++++ b/include/linux/phy.h
+@@ -489,6 +489,7 @@ void phy_start_machine(struct phy_device
+ void phy_stop_machine(struct phy_device *phydev);
+ int phy_ethtool_sset(struct phy_device *phydev, struct ethtool_cmd *cmd);
+ int phy_ethtool_gset(struct phy_device *phydev, struct ethtool_cmd *cmd);
++int phy_ethtool_ioctl(struct phy_device *phydev, void *useraddr);
+ int phy_mii_ioctl(struct phy_device *phydev,
+ 		struct mii_ioctl_data *mii_data, int cmd);
+ int phy_start_interrupts(struct phy_device *phydev);
diff -Nru a/target/linux/generic/patches-2.6.31/601-phy-add-aneg-done-function.patch b/target/linux/generic/patches-2.6.31/601-phy-add-aneg-done-function.patch
--- a/target/linux/generic/patches-2.6.31/601-phy-add-aneg-done-function.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/601-phy-add-aneg-done-function.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,45 @@
+--- a/include/linux/phy.h
++++ b/include/linux/phy.h
+@@ -379,9 +379,18 @@ struct phy_driver {
+ 	 */
+ 	int (*config_aneg)(struct phy_device *phydev);
+ 
++	/* Determine if autonegotiation is done */
++	int (*aneg_done)(struct phy_device *phydev);
++
+ 	/* Determines the negotiated speed and duplex */
+ 	int (*read_status)(struct phy_device *phydev);
+ 
++	/* 
++	 * Update the value in phydev->link to reflect the 
++	 * current link value
++	 */
++	int (*update_link)(struct phy_device *phydev);
++
+ 	/* Clears any pending interrupts */
+ 	int (*ack_interrupt)(struct phy_device *phydev);
+ 
+--- a/drivers/net/phy/phy_device.c
++++ b/drivers/net/phy/phy_device.c
+@@ -681,6 +681,9 @@ int genphy_update_link(struct phy_device
+ {
+ 	int status;
+ 
++	if (phydev->drv->update_link)
++		return phydev->drv->update_link(phydev);
++
+ 	/* Do a fake read */
+ 	status = phy_read(phydev, MII_BMSR);
+ 
+--- a/drivers/net/phy/phy.c
++++ b/drivers/net/phy/phy.c
+@@ -107,6 +107,9 @@ static inline int phy_aneg_done(struct p
+ {
+ 	int retval;
+ 
++	if (phydev->drv->aneg_done)
++		return phydev->drv->aneg_done(phydev);
++
+ 	retval = phy_read(phydev, MII_BMSR);
+ 
+ 	return (retval < 0) ? retval : (retval & BMSR_ANEGCOMPLETE);
diff -Nru a/target/linux/generic/patches-2.6.31/620-phy_adm6996.patch b/target/linux/generic/patches-2.6.31/620-phy_adm6996.patch
--- a/target/linux/generic/patches-2.6.31/620-phy_adm6996.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/620-phy_adm6996.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,26 @@
+--- a/drivers/net/phy/Kconfig
++++ b/drivers/net/phy/Kconfig
+@@ -82,6 +82,13 @@ config LSI_ET1011C_PHY
+ 	---help---
+ 	  Supports the LSI ET1011C PHY.
+ 
++config ADM6996_PHY
++	tristate "Driver for ADM6996 switches"
++	select SWCONFIG
++	---help---
++	  Currently supports the ADM6996FC and ADM6996M switches.
++	  Support for FC is very limited.
++
+ config FIXED_PHY
+ 	bool "Driver for MDIO Bus/PHY emulation with fixed speed/link PHYs"
+ 	depends on PHYLIB=y
+--- a/drivers/net/phy/Makefile
++++ b/drivers/net/phy/Makefile
+@@ -12,6 +12,7 @@ obj-$(CONFIG_SMSC_PHY)		+= smsc.o
+ obj-$(CONFIG_VITESSE_PHY)	+= vitesse.o
+ obj-$(CONFIG_BROADCOM_PHY)	+= broadcom.o
+ obj-$(CONFIG_ICPLUS_PHY)	+= icplus.o
++obj-$(CONFIG_ADM6996_PHY)	+= adm6996.o
+ obj-$(CONFIG_REALTEK_PHY)	+= realtek.o
+ obj-$(CONFIG_LSI_ET1011C_PHY)	+= et1011c.o
+ obj-$(CONFIG_FIXED_PHY)		+= fixed.o
diff -Nru a/target/linux/generic/patches-2.6.31/630-phy_packets.patch b/target/linux/generic/patches-2.6.31/630-phy_packets.patch
--- a/target/linux/generic/patches-2.6.31/630-phy_packets.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/630-phy_packets.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,63 @@
+--- a/drivers/net/phy/phy_device.c
++++ b/drivers/net/phy/phy_device.c
+@@ -146,6 +146,18 @@ int phy_scan_fixups(struct phy_device *p
+ }
+ EXPORT_SYMBOL(phy_scan_fixups);
+ 
++static int generic_receive_skb(struct sk_buff *skb)
++{
++	skb->protocol = eth_type_trans(skb, skb->dev);
++	return netif_receive_skb(skb);
++}
++
++static int generic_rx(struct sk_buff *skb)
++{
++	skb->protocol = eth_type_trans(skb, skb->dev);
++	return netif_rx(skb);
++}
++
+ struct phy_device* phy_device_create(struct mii_bus *bus, int addr, int phy_id)
+ {
+ 	struct phy_device *dev;
+@@ -175,6 +187,8 @@ struct phy_device* phy_device_create(str
+ 	dev_set_name(&dev->dev, PHY_ID_FMT, bus->id, addr);
+ 
+ 	dev->state = PHY_DOWN;
++	dev->netif_receive_skb = &generic_receive_skb;
++	dev->netif_rx = &generic_rx;
+ 
+ 	mutex_init(&dev->lock);
+ 
+--- a/include/linux/phy.h
++++ b/include/linux/phy.h
+@@ -325,6 +325,20 @@ struct phy_device {
+ 	void (*adjust_link)(struct net_device *dev);
+ 
+ 	void (*adjust_state)(struct net_device *dev);
++
++	/*
++	 * By default these point to the original functions
++	 * with the same name. adding them to the phy_device
++	 * allows the phy driver to override them for packet
++	 * mangling if the ethernet driver supports it
++	 * This is required to support some really horrible
++	 * switches such as the Marvell 88E6060
++	 */
++	int (*netif_receive_skb)(struct sk_buff *skb);
++	int (*netif_rx)(struct sk_buff *skb);
++
++	/* alignment offset for packets */
++	int pkt_align;
+ };
+ #define to_phy_device(d) container_of(d, struct phy_device, dev)
+ 
+--- a/include/linux/netdevice.h
++++ b/include/linux/netdevice.h
+@@ -804,6 +804,7 @@ struct net_device
+ 	void			*ax25_ptr;	/* AX.25 specific data */
+ 	struct wireless_dev	*ieee80211_ptr;	/* IEEE 802.11 specific data,
+ 						   assign before registering */
++	void			*phy_ptr; /* PHY device specific data */
+ 
+ /*
+  * Cache line mostly used on receive path (including eth_type_trans())
diff -Nru a/target/linux/generic/patches-2.6.31/640-br2684_backport_routed.patch b/target/linux/generic/patches-2.6.31/640-br2684_backport_routed.patch
--- a/target/linux/generic/patches-2.6.31/640-br2684_backport_routed.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/640-br2684_backport_routed.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,42 @@
+commit 2e302ebfeac04beb5a5d6af1ac583c6a1fb76d1a
+Author: chas williams - CONTRACTOR <chas@cmf.nrl.navy.mil>
+Date:   Fri Dec 4 11:06:32 2009 +0000
+
+    atm: [br2684] allow routed mode operation again
+    
+    in routed mode, we don't have a hardware address so netdev_ops doesnt
+    need to validate our hardware address via .ndo_validate_addr
+    
+    Reported-by: Manuel Fuentes <mfuentes@agenciaefe.com>
+    Signed-off-by: Chas Williams - CONTRACTOR <chas@cmf.nrl.navy.mil>
+    Signed-off-by: David S. Miller <davem@davemloft.net>
+
+--- a/net/atm/br2684.c
++++ b/net/atm/br2684.c
+@@ -536,6 +536,12 @@ static const struct net_device_ops br268
+ 	.ndo_validate_addr	= eth_validate_addr,
+ };
+ 
++static const struct net_device_ops br2684_netdev_ops_routed = {
++	.ndo_start_xmit 	= br2684_start_xmit,
++	.ndo_set_mac_address	= br2684_mac_addr,
++	.ndo_change_mtu		= eth_change_mtu
++};
++
+ static void br2684_setup(struct net_device *netdev)
+ {
+ 	struct br2684_dev *brdev = BRPRIV(netdev);
+@@ -551,11 +557,10 @@ static void br2684_setup(struct net_devi
+ static void br2684_setup_routed(struct net_device *netdev)
+ {
+ 	struct br2684_dev *brdev = BRPRIV(netdev);
+-	brdev->net_dev = netdev;
+ 
++	brdev->net_dev = netdev;
+ 	netdev->hard_header_len = 0;
+-
+-	netdev->netdev_ops = &br2684_netdev_ops;
++	netdev->netdev_ops = &br2684_netdev_ops_routed;
+ 	netdev->addr_len = 0;
+ 	netdev->mtu = 1500;
+ 	netdev->type = ARPHRD_PPP;
diff -Nru a/target/linux/generic/patches-2.6.31/650-swconfig.patch b/target/linux/generic/patches-2.6.31/650-swconfig.patch
--- a/target/linux/generic/patches-2.6.31/650-swconfig.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/650-swconfig.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,25 @@
+--- a/drivers/net/phy/Kconfig
++++ b/drivers/net/phy/Kconfig
+@@ -13,6 +13,12 @@ menuconfig PHYLIB
+ 
+ if PHYLIB
+ 
++config SWCONFIG
++	tristate "Switch configuration API"
++	---help---
++	  Switch configuration API using netlink. This allows
++	  you to configure the VLAN features of certain switches.
++
+ comment "MII PHY device drivers"
+ 
+ config MARVELL_PHY
+--- a/drivers/net/phy/Makefile
++++ b/drivers/net/phy/Makefile
+@@ -3,6 +3,7 @@
+ libphy-objs			:= phy.o phy_device.o mdio_bus.o
+ 
+ obj-$(CONFIG_PHYLIB)		+= libphy.o
++obj-$(CONFIG_SWCONFIG)		+= swconfig.o
+ obj-$(CONFIG_MARVELL_PHY)	+= marvell.o
+ obj-$(CONFIG_DAVICOM_PHY)	+= davicom.o
+ obj-$(CONFIG_CICADA_PHY)	+= cicada.o
diff -Nru a/target/linux/generic/patches-2.6.31/660-phy_mvswitch.patch b/target/linux/generic/patches-2.6.31/660-phy_mvswitch.patch
--- a/target/linux/generic/patches-2.6.31/660-phy_mvswitch.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/660-phy_mvswitch.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,22 @@
+--- a/drivers/net/phy/Kconfig
++++ b/drivers/net/phy/Kconfig
+@@ -95,6 +95,9 @@ config ADM6996_PHY
+ 	  Currently supports the ADM6996FC and ADM6996M switches.
+ 	  Support for FC is very limited.
+ 
++config MVSWITCH_PHY
++	tristate "Driver for Marvell 88E6060 switches"
++
+ config FIXED_PHY
+ 	bool "Driver for MDIO Bus/PHY emulation with fixed speed/link PHYs"
+ 	depends on PHYLIB=y
+--- a/drivers/net/phy/Makefile
++++ b/drivers/net/phy/Makefile
+@@ -14,6 +14,7 @@ obj-$(CONFIG_VITESSE_PHY)	+= vitesse.o
+ obj-$(CONFIG_BROADCOM_PHY)	+= broadcom.o
+ obj-$(CONFIG_ICPLUS_PHY)	+= icplus.o
+ obj-$(CONFIG_ADM6996_PHY)	+= adm6996.o
++obj-$(CONFIG_MVSWITCH_PHY)	+= mvswitch.o
+ obj-$(CONFIG_REALTEK_PHY)	+= realtek.o
+ obj-$(CONFIG_LSI_ET1011C_PHY)	+= et1011c.o
+ obj-$(CONFIG_FIXED_PHY)		+= fixed.o
diff -Nru a/target/linux/generic/patches-2.6.31/670-phy_ip175c.patch b/target/linux/generic/patches-2.6.31/670-phy_ip175c.patch
--- a/target/linux/generic/patches-2.6.31/670-phy_ip175c.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/670-phy_ip175c.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,23 @@
+--- a/drivers/net/phy/Kconfig
++++ b/drivers/net/phy/Kconfig
+@@ -98,6 +98,10 @@ config ADM6996_PHY
+ config MVSWITCH_PHY
+ 	tristate "Driver for Marvell 88E6060 switches"
+ 
++config IP17XX_PHY
++	tristate "Driver for IC+ IP17xx switches"
++	select SWCONFIG
++
+ config FIXED_PHY
+ 	bool "Driver for MDIO Bus/PHY emulation with fixed speed/link PHYs"
+ 	depends on PHYLIB=y
+--- a/drivers/net/phy/Makefile
++++ b/drivers/net/phy/Makefile
+@@ -15,6 +15,7 @@ obj-$(CONFIG_BROADCOM_PHY)	+= broadcom.o
+ obj-$(CONFIG_ICPLUS_PHY)	+= icplus.o
+ obj-$(CONFIG_ADM6996_PHY)	+= adm6996.o
+ obj-$(CONFIG_MVSWITCH_PHY)	+= mvswitch.o
++obj-$(CONFIG_IP17XX_PHY)	+= ip17xx.o
+ obj-$(CONFIG_REALTEK_PHY)	+= realtek.o
+ obj-$(CONFIG_LSI_ET1011C_PHY)	+= et1011c.o
+ obj-$(CONFIG_FIXED_PHY)		+= fixed.o
diff -Nru a/target/linux/generic/patches-2.6.31/680-phy_ar8216.patch b/target/linux/generic/patches-2.6.31/680-phy_ar8216.patch
--- a/target/linux/generic/patches-2.6.31/680-phy_ar8216.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/680-phy_ar8216.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,23 @@
+--- a/drivers/net/phy/Kconfig
++++ b/drivers/net/phy/Kconfig
+@@ -102,6 +102,10 @@ config IP17XX_PHY
+ 	tristate "Driver for IC+ IP17xx switches"
+ 	select SWCONFIG
+ 
++config AR8216_PHY
++	tristate "Driver for Atheros AR8216 switches"
++	select SWCONFIG
++
+ config FIXED_PHY
+ 	bool "Driver for MDIO Bus/PHY emulation with fixed speed/link PHYs"
+ 	depends on PHYLIB=y
+--- a/drivers/net/phy/Makefile
++++ b/drivers/net/phy/Makefile
+@@ -17,6 +17,7 @@ obj-$(CONFIG_ADM6996_PHY)	+= adm6996.o
+ obj-$(CONFIG_MVSWITCH_PHY)	+= mvswitch.o
+ obj-$(CONFIG_IP17XX_PHY)	+= ip17xx.o
+ obj-$(CONFIG_REALTEK_PHY)	+= realtek.o
++obj-$(CONFIG_AR8216_PHY)	+= ar8216.o
+ obj-$(CONFIG_LSI_ET1011C_PHY)	+= et1011c.o
+ obj-$(CONFIG_FIXED_PHY)		+= fixed.o
+ obj-$(CONFIG_MDIO_BITBANG)	+= mdio-bitbang.o
diff -Nru a/target/linux/generic/patches-2.6.31/690-phy_rtl8306.patch b/target/linux/generic/patches-2.6.31/690-phy_rtl8306.patch
--- a/target/linux/generic/patches-2.6.31/690-phy_rtl8306.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/690-phy_rtl8306.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,23 @@
+--- a/drivers/net/phy/Kconfig
++++ b/drivers/net/phy/Kconfig
+@@ -106,6 +106,10 @@ config AR8216_PHY
+ 	tristate "Driver for Atheros AR8216 switches"
+ 	select SWCONFIG
+ 
++config RTL8306_PHY
++	tristate "Driver for Realtek RTL8306S switches"
++	select SWCONFIG
++
+ config FIXED_PHY
+ 	bool "Driver for MDIO Bus/PHY emulation with fixed speed/link PHYs"
+ 	depends on PHYLIB=y
+--- a/drivers/net/phy/Makefile
++++ b/drivers/net/phy/Makefile
+@@ -18,6 +18,7 @@ obj-$(CONFIG_MVSWITCH_PHY)	+= mvswitch.o
+ obj-$(CONFIG_IP17XX_PHY)	+= ip17xx.o
+ obj-$(CONFIG_REALTEK_PHY)	+= realtek.o
+ obj-$(CONFIG_AR8216_PHY)	+= ar8216.o
++obj-$(CONFIG_RTL8306_PHY)	+= rtl8306.o
+ obj-$(CONFIG_LSI_ET1011C_PHY)	+= et1011c.o
+ obj-$(CONFIG_FIXED_PHY)		+= fixed.o
+ obj-$(CONFIG_MDIO_BITBANG)	+= mdio-bitbang.o
diff -Nru a/target/linux/generic/patches-2.6.31/691-phy_rtl8366.patch b/target/linux/generic/patches-2.6.31/691-phy_rtl8366.patch
--- a/target/linux/generic/patches-2.6.31/691-phy_rtl8366.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/691-phy_rtl8366.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,44 @@
+--- a/drivers/net/phy/Kconfig
++++ b/drivers/net/phy/Kconfig
+@@ -137,4 +137,29 @@ config MDIO_GPIO
+ 	  To compile this driver as a module, choose M here: the module
+ 	  will be called mdio-gpio.
+ 
++config RTL8366_SMI
++	tristate "Driver for the RTL8366 SMI interface"
++	depends on GENERIC_GPIO
++	---help---
++	  This module implements the SMI interface protocol which is used
++	  by some RTL8366 ethernet switch devices via the generic GPIO API.
++
++if RTL8366_SMI
++
++config RTL8366S_PHY
++	tristate "Driver for the Realtek RTL8366S switch"
++	select SWCONFIG
++
++config RTL8366RB_PHY
++	tristate "Driver for the Realtek RTL8366RB switch"
++	select SWCONFIG
++
++config RTL8366S_PHY_DEBUG_FS
++	bool "RTL8366 switch driver DEBUG_FS support"
++	depends on RTL8366S_PHY || RTL8366RB_PHY
++	depends on DEBUG_FS
++	default n
++
++endif # RTL8366_SMI
++
+ endif # PHYLIB
+--- a/drivers/net/phy/Makefile
++++ b/drivers/net/phy/Makefile
+@@ -19,6 +19,9 @@ obj-$(CONFIG_IP17XX_PHY)	+= ip17xx.o
+ obj-$(CONFIG_REALTEK_PHY)	+= realtek.o
+ obj-$(CONFIG_AR8216_PHY)	+= ar8216.o
+ obj-$(CONFIG_RTL8306_PHY)	+= rtl8306.o
++obj-$(CONFIG_RTL8366_SMI)	+= rtl8366_smi.o
++obj-$(CONFIG_RTL8366S_PHY)	+= rtl8366s.o
++obj-$(CONFIG_RTL8366RB_PHY)	+= rtl8366rb.o
+ obj-$(CONFIG_LSI_ET1011C_PHY)	+= et1011c.o
+ obj-$(CONFIG_FIXED_PHY)		+= fixed.o
+ obj-$(CONFIG_MDIO_BITBANG)	+= mdio-bitbang.o
diff -Nru a/target/linux/generic/patches-2.6.31/700-rtc7301.patch b/target/linux/generic/patches-2.6.31/700-rtc7301.patch
--- a/target/linux/generic/patches-2.6.31/700-rtc7301.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/700-rtc7301.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,250 @@
+--- a/drivers/rtc/Kconfig
++++ b/drivers/rtc/Kconfig
+@@ -535,6 +535,15 @@ config RTC_DRV_PCF50633
+ 	  If you say yes here you get support for the RTC subsystem of the
+ 	  NXP PCF50633 used in embedded systems.
+ 
++config RTC_DRV_RTC7301
++	tristate "Epson RTC-7301 SF/DG"
++	help
++	  If you say Y here you will get support for the
++	  Epson RTC-7301 SF/DG RTC chips.
++
++	  This driver can also be built as a module. If so, the module
++	  will be called rtc-7301.
++
+ comment "on-CPU RTC drivers"
+ 
+ config RTC_DRV_OMAP
+--- a/drivers/rtc/Makefile
++++ b/drivers/rtc/Makefile
+@@ -62,6 +62,7 @@ obj-$(CONFIG_RTC_DRV_R9701)	+= rtc-r9701
+ obj-$(CONFIG_RTC_DRV_RS5C313)	+= rtc-rs5c313.o
+ obj-$(CONFIG_RTC_DRV_RS5C348)	+= rtc-rs5c348.o
+ obj-$(CONFIG_RTC_DRV_RS5C372)	+= rtc-rs5c372.o
++obj-$(CONFIG_RTC_DRV_RTC7301)	+= rtc-rtc7301.o
+ obj-$(CONFIG_RTC_DRV_RX8025)	+= rtc-rx8025.o
+ obj-$(CONFIG_RTC_DRV_RX8581)	+= rtc-rx8581.o
+ obj-$(CONFIG_RTC_DRV_S35390A)	+= rtc-s35390a.o
+--- /dev/null
++++ b/drivers/rtc/rtc-rtc7301.c
+@@ -0,0 +1,219 @@
++/*
++ * Driver for Epson RTC-7301SF/DG
++ *
++ * Copyright (C) 2009 Jose Vasconcellos
++ *
++ * This program is free software; you can redistribute it and/or modify
++ * it under the terms of the GNU General Public License version 2 as
++ * published by the Free Software Foundation.
++ */
++
++#include <linux/module.h>
++#include <linux/rtc.h>
++#include <linux/platform_device.h>
++#include <linux/io.h>
++#include <linux/delay.h>
++#include <linux/bcd.h>
++
++#define RTC_NAME "rtc7301"
++#define RTC_VERSION "0.1"
++
++/* Epson RTC-7301 register addresses */
++#define RTC7301_SEC		0x00
++#define RTC7301_SEC10		0x01
++#define RTC7301_MIN		0x02
++#define RTC7301_MIN10		0x03
++#define RTC7301_HOUR		0x04
++#define RTC7301_HOUR10		0x05
++#define RTC7301_WEEKDAY		0x06
++#define RTC7301_DAY		0x07
++#define RTC7301_DAY10		0x08
++#define RTC7301_MON		0x09
++#define RTC7301_MON10		0x0A
++#define RTC7301_YEAR		0x0B
++#define RTC7301_YEAR10		0x0C
++#define RTC7301_YEAR100		0x0D
++#define RTC7301_YEAR1000	0x0E
++#define RTC7301_CTRLREG		0x0F
++
++static uint8_t __iomem *rtc7301_base;
++
++#define read_reg(offset) (readb(rtc7301_base + offset) & 0xf)
++#define write_reg(offset, data) writeb(data, rtc7301_base + (offset))
++
++#define rtc7301_isbusy() (read_reg(RTC7301_CTRLREG) & 1)
++
++static void rtc7301_init_settings(void)
++{
++	int i;
++
++	write_reg(RTC7301_CTRLREG, 2);
++	write_reg(RTC7301_YEAR1000, 2);
++	udelay(122);
++
++	/* bank 1 */
++	write_reg(RTC7301_CTRLREG, 6);
++	for (i=0; i<15; i++)
++		write_reg(i, 0);
++
++	/* bank 2 */
++	write_reg(RTC7301_CTRLREG, 14);
++	for (i=0; i<15; i++)
++		write_reg(i, 0);
++	write_reg(RTC7301_CTRLREG, 0);
++}
++
++static int rtc7301_get_datetime(struct device *dev, struct rtc_time *dt)
++{
++	int cnt;
++	uint8_t buf[16];
++
++	cnt = 0;
++	while (rtc7301_isbusy()) {
++		udelay(244);
++		if (cnt++ > 100) {
++			dev_err(dev, "%s: timeout error %x\n", __func__, rtc7301_base[RTC7301_CTRLREG]);
++			return -EIO;
++		}
++	}
++
++	for (cnt=0; cnt<16; cnt++)
++		buf[cnt] = read_reg(cnt);
++
++	if (buf[RTC7301_SEC10] & 8) {
++		dev_err(dev, "%s: RTC not set\n", __func__);
++		return -EINVAL;
++	}
++
++	memset(dt, 0, sizeof(*dt));
++
++	dt->tm_sec =  buf[RTC7301_SEC] + buf[RTC7301_SEC10]*10;
++	dt->tm_min =  buf[RTC7301_MIN] + buf[RTC7301_MIN10]*10;
++	dt->tm_hour = buf[RTC7301_HOUR] + buf[RTC7301_HOUR10]*10;
++
++	dt->tm_mday = buf[RTC7301_DAY] + buf[RTC7301_DAY10]*10;
++	dt->tm_mon =  buf[RTC7301_MON] + buf[RTC7301_MON10]*10 - 1;
++	dt->tm_year = buf[RTC7301_YEAR] + buf[RTC7301_YEAR10]*10 +
++		      buf[RTC7301_YEAR100]*100 +
++		      ((buf[RTC7301_YEAR1000] & 3)*1000) - 1900;
++
++	/* the rtc device may contain illegal values on power up
++	 * according to the data sheet. make sure they are valid.
++	 */
++
++	return rtc_valid_tm(dt);
++}
++
++static int rtc7301_set_datetime(struct device *dev, struct rtc_time *dt)
++{
++	int data;
++
++	data = dt->tm_year + 1900;
++	if (data >= 2100 || data < 1900)
++		return -EINVAL;
++
++	write_reg(RTC7301_CTRLREG, 2);
++       	udelay(122);
++
++	data = bin2bcd(dt->tm_sec);
++	write_reg(RTC7301_SEC, data);
++	write_reg(RTC7301_SEC10, (data >> 4));
++
++	data = bin2bcd(dt->tm_min);
++	write_reg(RTC7301_MIN, data );
++	write_reg(RTC7301_MIN10, (data >> 4));
++
++	data = bin2bcd(dt->tm_hour);
++	write_reg(RTC7301_HOUR, data);
++	write_reg(RTC7301_HOUR10, (data >> 4));
++
++	data = bin2bcd(dt->tm_mday);
++	write_reg(RTC7301_DAY, data);
++	write_reg(RTC7301_DAY10, (data>> 4));
++
++	data = bin2bcd(dt->tm_mon + 1);
++	write_reg(RTC7301_MON, data);
++	write_reg(RTC7301_MON10, (data >> 4));
++
++	data = bin2bcd(dt->tm_year % 100);
++	write_reg(RTC7301_YEAR, data);
++	write_reg(RTC7301_YEAR10, (data >> 4));
++	data = bin2bcd((1900 + dt->tm_year) / 100);
++	write_reg(RTC7301_YEAR100, data);
++
++	data = bin2bcd(dt->tm_wday);
++	write_reg(RTC7301_WEEKDAY, data);
++
++	write_reg(RTC7301_CTRLREG, 0);
++
++	return 0;
++}
++
++static const struct rtc_class_ops rtc7301_rtc_ops = {
++	.read_time	= rtc7301_get_datetime,
++	.set_time	= rtc7301_set_datetime,
++};
++
++static int __devinit rtc7301_probe(struct platform_device *pdev)
++{
++	struct rtc_device *rtc;
++	struct resource *res;
++
++	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
++	if (!res)
++		return -ENOENT;
++
++	rtc7301_base = ioremap_nocache(res->start, 0x1000 /*res->end - res->start + 1*/);
++	if (!rtc7301_base)
++		return -EINVAL;
++
++	rtc = rtc_device_register(RTC_NAME, &pdev->dev,
++				&rtc7301_rtc_ops, THIS_MODULE);
++	if (IS_ERR(rtc)) {
++		iounmap(rtc7301_base);
++		return PTR_ERR(rtc);
++	}
++
++	platform_set_drvdata(pdev, rtc);
++
++	rtc7301_init_settings();
++	return 0;
++}
++
++static int __devexit rtc7301_remove(struct platform_device *pdev)
++{
++	struct rtc_device *rtc = platform_get_drvdata(pdev);
++
++	if (rtc)
++		rtc_device_unregister(rtc);
++	if (rtc7301_base)
++		iounmap(rtc7301_base);
++	return 0;
++}
++
++static struct platform_driver rtc7301_driver = {
++	.driver = {
++		.name	= RTC_NAME,
++		.owner	= THIS_MODULE,
++	},
++	.probe	= rtc7301_probe,
++	.remove = __devexit_p(rtc7301_remove),
++};
++
++static __init int rtc7301_init(void)
++{
++	return platform_driver_register(&rtc7301_driver);
++}
++module_init(rtc7301_init);
++
++static __exit void rtc7301_exit(void)
++{
++	platform_driver_unregister(&rtc7301_driver);
++}
++module_exit(rtc7301_exit);
++
++MODULE_DESCRIPTION("Epson 7301 RTC driver");
++MODULE_AUTHOR("Jose Vasconcellos <jvasco@verizon.net>");
++MODULE_LICENSE("GPL");
++MODULE_ALIAS("platform:" RTC_NAME);
++MODULE_VERSION(RTC_VERSION);
diff -Nru a/target/linux/generic/patches-2.6.31/750-glamo-headers.patch b/target/linux/generic/patches-2.6.31/750-glamo-headers.patch
--- a/target/linux/generic/patches-2.6.31/750-glamo-headers.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/750-glamo-headers.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,21 @@
+--- a/include/linux/fb.h
++++ b/include/linux/fb.h
+@@ -124,6 +124,7 @@ struct dentry;
+ #define FB_ACCEL_TRIDENT_BLADE3D 52	/* Trident Blade3D		*/
+ #define FB_ACCEL_TRIDENT_BLADEXP 53	/* Trident BladeXP		*/
+ #define FB_ACCEL_CIRRUS_ALPINE   53	/* Cirrus Logic 543x/544x/5480	*/
++#define FB_ACCEL_GLAMO		50	/* SMedia Glamo                 */
+ #define FB_ACCEL_NEOMAGIC_NM2070 90	/* NeoMagic NM2070              */
+ #define FB_ACCEL_NEOMAGIC_NM2090 91	/* NeoMagic NM2090              */
+ #define FB_ACCEL_NEOMAGIC_NM2093 92	/* NeoMagic NM2093              */
+--- a/include/linux/Kbuild
++++ b/include/linux/Kbuild
+@@ -76,6 +76,8 @@ header-y += genetlink.h
+ header-y += gen_stats.h
+ header-y += gfs2_ondisk.h
+ header-y += gigaset_dev.h
++header-y += glamofb.h
++header-y += glamo-engine.h
+ header-y += hysdn_if.h
+ header-y += i2o-dev.h
+ header-y += i8k.h
diff -Nru a/target/linux/generic/patches-2.6.31/780-fix-race-in-snd_soc_jack_add_gpios.patch b/target/linux/generic/patches-2.6.31/780-fix-race-in-snd_soc_jack_add_gpios.patch
--- a/target/linux/generic/patches-2.6.31/780-fix-race-in-snd_soc_jack_add_gpios.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/780-fix-race-in-snd_soc_jack_add_gpios.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,33 @@
+commit 5ced436d549d911ce610ea47d85f71fae5bbfce4
+Author: Lars-Peter Clausen <lars@metafoo.de>
+Date:   Fri Jul 31 18:26:48 2009 +0200
+
+    ASoC: jack: Fix race in snd_soc_jack_add_gpios
+    
+    The irq can fire as soon as it has been requested, thus all fields accessed
+    from within the irq handler must be initialized prior to requesting the irq.
+    
+    Signed-off-by: Lars-Peter Clausen <lars@metafoo.de>
+
+--- a/sound/soc/soc-jack.c
++++ b/sound/soc/soc-jack.c
+@@ -220,6 +220,9 @@ int snd_soc_jack_add_gpios(struct snd_so
+ 		if (ret)
+ 			goto err;
+ 
++		INIT_WORK(&gpios[i].work, gpio_work);
++		gpios[i].jack = jack;
++
+ 		ret = request_irq(gpio_to_irq(gpios[i].gpio),
+ 				gpio_handler,
+ 				IRQF_TRIGGER_RISING | IRQF_TRIGGER_FALLING,
+@@ -227,9 +230,6 @@ int snd_soc_jack_add_gpios(struct snd_so
+ 				&gpios[i]);
+ 		if (ret)
+ 			goto err;
+-
+-		INIT_WORK(&gpios[i].work, gpio_work);
+-		gpios[i].jack = jack;
+ 	}
+ 
+ 	return 0;
diff -Nru a/target/linux/generic/patches-2.6.31/822-usb_serial_option_add_more_devices.patch b/target/linux/generic/patches-2.6.31/822-usb_serial_option_add_more_devices.patch
--- a/target/linux/generic/patches-2.6.31/822-usb_serial_option_add_more_devices.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/822-usb_serial_option_add_more_devices.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,48 @@
+--- a/drivers/usb/serial/option.c
++++ b/drivers/usb/serial/option.c
+@@ -167,6 +167,11 @@ static int  option_resume(struct usb_ser
+ #define HUAWEI_PRODUCT_E143E			0x143E
+ #define HUAWEI_PRODUCT_E143F			0x143F
+ #define HUAWEI_PRODUCT_E14AC			0x14AC
++#define HUAWEI_PRODUCT_K3770			0x14C9
++#define HUAWEI_PRODUCT_K3771			0x14CA
++#define HUAWEI_PRODUCT_K4510			0x14CB
++#define HUAWEI_PRODUCT_K4511			0x14CC
++#define HUAWEI_PRODUCT_E173S			0x1C05
+ 
+ #define QUANTA_VENDOR_ID			0x0408
+ #define QUANTA_PRODUCT_Q101			0xEA02
+@@ -332,6 +337,7 @@ static int  option_resume(struct usb_ser
+ /* ALCATEL PRODUCTS */
+ #define ALCATEL_VENDOR_ID			0x1bbb
+ #define ALCATEL_PRODUCT_X060S			0x0000
++#define ALCATEL_PRODUCT_X220D			0x0017
+ 
+ /* Airplus products */
+ #define AIRPLUS_VENDOR_ID			0x1011
+@@ -437,8 +443,17 @@ static struct usb_device_id option_ids[]
+ 	{ USB_DEVICE_AND_INTERFACE_INFO(HUAWEI_VENDOR_ID, HUAWEI_PRODUCT_E143C, 0xff, 0xff, 0xff) },
+ 	{ USB_DEVICE_AND_INTERFACE_INFO(HUAWEI_VENDOR_ID, HUAWEI_PRODUCT_E143D, 0xff, 0xff, 0xff) },
+ 	{ USB_DEVICE_AND_INTERFACE_INFO(HUAWEI_VENDOR_ID, HUAWEI_PRODUCT_E143E, 0xff, 0xff, 0xff) },
++	{ USB_DEVICE_AND_INTERFACE_INFO(HUAWEI_VENDOR_ID, HUAWEI_PRODUCT_K3770, 0xff, 0x02, 0x31) },
++	{ USB_DEVICE_AND_INTERFACE_INFO(HUAWEI_VENDOR_ID, HUAWEI_PRODUCT_K3770, 0xff, 0x02, 0x32) },
++	{ USB_DEVICE_AND_INTERFACE_INFO(HUAWEI_VENDOR_ID, HUAWEI_PRODUCT_K3771, 0xff, 0x02, 0x31) },
++	{ USB_DEVICE_AND_INTERFACE_INFO(HUAWEI_VENDOR_ID, HUAWEI_PRODUCT_K3771, 0xff, 0x02, 0x32) },
++	{ USB_DEVICE_AND_INTERFACE_INFO(HUAWEI_VENDOR_ID, HUAWEI_PRODUCT_K4510, 0xff, 0x01, 0x31) },
++	{ USB_DEVICE_AND_INTERFACE_INFO(HUAWEI_VENDOR_ID, HUAWEI_PRODUCT_K4510, 0xff, 0x01, 0x32) },
++	{ USB_DEVICE_AND_INTERFACE_INFO(HUAWEI_VENDOR_ID, HUAWEI_PRODUCT_K4511, 0xff, 0x01, 0x31) },
++	{ USB_DEVICE_AND_INTERFACE_INFO(HUAWEI_VENDOR_ID, HUAWEI_PRODUCT_K4511, 0xff, 0x01, 0x32) },
+ 	{ USB_DEVICE_AND_INTERFACE_INFO(HUAWEI_VENDOR_ID, HUAWEI_PRODUCT_E143F, 0xff, 0xff, 0xff) },
+ 	{ USB_DEVICE(HUAWEI_VENDOR_ID, HUAWEI_PRODUCT_E14AC) },
++	{ USB_DEVICE(HUAWEI_VENDOR_ID, HUAWEI_PRODUCT_E173S) },
+ 	{ USB_DEVICE(AMOI_VENDOR_ID, AMOI_PRODUCT_9508) },
+ 	{ USB_DEVICE(NOVATELWIRELESS_VENDOR_ID, NOVATELWIRELESS_PRODUCT_V640) }, /* Novatel Merlin V640/XV620 */
+ 	{ USB_DEVICE(NOVATELWIRELESS_VENDOR_ID, NOVATELWIRELESS_PRODUCT_V620) }, /* Novatel Merlin V620/S620 */
+@@ -639,6 +654,7 @@ static struct usb_device_id option_ids[]
+ 	{ USB_DEVICE(ALINK_VENDOR_ID, 0xce16) },
+ 	{ USB_DEVICE_AND_INTERFACE_INFO(ALINK_VENDOR_ID, ALINK_PRODUCT_3GU, 0xff, 0xff, 0xff) },
+ 	{ USB_DEVICE(ALCATEL_VENDOR_ID, ALCATEL_PRODUCT_X060S) },
++	{ USB_DEVICE(ALCATEL_VENDOR_ID, ALCATEL_PRODUCT_X220D) },
+ 	{ USB_DEVICE(AIRPLUS_VENDOR_ID, AIRPLUS_PRODUCT_MCD650) },
+ 	{ USB_DEVICE(TLAYTECH_VENDOR_ID, TLAYTECH_PRODUCT_TEU800) },
+ 	{ USB_DEVICE(HAIER_VENDOR_ID, HAIER_PRODUCT_CE100) },
diff -Nru a/target/linux/generic/patches-2.6.31/840-unable_to_open_console.patch b/target/linux/generic/patches-2.6.31/840-unable_to_open_console.patch
--- a/target/linux/generic/patches-2.6.31/840-unable_to_open_console.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/840-unable_to_open_console.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,11 @@
+--- a/init/main.c
++++ b/init/main.c
+@@ -839,7 +839,7 @@ static noinline int init_post(void)
+ 	numa_default_policy();
+ 
+ 	if (sys_open((const char __user *) "/dev/console", O_RDWR, 0) < 0)
+-		printk(KERN_WARNING "Warning: unable to open an initial console.\n");
++		printk(KERN_WARNING "Please be patient, while OpenWrt loads ...\n");
+ 
+ 	(void) sys_dup(0);
+ 	(void) sys_dup(0);
diff -Nru a/target/linux/generic/patches-2.6.31/902-darwin_scripts_include.patch b/target/linux/generic/patches-2.6.31/902-darwin_scripts_include.patch
--- a/target/linux/generic/patches-2.6.31/902-darwin_scripts_include.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/902-darwin_scripts_include.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,102 @@
+--- a/scripts/genksyms/parse.c_shipped
++++ b/scripts/genksyms/parse.c_shipped
+@@ -160,7 +160,9 @@
+ 
+ 
+ #include <assert.h>
++#ifndef __APPLE__
+ #include <malloc.h>
++#endif
+ #include "genksyms.h"
+ 
+ static int is_typedef;
+--- a/scripts/genksyms/parse.y
++++ b/scripts/genksyms/parse.y
+@@ -24,7 +24,9 @@
+ %{
+ 
+ #include <assert.h>
++#ifndef __APPLE__
+ #include <malloc.h>
++#endif
+ #include "genksyms.h"
+ 
+ static int is_typedef;
+--- a/scripts/kallsyms.c
++++ b/scripts/kallsyms.c
+@@ -22,6 +22,35 @@
+ #include <stdlib.h>
+ #include <string.h>
+ #include <ctype.h>
++#ifdef __APPLE__
++/* Darwin has no memmem implementation, this one is ripped of the uClibc-0.9.28 source */
++void *memmem (const void *haystack, size_t haystack_len,
++                          const void *needle,  size_t needle_len)
++{
++  const char *begin;
++  const char *const last_possible
++    = (const char *) haystack + haystack_len - needle_len;
++
++  if (needle_len == 0)
++    /* The first occurrence of the empty string is deemed to occur at
++       the beginning of the string.  */
++    return (void *) haystack;
++
++  /* Sanity check, otherwise the loop might search through the whole
++     memory.  */
++  if (__builtin_expect (haystack_len < needle_len, 0))
++    return NULL;
++
++  for (begin = (const char *) haystack; begin <= last_possible; ++begin)
++    if (begin[0] == ((const char *) needle)[0] &&
++        !memcmp ((const void *) &begin[1],
++                 (const void *) ((const char *) needle + 1),
++                 needle_len - 1))
++      return (void *) begin;
++
++  return NULL;
++}
++#endif
+ 
+ #ifndef ARRAY_SIZE
+ #define ARRAY_SIZE(arr) (sizeof(arr) / sizeof(arr[0]))
+--- a/scripts/kconfig/Makefile
++++ b/scripts/kconfig/Makefile
+@@ -97,6 +97,9 @@ check-lxdialog  := $(srctree)/$(src)/lxd
+ # we really need to do so. (Do not call gcc as part of make mrproper)
+ HOST_EXTRACFLAGS = $(shell $(CONFIG_SHELL) $(check-lxdialog) -ccflags)
+ HOST_LOADLIBES   = $(shell $(CONFIG_SHELL) $(check-lxdialog) -ldflags $(HOSTCC))
++ifeq ($(shell uname -s),Darwin)
++HOST_LOADLIBES  += -lncurses
++endif
+ 
+ HOST_EXTRACFLAGS += -DLOCALE
+ 
+--- a/scripts/mod/mk_elfconfig.c
++++ b/scripts/mod/mk_elfconfig.c
+@@ -1,7 +1,11 @@
+ #include <stdio.h>
+ #include <stdlib.h>
+ #include <string.h>
++#ifndef __APPLE__
+ #include <elf.h>
++#else
++#include "../../../../../tools/sstrip/include/elf.h"
++#endif
+ 
+ int
+ main(int argc, char **argv)
+--- a/scripts/mod/modpost.h
++++ b/scripts/mod/modpost.h
+@@ -7,7 +7,11 @@
+ #include <sys/mman.h>
+ #include <fcntl.h>
+ #include <unistd.h>
++#if !(defined(__APPLE__) || defined(__CYGWIN__))
+ #include <elf.h>
++#else
++#include "../../../../../tools/sstrip/include/elf.h"
++#endif
+ 
+ #include "elfconfig.h"
+ 
diff -Nru a/target/linux/generic/patches-2.6.31/903-hostap_txpower.patch b/target/linux/generic/patches-2.6.31/903-hostap_txpower.patch
--- a/target/linux/generic/patches-2.6.31/903-hostap_txpower.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/903-hostap_txpower.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,154 @@
+--- a/drivers/net/wireless/hostap/hostap_ap.c
++++ b/drivers/net/wireless/hostap/hostap_ap.c
+@@ -2335,13 +2335,13 @@ int prism2_ap_get_sta_qual(local_info_t
+ 		addr[count].sa_family = ARPHRD_ETHER;
+ 		memcpy(addr[count].sa_data, sta->addr, ETH_ALEN);
+ 		if (sta->last_rx_silence == 0)
+-			qual[count].qual = sta->last_rx_signal < 27 ?
+-				0 : (sta->last_rx_signal - 27) * 92 / 127;
++                        qual[count].qual = (sta->last_rx_signal - 156) == 0 ?
++                                0 : (sta->last_rx_signal - 156) * 92 / 64;
+ 		else
+-			qual[count].qual = sta->last_rx_signal -
+-				sta->last_rx_silence - 35;
+-		qual[count].level = HFA384X_LEVEL_TO_dBm(sta->last_rx_signal);
+-		qual[count].noise = HFA384X_LEVEL_TO_dBm(sta->last_rx_silence);
++                        qual[count].qual = (sta->last_rx_signal -
++                                sta->last_rx_silence) * 92 / 64;
++                qual[count].level = sta->last_rx_signal;
++                qual[count].noise = sta->last_rx_silence;
+ 		qual[count].updated = sta->last_rx_updated;
+ 
+ 		sta->last_rx_updated = IW_QUAL_DBM;
+@@ -2407,13 +2407,13 @@ int prism2_ap_translate_scan(struct net_
+ 		memset(&iwe, 0, sizeof(iwe));
+ 		iwe.cmd = IWEVQUAL;
+ 		if (sta->last_rx_silence == 0)
+-			iwe.u.qual.qual = sta->last_rx_signal < 27 ?
+-				0 : (sta->last_rx_signal - 27) * 92 / 127;
++	                iwe.u.qual.qual = (sta->last_rx_signal -156) == 0 ?
++	                        0 : (sta->last_rx_signal - 156) * 92 / 64;
+ 		else
+-			iwe.u.qual.qual = sta->last_rx_signal -
+-				sta->last_rx_silence - 35;
+-		iwe.u.qual.level = HFA384X_LEVEL_TO_dBm(sta->last_rx_signal);
+-		iwe.u.qual.noise = HFA384X_LEVEL_TO_dBm(sta->last_rx_silence);
++                        iwe.u.qual.qual = (sta->last_rx_signal -
++                                sta->last_rx_silence) * 92 / 64;
++                iwe.u.qual.level = sta->last_rx_signal;
++                iwe.u.qual.noise = sta->last_rx_silence;
+ 		iwe.u.qual.updated = sta->last_rx_updated;
+ 		iwe.len = IW_EV_QUAL_LEN;
+ 		current_ev = iwe_stream_add_event(info, current_ev, end_buf,
+--- a/drivers/net/wireless/hostap/hostap_config.h
++++ b/drivers/net/wireless/hostap/hostap_config.h
+@@ -45,4 +45,9 @@
+  */
+ /* #define PRISM2_NO_STATION_MODES */
+ 
++/* Enable TX power Setting functions
++ * (min att = -128 , max att =  127)
++ */
++#define RAW_TXPOWER_SETTING
++
+ #endif /* HOSTAP_CONFIG_H */
+--- a/drivers/net/wireless/hostap/hostap.h
++++ b/drivers/net/wireless/hostap/hostap.h
+@@ -90,6 +90,7 @@ extern const struct iw_handler_def hosta
+ extern const struct ethtool_ops prism2_ethtool_ops;
+ 
+ int hostap_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd);
++int hostap_restore_power(struct net_device *dev);
+ 
+ 
+ #endif /* HOSTAP_H */
+--- a/drivers/net/wireless/hostap/hostap_hw.c
++++ b/drivers/net/wireless/hostap/hostap_hw.c
+@@ -932,6 +932,7 @@ static int hfa384x_set_rid(struct net_de
+ 			prism2_hw_reset(dev);
+ 	}
+ 
++	hostap_restore_power(dev);
+ 	return res;
+ }
+ 
+--- a/drivers/net/wireless/hostap/hostap_info.c
++++ b/drivers/net/wireless/hostap/hostap_info.c
+@@ -431,6 +431,11 @@ static void handle_info_queue_linkstatus
+ 	}
+ 
+ 	/* Get BSSID if we have a valid AP address */
++
++	if ( val == HFA384X_LINKSTATUS_CONNECTED ||
++	     val == HFA384X_LINKSTATUS_DISCONNECTED )
++			hostap_restore_power(local->dev);
++
+ 	if (connected) {
+ 		netif_carrier_on(local->dev);
+ 		netif_carrier_on(local->ddev);
+--- a/drivers/net/wireless/hostap/hostap_ioctl.c
++++ b/drivers/net/wireless/hostap/hostap_ioctl.c
+@@ -1475,23 +1475,20 @@ static int prism2_txpower_hfa386x_to_dBm
+ 		val = 255;
+ 
+ 	tmp = val;
+-	tmp >>= 2;
+ 
+-	return -12 - tmp;
++	return tmp;
+ }
+ 
+ static u16 prism2_txpower_dBm_to_hfa386x(int val)
+ {
+ 	signed char tmp;
+ 
+-	if (val > 20)
+-		return 128;
+-	else if (val < -43)
++	if (val > 127)
+ 		return 127;
++	else if (val < -128)
++		return 128;
+ 
+ 	tmp = val;
+-	tmp = -12 - tmp;
+-	tmp <<= 2;
+ 
+ 	return (unsigned char) tmp;
+ }
+@@ -4055,3 +4052,35 @@ int hostap_ioctl(struct net_device *dev,
+ 
+ 	return ret;
+ }
++
++/* BUG FIX: Restore power setting value when lost due to F/W bug */
++
++int hostap_restore_power(struct net_device *dev)
++{
++        struct hostap_interface *iface = netdev_priv(dev);
++       local_info_t *local = iface->local;
++
++       u16 val;
++       int ret = 0;
++
++       if (local->txpower_type == PRISM2_TXPOWER_OFF) {
++                       val = 0xff; /* use all standby and sleep modes */
++                       ret = local->func->cmd(dev, HFA384X_CMDCODE_WRITEMIF,
++                                              HFA386X_CR_A_D_TEST_MODES2,
++                                              &val, NULL);
++       }
++
++#ifdef RAW_TXPOWER_SETTING
++       if (local->txpower_type == PRISM2_TXPOWER_FIXED) {
++               val = HFA384X_TEST_CFG_BIT_ALC;
++               local->func->cmd(dev, HFA384X_CMDCODE_TEST |
++                                (HFA384X_TEST_CFG_BITS << 8), 0, &val, NULL);
++               val = prism2_txpower_dBm_to_hfa386x(local->txpower);
++               ret = (local->func->cmd(dev, HFA384X_CMDCODE_WRITEMIF,
++                            HFA386X_CR_MANUAL_TX_POWER, &val, NULL));
++       }
++#endif /* RAW_TXPOWER_SETTING */
++       return (ret ? -EOPNOTSUPP : 0);
++}
++
++EXPORT_SYMBOL(hostap_restore_power);
diff -Nru a/target/linux/generic/patches-2.6.31/903-stddef_include.patch b/target/linux/generic/patches-2.6.31/903-stddef_include.patch
--- a/target/linux/generic/patches-2.6.31/903-stddef_include.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/903-stddef_include.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,17 @@
+--- a/include/linux/stddef.h
++++ b/include/linux/stddef.h
+@@ -16,6 +16,7 @@ enum {
+ 	false	= 0,
+ 	true	= 1
+ };
++#endif /* __KERNEL__ */
+ 
+ #undef offsetof
+ #ifdef __compiler_offsetof
+@@ -23,6 +24,5 @@ enum {
+ #else
+ #define offsetof(TYPE, MEMBER) ((size_t) &((TYPE *)0)->MEMBER)
+ #endif
+-#endif /* __KERNEL__ */
+ 
+ #endif
diff -Nru a/target/linux/generic/patches-2.6.31/920-01-hotpluggable-spi-gpio.patch b/target/linux/generic/patches-2.6.31/920-01-hotpluggable-spi-gpio.patch
--- a/target/linux/generic/patches-2.6.31/920-01-hotpluggable-spi-gpio.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/920-01-hotpluggable-spi-gpio.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,60 @@
+Fix spi-gpio for hotplug.
+
+--mb
+
+
+
+--- a/drivers/spi/spi_gpio.c
++++ b/drivers/spi/spi_gpio.c
+@@ -218,7 +218,7 @@ static void spi_gpio_cleanup(struct spi_
+ 	spi_bitbang_cleanup(spi);
+ }
+ 
+-static int __init spi_gpio_alloc(unsigned pin, const char *label, bool is_in)
++static int __devinit spi_gpio_alloc(unsigned pin, const char *label, bool is_in)
+ {
+ 	int value;
+ 
+@@ -232,7 +232,7 @@ static int __init spi_gpio_alloc(unsigne
+ 	return value;
+ }
+ 
+-static int __init
++static int __devinit
+ spi_gpio_request(struct spi_gpio_platform_data *pdata, const char *label)
+ {
+ 	int value;
+@@ -261,7 +261,7 @@ done:
+ 	return value;
+ }
+ 
+-static int __init spi_gpio_probe(struct platform_device *pdev)
++static int __devinit spi_gpio_probe(struct platform_device *pdev)
+ {
+ 	int				status;
+ 	struct spi_master		*master;
+@@ -317,7 +317,7 @@ gpio_free:
+ 	return status;
+ }
+ 
+-static int __exit spi_gpio_remove(struct platform_device *pdev)
++static int __devexit spi_gpio_remove(struct platform_device *pdev)
+ {
+ 	struct spi_gpio			*spi_gpio;
+ 	struct spi_gpio_platform_data	*pdata;
+@@ -344,12 +344,13 @@ MODULE_ALIAS("platform:" DRIVER_NAME);
+ static struct platform_driver spi_gpio_driver = {
+ 	.driver.name	= DRIVER_NAME,
+ 	.driver.owner	= THIS_MODULE,
+-	.remove		= __exit_p(spi_gpio_remove),
++	.probe		= spi_gpio_probe,
++	.remove		= __devexit_p(spi_gpio_remove),
+ };
+ 
+ static int __init spi_gpio_init(void)
+ {
+-	return platform_driver_probe(&spi_gpio_driver, spi_gpio_probe);
++	return platform_driver_register(&spi_gpio_driver);
+ }
+ module_init(spi_gpio_init);
+ 
diff -Nru a/target/linux/generic/patches-2.6.31/920-04-spi-gpio-implement-spi-delay.patch b/target/linux/generic/patches-2.6.31/920-04-spi-gpio-implement-spi-delay.patch
--- a/target/linux/generic/patches-2.6.31/920-04-spi-gpio-implement-spi-delay.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/920-04-spi-gpio-implement-spi-delay.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,58 @@
+Implement the SPI-GPIO delay function for busses that need speed limitation.
+
+--mb
+
+
+
+--- a/drivers/spi/spi_gpio.c
++++ b/drivers/spi/spi_gpio.c
+@@ -21,6 +21,7 @@
+ #include <linux/init.h>
+ #include <linux/platform_device.h>
+ #include <linux/gpio.h>
++#include <linux/delay.h>
+ 
+ #include <linux/spi/spi.h>
+ #include <linux/spi/spi_bitbang.h>
+@@ -69,6 +70,7 @@ struct spi_gpio {
+  *		#define	SPI_MOSI_GPIO	120
+  *		#define	SPI_SCK_GPIO	121
+  *		#define	SPI_N_CHIPSEL	4
++ *		#undef NEED_SPIDELAY
+  *		#include "spi_gpio.c"
+  */
+ 
+@@ -76,6 +78,7 @@ struct spi_gpio {
+ #define DRIVER_NAME	"spi_gpio"
+ 
+ #define GENERIC_BITBANG	/* vs tight inlines */
++#define NEED_SPIDELAY	1
+ 
+ /* all functions referencing these symbols must define pdata */
+ #define SPI_MISO_GPIO	((pdata)->miso)
+@@ -120,12 +123,20 @@ static inline int getmiso(const struct s
+ #undef pdata
+ 
+ /*
+- * NOTE:  this clocks "as fast as we can".  It "should" be a function of the
+- * requested device clock.  Software overhead means we usually have trouble
+- * reaching even one Mbit/sec (except when we can inline bitops), so for now
+- * we'll just assume we never need additional per-bit slowdowns.
++ * NOTE:  to clock "as fast as we can", set spi_device.max_speed_hz
++ * and spi_transfer.speed_hz to 0.
++ * Otherwise this is a function of the requested device clock.
++ * Software overhead means we usually have trouble
++ * reaching even one Mbit/sec (except when we can inline bitops). So on small
++ * embedded devices with fast SPI slaves you usually don't need a delay.
+  */
+-#define spidelay(nsecs)	do {} while (0)
++static inline void spidelay(unsigned nsecs)
++{
++#ifdef NEED_SPIDELAY
++	if (unlikely(nsecs))
++		ndelay(nsecs);
++#endif /* NEED_SPIDELAY */
++}
+ 
+ #define	EXPAND_BITBANG_TXRX
+ #include <linux/spi/spi_bitbang.h>
diff -Nru a/target/linux/generic/patches-2.6.31/921-gpio_spi_driver.patch b/target/linux/generic/patches-2.6.31/921-gpio_spi_driver.patch
--- a/target/linux/generic/patches-2.6.31/921-gpio_spi_driver.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/921-gpio_spi_driver.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,366 @@
+THIS CODE IS DEPRECATED.
+
+Please use the new mainline SPI-GPIO driver, as of 2.6.29.
+
+--mb
+
+
+
+--- /dev/null
++++ b/include/linux/spi/spi_gpio_old.h
+@@ -0,0 +1,73 @@
++/*
++ * spi_gpio interface to platform code
++ *
++ * Copyright (c) 2008 Piotr Skamruk
++ * Copyright (c) 2008 Michael Buesch
++ *
++ * This program is free software; you can redistribute it and/or modify
++ * it under the terms of the GNU General Public License version 2 as
++ * published by the Free Software Foundation.
++ */
++#ifndef _LINUX_SPI_SPI_GPIO
++#define _LINUX_SPI_SPI_GPIO
++
++#include <linux/types.h>
++#include <linux/spi/spi.h>
++
++
++/**
++ * struct spi_gpio_platform_data - Data definitions for a SPI-GPIO device.
++ *
++ * This structure holds information about a GPIO-based SPI device.
++ *
++ * @pin_clk: The GPIO pin number of the CLOCK pin.
++ *
++ * @pin_miso: The GPIO pin number of the MISO pin.
++ *
++ * @pin_mosi: The GPIO pin number of the MOSI pin.
++ *
++ * @pin_cs: The GPIO pin number of the CHIPSELECT pin.
++ *
++ * @cs_activelow: If true, the chip is selected when the CS line is low.
++ *
++ * @no_spi_delay: If true, no delay is done in the lowlevel bitbanging.
++ *                Note that doing no delay is not standards compliant,
++ *                but it might be needed to speed up transfers on some
++ *                slow embedded machines.
++ *
++ * @boardinfo_setup: This callback is called after the
++ *                   SPI master device was registered, but before the
++ *                   device is registered.
++ * @boardinfo_setup_data: Data argument passed to boardinfo_setup().
++ */
++struct spi_gpio_platform_data {
++	unsigned int pin_clk;
++	unsigned int pin_miso;
++	unsigned int pin_mosi;
++	unsigned int pin_cs;
++	bool cs_activelow;
++	bool no_spi_delay;
++	int (*boardinfo_setup)(struct spi_board_info *bi,
++			       struct spi_master *master,
++			       void *data);
++	void *boardinfo_setup_data;
++};
++
++/**
++ * SPI_GPIO_PLATDEV_NAME - The platform device name string.
++ *
++ * The name string that has to be used for platform_device_alloc
++ * when allocating a spi-gpio device.
++ */
++#define SPI_GPIO_PLATDEV_NAME	"spi-gpio"
++
++/**
++ * spi_gpio_next_id - Get another platform device ID number.
++ *
++ * This returns the next platform device ID number that has to be used
++ * for platform_device_alloc. The ID is opaque and should not be used for
++ * anything else.
++ */
++int spi_gpio_next_id(void);
++
++#endif /* _LINUX_SPI_SPI_GPIO */
+--- /dev/null
++++ b/drivers/spi/spi_gpio_old.c
+@@ -0,0 +1,251 @@
++/*
++ * Bitbanging SPI bus driver using GPIO API
++ *
++ * Copyright (c) 2008 Piotr Skamruk
++ * Copyright (c) 2008 Michael Buesch
++ *
++ * based on spi_s3c2410_gpio.c
++ *   Copyright (c) 2006 Ben Dooks
++ *   Copyright (c) 2006 Simtec Electronics
++ * and on i2c-gpio.c
++ *   Copyright (C) 2007 Atmel Corporation
++ *
++ * This program is free software; you can redistribute it and/or modify
++ * it under the terms of the GNU General Public License version 2 as
++ * published by the Free Software Foundation.
++ */
++
++#include <linux/kernel.h>
++#include <linux/init.h>
++#include <linux/delay.h>
++#include <linux/spinlock.h>
++#include <linux/workqueue.h>
++#include <linux/module.h>
++#include <linux/platform_device.h>
++#include <linux/spi/spi.h>
++#include <linux/spi/spi_bitbang.h>
++#include <linux/spi/spi_gpio_old.h>
++#include <linux/gpio.h>
++#include <asm/atomic.h>
++
++
++struct spi_gpio {
++	struct spi_bitbang bitbang;
++	struct spi_gpio_platform_data *info;
++	struct platform_device *pdev;
++	struct spi_board_info bi;
++};
++
++
++static inline struct spi_gpio *spidev_to_sg(struct spi_device *dev)
++{
++	return dev->controller_data;
++}
++
++static inline void setsck(struct spi_device *dev, int val)
++{
++	struct spi_gpio *sp = spidev_to_sg(dev);
++	gpio_set_value(sp->info->pin_clk, val ? 1 : 0);
++}
++
++static inline void setmosi(struct spi_device *dev, int val)
++{
++	struct spi_gpio *sp = spidev_to_sg(dev);
++	gpio_set_value(sp->info->pin_mosi, val ? 1 : 0);
++}
++
++static inline u32 getmiso(struct spi_device *dev)
++{
++	struct spi_gpio *sp = spidev_to_sg(dev);
++	return gpio_get_value(sp->info->pin_miso) ? 1 : 0;
++}
++
++static inline void do_spidelay(struct spi_device *dev, unsigned nsecs)
++{
++	struct spi_gpio *sp = spidev_to_sg(dev);
++
++	if (!sp->info->no_spi_delay)
++		ndelay(nsecs);
++}
++
++#define spidelay(nsecs) do {					\
++	/* Steal the spi_device pointer from our caller.	\
++	 * The bitbang-API should probably get fixed here... */	\
++	do_spidelay(spi, nsecs);				\
++  } while (0)
++
++#define EXPAND_BITBANG_TXRX
++#include <linux/spi/spi_bitbang.h>
++
++static u32 spi_gpio_txrx_mode0(struct spi_device *spi,
++			       unsigned nsecs, u32 word, u8 bits)
++{
++	return bitbang_txrx_be_cpha0(spi, nsecs, 0, word, bits);
++}
++
++static u32 spi_gpio_txrx_mode1(struct spi_device *spi,
++			       unsigned nsecs, u32 word, u8 bits)
++{
++	return bitbang_txrx_be_cpha1(spi, nsecs, 0, word, bits);
++}
++
++static u32 spi_gpio_txrx_mode2(struct spi_device *spi,
++			       unsigned nsecs, u32 word, u8 bits)
++{
++	return bitbang_txrx_be_cpha0(spi, nsecs, 1, word, bits);
++}
++
++static u32 spi_gpio_txrx_mode3(struct spi_device *spi,
++			       unsigned nsecs, u32 word, u8 bits)
++{
++	return bitbang_txrx_be_cpha1(spi, nsecs, 1, word, bits);
++}
++
++static void spi_gpio_chipselect(struct spi_device *dev, int on)
++{
++	struct spi_gpio *sp = spidev_to_sg(dev);
++
++	if (sp->info->cs_activelow)
++		on = !on;
++	gpio_set_value(sp->info->pin_cs, on ? 1 : 0);
++}
++
++static int spi_gpio_probe(struct platform_device *pdev)
++{
++	struct spi_master *master;
++	struct spi_gpio_platform_data *pdata;
++	struct spi_gpio *sp;
++	struct spi_device *spidev;
++	int err;
++
++	pdata = pdev->dev.platform_data;
++	if (!pdata)
++		return -ENXIO;
++
++	err = -ENOMEM;
++	master = spi_alloc_master(&pdev->dev, sizeof(struct spi_gpio));
++	if (!master)
++		goto err_alloc_master;
++
++	sp = spi_master_get_devdata(master);
++	platform_set_drvdata(pdev, sp);
++	sp->info = pdata;
++
++	err = gpio_request(pdata->pin_clk, "spi_clock");
++	if (err)
++		goto err_request_clk;
++	err = gpio_request(pdata->pin_mosi, "spi_mosi");
++	if (err)
++		goto err_request_mosi;
++	err = gpio_request(pdata->pin_miso, "spi_miso");
++	if (err)
++		goto err_request_miso;
++	err = gpio_request(pdata->pin_cs, "spi_cs");
++	if (err)
++		goto err_request_cs;
++
++	sp->bitbang.master = spi_master_get(master);
++	sp->bitbang.master->bus_num = -1;
++	sp->bitbang.master->num_chipselect = 1;
++	sp->bitbang.chipselect = spi_gpio_chipselect;
++	sp->bitbang.txrx_word[SPI_MODE_0] = spi_gpio_txrx_mode0;
++	sp->bitbang.txrx_word[SPI_MODE_1] = spi_gpio_txrx_mode1;
++	sp->bitbang.txrx_word[SPI_MODE_2] = spi_gpio_txrx_mode2;
++	sp->bitbang.txrx_word[SPI_MODE_3] = spi_gpio_txrx_mode3;
++
++	gpio_direction_output(pdata->pin_clk, 0);
++	gpio_direction_output(pdata->pin_mosi, 0);
++	gpio_direction_output(pdata->pin_cs,
++			      pdata->cs_activelow ? 1 : 0);
++	gpio_direction_input(pdata->pin_miso);
++
++	err = spi_bitbang_start(&sp->bitbang);
++	if (err)
++		goto err_no_bitbang;
++	err = pdata->boardinfo_setup(&sp->bi, master,
++				     pdata->boardinfo_setup_data);
++	if (err)
++		goto err_bi_setup;
++	sp->bi.controller_data = sp;
++	spidev = spi_new_device(master, &sp->bi);
++	if (!spidev)
++		goto err_new_dev;
++
++	return 0;
++
++err_new_dev:
++err_bi_setup:
++	spi_bitbang_stop(&sp->bitbang);
++err_no_bitbang:
++	spi_master_put(sp->bitbang.master);
++	gpio_free(pdata->pin_cs);
++err_request_cs:
++	gpio_free(pdata->pin_miso);
++err_request_miso:
++	gpio_free(pdata->pin_mosi);
++err_request_mosi:
++	gpio_free(pdata->pin_clk);
++err_request_clk:
++	kfree(master);
++
++err_alloc_master:
++	return err;
++}
++
++static int __devexit spi_gpio_remove(struct platform_device *pdev)
++{
++	struct spi_gpio *sp;
++	struct spi_gpio_platform_data *pdata;
++
++	pdata = pdev->dev.platform_data;
++	sp = platform_get_drvdata(pdev);
++
++	gpio_free(pdata->pin_clk);
++	gpio_free(pdata->pin_mosi);
++	gpio_free(pdata->pin_miso);
++	gpio_free(pdata->pin_cs);
++	spi_bitbang_stop(&sp->bitbang);
++	spi_master_put(sp->bitbang.master);
++
++	return 0;
++}
++
++static struct platform_driver spi_gpio_driver = {
++	.driver		= {
++		.name	= SPI_GPIO_PLATDEV_NAME,
++		.owner	= THIS_MODULE,
++	},
++	.probe		= spi_gpio_probe,
++	.remove		= __devexit_p(spi_gpio_remove),
++};
++
++int spi_gpio_next_id(void)
++{
++	static atomic_t counter = ATOMIC_INIT(-1);
++
++	return atomic_inc_return(&counter);
++}
++EXPORT_SYMBOL(spi_gpio_next_id);
++
++static int __init spi_gpio_init(void)
++{
++	int err;
++
++	err = platform_driver_register(&spi_gpio_driver);
++	if (err)
++		printk(KERN_ERR "spi-gpio: register failed: %d\n", err);
++
++	return err;
++}
++module_init(spi_gpio_init);
++
++static void __exit spi_gpio_exit(void)
++{
++	platform_driver_unregister(&spi_gpio_driver);
++}
++module_exit(spi_gpio_exit);
++
++MODULE_AUTHOR("Piot Skamruk <piotr.skamruk at gmail.com>");
++MODULE_AUTHOR("Michael Buesch");
++MODULE_DESCRIPTION("Platform independent GPIO bitbanging SPI driver");
++MODULE_LICENSE("GPL v2");
+--- a/drivers/spi/Kconfig
++++ b/drivers/spi/Kconfig
+@@ -116,6 +116,15 @@ config SPI_GPIO
+ 	  GPIO operations, you should be able to leverage that for better
+ 	  speed with a custom version of this driver; see the source code.
+ 
++config SPI_GPIO_OLD
++	tristate "Old GPIO API based bitbanging SPI controller (DEPRECATED)"
++	depends on SPI_MASTER && GENERIC_GPIO
++	select SPI_BITBANG
++	help
++	  This code is deprecated. Please use the new mainline SPI-GPIO driver.
++
++	  If unsure, say N.
++
+ config SPI_IMX
+ 	tristate "Freescale iMX SPI controller"
+ 	depends on ARCH_MX1 && EXPERIMENTAL
+--- a/drivers/spi/Makefile
++++ b/drivers/spi/Makefile
+@@ -17,6 +17,7 @@ obj-$(CONFIG_SPI_BITBANG)		+= spi_bitban
+ obj-$(CONFIG_SPI_AU1550)		+= au1550_spi.o
+ obj-$(CONFIG_SPI_BUTTERFLY)		+= spi_butterfly.o
+ obj-$(CONFIG_SPI_GPIO)			+= spi_gpio.o
++obj-$(CONFIG_SPI_GPIO_OLD)		+= spi_gpio_old.o
+ obj-$(CONFIG_SPI_IMX)			+= spi_imx.o
+ obj-$(CONFIG_SPI_LM70_LLP)		+= spi_lm70llp.o
+ obj-$(CONFIG_SPI_PXA2XX)		+= pxa2xx_spi.o
diff -Nru a/target/linux/generic/patches-2.6.31/922-gpiommc.patch b/target/linux/generic/patches-2.6.31/922-gpiommc.patch
--- a/target/linux/generic/patches-2.6.31/922-gpiommc.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/922-gpiommc.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,843 @@
+--- /dev/null
++++ b/drivers/mmc/host/gpiommc.c
+@@ -0,0 +1,608 @@
++/*
++ * Driver an MMC/SD card on a bitbanging GPIO SPI bus.
++ * This module hooks up the mmc_spi and spi_gpio modules and also
++ * provides a configfs interface.
++ *
++ * Copyright 2008 Michael Buesch <mb@bu3sch.de>
++ *
++ * Licensed under the GNU/GPL. See COPYING for details.
++ */
++
++#include <linux/mmc/gpiommc.h>
++#include <linux/platform_device.h>
++#include <linux/list.h>
++#include <linux/mutex.h>
++#include <linux/spi/spi_gpio_old.h>
++#include <linux/configfs.h>
++#include <linux/gpio.h>
++#include <asm/atomic.h>
++
++
++#define PFX				"gpio-mmc: "
++
++
++struct gpiommc_device {
++	struct platform_device *pdev;
++	struct platform_device *spi_pdev;
++	struct spi_board_info boardinfo;
++};
++
++
++MODULE_DESCRIPTION("GPIO based MMC driver");
++MODULE_AUTHOR("Michael Buesch");
++MODULE_LICENSE("GPL");
++
++
++static int gpiommc_boardinfo_setup(struct spi_board_info *bi,
++				   struct spi_master *master,
++				   void *data)
++{
++	struct gpiommc_device *d = data;
++	struct gpiommc_platform_data *pdata = d->pdev->dev.platform_data;
++
++	/* Bind the SPI master to the MMC-SPI host driver. */
++	strlcpy(bi->modalias, "mmc_spi", sizeof(bi->modalias));
++
++	bi->max_speed_hz = pdata->max_bus_speed;
++	bi->bus_num = master->bus_num;
++	bi->mode = pdata->mode;
++
++	return 0;
++}
++
++static int gpiommc_probe(struct platform_device *pdev)
++{
++	struct gpiommc_platform_data *mmc_pdata = pdev->dev.platform_data;
++	struct spi_gpio_platform_data spi_pdata;
++	struct gpiommc_device *d;
++	int err;
++
++	err = -ENXIO;
++	if (!mmc_pdata)
++		goto error;
++
++#ifdef CONFIG_MMC_SPI_MODULE
++	err = request_module("mmc_spi");
++	if (err) {
++		printk(KERN_WARNING PFX
++		       "Failed to request mmc_spi module.\n");
++	}
++#endif /* CONFIG_MMC_SPI_MODULE */
++
++	/* Allocate the GPIO-MMC device */
++	err = -ENOMEM;
++	d = kzalloc(sizeof(*d), GFP_KERNEL);
++	if (!d)
++		goto error;
++	d->pdev = pdev;
++
++	/* Create the SPI-GPIO device */
++	d->spi_pdev = platform_device_alloc(SPI_GPIO_PLATDEV_NAME,
++					    spi_gpio_next_id());
++	if (!d->spi_pdev)
++		goto err_free_d;
++
++	memset(&spi_pdata, 0, sizeof(spi_pdata));
++	spi_pdata.pin_clk = mmc_pdata->pins.gpio_clk;
++	spi_pdata.pin_miso = mmc_pdata->pins.gpio_do;
++	spi_pdata.pin_mosi = mmc_pdata->pins.gpio_di;
++	spi_pdata.pin_cs = mmc_pdata->pins.gpio_cs;
++	spi_pdata.cs_activelow = mmc_pdata->pins.cs_activelow;
++	spi_pdata.no_spi_delay = mmc_pdata->no_spi_delay;
++	spi_pdata.boardinfo_setup = gpiommc_boardinfo_setup;
++	spi_pdata.boardinfo_setup_data = d;
++
++	err = platform_device_add_data(d->spi_pdev, &spi_pdata,
++				       sizeof(spi_pdata));
++	if (err)
++		goto err_free_pdev;
++	err = platform_device_add(d->spi_pdev);
++	if (err)
++		goto err_free_pdata;
++	platform_set_drvdata(pdev, d);
++
++	printk(KERN_INFO PFX "MMC-Card \"%s\" "
++	       "attached to GPIO pins di=%u, do=%u, clk=%u, cs=%u\n",
++	       mmc_pdata->name, mmc_pdata->pins.gpio_di,
++	       mmc_pdata->pins.gpio_do,
++	       mmc_pdata->pins.gpio_clk,
++	       mmc_pdata->pins.gpio_cs);
++
++	return 0;
++
++err_free_pdata:
++	kfree(d->spi_pdev->dev.platform_data);
++	d->spi_pdev->dev.platform_data = NULL;
++err_free_pdev:
++	platform_device_put(d->spi_pdev);
++err_free_d:
++	kfree(d);
++error:
++	return err;
++}
++
++static int gpiommc_remove(struct platform_device *pdev)
++{
++	struct gpiommc_device *d = platform_get_drvdata(pdev);
++	struct gpiommc_platform_data *pdata = d->pdev->dev.platform_data;
++
++	platform_device_unregister(d->spi_pdev);
++	printk(KERN_INFO PFX "GPIO based MMC-Card \"%s\" removed\n",
++	       pdata->name);
++	platform_device_put(d->spi_pdev);
++
++	return 0;
++}
++
++#ifdef CONFIG_GPIOMMC_CONFIGFS
++
++/* A device that was created through configfs */
++struct gpiommc_configfs_device {
++	struct config_item item;
++	/* The platform device, after registration. */
++	struct platform_device *pdev;
++	/* The configuration */
++	struct gpiommc_platform_data pdata;
++};
++
++#define GPIO_INVALID	-1
++
++static inline bool gpiommc_is_registered(struct gpiommc_configfs_device *dev)
++{
++	return (dev->pdev != NULL);
++}
++
++static inline struct gpiommc_configfs_device *ci_to_gpiommc(struct config_item *item)
++{
++	return item ? container_of(item, struct gpiommc_configfs_device, item) : NULL;
++}
++
++static struct configfs_attribute gpiommc_attr_DI = {
++	.ca_owner = THIS_MODULE,
++	.ca_name = "gpio_data_in",
++	.ca_mode = S_IRUGO | S_IWUSR,
++};
++
++static struct configfs_attribute gpiommc_attr_DO = {
++	.ca_owner = THIS_MODULE,
++	.ca_name = "gpio_data_out",
++	.ca_mode = S_IRUGO | S_IWUSR,
++};
++
++static struct configfs_attribute gpiommc_attr_CLK = {
++	.ca_owner = THIS_MODULE,
++	.ca_name = "gpio_clock",
++	.ca_mode = S_IRUGO | S_IWUSR,
++};
++
++static struct configfs_attribute gpiommc_attr_CS = {
++	.ca_owner = THIS_MODULE,
++	.ca_name = "gpio_chipselect",
++	.ca_mode = S_IRUGO | S_IWUSR,
++};
++
++static struct configfs_attribute gpiommc_attr_CS_activelow = {
++	.ca_owner = THIS_MODULE,
++	.ca_name = "gpio_chipselect_activelow",
++	.ca_mode = S_IRUGO | S_IWUSR,
++};
++
++static struct configfs_attribute gpiommc_attr_spimode = {
++	.ca_owner = THIS_MODULE,
++	.ca_name = "spi_mode",
++	.ca_mode = S_IRUGO | S_IWUSR,
++};
++
++static struct configfs_attribute gpiommc_attr_spidelay = {
++	.ca_owner = THIS_MODULE,
++	.ca_name = "spi_delay",
++	.ca_mode = S_IRUGO | S_IWUSR,
++};
++
++static struct configfs_attribute gpiommc_attr_max_bus_speed = {
++	.ca_owner = THIS_MODULE,
++	.ca_name = "max_bus_speed",
++	.ca_mode = S_IRUGO | S_IWUSR,
++};
++
++static struct configfs_attribute gpiommc_attr_register = {
++	.ca_owner = THIS_MODULE,
++	.ca_name = "register",
++	.ca_mode = S_IRUGO | S_IWUSR,
++};
++
++static struct configfs_attribute *gpiommc_config_attrs[] = {
++	&gpiommc_attr_DI,
++	&gpiommc_attr_DO,
++	&gpiommc_attr_CLK,
++	&gpiommc_attr_CS,
++	&gpiommc_attr_CS_activelow,
++	&gpiommc_attr_spimode,
++	&gpiommc_attr_spidelay,
++	&gpiommc_attr_max_bus_speed,
++	&gpiommc_attr_register,
++	NULL,
++};
++
++static ssize_t gpiommc_config_attr_show(struct config_item *item,
++					struct configfs_attribute *attr,
++					char *page)
++{
++	struct gpiommc_configfs_device *dev = ci_to_gpiommc(item);
++	ssize_t count = 0;
++	unsigned int gpio;
++	int err = 0;
++
++	if (attr == &gpiommc_attr_DI) {
++		gpio = dev->pdata.pins.gpio_di;
++		if (gpio == GPIO_INVALID)
++			count = snprintf(page, PAGE_SIZE, "not configured\n");
++		else
++			count = snprintf(page, PAGE_SIZE, "%u\n", gpio);
++		goto out;
++	}
++	if (attr == &gpiommc_attr_DO) {
++		gpio = dev->pdata.pins.gpio_do;
++		if (gpio == GPIO_INVALID)
++			count = snprintf(page, PAGE_SIZE, "not configured\n");
++		else
++			count = snprintf(page, PAGE_SIZE, "%u\n", gpio);
++		goto out;
++	}
++	if (attr == &gpiommc_attr_CLK) {
++		gpio = dev->pdata.pins.gpio_clk;
++		if (gpio == GPIO_INVALID)
++			count = snprintf(page, PAGE_SIZE, "not configured\n");
++		else
++			count = snprintf(page, PAGE_SIZE, "%u\n", gpio);
++		goto out;
++	}
++	if (attr == &gpiommc_attr_CS) {
++		gpio = dev->pdata.pins.gpio_cs;
++		if (gpio == GPIO_INVALID)
++			count = snprintf(page, PAGE_SIZE, "not configured\n");
++		else
++			count = snprintf(page, PAGE_SIZE, "%u\n", gpio);
++		goto out;
++	}
++	if (attr == &gpiommc_attr_CS_activelow) {
++		count = snprintf(page, PAGE_SIZE, "%u\n",
++				 dev->pdata.pins.cs_activelow);
++		goto out;
++	}
++	if (attr == &gpiommc_attr_spimode) {
++		count = snprintf(page, PAGE_SIZE, "%u\n",
++				 dev->pdata.mode);
++		goto out;
++	}
++	if (attr == &gpiommc_attr_spidelay) {
++		count = snprintf(page, PAGE_SIZE, "%u\n",
++				 !dev->pdata.no_spi_delay);
++		goto out;
++	}
++	if (attr == &gpiommc_attr_max_bus_speed) {
++		count = snprintf(page, PAGE_SIZE, "%u\n",
++				 dev->pdata.max_bus_speed);
++		goto out;
++	}
++	if (attr == &gpiommc_attr_register) {
++		count = snprintf(page, PAGE_SIZE, "%u\n",
++				 gpiommc_is_registered(dev));
++		goto out;
++	}
++	WARN_ON(1);
++	err = -ENOSYS;
++out:
++	return err ? err : count;
++}
++
++static int gpiommc_do_register(struct gpiommc_configfs_device *dev,
++			       const char *name)
++{
++	int err;
++
++	if (gpiommc_is_registered(dev))
++		return 0;
++
++	if (!gpio_is_valid(dev->pdata.pins.gpio_di) ||
++	    !gpio_is_valid(dev->pdata.pins.gpio_do) ||
++	    !gpio_is_valid(dev->pdata.pins.gpio_clk) ||
++	    !gpio_is_valid(dev->pdata.pins.gpio_cs)) {
++		printk(KERN_ERR PFX
++		       "configfs: Invalid GPIO pin number(s)\n");
++		return -EINVAL;
++	}
++
++	strlcpy(dev->pdata.name, name,
++		sizeof(dev->pdata.name));
++
++	dev->pdev = platform_device_alloc(GPIOMMC_PLATDEV_NAME,
++					  gpiommc_next_id());
++	if (!dev->pdev)
++		return -ENOMEM;
++	err = platform_device_add_data(dev->pdev, &dev->pdata,
++				       sizeof(dev->pdata));
++	if (err) {
++		platform_device_put(dev->pdev);
++		return err;
++	}
++	err = platform_device_add(dev->pdev);
++	if (err) {
++		platform_device_put(dev->pdev);
++		return err;
++	}
++
++	return 0;
++}
++
++static void gpiommc_do_unregister(struct gpiommc_configfs_device *dev)
++{
++	if (!gpiommc_is_registered(dev))
++		return;
++
++	platform_device_unregister(dev->pdev);
++	dev->pdev = NULL;
++}
++
++static ssize_t gpiommc_config_attr_store(struct config_item *item,
++					 struct configfs_attribute *attr,
++					 const char *page, size_t count)
++{
++	struct gpiommc_configfs_device *dev = ci_to_gpiommc(item);
++	int err = -EINVAL;
++	unsigned long data;
++
++	if (attr == &gpiommc_attr_register) {
++		err = strict_strtoul(page, 10, &data);
++		if (err)
++			goto out;
++		err = -EINVAL;
++		if (data == 1)
++			err = gpiommc_do_register(dev, item->ci_name);
++		if (data == 0) {
++			gpiommc_do_unregister(dev);
++			err = 0;
++		}
++		goto out;
++	}
++
++	if (gpiommc_is_registered(dev)) {
++		/* The rest of the config parameters can only be set
++		 * as long as the device is not registered, yet. */
++		err = -EBUSY;
++		goto out;
++	}
++
++	if (attr == &gpiommc_attr_DI) {
++		err = strict_strtoul(page, 10, &data);
++		if (err)
++			goto out;
++		err = -EINVAL;
++		if (!gpio_is_valid(data))
++			goto out;
++		dev->pdata.pins.gpio_di = data;
++		err = 0;
++		goto out;
++	}
++	if (attr == &gpiommc_attr_DO) {
++		err = strict_strtoul(page, 10, &data);
++		if (err)
++			goto out;
++		err = -EINVAL;
++		if (!gpio_is_valid(data))
++			goto out;
++		dev->pdata.pins.gpio_do = data;
++		err = 0;
++		goto out;
++	}
++	if (attr == &gpiommc_attr_CLK) {
++		err = strict_strtoul(page, 10, &data);
++		if (err)
++			goto out;
++		err = -EINVAL;
++		if (!gpio_is_valid(data))
++			goto out;
++		dev->pdata.pins.gpio_clk = data;
++		err = 0;
++		goto out;
++	}
++	if (attr == &gpiommc_attr_CS) {
++		err = strict_strtoul(page, 10, &data);
++		if (err)
++			goto out;
++		err = -EINVAL;
++		if (!gpio_is_valid(data))
++			goto out;
++		dev->pdata.pins.gpio_cs = data;
++		err = 0;
++		goto out;
++	}
++	if (attr == &gpiommc_attr_CS_activelow) {
++		err = strict_strtoul(page, 10, &data);
++		if (err)
++			goto out;
++		err = -EINVAL;
++		if (data != 0 && data != 1)
++			goto out;
++		dev->pdata.pins.cs_activelow = data;
++		err = 0;
++		goto out;
++	}
++	if (attr == &gpiommc_attr_spimode) {
++		err = strict_strtoul(page, 10, &data);
++		if (err)
++			goto out;
++		err = -EINVAL;
++		switch (data) {
++		case 0:
++			dev->pdata.mode = SPI_MODE_0;
++			break;
++		case 1:
++			dev->pdata.mode = SPI_MODE_1;
++			break;
++		case 2:
++			dev->pdata.mode = SPI_MODE_2;
++			break;
++		case 3:
++			dev->pdata.mode = SPI_MODE_3;
++			break;
++		default:
++			goto out;
++		}
++		err = 0;
++		goto out;
++	}
++	if (attr == &gpiommc_attr_spidelay) {
++		err = strict_strtoul(page, 10, &data);
++		if (err)
++			goto out;
++		err = -EINVAL;
++		if (data != 0 && data != 1)
++			goto out;
++		dev->pdata.no_spi_delay = !data;
++		err = 0;
++		goto out;
++	}
++	if (attr == &gpiommc_attr_max_bus_speed) {
++		err = strict_strtoul(page, 10, &data);
++		if (err)
++			goto out;
++		err = -EINVAL;
++		if (data > UINT_MAX)
++			goto out;
++		dev->pdata.max_bus_speed = data;
++		err = 0;
++		goto out;
++	}
++	WARN_ON(1);
++	err = -ENOSYS;
++out:
++	return err ? err : count;
++}
++
++static void gpiommc_config_item_release(struct config_item *item)
++{
++	struct gpiommc_configfs_device *dev = ci_to_gpiommc(item);
++
++	kfree(dev);
++}
++
++static struct configfs_item_operations gpiommc_config_item_ops = {
++	.release		= gpiommc_config_item_release,
++	.show_attribute		= gpiommc_config_attr_show,
++	.store_attribute	= gpiommc_config_attr_store,
++};
++
++static struct config_item_type gpiommc_dev_ci_type = {
++	.ct_item_ops	= &gpiommc_config_item_ops,
++	.ct_attrs	= gpiommc_config_attrs,
++	.ct_owner	= THIS_MODULE,
++};
++
++static struct config_item *gpiommc_make_item(struct config_group *group,
++					     const char *name)
++{
++	struct gpiommc_configfs_device *dev;
++
++	if (strlen(name) > GPIOMMC_MAX_NAMELEN) {
++		printk(KERN_ERR PFX "configfs: device name too long\n");
++		return NULL;
++	}
++
++	dev = kzalloc(sizeof(*dev), GFP_KERNEL);
++	if (!dev)
++		return NULL;
++
++	config_item_init_type_name(&dev->item, name,
++				   &gpiommc_dev_ci_type);
++
++	/* Assign default configuration */
++	dev->pdata.pins.gpio_di = GPIO_INVALID;
++	dev->pdata.pins.gpio_do = GPIO_INVALID;
++	dev->pdata.pins.gpio_clk = GPIO_INVALID;
++	dev->pdata.pins.gpio_cs = GPIO_INVALID;
++	dev->pdata.pins.cs_activelow = 1;
++	dev->pdata.mode = SPI_MODE_0;
++	dev->pdata.no_spi_delay = 0;
++	dev->pdata.max_bus_speed = 5000000; /* 5 MHz */
++
++	return &(dev->item);
++}
++
++static void gpiommc_drop_item(struct config_group *group,
++			      struct config_item *item)
++{
++	struct gpiommc_configfs_device *dev = ci_to_gpiommc(item);
++
++	gpiommc_do_unregister(dev);
++	kfree(dev);
++}
++
++static struct configfs_group_operations gpiommc_ct_group_ops = {
++	.make_item	= gpiommc_make_item,
++	.drop_item	= gpiommc_drop_item,
++};
++
++static struct config_item_type gpiommc_ci_type = {
++	.ct_group_ops	= &gpiommc_ct_group_ops,
++	.ct_owner	= THIS_MODULE,
++};
++
++static struct configfs_subsystem gpiommc_subsys = {
++	.su_group = {
++		.cg_item = {
++			.ci_namebuf = GPIOMMC_PLATDEV_NAME,
++			.ci_type = &gpiommc_ci_type,
++		},
++	},
++	.su_mutex = __MUTEX_INITIALIZER(gpiommc_subsys.su_mutex),
++};
++
++#endif /* CONFIG_GPIOMMC_CONFIGFS */
++
++static struct platform_driver gpiommc_plat_driver = {
++	.probe	= gpiommc_probe,
++	.remove	= gpiommc_remove,
++	.driver	= {
++		.name	= GPIOMMC_PLATDEV_NAME,
++		.owner	= THIS_MODULE,
++	},
++};
++
++int gpiommc_next_id(void)
++{
++	static atomic_t counter = ATOMIC_INIT(-1);
++
++	return atomic_inc_return(&counter);
++}
++EXPORT_SYMBOL(gpiommc_next_id);
++
++static int __init gpiommc_modinit(void)
++{
++	int err;
++
++	err = platform_driver_register(&gpiommc_plat_driver);
++	if (err)
++		return err;
++
++#ifdef CONFIG_GPIOMMC_CONFIGFS
++	config_group_init(&gpiommc_subsys.su_group);
++	err = configfs_register_subsystem(&gpiommc_subsys);
++	if (err) {
++		platform_driver_unregister(&gpiommc_plat_driver);
++		return err;
++	}
++#endif /* CONFIG_GPIOMMC_CONFIGFS */
++
++	return 0;
++}
++module_init(gpiommc_modinit);
++
++static void __exit gpiommc_modexit(void)
++{
++#ifdef CONFIG_GPIOMMC_CONFIGFS
++	configfs_unregister_subsystem(&gpiommc_subsys);
++#endif
++	platform_driver_unregister(&gpiommc_plat_driver);
++}
++module_exit(gpiommc_modexit);
+--- a/drivers/mmc/host/Kconfig
++++ b/drivers/mmc/host/Kconfig
+@@ -278,6 +278,31 @@ config MMC_TMIO
+ 	  This provides support for the SD/MMC cell found in TC6393XB,
+ 	  T7L66XB and also HTC ASIC3
+ 
++config GPIOMMC
++	tristate "MMC/SD over GPIO-based SPI"
++	depends on MMC && MMC_SPI && SPI_GPIO_OLD
++	help
++	  This driver hooks up the mmc_spi and spi_gpio modules so that
++	  MMC/SD cards can be used on a GPIO based bus by bitbanging
++	  the SPI protocol in software.
++
++	  This driver provides a configfs interface to dynamically create
++	  and destroy GPIO-based MMC/SD card devices. It also provides
++	  a platform device interface API.
++	  See Documentation/gpiommc.txt for details.
++
++	  The module will be called gpiommc.
++
++	  If unsure, say N.
++
++config GPIOMMC_CONFIGFS
++	bool
++	depends on GPIOMMC && CONFIGFS_FS
++	default y
++	help
++	  This option automatically enables configfs support for gpiommc
++	  if configfs is available.
++
+ config MMC_CB710
+ 	tristate "ENE CB710 MMC/SD Interface support"
+ 	depends on PCI
+--- a/drivers/mmc/host/Makefile
++++ b/drivers/mmc/host/Makefile
+@@ -33,6 +33,7 @@ obj-$(CONFIG_MMC_SDRICOH_CS)	+= sdricoh_
+ obj-$(CONFIG_MMC_TMIO)		+= tmio_mmc.o
+ obj-$(CONFIG_MMC_CB710)	+= cb710-mmc.o
+ obj-$(CONFIG_MMC_VIA_SDMMC)	+= via-sdmmc.o
++obj-$(CONFIG_GPIOMMC)		+= gpiommc.o
+ 
+ ifeq ($(CONFIG_CB710_DEBUG),y)
+ 	CFLAGS-cb710-mmc	+= -DDEBUG
+--- /dev/null
++++ b/include/linux/mmc/gpiommc.h
+@@ -0,0 +1,71 @@
++/*
++ * Device driver for MMC/SD cards driven over a GPIO bus.
++ *
++ * Copyright (c) 2008 Michael Buesch
++ *
++ * Licensed under the GNU/GPL version 2.
++ */
++#ifndef LINUX_GPIOMMC_H_
++#define LINUX_GPIOMMC_H_
++
++#include <linux/types.h>
++
++
++#define GPIOMMC_MAX_NAMELEN		15
++#define GPIOMMC_MAX_NAMELEN_STR		__stringify(GPIOMMC_MAX_NAMELEN)
++
++/**
++ * struct gpiommc_pins - Hardware pin assignments
++ *
++ * @gpio_di: The GPIO number of the DATA IN pin
++ * @gpio_do: The GPIO number of the DATA OUT pin
++ * @gpio_clk: The GPIO number of the CLOCK pin
++ * @gpio_cs: The GPIO number of the CHIPSELECT pin
++ * @cs_activelow: If true, the chip is considered selected if @gpio_cs is low.
++ */
++struct gpiommc_pins {
++	unsigned int gpio_di;
++	unsigned int gpio_do;
++	unsigned int gpio_clk;
++	unsigned int gpio_cs;
++	bool cs_activelow;
++};
++
++/**
++ * struct gpiommc_platform_data - Platform data for a MMC-over-SPI-GPIO device.
++ *
++ * @name: The unique name string of the device.
++ * @pins: The hardware pin assignments.
++ * @mode: The hardware mode. This is either SPI_MODE_0,
++ *        SPI_MODE_1, SPI_MODE_2 or SPI_MODE_3. See the SPI documentation.
++ * @no_spi_delay: Do not use delays in the lowlevel SPI bitbanging code.
++ *                This is not standards compliant, but may be required for some
++ *                embedded machines to gain reasonable speed.
++ * @max_bus_speed: The maximum speed of the SPI bus, in Hertz.
++ */
++struct gpiommc_platform_data {
++	char name[GPIOMMC_MAX_NAMELEN + 1];
++	struct gpiommc_pins pins;
++	u8 mode;
++	bool no_spi_delay;
++	unsigned int max_bus_speed;
++};
++
++/**
++ * GPIOMMC_PLATDEV_NAME - The platform device name string.
++ *
++ * The name string that has to be used for platform_device_alloc
++ * when allocating a gpiommc device.
++ */
++#define GPIOMMC_PLATDEV_NAME	"gpiommc"
++
++/**
++ * gpiommc_next_id - Get another platform device ID number.
++ *
++ * This returns the next platform device ID number that has to be used
++ * for platform_device_alloc. The ID is opaque and should not be used for
++ * anything else.
++ */
++int gpiommc_next_id(void);
++
++#endif /* LINUX_GPIOMMC_H_ */
+--- /dev/null
++++ b/Documentation/gpiommc.txt
+@@ -0,0 +1,97 @@
++GPIOMMC - Driver for an MMC/SD card on a bitbanging GPIO SPI bus
++================================================================
++
++The gpiommc module hooks up the mmc_spi and spi_gpio modules for running an
++MMC or SD card on GPIO pins.
++
++Two interfaces for registering a new MMC/SD card device are provided:
++A static platform-device based mechanism and a dynamic configfs based interface.
++
++
++Registering devices via platform-device
++=======================================
++
++The platform-device interface is used for registering MMC/SD devices that are
++part of the hardware platform. This is most useful only for embedded machines
++with MMC/SD devices statically connected to the platform GPIO bus.
++
++The data structures are declared in <linux/mmc/gpiommc.h>.
++
++To register a new device, define an instance of struct gpiommc_platform_data.
++This structure holds any information about how the device is hooked up to the
++GPIO pins and what hardware modes the device supports. See the docbook-style
++documentation in the header file for more information on the struct fields.
++
++Then allocate a new instance of a platform device by doing:
++
++	pdev = platform_device_alloc(GPIOMMC_PLATDEV_NAME, gpiommc_next_id());
++
++This will allocate the platform device data structures and hook it up to the
++gpiommc driver.
++Then add the gpiommc_platform_data to the platform device.
++
++	err = platform_device_add_data(pdev, pdata, sizeof(struct gpiommc_platform_data));
++
++You may free the local instance of struct gpiommc_platform_data now. (So the
++struct may be allocated on the stack, too).
++Now simply register the platform device.
++
++	err = platform_device_add(pdev);
++
++Done. The gpiommc probe routine will be invoked now and you should see a kernel
++log message for the added device.
++
++
++Registering devices via configfs
++================================
++
++MMC/SD cards connected via GPIO often are a pretty dynamic thing, as for example
++selfmade hacks for soldering an MMC/SD card to standard GPIO pins on embedded
++hardware are a common situation.
++So we provide a dynamic interface to conveniently handle adding and removing
++devices from userspace, without the need to recompile the kernel.
++
++The "gpiommc" subdirectory at the configfs mountpoint is used for handling
++the dynamic configuration.
++
++To create a new device, it must first be allocated with mkdir.
++The following command will allocate a device named "my_mmc":
++	mkdir /config/gpiommc/my_mmc
++
++There are several configuration files available in the new
++/config/gpiommc/my_mmc/ directory:
++
++gpio_data_in			= The SPI data-IN GPIO pin number.
++gpio_data_out			= The SPI data-OUT GPIO pin number.
++gpio_clock			= The SPI Clock GPIO pin number.
++gpio_chipselect			= The SPI Chipselect GPIO pin number.
++gpio_chipselect_activelow	= Boolean. If 0, Chipselect is active-HIGH.
++				  If 1, Chipselect is active-LOW.
++spi_mode			= The SPI data mode. Can be 0-3.
++spi_delay			= Enable all delays in the lowlevel bitbanging.
++max_bus_speed			= The maximum SPI bus speed. In Hertz.
++
++register			= Not a configuration parameter.
++				  Used to register the configured card
++				  with the kernel.
++
++The device must first get configured and then registered by writing "1" to
++the "register" file.
++The configuration parameters "gpio_data_in", "gpio_data_out", "gpio_clock"
++and "gpio_chipselect" are essential and _must_ be configured before writing
++"1" to the "register" file. The registration will fail, otherwise.
++
++The default values for the other parameters are:
++gpio_chipselect_activelow	= 1		(CS active-LOW)
++spi_mode			= 0		(SPI_MODE_0)
++spi_delay			= 1		(enabled)
++max_bus_speed			= 5000000	(5 Mhz)
++
++Configuration values can not be changed after registration. To unregister
++the device, write a "0" to the "register" file. The configuration can be
++changed again after unregistering.
++
++To completely remove the device, simply rmdir the directory
++(/config/gpiommc/my_mmc in this example).
++There's no need to first unregister the device before removing it. That will
++be done automatically.
+--- a/MAINTAINERS
++++ b/MAINTAINERS
+@@ -2266,6 +2266,11 @@ T:	git git://git.kernel.org/pub/scm/linu
+ S:	Maintained
+ F:	drivers/media/video/gspca/
+ 
++GPIOMMC DRIVER
++P:	Michael Buesch
++M:	mb@bu3sch.de
++S:	Maintained
++
+ HARDWARE MONITORING
+ L:	lm-sensors@lm-sensors.org
+ W:	http://www.lm-sensors.org/
diff -Nru a/target/linux/generic/patches-2.6.31/923-gpiommc-configfs-locking.patch b/target/linux/generic/patches-2.6.31/923-gpiommc-configfs-locking.patch
--- a/target/linux/generic/patches-2.6.31/923-gpiommc-configfs-locking.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/923-gpiommc-configfs-locking.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,58 @@
+The gpiommc configfs context structure needs locking, as configfs
+does not lock access between files.
+
+--- a/drivers/mmc/host/gpiommc.c
++++ b/drivers/mmc/host/gpiommc.c
+@@ -143,6 +143,8 @@ struct gpiommc_configfs_device {
+ 	struct platform_device *pdev;
+ 	/* The configuration */
+ 	struct gpiommc_platform_data pdata;
++	/* Mutex to protect this structure */
++	struct mutex mutex;
+ };
+ 
+ #define GPIO_INVALID	-1
+@@ -233,6 +235,8 @@ static ssize_t gpiommc_config_attr_show(
+ 	unsigned int gpio;
+ 	int err = 0;
+ 
++	mutex_lock(&dev->mutex);
++
+ 	if (attr == &gpiommc_attr_DI) {
+ 		gpio = dev->pdata.pins.gpio_di;
+ 		if (gpio == GPIO_INVALID)
+@@ -293,6 +297,8 @@ static ssize_t gpiommc_config_attr_show(
+ 	WARN_ON(1);
+ 	err = -ENOSYS;
+ out:
++	mutex_unlock(&dev->mutex);
++
+ 	return err ? err : count;
+ }
+ 
+@@ -352,6 +358,8 @@ static ssize_t gpiommc_config_attr_store
+ 	int err = -EINVAL;
+ 	unsigned long data;
+ 
++	mutex_lock(&dev->mutex);
++
+ 	if (attr == &gpiommc_attr_register) {
+ 		err = strict_strtoul(page, 10, &data);
+ 		if (err)
+@@ -477,6 +485,8 @@ static ssize_t gpiommc_config_attr_store
+ 	WARN_ON(1);
+ 	err = -ENOSYS;
+ out:
++	mutex_unlock(&dev->mutex);
++
+ 	return err ? err : count;
+ }
+ 
+@@ -513,6 +523,7 @@ static struct config_item *gpiommc_make_
+ 	if (!dev)
+ 		return NULL;
+ 
++	mutex_init(&dev->mutex);
+ 	config_item_init_type_name(&dev->item, name,
+ 				   &gpiommc_dev_ci_type);
+ 
diff -Nru a/target/linux/generic/patches-2.6.31/925-modify-i2c-gpio-initcall-level.patch b/target/linux/generic/patches-2.6.31/925-modify-i2c-gpio-initcall-level.patch
--- a/target/linux/generic/patches-2.6.31/925-modify-i2c-gpio-initcall-level.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/925-modify-i2c-gpio-initcall-level.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,11 @@
+--- a/drivers/i2c/busses/i2c-gpio.c
++++ b/drivers/i2c/busses/i2c-gpio.c
+@@ -210,7 +210,7 @@ static int __init i2c_gpio_init(void)
+ 
+ 	return ret;
+ }
+-module_init(i2c_gpio_init);
++subsys_initcall(i2c_gpio_init);
+ 
+ static void __exit i2c_gpio_exit(void)
+ {
diff -Nru a/target/linux/generic/patches-2.6.31/940-wireless_mesh_header.patch b/target/linux/generic/patches-2.6.31/940-wireless_mesh_header.patch
--- a/target/linux/generic/patches-2.6.31/940-wireless_mesh_header.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/940-wireless_mesh_header.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,22 @@
+--- a/include/linux/netdevice.h
++++ b/include/linux/netdevice.h
+@@ -100,7 +100,7 @@ struct wireless_dev;
+  */
+ 
+ #if defined(CONFIG_WLAN_80211) || defined(CONFIG_AX25) || defined(CONFIG_AX25_MODULE)
+-# if defined(CONFIG_MAC80211_MESH)
++# if 1 || defined(CONFIG_MAC80211_MESH)
+ #  define LL_MAX_HEADER 128
+ # else
+ #  define LL_MAX_HEADER 96
+--- a/include/linux/skbuff.h
++++ b/include/linux/skbuff.h
+@@ -380,7 +380,7 @@ struct sk_buff {
+ #ifdef CONFIG_IPV6_NDISC_NODETYPE
+ 	__u8			ndisc_nodetype:2;
+ #endif
+-#if defined(CONFIG_MAC80211) || defined(CONFIG_MAC80211_MODULE)
++#if 1
+ 	__u8			do_not_encrypt:1;
+ #endif
+ 	kmemcheck_bitfield_end(flags2);
diff -Nru a/target/linux/generic/patches-2.6.31/941-ssb_update.patch b/target/linux/generic/patches-2.6.31/941-ssb_update.patch
--- a/target/linux/generic/patches-2.6.31/941-ssb_update.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/941-ssb_update.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,4343 @@
+--- a/drivers/ssb/Kconfig
++++ b/drivers/ssb/Kconfig
+@@ -66,6 +66,20 @@ config SSB_PCMCIAHOST
+ 
+ 	  If unsure, say N
+ 
++config SSB_SDIOHOST_POSSIBLE
++	bool
++	depends on SSB && (MMC = y || MMC = SSB)
++	default y
++
++config SSB_SDIOHOST
++	bool "Support for SSB on SDIO-bus host"
++	depends on SSB_SDIOHOST_POSSIBLE
++	help
++	  Support for a Sonics Silicon Backplane on top
++	  of a SDIO device.
++
++	  If unsure, say N
++
+ config SSB_SILENT
+ 	bool "No SSB kernel messages"
+ 	depends on SSB && EMBEDDED
+--- a/drivers/ssb/Makefile
++++ b/drivers/ssb/Makefile
+@@ -6,6 +6,7 @@ ssb-$(CONFIG_SSB_SPROM)			+= sprom.o
+ # host support
+ ssb-$(CONFIG_SSB_PCIHOST)		+= pci.o pcihost_wrapper.o
+ ssb-$(CONFIG_SSB_PCMCIAHOST)		+= pcmcia.o
++ssb-$(CONFIG_SSB_SDIOHOST)		+= sdio.o
+ 
+ # built-in drivers
+ ssb-y					+= driver_chipcommon.o
+--- a/drivers/ssb/b43_pci_bridge.c
++++ b/drivers/ssb/b43_pci_bridge.c
+@@ -5,12 +5,13 @@
+  * because of its small size we include it in the SSB core
+  * instead of creating a standalone module.
+  *
+- * Copyright 2007  Michael Buesch <mb@bu3sch.de>
++ * Copyright 2007  Michael Buesch <m@bues.ch>
+  *
+  * Licensed under the GNU/GPL. See COPYING for details.
+  */
+ 
+ #include <linux/pci.h>
++#include <linux/module.h>
+ #include <linux/ssb/ssb.h>
+ 
+ #include "ssb_private.h"
+@@ -24,6 +25,7 @@ static const struct pci_device_id b43_pc
+ 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4312) },
+ 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4315) },
+ 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4318) },
++	{ PCI_DEVICE(PCI_VENDOR_ID_BCM_GVC,  0x4318) },
+ 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4319) },
+ 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4320) },
+ 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4321) },
+--- a/drivers/ssb/driver_chipcommon.c
++++ b/drivers/ssb/driver_chipcommon.c
+@@ -3,7 +3,7 @@
+  * Broadcom ChipCommon core driver
+  *
+  * Copyright 2005, Broadcom Corporation
+- * Copyright 2006, 2007, Michael Buesch <mb@bu3sch.de>
++ * Copyright 2006, 2007, Michael Buesch <m@bues.ch>
+  *
+  * Licensed under the GNU/GPL. See COPYING for details.
+  */
+@@ -46,40 +46,66 @@ void ssb_chipco_set_clockmode(struct ssb
+ 	if (!ccdev)
+ 		return;
+ 	bus = ccdev->bus;
++
++	/* We support SLOW only on 6..9 */
++	if (ccdev->id.revision >= 10 && mode == SSB_CLKMODE_SLOW)
++		mode = SSB_CLKMODE_DYNAMIC;
++
++	if (cc->capabilities & SSB_CHIPCO_CAP_PMU)
++		return; /* PMU controls clockmode, separated function needed */
++	SSB_WARN_ON(ccdev->id.revision >= 20);
++
+ 	/* chipcommon cores prior to rev6 don't support dynamic clock control */
+ 	if (ccdev->id.revision < 6)
+ 		return;
+-	/* chipcommon cores rev10 are a whole new ball game */
++
++	/* ChipCommon cores rev10+ need testing */
+ 	if (ccdev->id.revision >= 10)
+ 		return;
++
+ 	if (!(cc->capabilities & SSB_CHIPCO_CAP_PCTL))
+ 		return;
+ 
+ 	switch (mode) {
+-	case SSB_CLKMODE_SLOW:
++	case SSB_CLKMODE_SLOW: /* For revs 6..9 only */
+ 		tmp = chipco_read32(cc, SSB_CHIPCO_SLOWCLKCTL);
+ 		tmp |= SSB_CHIPCO_SLOWCLKCTL_FSLOW;
+ 		chipco_write32(cc, SSB_CHIPCO_SLOWCLKCTL, tmp);
+ 		break;
+ 	case SSB_CLKMODE_FAST:
+-		ssb_pci_xtal(bus, SSB_GPIO_XTAL, 1); /* Force crystal on */
+-		tmp = chipco_read32(cc, SSB_CHIPCO_SLOWCLKCTL);
+-		tmp &= ~SSB_CHIPCO_SLOWCLKCTL_FSLOW;
+-		tmp |= SSB_CHIPCO_SLOWCLKCTL_IPLL;
+-		chipco_write32(cc, SSB_CHIPCO_SLOWCLKCTL, tmp);
++		if (ccdev->id.revision < 10) {
++			ssb_pci_xtal(bus, SSB_GPIO_XTAL, 1); /* Force crystal on */
++			tmp = chipco_read32(cc, SSB_CHIPCO_SLOWCLKCTL);
++			tmp &= ~SSB_CHIPCO_SLOWCLKCTL_FSLOW;
++			tmp |= SSB_CHIPCO_SLOWCLKCTL_IPLL;
++			chipco_write32(cc, SSB_CHIPCO_SLOWCLKCTL, tmp);
++		} else {
++			chipco_write32(cc, SSB_CHIPCO_SYSCLKCTL,
++				(chipco_read32(cc, SSB_CHIPCO_SYSCLKCTL) |
++				 SSB_CHIPCO_SYSCLKCTL_FORCEHT));
++			/* udelay(150); TODO: not available in early init */
++		}
+ 		break;
+ 	case SSB_CLKMODE_DYNAMIC:
+-		tmp = chipco_read32(cc, SSB_CHIPCO_SLOWCLKCTL);
+-		tmp &= ~SSB_CHIPCO_SLOWCLKCTL_FSLOW;
+-		tmp &= ~SSB_CHIPCO_SLOWCLKCTL_IPLL;
+-		tmp &= ~SSB_CHIPCO_SLOWCLKCTL_ENXTAL;
+-		if ((tmp & SSB_CHIPCO_SLOWCLKCTL_SRC) != SSB_CHIPCO_SLOWCLKCTL_SRC_XTAL)
+-			tmp |= SSB_CHIPCO_SLOWCLKCTL_ENXTAL;
+-		chipco_write32(cc, SSB_CHIPCO_SLOWCLKCTL, tmp);
+-
+-		/* for dynamic control, we have to release our xtal_pu "force on" */
+-		if (tmp & SSB_CHIPCO_SLOWCLKCTL_ENXTAL)
+-			ssb_pci_xtal(bus, SSB_GPIO_XTAL, 0);
++		if (ccdev->id.revision < 10) {
++			tmp = chipco_read32(cc, SSB_CHIPCO_SLOWCLKCTL);
++			tmp &= ~SSB_CHIPCO_SLOWCLKCTL_FSLOW;
++			tmp &= ~SSB_CHIPCO_SLOWCLKCTL_IPLL;
++			tmp &= ~SSB_CHIPCO_SLOWCLKCTL_ENXTAL;
++			if ((tmp & SSB_CHIPCO_SLOWCLKCTL_SRC) !=
++			    SSB_CHIPCO_SLOWCLKCTL_SRC_XTAL)
++				tmp |= SSB_CHIPCO_SLOWCLKCTL_ENXTAL;
++			chipco_write32(cc, SSB_CHIPCO_SLOWCLKCTL, tmp);
++
++			/* For dynamic control, we have to release our xtal_pu
++			 * "force on" */
++			if (tmp & SSB_CHIPCO_SLOWCLKCTL_ENXTAL)
++				ssb_pci_xtal(bus, SSB_GPIO_XTAL, 0);
++		} else {
++			chipco_write32(cc, SSB_CHIPCO_SYSCLKCTL,
++				(chipco_read32(cc, SSB_CHIPCO_SYSCLKCTL) &
++				 ~SSB_CHIPCO_SYSCLKCTL_FORCEHT));
++		}
+ 		break;
+ 	default:
+ 		SSB_WARN_ON(1);
+@@ -209,6 +235,24 @@ static void chipco_powercontrol_init(str
+ 	}
+ }
+ 
++/* http://bcm-v4.sipsolutions.net/802.11/PmuFastPwrupDelay */
++static u16 pmu_fast_powerup_delay(struct ssb_chipcommon *cc)
++{
++	struct ssb_bus *bus = cc->dev->bus;
++
++	switch (bus->chip_id) {
++	case 0x4312:
++	case 0x4322:
++	case 0x4328:
++		return 7000;
++	case 0x4325:
++		/* TODO: */
++	default:
++		return 15000;
++	}
++}
++
++/* http://bcm-v4.sipsolutions.net/802.11/ClkctlFastPwrupDelay */
+ static void calc_fast_powerup_delay(struct ssb_chipcommon *cc)
+ {
+ 	struct ssb_bus *bus = cc->dev->bus;
+@@ -218,6 +262,12 @@ static void calc_fast_powerup_delay(stru
+ 
+ 	if (bus->bustype != SSB_BUSTYPE_PCI)
+ 		return;
++
++	if (cc->capabilities & SSB_CHIPCO_CAP_PMU) {
++		cc->fast_pwrup_delay = pmu_fast_powerup_delay(cc);
++		return;
++	}
++
+ 	if (!(cc->capabilities & SSB_CHIPCO_CAP_PCTL))
+ 		return;
+ 
+@@ -233,6 +283,15 @@ void ssb_chipcommon_init(struct ssb_chip
+ {
+ 	if (!cc->dev)
+ 		return; /* We don't have a ChipCommon */
++	if (cc->dev->id.revision >= 11)
++		cc->status = chipco_read32(cc, SSB_CHIPCO_CHIPSTAT);
++	ssb_dprintk(KERN_INFO PFX "chipcommon status is 0x%x\n", cc->status);
++
++	if (cc->dev->id.revision >= 20) {
++		chipco_write32(cc, SSB_CHIPCO_GPIOPULLUP, 0);
++		chipco_write32(cc, SSB_CHIPCO_GPIOPULLDOWN, 0);
++	}
++
+ 	ssb_pmu_init(cc);
+ 	chipco_powercontrol_init(cc);
+ 	ssb_chipco_set_clockmode(cc, SSB_CLKMODE_FAST);
+@@ -370,6 +429,7 @@ u32 ssb_chipco_gpio_control(struct ssb_c
+ {
+ 	return chipco_write32_masked(cc, SSB_CHIPCO_GPIOCTL, mask, value);
+ }
++EXPORT_SYMBOL(ssb_chipco_gpio_control);
+ 
+ u32 ssb_chipco_gpio_intmask(struct ssb_chipcommon *cc, u32 mask, u32 value)
+ {
+--- a/drivers/ssb/driver_chipcommon_pmu.c
++++ b/drivers/ssb/driver_chipcommon_pmu.c
+@@ -2,7 +2,7 @@
+  * Sonics Silicon Backplane
+  * Broadcom ChipCommon Power Management Unit driver
+  *
+- * Copyright 2009, Michael Buesch <mb@bu3sch.de>
++ * Copyright 2009, Michael Buesch <m@bues.ch>
+  * Copyright 2007, Broadcom Corporation
+  *
+  * Licensed under the GNU/GPL. See COPYING for details.
+@@ -12,6 +12,9 @@
+ #include <linux/ssb/ssb_regs.h>
+ #include <linux/ssb/ssb_driver_chipcommon.h>
+ #include <linux/delay.h>
++#ifdef CONFIG_BCM47XX
++#include <asm/mach-bcm47xx/nvram.h>
++#endif
+ 
+ #include "ssb_private.h"
+ 
+@@ -28,6 +31,21 @@ static void ssb_chipco_pll_write(struct
+ 	chipco_write32(cc, SSB_CHIPCO_PLLCTL_DATA, value);
+ }
+ 
++static void ssb_chipco_regctl_maskset(struct ssb_chipcommon *cc,
++				   u32 offset, u32 mask, u32 set)
++{
++	u32 value;
++
++	chipco_read32(cc, SSB_CHIPCO_REGCTL_ADDR);
++	chipco_write32(cc, SSB_CHIPCO_REGCTL_ADDR, offset);
++	chipco_read32(cc, SSB_CHIPCO_REGCTL_ADDR);
++	value = chipco_read32(cc, SSB_CHIPCO_REGCTL_DATA);
++	value &= mask;
++	value |= set;
++	chipco_write32(cc, SSB_CHIPCO_REGCTL_DATA, value);
++	chipco_read32(cc, SSB_CHIPCO_REGCTL_DATA);
++}
++
+ struct pmu0_plltab_entry {
+ 	u16 freq;	/* Crystal frequency in kHz.*/
+ 	u8 xf;		/* Crystal frequency value for PMU control */
+@@ -76,10 +94,6 @@ static void ssb_pmu0_pllinit_r0(struct s
+ 	u32 pmuctl, tmp, pllctl;
+ 	unsigned int i;
+ 
+-	if ((bus->chip_id == 0x5354) && !crystalfreq) {
+-		/* The 5354 crystal freq is 25MHz */
+-		crystalfreq = 25000;
+-	}
+ 	if (crystalfreq)
+ 		e = pmu0_plltab_find_entry(crystalfreq);
+ 	if (!e)
+@@ -305,7 +319,11 @@ static void ssb_pmu_pll_init(struct ssb_
+ 	u32 crystalfreq = 0; /* in kHz. 0 = keep default freq. */
+ 
+ 	if (bus->bustype == SSB_BUSTYPE_SSB) {
+-		/* TODO: The user may override the crystal frequency. */
++#ifdef CONFIG_BCM47XX
++		char buf[20];
++		if (nvram_getenv("xtalfreq", buf, sizeof(buf)) >= 0)
++			crystalfreq = simple_strtoul(buf, NULL, 0);
++#endif
+ 	}
+ 
+ 	switch (bus->chip_id) {
+@@ -314,9 +332,19 @@ static void ssb_pmu_pll_init(struct ssb_
+ 		ssb_pmu1_pllinit_r0(cc, crystalfreq);
+ 		break;
+ 	case 0x4328:
++		ssb_pmu0_pllinit_r0(cc, crystalfreq);
++		break;
+ 	case 0x5354:
++		if (crystalfreq == 0)
++			crystalfreq = 25000;
+ 		ssb_pmu0_pllinit_r0(cc, crystalfreq);
+ 		break;
++	case 0x4322:
++		if (cc->pmu.rev == 2) {
++			chipco_write32(cc, SSB_CHIPCO_PLLCTL_ADDR, 0x0000000A);
++			chipco_write32(cc, SSB_CHIPCO_PLLCTL_DATA, 0x380005C0);
++		}
++		break;
+ 	default:
+ 		ssb_printk(KERN_ERR PFX
+ 			   "ERROR: PLL init unknown for device %04X\n",
+@@ -396,12 +424,15 @@ static void ssb_pmu_resources_init(struc
+ 	u32 min_msk = 0, max_msk = 0;
+ 	unsigned int i;
+ 	const struct pmu_res_updown_tab_entry *updown_tab = NULL;
+-	unsigned int updown_tab_size;
++	unsigned int updown_tab_size = 0;
+ 	const struct pmu_res_depend_tab_entry *depend_tab = NULL;
+-	unsigned int depend_tab_size;
++	unsigned int depend_tab_size = 0;
+ 
+ 	switch (bus->chip_id) {
+ 	case 0x4312:
++		 min_msk = 0xCBB;
++		 break;
++	case 0x4322:
+ 		/* We keep the default settings:
+ 		 * min_msk = 0xCBB
+ 		 * max_msk = 0x7FFFF
+@@ -480,9 +511,9 @@ static void ssb_pmu_resources_init(struc
+ 		chipco_write32(cc, SSB_CHIPCO_PMU_MAXRES_MSK, max_msk);
+ }
+ 
++/* http://bcm-v4.sipsolutions.net/802.11/SSB/PmuInit */
+ void ssb_pmu_init(struct ssb_chipcommon *cc)
+ {
+-	struct ssb_bus *bus = cc->dev->bus;
+ 	u32 pmucap;
+ 
+ 	if (!(cc->capabilities & SSB_CHIPCO_CAP_PMU))
+@@ -494,15 +525,122 @@ void ssb_pmu_init(struct ssb_chipcommon
+ 	ssb_dprintk(KERN_DEBUG PFX "Found rev %u PMU (capabilities 0x%08X)\n",
+ 		    cc->pmu.rev, pmucap);
+ 
+-	if (cc->pmu.rev >= 1) {
+-		if ((bus->chip_id == 0x4325) && (bus->chip_rev < 2)) {
+-			chipco_mask32(cc, SSB_CHIPCO_PMU_CTL,
+-				      ~SSB_CHIPCO_PMU_CTL_NOILPONW);
+-		} else {
+-			chipco_set32(cc, SSB_CHIPCO_PMU_CTL,
+-				     SSB_CHIPCO_PMU_CTL_NOILPONW);
+-		}
+-	}
++	if (cc->pmu.rev == 1)
++		chipco_mask32(cc, SSB_CHIPCO_PMU_CTL,
++			      ~SSB_CHIPCO_PMU_CTL_NOILPONW);
++	else
++		chipco_set32(cc, SSB_CHIPCO_PMU_CTL,
++			     SSB_CHIPCO_PMU_CTL_NOILPONW);
+ 	ssb_pmu_pll_init(cc);
+ 	ssb_pmu_resources_init(cc);
+ }
++
++void ssb_pmu_set_ldo_voltage(struct ssb_chipcommon *cc,
++			     enum ssb_pmu_ldo_volt_id id, u32 voltage)
++{
++	struct ssb_bus *bus = cc->dev->bus;
++	u32 addr, shift, mask;
++
++	switch (bus->chip_id) {
++	case 0x4328:
++	case 0x5354:
++		switch (id) {
++		case LDO_VOLT1:
++			addr = 2;
++			shift = 25;
++			mask = 0xF;
++			break;
++		case LDO_VOLT2:
++			addr = 3;
++			shift = 1;
++			mask = 0xF;
++			break;
++		case LDO_VOLT3:
++			addr = 3;
++			shift = 9;
++			mask = 0xF;
++			break;
++		case LDO_PAREF:
++			addr = 3;
++			shift = 17;
++			mask = 0x3F;
++			break;
++		default:
++			SSB_WARN_ON(1);
++			return;
++		}
++		break;
++	case 0x4312:
++		if (SSB_WARN_ON(id != LDO_PAREF))
++			return;
++		addr = 0;
++		shift = 21;
++		mask = 0x3F;
++		break;
++	default:
++		return;
++	}
++
++	ssb_chipco_regctl_maskset(cc, addr, ~(mask << shift),
++				  (voltage & mask) << shift);
++}
++
++void ssb_pmu_set_ldo_paref(struct ssb_chipcommon *cc, bool on)
++{
++	struct ssb_bus *bus = cc->dev->bus;
++	int ldo;
++
++	switch (bus->chip_id) {
++	case 0x4312:
++		ldo = SSB_PMURES_4312_PA_REF_LDO;
++		break;
++	case 0x4328:
++		ldo = SSB_PMURES_4328_PA_REF_LDO;
++		break;
++	case 0x5354:
++		ldo = SSB_PMURES_5354_PA_REF_LDO;
++		break;
++	default:
++		return;
++	}
++
++	if (on)
++		chipco_set32(cc, SSB_CHIPCO_PMU_MINRES_MSK, 1 << ldo);
++	else
++		chipco_mask32(cc, SSB_CHIPCO_PMU_MINRES_MSK, ~(1 << ldo));
++	chipco_read32(cc, SSB_CHIPCO_PMU_MINRES_MSK); //SPEC FIXME found via mmiotrace - dummy read?
++}
++
++EXPORT_SYMBOL(ssb_pmu_set_ldo_voltage);
++EXPORT_SYMBOL(ssb_pmu_set_ldo_paref);
++
++u32 ssb_pmu_get_cpu_clock(struct ssb_chipcommon *cc)
++{
++	struct ssb_bus *bus = cc->dev->bus;
++
++	switch (bus->chip_id) {
++	case 0x5354:
++		/* 5354 chip uses a non programmable PLL of frequency 240MHz */
++		return 240000000;
++	default:
++		ssb_printk(KERN_ERR PFX
++			   "ERROR: PMU cpu clock unknown for device %04X\n",
++			   bus->chip_id);
++		return 0;
++	}
++}
++
++u32 ssb_pmu_get_controlclock(struct ssb_chipcommon *cc)
++{
++	struct ssb_bus *bus = cc->dev->bus;
++
++	switch (bus->chip_id) {
++	case 0x5354:
++		return 120000000;
++	default:
++		ssb_printk(KERN_ERR PFX
++			   "ERROR: PMU controlclock unknown for device %04X\n",
++			   bus->chip_id);
++		return 0;
++	}
++}
+--- a/drivers/ssb/driver_gige.c
++++ b/drivers/ssb/driver_gige.c
+@@ -3,7 +3,7 @@
+  * Broadcom Gigabit Ethernet core driver
+  *
+  * Copyright 2008, Broadcom Corporation
+- * Copyright 2008, Michael Buesch <mb@bu3sch.de>
++ * Copyright 2008, Michael Buesch <m@bues.ch>
+  *
+  * Licensed under the GNU/GPL. See COPYING for details.
+  */
+@@ -12,6 +12,7 @@
+ #include <linux/ssb/ssb_driver_gige.h>
+ #include <linux/pci.h>
+ #include <linux/pci_regs.h>
++#include <linux/slab.h>
+ 
+ 
+ /*
+@@ -105,8 +106,9 @@ void gige_pcicfg_write32(struct ssb_gige
+ 	gige_write32(dev, SSB_GIGE_PCICFG + offset, value);
+ }
+ 
+-static int ssb_gige_pci_read_config(struct pci_bus *bus, unsigned int devfn,
+-				    int reg, int size, u32 *val)
++static int __devinit ssb_gige_pci_read_config(struct pci_bus *bus,
++					      unsigned int devfn, int reg,
++					      int size, u32 *val)
+ {
+ 	struct ssb_gige *dev = container_of(bus->ops, struct ssb_gige, pci_ops);
+ 	unsigned long flags;
+@@ -135,8 +137,9 @@ static int ssb_gige_pci_read_config(stru
+ 	return PCIBIOS_SUCCESSFUL;
+ }
+ 
+-static int ssb_gige_pci_write_config(struct pci_bus *bus, unsigned int devfn,
+-				     int reg, int size, u32 val)
++static int __devinit ssb_gige_pci_write_config(struct pci_bus *bus,
++					       unsigned int devfn, int reg,
++					       int size, u32 val)
+ {
+ 	struct ssb_gige *dev = container_of(bus->ops, struct ssb_gige, pci_ops);
+ 	unsigned long flags;
+@@ -165,7 +168,8 @@ static int ssb_gige_pci_write_config(str
+ 	return PCIBIOS_SUCCESSFUL;
+ }
+ 
+-static int ssb_gige_probe(struct ssb_device *sdev, const struct ssb_device_id *id)
++static int __devinit ssb_gige_probe(struct ssb_device *sdev,
++				    const struct ssb_device_id *id)
+ {
+ 	struct ssb_gige *dev;
+ 	u32 base, tmslow, tmshigh;
+--- a/drivers/ssb/driver_mipscore.c
++++ b/drivers/ssb/driver_mipscore.c
+@@ -3,7 +3,7 @@
+  * Broadcom MIPS core driver
+  *
+  * Copyright 2005, Broadcom Corporation
+- * Copyright 2006, 2007, Michael Buesch <mb@bu3sch.de>
++ * Copyright 2006, 2007, Michael Buesch <m@bues.ch>
+  *
+  * Licensed under the GNU/GPL. See COPYING for details.
+  */
+@@ -208,6 +208,9 @@ u32 ssb_cpu_clock(struct ssb_mipscore *m
+ 	struct ssb_bus *bus = mcore->dev->bus;
+ 	u32 pll_type, n, m, rate = 0;
+ 
++	if (bus->chipco.capabilities & SSB_CHIPCO_CAP_PMU)
++		return ssb_pmu_get_cpu_clock(&bus->chipco);
++
+ 	if (bus->extif.dev) {
+ 		ssb_extif_get_clockcontrol(&bus->extif, &pll_type, &n, &m);
+ 	} else if (bus->chipco.dev) {
+@@ -270,7 +273,6 @@ void ssb_mipscore_init(struct ssb_mipsco
+ 				set_irq(dev, irq++);
+ 			}
+ 			break;
+-			/* fallthrough */
+ 		case SSB_DEV_PCI:
+ 		case SSB_DEV_ETHERNET:
+ 		case SSB_DEV_ETHERNET_GBIT:
+@@ -281,6 +283,10 @@ void ssb_mipscore_init(struct ssb_mipsco
+ 				set_irq(dev, irq++);
+ 				break;
+ 			}
++			/* fallthrough */
++		case SSB_DEV_EXTIF:
++			set_irq(dev, 0);
++			break;
+ 		}
+ 	}
+ 	ssb_dprintk(KERN_INFO PFX "after irq reconfiguration\n");
+--- a/drivers/ssb/driver_pcicore.c
++++ b/drivers/ssb/driver_pcicore.c
+@@ -3,7 +3,7 @@
+  * Broadcom PCI-core driver
+  *
+  * Copyright 2005, Broadcom Corporation
+- * Copyright 2006, 2007, Michael Buesch <mb@bu3sch.de>
++ * Copyright 2006, 2007, Michael Buesch <m@bues.ch>
+  *
+  * Licensed under the GNU/GPL. See COPYING for details.
+  */
+@@ -15,6 +15,11 @@
+ 
+ #include "ssb_private.h"
+ 
++static u32 ssb_pcie_read(struct ssb_pcicore *pc, u32 address);
++static void ssb_pcie_write(struct ssb_pcicore *pc, u32 address, u32 data);
++static u16 ssb_pcie_mdio_read(struct ssb_pcicore *pc, u8 device, u8 address);
++static void ssb_pcie_mdio_write(struct ssb_pcicore *pc, u8 device,
++				u8 address, u16 data);
+ 
+ static inline
+ u32 pcicore_read32(struct ssb_pcicore *pc, u16 offset)
+@@ -69,7 +74,7 @@ static u32 get_cfgspace_addr(struct ssb_
+ 	u32 tmp;
+ 
+ 	/* We do only have one cardbus device behind the bridge. */
+-	if (pc->cardbusmode && (dev >= 1))
++	if (pc->cardbusmode && (dev > 1))
+ 		goto out;
+ 
+ 	if (bus == 0) {
+@@ -246,20 +251,12 @@ static struct pci_controller ssb_pcicore
+ 	.pci_ops	= &ssb_pcicore_pciops,
+ 	.io_resource	= &ssb_pcicore_io_resource,
+ 	.mem_resource	= &ssb_pcicore_mem_resource,
+-	.mem_offset	= 0x24000000,
+ };
+ 
+-static u32 ssb_pcicore_pcibus_iobase = 0x100;
+-static u32 ssb_pcicore_pcibus_membase = SSB_PCI_DMA;
+-
+ /* This function is called when doing a pci_enable_device().
+  * We must first check if the device is a device on the PCI-core bridge. */
+ int ssb_pcicore_plat_dev_init(struct pci_dev *d)
+ {
+-	struct resource *res;
+-	int pos, size;
+-	u32 *base;
+-
+ 	if (d->bus->ops != &ssb_pcicore_pciops) {
+ 		/* This is not a device on the PCI-core bridge. */
+ 		return -ENODEV;
+@@ -268,27 +265,6 @@ int ssb_pcicore_plat_dev_init(struct pci
+ 	ssb_printk(KERN_INFO "PCI: Fixing up device %s\n",
+ 		   pci_name(d));
+ 
+-	/* Fix up resource bases */
+-	for (pos = 0; pos < 6; pos++) {
+-		res = &d->resource[pos];
+-		if (res->flags & IORESOURCE_IO)
+-			base = &ssb_pcicore_pcibus_iobase;
+-		else
+-			base = &ssb_pcicore_pcibus_membase;
+-		res->flags |= IORESOURCE_PCI_FIXED;
+-		if (res->end) {
+-			size = res->end - res->start + 1;
+-			if (*base & (size - 1))
+-				*base = (*base + size) & ~(size - 1);
+-			res->start = *base;
+-			res->end = res->start + size - 1;
+-			*base += size;
+-			pci_write_config_dword(d, PCI_BASE_ADDRESS_0 + (pos << 2), res->start);
+-		}
+-		/* Fix up PCI bridge BAR0 only */
+-		if (d->bus->number == 0 && PCI_SLOT(d->devfn) == 0)
+-			break;
+-	}
+ 	/* Fix up interrupt lines */
+ 	d->irq = ssb_mips_irq(extpci_core->dev) + 2;
+ 	pci_write_config_byte(d, PCI_INTERRUPT_LINE, d->irq);
+@@ -338,7 +314,7 @@ int ssb_pcicore_pcibios_map_irq(const st
+ 	return ssb_mips_irq(extpci_core->dev) + 2;
+ }
+ 
+-static void ssb_pcicore_init_hostmode(struct ssb_pcicore *pc)
++static void __devinit ssb_pcicore_init_hostmode(struct ssb_pcicore *pc)
+ {
+ 	u32 val;
+ 
+@@ -403,7 +379,7 @@ static void ssb_pcicore_init_hostmode(st
+ 	register_pci_controller(&ssb_pcicore_controller);
+ }
+ 
+-static int pcicore_is_in_hostmode(struct ssb_pcicore *pc)
++static int __devinit pcicore_is_in_hostmode(struct ssb_pcicore *pc)
+ {
+ 	struct ssb_bus *bus = pc->dev->bus;
+ 	u16 chipid_top;
+@@ -432,25 +408,137 @@ static int pcicore_is_in_hostmode(struct
+ }
+ #endif /* CONFIG_SSB_PCICORE_HOSTMODE */
+ 
++/**************************************************
++ * Workarounds.
++ **************************************************/
++
++static void __devinit ssb_pcicore_fix_sprom_core_index(struct ssb_pcicore *pc)
++{
++	u16 tmp = pcicore_read16(pc, SSB_PCICORE_SPROM(0));
++	if (((tmp & 0xF000) >> 12) != pc->dev->core_index) {
++		tmp &= ~0xF000;
++		tmp |= (pc->dev->core_index << 12);
++		pcicore_write16(pc, SSB_PCICORE_SPROM(0), tmp);
++	}
++}
++
++static u8 ssb_pcicore_polarity_workaround(struct ssb_pcicore *pc)
++{
++	return (ssb_pcie_read(pc, 0x204) & 0x10) ? 0xC0 : 0x80;
++}
++
++static void ssb_pcicore_serdes_workaround(struct ssb_pcicore *pc)
++{
++	const u8 serdes_pll_device = 0x1D;
++	const u8 serdes_rx_device = 0x1F;
++	u16 tmp;
++
++	ssb_pcie_mdio_write(pc, serdes_rx_device, 1 /* Control */,
++			    ssb_pcicore_polarity_workaround(pc));
++	tmp = ssb_pcie_mdio_read(pc, serdes_pll_device, 1 /* Control */);
++	if (tmp & 0x4000)
++		ssb_pcie_mdio_write(pc, serdes_pll_device, 1, tmp & ~0x4000);
++}
++
++static void ssb_pcicore_pci_setup_workarounds(struct ssb_pcicore *pc)
++{
++	struct ssb_device *pdev = pc->dev;
++	struct ssb_bus *bus = pdev->bus;
++	u32 tmp;
++
++	tmp = pcicore_read32(pc, SSB_PCICORE_SBTOPCI2);
++	tmp |= SSB_PCICORE_SBTOPCI_PREF;
++	tmp |= SSB_PCICORE_SBTOPCI_BURST;
++	pcicore_write32(pc, SSB_PCICORE_SBTOPCI2, tmp);
++
++	if (pdev->id.revision < 5) {
++		tmp = ssb_read32(pdev, SSB_IMCFGLO);
++		tmp &= ~SSB_IMCFGLO_SERTO;
++		tmp |= 2;
++		tmp &= ~SSB_IMCFGLO_REQTO;
++		tmp |= 3 << SSB_IMCFGLO_REQTO_SHIFT;
++		ssb_write32(pdev, SSB_IMCFGLO, tmp);
++		ssb_commit_settings(bus);
++	} else if (pdev->id.revision >= 11) {
++		tmp = pcicore_read32(pc, SSB_PCICORE_SBTOPCI2);
++		tmp |= SSB_PCICORE_SBTOPCI_MRM;
++		pcicore_write32(pc, SSB_PCICORE_SBTOPCI2, tmp);
++	}
++}
++
++static void ssb_pcicore_pcie_setup_workarounds(struct ssb_pcicore *pc)
++{
++	u32 tmp;
++	u8 rev = pc->dev->id.revision;
++
++	if (rev == 0 || rev == 1) {
++		/* TLP Workaround register. */
++		tmp = ssb_pcie_read(pc, 0x4);
++		tmp |= 0x8;
++		ssb_pcie_write(pc, 0x4, tmp);
++	}
++	if (rev == 1) {
++		/* DLLP Link Control register. */
++		tmp = ssb_pcie_read(pc, 0x100);
++		tmp |= 0x40;
++		ssb_pcie_write(pc, 0x100, tmp);
++	}
++
++	if (rev == 0) {
++		const u8 serdes_rx_device = 0x1F;
++
++		ssb_pcie_mdio_write(pc, serdes_rx_device,
++					2 /* Timer */, 0x8128);
++		ssb_pcie_mdio_write(pc, serdes_rx_device,
++					6 /* CDR */, 0x0100);
++		ssb_pcie_mdio_write(pc, serdes_rx_device,
++					7 /* CDR BW */, 0x1466);
++	} else if (rev == 3 || rev == 4 || rev == 5) {
++		/* TODO: DLLP Power Management Threshold */
++		ssb_pcicore_serdes_workaround(pc);
++		/* TODO: ASPM */
++	} else if (rev == 7) {
++		/* TODO: No PLL down */
++	}
++
++	if (rev >= 6) {
++		/* Miscellaneous Configuration Fixup */
++		tmp = pcicore_read16(pc, SSB_PCICORE_SPROM(5));
++		if (!(tmp & 0x8000))
++			pcicore_write16(pc, SSB_PCICORE_SPROM(5),
++					tmp | 0x8000);
++	}
++}
+ 
+ /**************************************************
+  * Generic and Clientmode operation code.
+  **************************************************/
+ 
+-static void ssb_pcicore_init_clientmode(struct ssb_pcicore *pc)
++static void __devinit ssb_pcicore_init_clientmode(struct ssb_pcicore *pc)
+ {
++	struct ssb_device *pdev = pc->dev;
++	struct ssb_bus *bus = pdev->bus;
++
++	if (bus->bustype == SSB_BUSTYPE_PCI)
++		ssb_pcicore_fix_sprom_core_index(pc);
++
+ 	/* Disable PCI interrupts. */
+-	ssb_write32(pc->dev, SSB_INTVEC, 0);
++	ssb_write32(pdev, SSB_INTVEC, 0);
++
++	/* Additional PCIe always once-executed workarounds */
++	if (pc->dev->id.coreid == SSB_DEV_PCIE) {
++		ssb_pcicore_serdes_workaround(pc);
++		/* TODO: ASPM */
++		/* TODO: Clock Request Update */
++	}
+ }
+ 
+-void ssb_pcicore_init(struct ssb_pcicore *pc)
++void __devinit ssb_pcicore_init(struct ssb_pcicore *pc)
+ {
+ 	struct ssb_device *dev = pc->dev;
+-	struct ssb_bus *bus;
+ 
+ 	if (!dev)
+ 		return;
+-	bus = dev->bus;
+ 	if (!ssb_device_is_enabled(dev))
+ 		ssb_device_enable(dev, 0);
+ 
+@@ -475,58 +563,104 @@ static void ssb_pcie_write(struct ssb_pc
+ 	pcicore_write32(pc, 0x134, data);
+ }
+ 
+-static void ssb_pcie_mdio_write(struct ssb_pcicore *pc, u8 device,
+-				u8 address, u16 data)
++static void ssb_pcie_mdio_set_phy(struct ssb_pcicore *pc, u8 phy)
+ {
+ 	const u16 mdio_control = 0x128;
+ 	const u16 mdio_data = 0x12C;
+ 	u32 v;
+ 	int i;
+ 
++	v = (1 << 30); /* Start of Transaction */
++	v |= (1 << 28); /* Write Transaction */
++	v |= (1 << 17); /* Turnaround */
++	v |= (0x1F << 18);
++	v |= (phy << 4);
++	pcicore_write32(pc, mdio_data, v);
++
++	udelay(10);
++	for (i = 0; i < 200; i++) {
++		v = pcicore_read32(pc, mdio_control);
++		if (v & 0x100 /* Trans complete */)
++			break;
++		msleep(1);
++	}
++}
++
++static u16 ssb_pcie_mdio_read(struct ssb_pcicore *pc, u8 device, u8 address)
++{
++	const u16 mdio_control = 0x128;
++	const u16 mdio_data = 0x12C;
++	int max_retries = 10;
++	u16 ret = 0;
++	u32 v;
++	int i;
++
+ 	v = 0x80; /* Enable Preamble Sequence */
+ 	v |= 0x2; /* MDIO Clock Divisor */
+ 	pcicore_write32(pc, mdio_control, v);
+ 
++	if (pc->dev->id.revision >= 10) {
++		max_retries = 200;
++		ssb_pcie_mdio_set_phy(pc, device);
++	}
++
+ 	v = (1 << 30); /* Start of Transaction */
+-	v |= (1 << 28); /* Write Transaction */
++	v |= (1 << 29); /* Read Transaction */
+ 	v |= (1 << 17); /* Turnaround */
+-	v |= (u32)device << 22;
++	if (pc->dev->id.revision < 10)
++		v |= (u32)device << 22;
+ 	v |= (u32)address << 18;
+-	v |= data;
+ 	pcicore_write32(pc, mdio_data, v);
+ 	/* Wait for the device to complete the transaction */
+ 	udelay(10);
+-	for (i = 0; i < 10; i++) {
++	for (i = 0; i < max_retries; i++) {
+ 		v = pcicore_read32(pc, mdio_control);
+-		if (v & 0x100 /* Trans complete */)
++		if (v & 0x100 /* Trans complete */) {
++			udelay(10);
++			ret = pcicore_read32(pc, mdio_data);
+ 			break;
++		}
+ 		msleep(1);
+ 	}
+ 	pcicore_write32(pc, mdio_control, 0);
++	return ret;
+ }
+ 
+-static void ssb_broadcast_value(struct ssb_device *dev,
+-				u32 address, u32 data)
++static void ssb_pcie_mdio_write(struct ssb_pcicore *pc, u8 device,
++				u8 address, u16 data)
+ {
+-	/* This is used for both, PCI and ChipCommon core, so be careful. */
+-	BUILD_BUG_ON(SSB_PCICORE_BCAST_ADDR != SSB_CHIPCO_BCAST_ADDR);
+-	BUILD_BUG_ON(SSB_PCICORE_BCAST_DATA != SSB_CHIPCO_BCAST_DATA);
++	const u16 mdio_control = 0x128;
++	const u16 mdio_data = 0x12C;
++	int max_retries = 10;
++	u32 v;
++	int i;
+ 
+-	ssb_write32(dev, SSB_PCICORE_BCAST_ADDR, address);
+-	ssb_read32(dev, SSB_PCICORE_BCAST_ADDR); /* flush */
+-	ssb_write32(dev, SSB_PCICORE_BCAST_DATA, data);
+-	ssb_read32(dev, SSB_PCICORE_BCAST_DATA); /* flush */
+-}
++	v = 0x80; /* Enable Preamble Sequence */
++	v |= 0x2; /* MDIO Clock Divisor */
++	pcicore_write32(pc, mdio_control, v);
+ 
+-static void ssb_commit_settings(struct ssb_bus *bus)
+-{
+-	struct ssb_device *dev;
++	if (pc->dev->id.revision >= 10) {
++		max_retries = 200;
++		ssb_pcie_mdio_set_phy(pc, device);
++	}
+ 
+-	dev = bus->chipco.dev ? bus->chipco.dev : bus->pcicore.dev;
+-	if (WARN_ON(!dev))
+-		return;
+-	/* This forces an update of the cached registers. */
+-	ssb_broadcast_value(dev, 0xFD8, 0);
++	v = (1 << 30); /* Start of Transaction */
++	v |= (1 << 28); /* Write Transaction */
++	v |= (1 << 17); /* Turnaround */
++	if (pc->dev->id.revision < 10)
++		v |= (u32)device << 22;
++	v |= (u32)address << 18;
++	v |= data;
++	pcicore_write32(pc, mdio_data, v);
++	/* Wait for the device to complete the transaction */
++	udelay(10);
++	for (i = 0; i < max_retries; i++) {
++		v = pcicore_read32(pc, mdio_control);
++		if (v & 0x100 /* Trans complete */)
++			break;
++		msleep(1);
++	}
++	pcicore_write32(pc, mdio_control, 0);
+ }
+ 
+ int ssb_pcicore_dev_irqvecs_enable(struct ssb_pcicore *pc,
+@@ -551,13 +685,13 @@ int ssb_pcicore_dev_irqvecs_enable(struc
+ 	might_sleep_if(pdev->id.coreid != SSB_DEV_PCI);
+ 
+ 	/* Enable interrupts for this device. */
+-	if (bus->host_pci &&
+-	    ((pdev->id.revision >= 6) || (pdev->id.coreid == SSB_DEV_PCIE))) {
++	if ((pdev->id.revision >= 6) || (pdev->id.coreid == SSB_DEV_PCIE)) {
+ 		u32 coremask;
+ 
+ 		/* Calculate the "coremask" for the device. */
+ 		coremask = (1 << dev->core_index);
+ 
++		SSB_WARN_ON(bus->bustype != SSB_BUSTYPE_PCI);
+ 		err = pci_read_config_dword(bus->host_pci, SSB_PCI_IRQMASK, &tmp);
+ 		if (err)
+ 			goto out;
+@@ -579,48 +713,10 @@ int ssb_pcicore_dev_irqvecs_enable(struc
+ 	if (pc->setup_done)
+ 		goto out;
+ 	if (pdev->id.coreid == SSB_DEV_PCI) {
+-		tmp = pcicore_read32(pc, SSB_PCICORE_SBTOPCI2);
+-		tmp |= SSB_PCICORE_SBTOPCI_PREF;
+-		tmp |= SSB_PCICORE_SBTOPCI_BURST;
+-		pcicore_write32(pc, SSB_PCICORE_SBTOPCI2, tmp);
+-
+-		if (pdev->id.revision < 5) {
+-			tmp = ssb_read32(pdev, SSB_IMCFGLO);
+-			tmp &= ~SSB_IMCFGLO_SERTO;
+-			tmp |= 2;
+-			tmp &= ~SSB_IMCFGLO_REQTO;
+-			tmp |= 3 << SSB_IMCFGLO_REQTO_SHIFT;
+-			ssb_write32(pdev, SSB_IMCFGLO, tmp);
+-			ssb_commit_settings(bus);
+-		} else if (pdev->id.revision >= 11) {
+-			tmp = pcicore_read32(pc, SSB_PCICORE_SBTOPCI2);
+-			tmp |= SSB_PCICORE_SBTOPCI_MRM;
+-			pcicore_write32(pc, SSB_PCICORE_SBTOPCI2, tmp);
+-		}
++		ssb_pcicore_pci_setup_workarounds(pc);
+ 	} else {
+ 		WARN_ON(pdev->id.coreid != SSB_DEV_PCIE);
+-		//TODO: Better make defines for all these magic PCIE values.
+-		if ((pdev->id.revision == 0) || (pdev->id.revision == 1)) {
+-			/* TLP Workaround register. */
+-			tmp = ssb_pcie_read(pc, 0x4);
+-			tmp |= 0x8;
+-			ssb_pcie_write(pc, 0x4, tmp);
+-		}
+-		if (pdev->id.revision == 0) {
+-			const u8 serdes_rx_device = 0x1F;
+-
+-			ssb_pcie_mdio_write(pc, serdes_rx_device,
+-					    2 /* Timer */, 0x8128);
+-			ssb_pcie_mdio_write(pc, serdes_rx_device,
+-					    6 /* CDR */, 0x0100);
+-			ssb_pcie_mdio_write(pc, serdes_rx_device,
+-					    7 /* CDR BW */, 0x1466);
+-		} else if (pdev->id.revision == 1) {
+-			/* DLLP Link Control register. */
+-			tmp = ssb_pcie_read(pc, 0x100);
+-			tmp |= 0x40;
+-			ssb_pcie_write(pc, 0x100, tmp);
+-		}
++		ssb_pcicore_pcie_setup_workarounds(pc);
+ 	}
+ 	pc->setup_done = 1;
+ out:
+--- a/drivers/ssb/main.c
++++ b/drivers/ssb/main.c
+@@ -3,7 +3,7 @@
+  * Subsystem core
+  *
+  * Copyright 2005, Broadcom Corporation
+- * Copyright 2006, 2007, Michael Buesch <mb@bu3sch.de>
++ * Copyright 2006, 2007, Michael Buesch <m@bues.ch>
+  *
+  * Licensed under the GNU/GPL. See COPYING for details.
+  */
+@@ -12,11 +12,14 @@
+ 
+ #include <linux/delay.h>
+ #include <linux/io.h>
++#include <linux/module.h>
+ #include <linux/ssb/ssb.h>
+ #include <linux/ssb/ssb_regs.h>
+ #include <linux/ssb/ssb_driver_gige.h>
+ #include <linux/dma-mapping.h>
+ #include <linux/pci.h>
++#include <linux/mmc/sdio_func.h>
++#include <linux/slab.h>
+ 
+ #include <pcmcia/cs_types.h>
+ #include <pcmcia/cs.h>
+@@ -88,6 +91,25 @@ found:
+ }
+ #endif /* CONFIG_SSB_PCMCIAHOST */
+ 
++#ifdef CONFIG_SSB_SDIOHOST
++struct ssb_bus *ssb_sdio_func_to_bus(struct sdio_func *func)
++{
++	struct ssb_bus *bus;
++
++	ssb_buses_lock();
++	list_for_each_entry(bus, &buses, list) {
++		if (bus->bustype == SSB_BUSTYPE_SDIO &&
++		    bus->host_sdio == func)
++			goto found;
++	}
++	bus = NULL;
++found:
++	ssb_buses_unlock();
++
++	return bus;
++}
++#endif /* CONFIG_SSB_SDIOHOST */
++
+ int ssb_for_each_bus_call(unsigned long data,
+ 			  int (*func)(struct ssb_bus *bus, unsigned long data))
+ {
+@@ -190,90 +212,78 @@ int ssb_bus_suspend(struct ssb_bus *bus)
+ EXPORT_SYMBOL(ssb_bus_suspend);
+ 
+ #ifdef CONFIG_SSB_SPROM
+-int ssb_devices_freeze(struct ssb_bus *bus)
++/** ssb_devices_freeze - Freeze all devices on the bus.
++ *
++ * After freezing no device driver will be handling a device
++ * on this bus anymore. ssb_devices_thaw() must be called after
++ * a successful freeze to reactivate the devices.
++ *
++ * @bus: The bus.
++ * @ctx: Context structure. Pass this to ssb_devices_thaw().
++ */
++int ssb_devices_freeze(struct ssb_bus *bus, struct ssb_freeze_context *ctx)
+ {
+-	struct ssb_device *dev;
+-	struct ssb_driver *drv;
+-	int err = 0;
+-	int i;
+-	pm_message_t state = PMSG_FREEZE;
++	struct ssb_device *sdev;
++	struct ssb_driver *sdrv;
++	unsigned int i;
++
++	memset(ctx, 0, sizeof(*ctx));
++	ctx->bus = bus;
++	SSB_WARN_ON(bus->nr_devices > ARRAY_SIZE(ctx->device_frozen));
+ 
+-	/* First check that we are capable to freeze all devices. */
+ 	for (i = 0; i < bus->nr_devices; i++) {
+-		dev = &(bus->devices[i]);
+-		if (!dev->dev ||
+-		    !dev->dev->driver ||
+-		    !device_is_registered(dev->dev))
+-			continue;
+-		drv = drv_to_ssb_drv(dev->dev->driver);
+-		if (!drv)
++		sdev = ssb_device_get(&bus->devices[i]);
++
++		if (!sdev->dev || !sdev->dev->driver ||
++		    !device_is_registered(sdev->dev)) {
++			ssb_device_put(sdev);
+ 			continue;
+-		if (!drv->suspend) {
+-			/* Nope, can't suspend this one. */
+-			return -EOPNOTSUPP;
+ 		}
+-	}
+-	/* Now suspend all devices */
+-	for (i = 0; i < bus->nr_devices; i++) {
+-		dev = &(bus->devices[i]);
+-		if (!dev->dev ||
+-		    !dev->dev->driver ||
+-		    !device_is_registered(dev->dev))
+-			continue;
+-		drv = drv_to_ssb_drv(dev->dev->driver);
+-		if (!drv)
++		sdrv = drv_to_ssb_drv(sdev->dev->driver);
++		if (SSB_WARN_ON(!sdrv->remove))
+ 			continue;
+-		err = drv->suspend(dev, state);
+-		if (err) {
+-			ssb_printk(KERN_ERR PFX "Failed to freeze device %s\n",
+-				   dev_name(dev->dev));
+-			goto err_unwind;
+-		}
++		sdrv->remove(sdev);
++		ctx->device_frozen[i] = 1;
+ 	}
+ 
+ 	return 0;
+-err_unwind:
+-	for (i--; i >= 0; i--) {
+-		dev = &(bus->devices[i]);
+-		if (!dev->dev ||
+-		    !dev->dev->driver ||
+-		    !device_is_registered(dev->dev))
+-			continue;
+-		drv = drv_to_ssb_drv(dev->dev->driver);
+-		if (!drv)
+-			continue;
+-		if (drv->resume)
+-			drv->resume(dev);
+-	}
+-	return err;
+ }
+ 
+-int ssb_devices_thaw(struct ssb_bus *bus)
++/** ssb_devices_thaw - Unfreeze all devices on the bus.
++ *
++ * This will re-attach the device drivers and re-init the devices.
++ *
++ * @ctx: The context structure from ssb_devices_freeze()
++ */
++int ssb_devices_thaw(struct ssb_freeze_context *ctx)
+ {
+-	struct ssb_device *dev;
+-	struct ssb_driver *drv;
+-	int err;
+-	int i;
++	struct ssb_bus *bus = ctx->bus;
++	struct ssb_device *sdev;
++	struct ssb_driver *sdrv;
++	unsigned int i;
++	int err, result = 0;
+ 
+ 	for (i = 0; i < bus->nr_devices; i++) {
+-		dev = &(bus->devices[i]);
+-		if (!dev->dev ||
+-		    !dev->dev->driver ||
+-		    !device_is_registered(dev->dev))
++		if (!ctx->device_frozen[i])
+ 			continue;
+-		drv = drv_to_ssb_drv(dev->dev->driver);
+-		if (!drv)
++		sdev = &bus->devices[i];
++
++		if (SSB_WARN_ON(!sdev->dev || !sdev->dev->driver))
+ 			continue;
+-		if (SSB_WARN_ON(!drv->resume))
++		sdrv = drv_to_ssb_drv(sdev->dev->driver);
++		if (SSB_WARN_ON(!sdrv || !sdrv->probe))
+ 			continue;
+-		err = drv->resume(dev);
++
++		err = sdrv->probe(sdev, &sdev->id);
+ 		if (err) {
+ 			ssb_printk(KERN_ERR PFX "Failed to thaw device %s\n",
+-				   dev_name(dev->dev));
++				   dev_name(sdev->dev));
++			result = err;
+ 		}
++		ssb_device_put(sdev);
+ 	}
+ 
+-	return 0;
++	return result;
+ }
+ #endif /* CONFIG_SSB_SPROM */
+ 
+@@ -360,6 +370,35 @@ static int ssb_device_uevent(struct devi
+ 			     ssb_dev->id.revision);
+ }
+ 
++#define ssb_config_attr(attrib, field, format_string) \
++static ssize_t \
++attrib##_show(struct device *dev, struct device_attribute *attr, char *buf) \
++{ \
++	return sprintf(buf, format_string, dev_to_ssb_dev(dev)->field); \
++}
++
++ssb_config_attr(core_num, core_index, "%u\n")
++ssb_config_attr(coreid, id.coreid, "0x%04x\n")
++ssb_config_attr(vendor, id.vendor, "0x%04x\n")
++ssb_config_attr(revision, id.revision, "%u\n")
++ssb_config_attr(irq, irq, "%u\n")
++static ssize_t
++name_show(struct device *dev, struct device_attribute *attr, char *buf)
++{
++	return sprintf(buf, "%s\n",
++		       ssb_core_name(dev_to_ssb_dev(dev)->id.coreid));
++}
++
++static struct device_attribute ssb_device_attrs[] = {
++	__ATTR_RO(name),
++	__ATTR_RO(core_num),
++	__ATTR_RO(coreid),
++	__ATTR_RO(vendor),
++	__ATTR_RO(revision),
++	__ATTR_RO(irq),
++	__ATTR_NULL,
++};
++
+ static struct bus_type ssb_bustype = {
+ 	.name		= "ssb",
+ 	.match		= ssb_bus_match,
+@@ -369,6 +408,7 @@ static struct bus_type ssb_bustype = {
+ 	.suspend	= ssb_device_suspend,
+ 	.resume		= ssb_device_resume,
+ 	.uevent		= ssb_device_uevent,
++	.dev_attrs	= ssb_device_attrs,
+ };
+ 
+ static void ssb_buses_lock(void)
+@@ -461,6 +501,7 @@ static int ssb_devices_register(struct s
+ #ifdef CONFIG_SSB_PCIHOST
+ 			sdev->irq = bus->host_pci->irq;
+ 			dev->parent = &bus->host_pci->dev;
++			sdev->dma_dev = dev->parent;
+ #endif
+ 			break;
+ 		case SSB_BUSTYPE_PCMCIA:
+@@ -469,8 +510,14 @@ static int ssb_devices_register(struct s
+ 			dev->parent = &bus->host_pcmcia->dev;
+ #endif
+ 			break;
++		case SSB_BUSTYPE_SDIO:
++#ifdef CONFIG_SSB_SDIOHOST
++			dev->parent = &bus->host_sdio->dev;
++#endif
++			break;
+ 		case SSB_BUSTYPE_SSB:
+ 			dev->dma_mask = &dev->coherent_dma_mask;
++			sdev->dma_dev = dev;
+ 			break;
+ 		}
+ 
+@@ -497,7 +544,7 @@ error:
+ }
+ 
+ /* Needs ssb_buses_lock() */
+-static int ssb_attach_queued_buses(void)
++static int __devinit ssb_attach_queued_buses(void)
+ {
+ 	struct ssb_bus *bus, *n;
+ 	int err = 0;
+@@ -708,9 +755,9 @@ out:
+ 	return err;
+ }
+ 
+-static int ssb_bus_register(struct ssb_bus *bus,
+-			    ssb_invariants_func_t get_invariants,
+-			    unsigned long baseaddr)
++static int __devinit ssb_bus_register(struct ssb_bus *bus,
++				      ssb_invariants_func_t get_invariants,
++				      unsigned long baseaddr)
+ {
+ 	int err;
+ 
+@@ -724,12 +771,18 @@ static int ssb_bus_register(struct ssb_b
+ 	err = ssb_pci_xtal(bus, SSB_GPIO_XTAL | SSB_GPIO_PLL, 1);
+ 	if (err)
+ 		goto out;
++
++	/* Init SDIO-host device (if any), before the scan */
++	err = ssb_sdio_init(bus);
++	if (err)
++		goto err_disable_xtal;
++
+ 	ssb_buses_lock();
+ 	bus->busnumber = next_busnumber;
+ 	/* Scan for devices (cores) */
+ 	err = ssb_bus_scan(bus, baseaddr);
+ 	if (err)
+-		goto err_disable_xtal;
++		goto err_sdio_exit;
+ 
+ 	/* Init PCI-host device (if any) */
+ 	err = ssb_pci_init(bus);
+@@ -776,6 +829,8 @@ err_pci_exit:
+ 	ssb_pci_exit(bus);
+ err_unmap:
+ 	ssb_iounmap(bus);
++err_sdio_exit:
++	ssb_sdio_exit(bus);
+ err_disable_xtal:
+ 	ssb_buses_unlock();
+ 	ssb_pci_xtal(bus, SSB_GPIO_XTAL | SSB_GPIO_PLL, 0);
+@@ -783,8 +838,8 @@ err_disable_xtal:
+ }
+ 
+ #ifdef CONFIG_SSB_PCIHOST
+-int ssb_bus_pcibus_register(struct ssb_bus *bus,
+-			    struct pci_dev *host_pci)
++int __devinit ssb_bus_pcibus_register(struct ssb_bus *bus,
++				      struct pci_dev *host_pci)
+ {
+ 	int err;
+ 
+@@ -796,6 +851,9 @@ int ssb_bus_pcibus_register(struct ssb_b
+ 	if (!err) {
+ 		ssb_printk(KERN_INFO PFX "Sonics Silicon Backplane found on "
+ 			   "PCI device %s\n", dev_name(&host_pci->dev));
++	} else {
++		ssb_printk(KERN_ERR PFX "Failed to register PCI version"
++			   " of SSB with error %d\n", err);
+ 	}
+ 
+ 	return err;
+@@ -804,9 +862,9 @@ EXPORT_SYMBOL(ssb_bus_pcibus_register);
+ #endif /* CONFIG_SSB_PCIHOST */
+ 
+ #ifdef CONFIG_SSB_PCMCIAHOST
+-int ssb_bus_pcmciabus_register(struct ssb_bus *bus,
+-			       struct pcmcia_device *pcmcia_dev,
+-			       unsigned long baseaddr)
++int __devinit ssb_bus_pcmciabus_register(struct ssb_bus *bus,
++					 struct pcmcia_device *pcmcia_dev,
++					 unsigned long baseaddr)
+ {
+ 	int err;
+ 
+@@ -825,9 +883,32 @@ int ssb_bus_pcmciabus_register(struct ss
+ EXPORT_SYMBOL(ssb_bus_pcmciabus_register);
+ #endif /* CONFIG_SSB_PCMCIAHOST */
+ 
+-int ssb_bus_ssbbus_register(struct ssb_bus *bus,
+-			    unsigned long baseaddr,
+-			    ssb_invariants_func_t get_invariants)
++#ifdef CONFIG_SSB_SDIOHOST
++int __devinit ssb_bus_sdiobus_register(struct ssb_bus *bus,
++				       struct sdio_func *func,
++				       unsigned int quirks)
++{
++	int err;
++
++	bus->bustype = SSB_BUSTYPE_SDIO;
++	bus->host_sdio = func;
++	bus->ops = &ssb_sdio_ops;
++	bus->quirks = quirks;
++
++	err = ssb_bus_register(bus, ssb_sdio_get_invariants, ~0);
++	if (!err) {
++		ssb_printk(KERN_INFO PFX "Sonics Silicon Backplane found on "
++			   "SDIO device %s\n", sdio_func_id(func));
++	}
++
++	return err;
++}
++EXPORT_SYMBOL(ssb_bus_sdiobus_register);
++#endif /* CONFIG_SSB_PCMCIAHOST */
++
++int __devinit ssb_bus_ssbbus_register(struct ssb_bus *bus,
++				      unsigned long baseaddr,
++				      ssb_invariants_func_t get_invariants)
+ {
+ 	int err;
+ 
+@@ -908,8 +989,8 @@ u32 ssb_calc_clock_rate(u32 plltype, u32
+ 	switch (plltype) {
+ 	case SSB_PLLTYPE_6: /* 100/200 or 120/240 only */
+ 		if (m & SSB_CHIPCO_CLK_T6_MMASK)
+-			return SSB_CHIPCO_CLK_T6_M0;
+-		return SSB_CHIPCO_CLK_T6_M1;
++			return SSB_CHIPCO_CLK_T6_M1;
++		return SSB_CHIPCO_CLK_T6_M0;
+ 	case SSB_PLLTYPE_1: /* 48Mhz base, 3 dividers */
+ 	case SSB_PLLTYPE_3: /* 25Mhz, 2 dividers */
+ 	case SSB_PLLTYPE_4: /* 48Mhz, 4 dividers */
+@@ -999,6 +1080,9 @@ u32 ssb_clockspeed(struct ssb_bus *bus)
+ 	u32 plltype;
+ 	u32 clkctl_n, clkctl_m;
+ 
++	if (bus->chipco.capabilities & SSB_CHIPCO_CAP_PMU)
++		return ssb_pmu_get_controlclock(&bus->chipco);
++
+ 	if (ssb_extif_available(&bus->extif))
+ 		ssb_extif_get_clockcontrol(&bus->extif, &plltype,
+ 					   &clkctl_n, &clkctl_m);
+@@ -1024,23 +1108,22 @@ static u32 ssb_tmslow_reject_bitmask(str
+ {
+ 	u32 rev = ssb_read32(dev, SSB_IDLOW) & SSB_IDLOW_SSBREV;
+ 
+-	/* The REJECT bit changed position in TMSLOW between
+-	 * Backplane revisions. */
++	/* The REJECT bit seems to be different for Backplane rev 2.3 */
+ 	switch (rev) {
+ 	case SSB_IDLOW_SSBREV_22:
+-		return SSB_TMSLOW_REJECT_22;
++	case SSB_IDLOW_SSBREV_24:
++	case SSB_IDLOW_SSBREV_26:
++		return SSB_TMSLOW_REJECT;
+ 	case SSB_IDLOW_SSBREV_23:
+ 		return SSB_TMSLOW_REJECT_23;
+-	case SSB_IDLOW_SSBREV_24:     /* TODO - find the proper REJECT bits */
+-	case SSB_IDLOW_SSBREV_25:     /* same here */
+-	case SSB_IDLOW_SSBREV_26:     /* same here */
++	case SSB_IDLOW_SSBREV_25:     /* TODO - find the proper REJECT bit */
+ 	case SSB_IDLOW_SSBREV_27:     /* same here */
+-		return SSB_TMSLOW_REJECT_23;	/* this is a guess */
++		return SSB_TMSLOW_REJECT;	/* this is a guess */
+ 	default:
+ 		printk(KERN_INFO "ssb: Backplane Revision 0x%.8X\n", rev);
+ 		WARN_ON(1);
+ 	}
+-	return (SSB_TMSLOW_REJECT_22 | SSB_TMSLOW_REJECT_23);
++	return (SSB_TMSLOW_REJECT | SSB_TMSLOW_REJECT_23);
+ }
+ 
+ int ssb_device_is_enabled(struct ssb_device *dev)
+@@ -1099,10 +1182,10 @@ void ssb_device_enable(struct ssb_device
+ }
+ EXPORT_SYMBOL(ssb_device_enable);
+ 
+-/* Wait for a bit in a register to get set or unset.
++/* Wait for bitmask in a register to get set or cleared.
+  * timeout is in units of ten-microseconds */
+-static int ssb_wait_bit(struct ssb_device *dev, u16 reg, u32 bitmask,
+-			int timeout, int set)
++static int ssb_wait_bits(struct ssb_device *dev, u16 reg, u32 bitmask,
++			 int timeout, int set)
+ {
+ 	int i;
+ 	u32 val;
+@@ -1110,7 +1193,7 @@ static int ssb_wait_bit(struct ssb_devic
+ 	for (i = 0; i < timeout; i++) {
+ 		val = ssb_read32(dev, reg);
+ 		if (set) {
+-			if (val & bitmask)
++			if ((val & bitmask) == bitmask)
+ 				return 0;
+ 		} else {
+ 			if (!(val & bitmask))
+@@ -1127,20 +1210,38 @@ static int ssb_wait_bit(struct ssb_devic
+ 
+ void ssb_device_disable(struct ssb_device *dev, u32 core_specific_flags)
+ {
+-	u32 reject;
++	u32 reject, val;
+ 
+ 	if (ssb_read32(dev, SSB_TMSLOW) & SSB_TMSLOW_RESET)
+ 		return;
+ 
+ 	reject = ssb_tmslow_reject_bitmask(dev);
+-	ssb_write32(dev, SSB_TMSLOW, reject | SSB_TMSLOW_CLOCK);
+-	ssb_wait_bit(dev, SSB_TMSLOW, reject, 1000, 1);
+-	ssb_wait_bit(dev, SSB_TMSHIGH, SSB_TMSHIGH_BUSY, 1000, 0);
+-	ssb_write32(dev, SSB_TMSLOW,
+-		    SSB_TMSLOW_FGC | SSB_TMSLOW_CLOCK |
+-		    reject | SSB_TMSLOW_RESET |
+-		    core_specific_flags);
+-	ssb_flush_tmslow(dev);
++
++	if (ssb_read32(dev, SSB_TMSLOW) & SSB_TMSLOW_CLOCK) {
++		ssb_write32(dev, SSB_TMSLOW, reject | SSB_TMSLOW_CLOCK);
++		ssb_wait_bits(dev, SSB_TMSLOW, reject, 1000, 1);
++		ssb_wait_bits(dev, SSB_TMSHIGH, SSB_TMSHIGH_BUSY, 1000, 0);
++
++		if (ssb_read32(dev, SSB_IDLOW) & SSB_IDLOW_INITIATOR) {
++			val = ssb_read32(dev, SSB_IMSTATE);
++			val |= SSB_IMSTATE_REJECT;
++			ssb_write32(dev, SSB_IMSTATE, val);
++			ssb_wait_bits(dev, SSB_IMSTATE, SSB_IMSTATE_BUSY, 1000,
++				      0);
++		}
++
++		ssb_write32(dev, SSB_TMSLOW,
++			SSB_TMSLOW_FGC | SSB_TMSLOW_CLOCK |
++			reject | SSB_TMSLOW_RESET |
++			core_specific_flags);
++		ssb_flush_tmslow(dev);
++
++		if (ssb_read32(dev, SSB_IDLOW) & SSB_IDLOW_INITIATOR) {
++			val = ssb_read32(dev, SSB_IMSTATE);
++			val &= ~SSB_IMSTATE_REJECT;
++			ssb_write32(dev, SSB_IMSTATE, val);
++		}
++	}
+ 
+ 	ssb_write32(dev, SSB_TMSLOW,
+ 		    reject | SSB_TMSLOW_RESET |
+@@ -1149,13 +1250,34 @@ void ssb_device_disable(struct ssb_devic
+ }
+ EXPORT_SYMBOL(ssb_device_disable);
+ 
++/* Some chipsets need routing known for PCIe and 64-bit DMA */
++static bool ssb_dma_translation_special_bit(struct ssb_device *dev)
++{
++	u16 chip_id = dev->bus->chip_id;
++
++	if (dev->id.coreid == SSB_DEV_80211) {
++		return (chip_id == 0x4322 || chip_id == 43221 ||
++			chip_id == 43231 || chip_id == 43222);
++	}
++
++	return 0;
++}
++
+ u32 ssb_dma_translation(struct ssb_device *dev)
+ {
+ 	switch (dev->bus->bustype) {
+ 	case SSB_BUSTYPE_SSB:
+ 		return 0;
+ 	case SSB_BUSTYPE_PCI:
+-		return SSB_PCI_DMA;
++		if (dev->bus->host_pci->is_pcie &&
++		    ssb_read32(dev, SSB_TMSHIGH) & SSB_TMSHIGH_DMA64) {
++			return SSB_PCIE_DMA_H32;
++		} else {
++			if (ssb_dma_translation_special_bit(dev))
++				return SSB_PCIE_DMA_H32;
++			else
++				return SSB_PCI_DMA;
++		}
+ 	default:
+ 		__ssb_dma_not_implemented(dev);
+ 	}
+@@ -1272,20 +1394,20 @@ EXPORT_SYMBOL(ssb_bus_may_powerdown);
+ 
+ int ssb_bus_powerup(struct ssb_bus *bus, bool dynamic_pctl)
+ {
+-	struct ssb_chipcommon *cc;
+ 	int err;
+ 	enum ssb_clkmode mode;
+ 
+ 	err = ssb_pci_xtal(bus, SSB_GPIO_XTAL | SSB_GPIO_PLL, 1);
+ 	if (err)
+ 		goto error;
+-	cc = &bus->chipco;
+-	mode = dynamic_pctl ? SSB_CLKMODE_DYNAMIC : SSB_CLKMODE_FAST;
+-	ssb_chipco_set_clockmode(cc, mode);
+ 
+ #ifdef CONFIG_SSB_DEBUG
+ 	bus->powered_up = 1;
+ #endif
++
++	mode = dynamic_pctl ? SSB_CLKMODE_DYNAMIC : SSB_CLKMODE_FAST;
++	ssb_chipco_set_clockmode(&bus->chipco, mode);
++
+ 	return 0;
+ error:
+ 	ssb_printk(KERN_ERR PFX "Bus powerup failed\n");
+@@ -1293,6 +1415,37 @@ error:
+ }
+ EXPORT_SYMBOL(ssb_bus_powerup);
+ 
++static void ssb_broadcast_value(struct ssb_device *dev,
++				u32 address, u32 data)
++{
++#ifdef CONFIG_SSB_DRIVER_PCICORE
++	/* This is used for both, PCI and ChipCommon core, so be careful. */
++	BUILD_BUG_ON(SSB_PCICORE_BCAST_ADDR != SSB_CHIPCO_BCAST_ADDR);
++	BUILD_BUG_ON(SSB_PCICORE_BCAST_DATA != SSB_CHIPCO_BCAST_DATA);
++#endif
++
++	ssb_write32(dev, SSB_CHIPCO_BCAST_ADDR, address);
++	ssb_read32(dev, SSB_CHIPCO_BCAST_ADDR); /* flush */
++	ssb_write32(dev, SSB_CHIPCO_BCAST_DATA, data);
++	ssb_read32(dev, SSB_CHIPCO_BCAST_DATA); /* flush */
++}
++
++void ssb_commit_settings(struct ssb_bus *bus)
++{
++	struct ssb_device *dev;
++
++#ifdef CONFIG_SSB_DRIVER_PCICORE
++	dev = bus->chipco.dev ? bus->chipco.dev : bus->pcicore.dev;
++#else
++	dev = bus->chipco.dev;
++#endif
++	if (WARN_ON(!dev))
++		return;
++	/* This forces an update of the cached registers. */
++	ssb_broadcast_value(dev, 0xFD8, 0);
++}
++EXPORT_SYMBOL(ssb_commit_settings);
++
+ u32 ssb_admatch_base(u32 adm)
+ {
+ 	u32 base = 0;
+@@ -1358,8 +1511,10 @@ static int __init ssb_modinit(void)
+ 	ssb_buses_lock();
+ 	err = ssb_attach_queued_buses();
+ 	ssb_buses_unlock();
+-	if (err)
++	if (err) {
+ 		bus_unregister(&ssb_bustype);
++		goto out;
++	}
+ 
+ 	err = b43_pci_ssb_bridge_init();
+ 	if (err) {
+@@ -1375,7 +1530,7 @@ static int __init ssb_modinit(void)
+ 		/* don't fail SSB init because of this */
+ 		err = 0;
+ 	}
+-
++out:
+ 	return err;
+ }
+ /* ssb must be initialized after PCI but before the ssb drivers.
+--- a/drivers/ssb/pci.c
++++ b/drivers/ssb/pci.c
+@@ -1,7 +1,7 @@
+ /*
+  * Sonics Silicon Backplane PCI-Hostbus related functions.
+  *
+- * Copyright (C) 2005-2006 Michael Buesch <mb@bu3sch.de>
++ * Copyright (C) 2005-2006 Michael Buesch <m@bues.ch>
+  * Copyright (C) 2005 Martin Langer <martin-langer@gmx.de>
+  * Copyright (C) 2005 Stefano Brivio <st3@riseup.net>
+  * Copyright (C) 2005 Danny van Dyk <kugelfang@gentoo.org>
+@@ -17,6 +17,7 @@
+ 
+ #include <linux/ssb/ssb.h>
+ #include <linux/ssb/ssb_regs.h>
++#include <linux/slab.h>
+ #include <linux/pci.h>
+ #include <linux/delay.h>
+ 
+@@ -167,10 +168,16 @@ err_pci:
+ }
+ 
+ /* Get the word-offset for a SSB_SPROM_XXX define. */
+-#define SPOFF(offset)	(((offset) - SSB_SPROM_BASE) / sizeof(u16))
++#define SPOFF(offset)	((offset) / sizeof(u16))
+ /* Helper to extract some _offset, which is one of the SSB_SPROM_XXX defines. */
+-#define SPEX(_outvar, _offset, _mask, _shift)	\
++#define SPEX16(_outvar, _offset, _mask, _shift)	\
+ 	out->_outvar = ((in[SPOFF(_offset)] & (_mask)) >> (_shift))
++#define SPEX32(_outvar, _offset, _mask, _shift)	\
++	out->_outvar = ((((u32)in[SPOFF((_offset)+2)] << 16 | \
++			   in[SPOFF(_offset)]) & (_mask)) >> (_shift))
++#define SPEX(_outvar, _offset, _mask, _shift) \
++	SPEX16(_outvar, _offset, _mask, _shift)
++
+ 
+ static inline u8 ssb_crc8(u8 crc, u8 data)
+ {
+@@ -247,7 +254,7 @@ static int sprom_do_read(struct ssb_bus
+ 	int i;
+ 
+ 	for (i = 0; i < bus->sprom_size; i++)
+-		sprom[i] = ioread16(bus->mmio + SSB_SPROM_BASE + (i * 2));
++		sprom[i] = ioread16(bus->mmio + bus->sprom_offset + (i * 2));
+ 
+ 	return 0;
+ }
+@@ -278,7 +285,7 @@ static int sprom_do_write(struct ssb_bus
+ 			ssb_printk("75%%");
+ 		else if (i % 2)
+ 			ssb_printk(".");
+-		writew(sprom[i], bus->mmio + SSB_SPROM_BASE + (i * 2));
++		writew(sprom[i], bus->mmio + bus->sprom_offset + (i * 2));
+ 		mmiowb();
+ 		msleep(20);
+ 	}
+@@ -324,7 +331,6 @@ static void sprom_extract_r123(struct ss
+ {
+ 	int i;
+ 	u16 v;
+-	s8 gain;
+ 	u16 loc[3];
+ 
+ 	if (out->revision == 3)			/* rev 3 moved MAC */
+@@ -383,20 +389,52 @@ static void sprom_extract_r123(struct ss
+ 		SPEX(boardflags_hi, SSB_SPROM2_BFLHI, 0xFFFF, 0);
+ 
+ 	/* Extract the antenna gain values. */
+-	gain = r123_extract_antgain(out->revision, in,
+-				    SSB_SPROM1_AGAIN_BG,
+-				    SSB_SPROM1_AGAIN_BG_SHIFT);
+-	out->antenna_gain.ghz24.a0 = gain;
+-	out->antenna_gain.ghz24.a1 = gain;
+-	out->antenna_gain.ghz24.a2 = gain;
+-	out->antenna_gain.ghz24.a3 = gain;
+-	gain = r123_extract_antgain(out->revision, in,
+-				    SSB_SPROM1_AGAIN_A,
+-				    SSB_SPROM1_AGAIN_A_SHIFT);
+-	out->antenna_gain.ghz5.a0 = gain;
+-	out->antenna_gain.ghz5.a1 = gain;
+-	out->antenna_gain.ghz5.a2 = gain;
+-	out->antenna_gain.ghz5.a3 = gain;
++	out->antenna_gain.a0 = r123_extract_antgain(out->revision, in,
++						    SSB_SPROM1_AGAIN_BG,
++						    SSB_SPROM1_AGAIN_BG_SHIFT);
++	out->antenna_gain.a1 = r123_extract_antgain(out->revision, in,
++						    SSB_SPROM1_AGAIN_A,
++						    SSB_SPROM1_AGAIN_A_SHIFT);
++}
++
++/* Revs 4 5 and 8 have partially shared layout */
++static void sprom_extract_r458(struct ssb_sprom *out, const u16 *in)
++{
++	SPEX(txpid2g[0], SSB_SPROM4_TXPID2G01,
++	     SSB_SPROM4_TXPID2G0, SSB_SPROM4_TXPID2G0_SHIFT);
++	SPEX(txpid2g[1], SSB_SPROM4_TXPID2G01,
++	     SSB_SPROM4_TXPID2G1, SSB_SPROM4_TXPID2G1_SHIFT);
++	SPEX(txpid2g[2], SSB_SPROM4_TXPID2G23,
++	     SSB_SPROM4_TXPID2G2, SSB_SPROM4_TXPID2G2_SHIFT);
++	SPEX(txpid2g[3], SSB_SPROM4_TXPID2G23,
++	     SSB_SPROM4_TXPID2G3, SSB_SPROM4_TXPID2G3_SHIFT);
++
++	SPEX(txpid5gl[0], SSB_SPROM4_TXPID5GL01,
++	     SSB_SPROM4_TXPID5GL0, SSB_SPROM4_TXPID5GL0_SHIFT);
++	SPEX(txpid5gl[1], SSB_SPROM4_TXPID5GL01,
++	     SSB_SPROM4_TXPID5GL1, SSB_SPROM4_TXPID5GL1_SHIFT);
++	SPEX(txpid5gl[2], SSB_SPROM4_TXPID5GL23,
++	     SSB_SPROM4_TXPID5GL2, SSB_SPROM4_TXPID5GL2_SHIFT);
++	SPEX(txpid5gl[3], SSB_SPROM4_TXPID5GL23,
++	     SSB_SPROM4_TXPID5GL3, SSB_SPROM4_TXPID5GL3_SHIFT);
++
++	SPEX(txpid5g[0], SSB_SPROM4_TXPID5G01,
++	     SSB_SPROM4_TXPID5G0, SSB_SPROM4_TXPID5G0_SHIFT);
++	SPEX(txpid5g[1], SSB_SPROM4_TXPID5G01,
++	     SSB_SPROM4_TXPID5G1, SSB_SPROM4_TXPID5G1_SHIFT);
++	SPEX(txpid5g[2], SSB_SPROM4_TXPID5G23,
++	     SSB_SPROM4_TXPID5G2, SSB_SPROM4_TXPID5G2_SHIFT);
++	SPEX(txpid5g[3], SSB_SPROM4_TXPID5G23,
++	     SSB_SPROM4_TXPID5G3, SSB_SPROM4_TXPID5G3_SHIFT);
++
++	SPEX(txpid5gh[0], SSB_SPROM4_TXPID5GH01,
++	     SSB_SPROM4_TXPID5GH0, SSB_SPROM4_TXPID5GH0_SHIFT);
++	SPEX(txpid5gh[1], SSB_SPROM4_TXPID5GH01,
++	     SSB_SPROM4_TXPID5GH1, SSB_SPROM4_TXPID5GH1_SHIFT);
++	SPEX(txpid5gh[2], SSB_SPROM4_TXPID5GH23,
++	     SSB_SPROM4_TXPID5GH2, SSB_SPROM4_TXPID5GH2_SHIFT);
++	SPEX(txpid5gh[3], SSB_SPROM4_TXPID5GH23,
++	     SSB_SPROM4_TXPID5GH3, SSB_SPROM4_TXPID5GH3_SHIFT);
+ }
+ 
+ static void sprom_extract_r45(struct ssb_sprom *out, const u16 *in)
+@@ -421,10 +459,14 @@ static void sprom_extract_r45(struct ssb
+ 		SPEX(country_code, SSB_SPROM4_CCODE, 0xFFFF, 0);
+ 		SPEX(boardflags_lo, SSB_SPROM4_BFLLO, 0xFFFF, 0);
+ 		SPEX(boardflags_hi, SSB_SPROM4_BFLHI, 0xFFFF, 0);
++		SPEX(boardflags2_lo, SSB_SPROM4_BFL2LO, 0xFFFF, 0);
++		SPEX(boardflags2_hi, SSB_SPROM4_BFL2HI, 0xFFFF, 0);
+ 	} else {
+ 		SPEX(country_code, SSB_SPROM5_CCODE, 0xFFFF, 0);
+ 		SPEX(boardflags_lo, SSB_SPROM5_BFLLO, 0xFFFF, 0);
+ 		SPEX(boardflags_hi, SSB_SPROM5_BFLHI, 0xFFFF, 0);
++		SPEX(boardflags2_lo, SSB_SPROM5_BFL2LO, 0xFFFF, 0);
++		SPEX(boardflags2_hi, SSB_SPROM5_BFL2HI, 0xFFFF, 0);
+ 	}
+ 	SPEX(ant_available_a, SSB_SPROM4_ANTAVAIL, SSB_SPROM4_ANTAVAIL_A,
+ 	     SSB_SPROM4_ANTAVAIL_A_SHIFT);
+@@ -453,16 +495,16 @@ static void sprom_extract_r45(struct ssb
+ 	}
+ 
+ 	/* Extract the antenna gain values. */
+-	SPEX(antenna_gain.ghz24.a0, SSB_SPROM4_AGAIN01,
++	SPEX(antenna_gain.a0, SSB_SPROM4_AGAIN01,
+ 	     SSB_SPROM4_AGAIN0, SSB_SPROM4_AGAIN0_SHIFT);
+-	SPEX(antenna_gain.ghz24.a1, SSB_SPROM4_AGAIN01,
++	SPEX(antenna_gain.a1, SSB_SPROM4_AGAIN01,
+ 	     SSB_SPROM4_AGAIN1, SSB_SPROM4_AGAIN1_SHIFT);
+-	SPEX(antenna_gain.ghz24.a2, SSB_SPROM4_AGAIN23,
++	SPEX(antenna_gain.a2, SSB_SPROM4_AGAIN23,
+ 	     SSB_SPROM4_AGAIN2, SSB_SPROM4_AGAIN2_SHIFT);
+-	SPEX(antenna_gain.ghz24.a3, SSB_SPROM4_AGAIN23,
++	SPEX(antenna_gain.a3, SSB_SPROM4_AGAIN23,
+ 	     SSB_SPROM4_AGAIN3, SSB_SPROM4_AGAIN3_SHIFT);
+-	memcpy(&out->antenna_gain.ghz5, &out->antenna_gain.ghz24,
+-	       sizeof(out->antenna_gain.ghz5));
++
++	sprom_extract_r458(out, in);
+ 
+ 	/* TODO - get remaining rev 4 stuff needed */
+ }
+@@ -470,16 +512,24 @@ static void sprom_extract_r45(struct ssb
+ static void sprom_extract_r8(struct ssb_sprom *out, const u16 *in)
+ {
+ 	int i;
+-	u16 v;
++	u16 v, o;
++	u16 pwr_info_offset[] = {
++		SSB_SROM8_PWR_INFO_CORE0, SSB_SROM8_PWR_INFO_CORE1,
++		SSB_SROM8_PWR_INFO_CORE2, SSB_SROM8_PWR_INFO_CORE3
++	};
++	BUILD_BUG_ON(ARRAY_SIZE(pwr_info_offset) !=
++			ARRAY_SIZE(out->core_pwr_info));
+ 
+ 	/* extract the MAC address */
+ 	for (i = 0; i < 3; i++) {
+-		v = in[SPOFF(SSB_SPROM1_IL0MAC) + i];
++		v = in[SPOFF(SSB_SPROM8_IL0MAC) + i];
+ 		*(((__be16 *)out->il0mac) + i) = cpu_to_be16(v);
+ 	}
+ 	SPEX(country_code, SSB_SPROM8_CCODE, 0xFFFF, 0);
+ 	SPEX(boardflags_lo, SSB_SPROM8_BFLLO, 0xFFFF, 0);
+ 	SPEX(boardflags_hi, SSB_SPROM8_BFLHI, 0xFFFF, 0);
++	SPEX(boardflags2_lo, SSB_SPROM8_BFL2LO, 0xFFFF, 0);
++	SPEX(boardflags2_hi, SSB_SPROM8_BFL2HI, 0xFFFF, 0);
+ 	SPEX(ant_available_a, SSB_SPROM8_ANTAVAIL, SSB_SPROM8_ANTAVAIL_A,
+ 	     SSB_SPROM8_ANTAVAIL_A_SHIFT);
+ 	SPEX(ant_available_bg, SSB_SPROM8_ANTAVAIL, SSB_SPROM8_ANTAVAIL_BG,
+@@ -490,24 +540,122 @@ static void sprom_extract_r8(struct ssb_
+ 	SPEX(maxpwr_a, SSB_SPROM8_MAXP_A, SSB_SPROM8_MAXP_A_MASK, 0);
+ 	SPEX(itssi_a, SSB_SPROM8_MAXP_A, SSB_SPROM8_ITSSI_A,
+ 	     SSB_SPROM8_ITSSI_A_SHIFT);
++	SPEX(maxpwr_ah, SSB_SPROM8_MAXP_AHL, SSB_SPROM8_MAXP_AH_MASK, 0);
++	SPEX(maxpwr_al, SSB_SPROM8_MAXP_AHL, SSB_SPROM8_MAXP_AL_MASK,
++	     SSB_SPROM8_MAXP_AL_SHIFT);
+ 	SPEX(gpio0, SSB_SPROM8_GPIOA, SSB_SPROM8_GPIOA_P0, 0);
+ 	SPEX(gpio1, SSB_SPROM8_GPIOA, SSB_SPROM8_GPIOA_P1,
+ 	     SSB_SPROM8_GPIOA_P1_SHIFT);
+ 	SPEX(gpio2, SSB_SPROM8_GPIOB, SSB_SPROM8_GPIOB_P2, 0);
+ 	SPEX(gpio3, SSB_SPROM8_GPIOB, SSB_SPROM8_GPIOB_P3,
+ 	     SSB_SPROM8_GPIOB_P3_SHIFT);
++	SPEX(tri2g, SSB_SPROM8_TRI25G, SSB_SPROM8_TRI2G, 0);
++	SPEX(tri5g, SSB_SPROM8_TRI25G, SSB_SPROM8_TRI5G,
++	     SSB_SPROM8_TRI5G_SHIFT);
++	SPEX(tri5gl, SSB_SPROM8_TRI5GHL, SSB_SPROM8_TRI5GL, 0);
++	SPEX(tri5gh, SSB_SPROM8_TRI5GHL, SSB_SPROM8_TRI5GH,
++	     SSB_SPROM8_TRI5GH_SHIFT);
++	SPEX(rxpo2g, SSB_SPROM8_RXPO, SSB_SPROM8_RXPO2G, 0);
++	SPEX(rxpo5g, SSB_SPROM8_RXPO, SSB_SPROM8_RXPO5G,
++	     SSB_SPROM8_RXPO5G_SHIFT);
++	SPEX(rssismf2g, SSB_SPROM8_RSSIPARM2G, SSB_SPROM8_RSSISMF2G, 0);
++	SPEX(rssismc2g, SSB_SPROM8_RSSIPARM2G, SSB_SPROM8_RSSISMC2G,
++	     SSB_SPROM8_RSSISMC2G_SHIFT);
++	SPEX(rssisav2g, SSB_SPROM8_RSSIPARM2G, SSB_SPROM8_RSSISAV2G,
++	     SSB_SPROM8_RSSISAV2G_SHIFT);
++	SPEX(bxa2g, SSB_SPROM8_RSSIPARM2G, SSB_SPROM8_BXA2G,
++	     SSB_SPROM8_BXA2G_SHIFT);
++	SPEX(rssismf5g, SSB_SPROM8_RSSIPARM5G, SSB_SPROM8_RSSISMF5G, 0);
++	SPEX(rssismc5g, SSB_SPROM8_RSSIPARM5G, SSB_SPROM8_RSSISMC5G,
++	     SSB_SPROM8_RSSISMC5G_SHIFT);
++	SPEX(rssisav5g, SSB_SPROM8_RSSIPARM5G, SSB_SPROM8_RSSISAV5G,
++	     SSB_SPROM8_RSSISAV5G_SHIFT);
++	SPEX(bxa5g, SSB_SPROM8_RSSIPARM5G, SSB_SPROM8_BXA5G,
++	     SSB_SPROM8_BXA5G_SHIFT);
++	SPEX(pa0b0, SSB_SPROM8_PA0B0, 0xFFFF, 0);
++	SPEX(pa0b1, SSB_SPROM8_PA0B1, 0xFFFF, 0);
++	SPEX(pa0b2, SSB_SPROM8_PA0B2, 0xFFFF, 0);
++	SPEX(pa1b0, SSB_SPROM8_PA1B0, 0xFFFF, 0);
++	SPEX(pa1b1, SSB_SPROM8_PA1B1, 0xFFFF, 0);
++	SPEX(pa1b2, SSB_SPROM8_PA1B2, 0xFFFF, 0);
++	SPEX(pa1lob0, SSB_SPROM8_PA1LOB0, 0xFFFF, 0);
++	SPEX(pa1lob1, SSB_SPROM8_PA1LOB1, 0xFFFF, 0);
++	SPEX(pa1lob2, SSB_SPROM8_PA1LOB2, 0xFFFF, 0);
++	SPEX(pa1hib0, SSB_SPROM8_PA1HIB0, 0xFFFF, 0);
++	SPEX(pa1hib1, SSB_SPROM8_PA1HIB1, 0xFFFF, 0);
++	SPEX(pa1hib2, SSB_SPROM8_PA1HIB2, 0xFFFF, 0);
++	SPEX(cck2gpo, SSB_SPROM8_CCK2GPO, 0xFFFF, 0);
++	SPEX32(ofdm2gpo, SSB_SPROM8_OFDM2GPO, 0xFFFFFFFF, 0);
++	SPEX32(ofdm5glpo, SSB_SPROM8_OFDM5GLPO, 0xFFFFFFFF, 0);
++	SPEX32(ofdm5gpo, SSB_SPROM8_OFDM5GPO, 0xFFFFFFFF, 0);
++	SPEX32(ofdm5ghpo, SSB_SPROM8_OFDM5GHPO, 0xFFFFFFFF, 0);
+ 
+ 	/* Extract the antenna gain values. */
+-	SPEX(antenna_gain.ghz24.a0, SSB_SPROM8_AGAIN01,
++	SPEX(antenna_gain.a0, SSB_SPROM8_AGAIN01,
+ 	     SSB_SPROM8_AGAIN0, SSB_SPROM8_AGAIN0_SHIFT);
+-	SPEX(antenna_gain.ghz24.a1, SSB_SPROM8_AGAIN01,
++	SPEX(antenna_gain.a1, SSB_SPROM8_AGAIN01,
+ 	     SSB_SPROM8_AGAIN1, SSB_SPROM8_AGAIN1_SHIFT);
+-	SPEX(antenna_gain.ghz24.a2, SSB_SPROM8_AGAIN23,
++	SPEX(antenna_gain.a2, SSB_SPROM8_AGAIN23,
+ 	     SSB_SPROM8_AGAIN2, SSB_SPROM8_AGAIN2_SHIFT);
+-	SPEX(antenna_gain.ghz24.a3, SSB_SPROM8_AGAIN23,
++	SPEX(antenna_gain.a3, SSB_SPROM8_AGAIN23,
+ 	     SSB_SPROM8_AGAIN3, SSB_SPROM8_AGAIN3_SHIFT);
+-	memcpy(&out->antenna_gain.ghz5, &out->antenna_gain.ghz24,
+-	       sizeof(out->antenna_gain.ghz5));
++
++	/* Extract cores power info info */
++	for (i = 0; i < ARRAY_SIZE(pwr_info_offset); i++) {
++		o = pwr_info_offset[i];
++		SPEX(core_pwr_info[i].itssi_2g, o + SSB_SROM8_2G_MAXP_ITSSI,
++			SSB_SPROM8_2G_ITSSI, SSB_SPROM8_2G_ITSSI_SHIFT);
++		SPEX(core_pwr_info[i].maxpwr_2g, o + SSB_SROM8_2G_MAXP_ITSSI,
++			SSB_SPROM8_2G_MAXP, 0);
++
++		SPEX(core_pwr_info[i].pa_2g[0], o + SSB_SROM8_2G_PA_0, ~0, 0);
++		SPEX(core_pwr_info[i].pa_2g[1], o + SSB_SROM8_2G_PA_1, ~0, 0);
++		SPEX(core_pwr_info[i].pa_2g[2], o + SSB_SROM8_2G_PA_2, ~0, 0);
++
++		SPEX(core_pwr_info[i].itssi_5g, o + SSB_SROM8_5G_MAXP_ITSSI,
++			SSB_SPROM8_5G_ITSSI, SSB_SPROM8_5G_ITSSI_SHIFT);
++		SPEX(core_pwr_info[i].maxpwr_5g, o + SSB_SROM8_5G_MAXP_ITSSI,
++			SSB_SPROM8_5G_MAXP, 0);
++		SPEX(core_pwr_info[i].maxpwr_5gh, o + SSB_SPROM8_5GHL_MAXP,
++			SSB_SPROM8_5GH_MAXP, 0);
++		SPEX(core_pwr_info[i].maxpwr_5gl, o + SSB_SPROM8_5GHL_MAXP,
++			SSB_SPROM8_5GL_MAXP, SSB_SPROM8_5GL_MAXP_SHIFT);
++
++		SPEX(core_pwr_info[i].pa_5gl[0], o + SSB_SROM8_5GL_PA_0, ~0, 0);
++		SPEX(core_pwr_info[i].pa_5gl[1], o + SSB_SROM8_5GL_PA_1, ~0, 0);
++		SPEX(core_pwr_info[i].pa_5gl[2], o + SSB_SROM8_5GL_PA_2, ~0, 0);
++		SPEX(core_pwr_info[i].pa_5g[0], o + SSB_SROM8_5G_PA_0, ~0, 0);
++		SPEX(core_pwr_info[i].pa_5g[1], o + SSB_SROM8_5G_PA_1, ~0, 0);
++		SPEX(core_pwr_info[i].pa_5g[2], o + SSB_SROM8_5G_PA_2, ~0, 0);
++		SPEX(core_pwr_info[i].pa_5gh[0], o + SSB_SROM8_5GH_PA_0, ~0, 0);
++		SPEX(core_pwr_info[i].pa_5gh[1], o + SSB_SROM8_5GH_PA_1, ~0, 0);
++		SPEX(core_pwr_info[i].pa_5gh[2], o + SSB_SROM8_5GH_PA_2, ~0, 0);
++	}
++
++	/* Extract FEM info */
++	SPEX(fem.ghz2.tssipos, SSB_SPROM8_FEM2G,
++		SSB_SROM8_FEM_TSSIPOS, SSB_SROM8_FEM_TSSIPOS_SHIFT);
++	SPEX(fem.ghz2.extpa_gain, SSB_SPROM8_FEM2G,
++		SSB_SROM8_FEM_EXTPA_GAIN, SSB_SROM8_FEM_EXTPA_GAIN_SHIFT);
++	SPEX(fem.ghz2.pdet_range, SSB_SPROM8_FEM2G,
++		SSB_SROM8_FEM_PDET_RANGE, SSB_SROM8_FEM_PDET_RANGE_SHIFT);
++	SPEX(fem.ghz2.tr_iso, SSB_SPROM8_FEM2G,
++		SSB_SROM8_FEM_TR_ISO, SSB_SROM8_FEM_TR_ISO_SHIFT);
++	SPEX(fem.ghz2.antswlut, SSB_SPROM8_FEM2G,
++		SSB_SROM8_FEM_ANTSWLUT, SSB_SROM8_FEM_ANTSWLUT_SHIFT);
++
++	SPEX(fem.ghz5.tssipos, SSB_SPROM8_FEM5G,
++		SSB_SROM8_FEM_TSSIPOS, SSB_SROM8_FEM_TSSIPOS_SHIFT);
++	SPEX(fem.ghz5.extpa_gain, SSB_SPROM8_FEM5G,
++		SSB_SROM8_FEM_EXTPA_GAIN, SSB_SROM8_FEM_EXTPA_GAIN_SHIFT);
++	SPEX(fem.ghz5.pdet_range, SSB_SPROM8_FEM5G,
++		SSB_SROM8_FEM_PDET_RANGE, SSB_SROM8_FEM_PDET_RANGE_SHIFT);
++	SPEX(fem.ghz5.tr_iso, SSB_SPROM8_FEM5G,
++		SSB_SROM8_FEM_TR_ISO, SSB_SROM8_FEM_TR_ISO_SHIFT);
++	SPEX(fem.ghz5.antswlut, SSB_SPROM8_FEM5G,
++		SSB_SROM8_FEM_ANTSWLUT, SSB_SROM8_FEM_ANTSWLUT_SHIFT);
++
++	sprom_extract_r458(out, in);
+ 
+ 	/* TODO - get remaining rev 8 stuff needed */
+ }
+@@ -521,36 +669,34 @@ static int sprom_extract(struct ssb_bus
+ 	ssb_dprintk(KERN_DEBUG PFX "SPROM revision %d detected.\n", out->revision);
+ 	memset(out->et0mac, 0xFF, 6);		/* preset et0 and et1 mac */
+ 	memset(out->et1mac, 0xFF, 6);
++
+ 	if ((bus->chip_id & 0xFF00) == 0x4400) {
+ 		/* Workaround: The BCM44XX chip has a stupid revision
+ 		 * number stored in the SPROM.
+ 		 * Always extract r1. */
+ 		out->revision = 1;
++		ssb_dprintk(KERN_DEBUG PFX "SPROM treated as revision %d\n", out->revision);
++	}
++
++	switch (out->revision) {
++	case 1:
++	case 2:
++	case 3:
+ 		sprom_extract_r123(out, in);
+-	} else if (bus->chip_id == 0x4321) {
+-		/* the BCM4328 has a chipid == 0x4321 and a rev 4 SPROM */
+-		out->revision = 4;
++		break;
++	case 4:
++	case 5:
+ 		sprom_extract_r45(out, in);
+-	} else {
+-		switch (out->revision) {
+-		case 1:
+-		case 2:
+-		case 3:
+-			sprom_extract_r123(out, in);
+-			break;
+-		case 4:
+-		case 5:
+-			sprom_extract_r45(out, in);
+-			break;
+-		case 8:
+-			sprom_extract_r8(out, in);
+-			break;
+-		default:
+-			ssb_printk(KERN_WARNING PFX "Unsupported SPROM"
+-				   "  revision %d detected. Will extract"
+-				   " v1\n", out->revision);
+-			sprom_extract_r123(out, in);
+-		}
++		break;
++	case 8:
++		sprom_extract_r8(out, in);
++		break;
++	default:
++		ssb_printk(KERN_WARNING PFX "Unsupported SPROM"
++			   " revision %d detected. Will extract"
++			   " v1\n", out->revision);
++		out->revision = 1;
++		sprom_extract_r123(out, in);
+ 	}
+ 
+ 	if (out->boardflags_lo == 0xFFFF)
+@@ -564,13 +710,34 @@ static int sprom_extract(struct ssb_bus
+ static int ssb_pci_sprom_get(struct ssb_bus *bus,
+ 			     struct ssb_sprom *sprom)
+ {
+-	const struct ssb_sprom *fallback;
+-	int err = -ENOMEM;
++	int err;
+ 	u16 *buf;
+ 
++	if (!ssb_is_sprom_available(bus)) {
++		ssb_printk(KERN_ERR PFX "No SPROM available!\n");
++		return -ENODEV;
++	}
++	if (bus->chipco.dev) {	/* can be unavailable! */
++		/*
++		 * get SPROM offset: SSB_SPROM_BASE1 except for
++		 * chipcommon rev >= 31 or chip ID is 0x4312 and
++		 * chipcommon status & 3 == 2
++		 */
++		if (bus->chipco.dev->id.revision >= 31)
++			bus->sprom_offset = SSB_SPROM_BASE31;
++		else if (bus->chip_id == 0x4312 &&
++			 (bus->chipco.status & 0x03) == 2)
++			bus->sprom_offset = SSB_SPROM_BASE31;
++		else
++			bus->sprom_offset = SSB_SPROM_BASE1;
++	} else {
++		bus->sprom_offset = SSB_SPROM_BASE1;
++	}
++	ssb_dprintk(KERN_INFO PFX "SPROM offset is 0x%x\n", bus->sprom_offset);
++
+ 	buf = kcalloc(SSB_SPROMSIZE_WORDS_R123, sizeof(u16), GFP_KERNEL);
+ 	if (!buf)
+-		goto out;
++		return -ENOMEM;
+ 	bus->sprom_size = SSB_SPROMSIZE_WORDS_R123;
+ 	sprom_do_read(bus, buf);
+ 	err = sprom_check_crc(buf, bus->sprom_size);
+@@ -580,17 +747,24 @@ static int ssb_pci_sprom_get(struct ssb_
+ 		buf = kcalloc(SSB_SPROMSIZE_WORDS_R4, sizeof(u16),
+ 			      GFP_KERNEL);
+ 		if (!buf)
+-			goto out;
++			return -ENOMEM;
+ 		bus->sprom_size = SSB_SPROMSIZE_WORDS_R4;
+ 		sprom_do_read(bus, buf);
+ 		err = sprom_check_crc(buf, bus->sprom_size);
+ 		if (err) {
+ 			/* All CRC attempts failed.
+ 			 * Maybe there is no SPROM on the device?
+-			 * If we have a fallback, use that. */
+-			fallback = ssb_get_fallback_sprom();
+-			if (fallback) {
+-				memcpy(sprom, fallback, sizeof(*sprom));
++			 * Now we ask the arch code if there is some sprom
++			 * available for this device in some other storage */
++			err = ssb_fill_sprom_with_fallback(bus, sprom);
++			if (err) {
++				ssb_printk(KERN_WARNING PFX "WARNING: Using"
++					   " fallback SPROM failed (err %d)\n",
++					   err);
++			} else {
++				ssb_dprintk(KERN_DEBUG PFX "Using SPROM"
++					    " revision %d provided by"
++					    " platform.\n", sprom->revision);
+ 				err = 0;
+ 				goto out_free;
+ 			}
+@@ -602,19 +776,15 @@ static int ssb_pci_sprom_get(struct ssb_
+ 
+ out_free:
+ 	kfree(buf);
+-out:
+ 	return err;
+ }
+ 
+ static void ssb_pci_get_boardinfo(struct ssb_bus *bus,
+ 				  struct ssb_boardinfo *bi)
+ {
+-	pci_read_config_word(bus->host_pci, PCI_SUBSYSTEM_VENDOR_ID,
+-			     &bi->vendor);
+-	pci_read_config_word(bus->host_pci, PCI_SUBSYSTEM_ID,
+-			     &bi->type);
+-	pci_read_config_word(bus->host_pci, PCI_REVISION_ID,
+-			     &bi->rev);
++	bi->vendor = bus->host_pci->subsystem_vendor;
++	bi->type = bus->host_pci->subsystem_device;
++	bi->rev = bus->host_pci->revision;
+ }
+ 
+ int ssb_pci_get_invariants(struct ssb_bus *bus,
+--- a/drivers/ssb/pcihost_wrapper.c
++++ b/drivers/ssb/pcihost_wrapper.c
+@@ -6,12 +6,13 @@
+  * Copyright (c) 2005 Stefano Brivio <st3@riseup.net>
+  * Copyright (c) 2005 Danny van Dyk <kugelfang@gentoo.org>
+  * Copyright (c) 2005 Andreas Jaggi <andreas.jaggi@waterwave.ch>
+- * Copyright (c) 2005-2007 Michael Buesch <mbuesch@freenet.de>
++ * Copyright (c) 2005-2007 Michael Buesch <m@bues.ch>
+  *
+  * Licensed under the GNU/GPL. See COPYING for details.
+  */
+ 
+ #include <linux/pci.h>
++#include <linux/slab.h>
+ #include <linux/ssb/ssb.h>
+ 
+ 
+@@ -52,12 +53,13 @@ static int ssb_pcihost_resume(struct pci
+ # define ssb_pcihost_resume	NULL
+ #endif /* CONFIG_PM */
+ 
+-static int ssb_pcihost_probe(struct pci_dev *dev,
+-			     const struct pci_device_id *id)
++static int __devinit ssb_pcihost_probe(struct pci_dev *dev,
++				       const struct pci_device_id *id)
+ {
+ 	struct ssb_bus *ssb;
+ 	int err = -ENOMEM;
+ 	const char *name;
++	u32 val;
+ 
+ 	ssb = kzalloc(sizeof(*ssb), GFP_KERNEL);
+ 	if (!ssb)
+@@ -73,6 +75,12 @@ static int ssb_pcihost_probe(struct pci_
+ 		goto err_pci_disable;
+ 	pci_set_master(dev);
+ 
++	/* Disable the RETRY_TIMEOUT register (0x41) to keep
++	 * PCI Tx retries from interfering with C3 CPU state */
++	pci_read_config_dword(dev, 0x40, &val);
++	if ((val & 0x0000ff00) != 0)
++		pci_write_config_dword(dev, 0x40, val & 0xffff00ff);
++
+ 	err = ssb_bus_pcibus_register(ssb, dev);
+ 	if (err)
+ 		goto err_pci_release_regions;
+@@ -102,7 +110,7 @@ static void ssb_pcihost_remove(struct pc
+ 	pci_set_drvdata(dev, NULL);
+ }
+ 
+-int ssb_pcihost_register(struct pci_driver *driver)
++int __devinit ssb_pcihost_register(struct pci_driver *driver)
+ {
+ 	driver->probe = ssb_pcihost_probe;
+ 	driver->remove = ssb_pcihost_remove;
+--- a/drivers/ssb/pcmcia.c
++++ b/drivers/ssb/pcmcia.c
+@@ -3,7 +3,7 @@
+  * PCMCIA-Hostbus related functions
+  *
+  * Copyright 2006 Johannes Berg <johannes@sipsolutions.net>
+- * Copyright 2007-2008 Michael Buesch <mb@bu3sch.de>
++ * Copyright 2007-2008 Michael Buesch <m@bues.ch>
+  *
+  * Licensed under the GNU/GPL. See COPYING for details.
+  */
+@@ -617,136 +617,136 @@ static int ssb_pcmcia_sprom_check_crc(co
+ 	}						\
+   } while (0)
+ 
+-int ssb_pcmcia_get_invariants(struct ssb_bus *bus,
+-			      struct ssb_init_invariants *iv)
++static int ssb_pcmcia_get_mac(struct pcmcia_device *p_dev,
++			tuple_t *tuple,
++			void *priv)
++{
++	struct ssb_sprom *sprom = priv;
++
++	if (tuple->TupleData[0] != CISTPL_FUNCE_LAN_NODE_ID)
++		return -EINVAL;
++	if (tuple->TupleDataLen != ETH_ALEN + 2)
++		return -EINVAL;
++	if (tuple->TupleData[1] != ETH_ALEN)
++		return -EINVAL;
++	memcpy(sprom->il0mac, &tuple->TupleData[2], ETH_ALEN);
++	return 0;
++};
++
++static int ssb_pcmcia_do_get_invariants(struct pcmcia_device *p_dev,
++					tuple_t *tuple,
++					void *priv)
+ {
+-	tuple_t tuple;
+-	int res;
+-	unsigned char buf[32];
++	struct ssb_init_invariants *iv = priv;
+ 	struct ssb_sprom *sprom = &iv->sprom;
+ 	struct ssb_boardinfo *bi = &iv->boardinfo;
+ 	const char *error_description;
+ 
++	GOTO_ERROR_ON(tuple->TupleDataLen < 1, "VEN tpl < 1");
++	switch (tuple->TupleData[0]) {
++	case SSB_PCMCIA_CIS_ID:
++		GOTO_ERROR_ON((tuple->TupleDataLen != 5) &&
++			      (tuple->TupleDataLen != 7),
++			      "id tpl size");
++		bi->vendor = tuple->TupleData[1] |
++			((u16)tuple->TupleData[2] << 8);
++		break;
++	case SSB_PCMCIA_CIS_BOARDREV:
++		GOTO_ERROR_ON(tuple->TupleDataLen != 2,
++			"boardrev tpl size");
++		sprom->board_rev = tuple->TupleData[1];
++		break;
++	case SSB_PCMCIA_CIS_PA:
++		GOTO_ERROR_ON((tuple->TupleDataLen != 9) &&
++			(tuple->TupleDataLen != 10),
++			"pa tpl size");
++		sprom->pa0b0 = tuple->TupleData[1] |
++			((u16)tuple->TupleData[2] << 8);
++		sprom->pa0b1 = tuple->TupleData[3] |
++			((u16)tuple->TupleData[4] << 8);
++		sprom->pa0b2 = tuple->TupleData[5] |
++			((u16)tuple->TupleData[6] << 8);
++		sprom->itssi_a = tuple->TupleData[7];
++		sprom->itssi_bg = tuple->TupleData[7];
++		sprom->maxpwr_a = tuple->TupleData[8];
++		sprom->maxpwr_bg = tuple->TupleData[8];
++		break;
++	case SSB_PCMCIA_CIS_OEMNAME:
++		/* We ignore this. */
++		break;
++	case SSB_PCMCIA_CIS_CCODE:
++		GOTO_ERROR_ON(tuple->TupleDataLen != 2,
++			"ccode tpl size");
++		sprom->country_code = tuple->TupleData[1];
++		break;
++	case SSB_PCMCIA_CIS_ANTENNA:
++		GOTO_ERROR_ON(tuple->TupleDataLen != 2,
++			"ant tpl size");
++		sprom->ant_available_a = tuple->TupleData[1];
++		sprom->ant_available_bg = tuple->TupleData[1];
++		break;
++	case SSB_PCMCIA_CIS_ANTGAIN:
++		GOTO_ERROR_ON(tuple->TupleDataLen != 2,
++			"antg tpl size");
++		sprom->antenna_gain.a0 = tuple->TupleData[1];
++		sprom->antenna_gain.a1 = tuple->TupleData[1];
++		sprom->antenna_gain.a2 = tuple->TupleData[1];
++		sprom->antenna_gain.a3 = tuple->TupleData[1];
++		break;
++	case SSB_PCMCIA_CIS_BFLAGS:
++		GOTO_ERROR_ON((tuple->TupleDataLen != 3) &&
++			(tuple->TupleDataLen != 5),
++			"bfl tpl size");
++		sprom->boardflags_lo = tuple->TupleData[1] |
++			((u16)tuple->TupleData[2] << 8);
++		break;
++	case SSB_PCMCIA_CIS_LEDS:
++		GOTO_ERROR_ON(tuple->TupleDataLen != 5,
++			"leds tpl size");
++		sprom->gpio0 = tuple->TupleData[1];
++		sprom->gpio1 = tuple->TupleData[2];
++		sprom->gpio2 = tuple->TupleData[3];
++		sprom->gpio3 = tuple->TupleData[4];
++		break;
++	}
++	return -ENOSPC; /* continue with next entry */
++
++error:
++	ssb_printk(KERN_ERR PFX
++		   "PCMCIA: Failed to fetch device invariants: %s\n",
++		   error_description);
++	return -ENODEV;
++}
++
++
++int ssb_pcmcia_get_invariants(struct ssb_bus *bus,
++			      struct ssb_init_invariants *iv)
++{
++	struct ssb_sprom *sprom = &iv->sprom;
++	int res;
++
+ 	memset(sprom, 0xFF, sizeof(*sprom));
+ 	sprom->revision = 1;
+ 	sprom->boardflags_lo = 0;
+ 	sprom->boardflags_hi = 0;
+ 
+ 	/* First fetch the MAC address. */
+-	memset(&tuple, 0, sizeof(tuple));
+-	tuple.DesiredTuple = CISTPL_FUNCE;
+-	tuple.TupleData = buf;
+-	tuple.TupleDataMax = sizeof(buf);
+-	res = pcmcia_get_first_tuple(bus->host_pcmcia, &tuple);
+-	GOTO_ERROR_ON(res != 0, "MAC first tpl");
+-	res = pcmcia_get_tuple_data(bus->host_pcmcia, &tuple);
+-	GOTO_ERROR_ON(res != 0, "MAC first tpl data");
+-	while (1) {
+-		GOTO_ERROR_ON(tuple.TupleDataLen < 1, "MAC tpl < 1");
+-		if (tuple.TupleData[0] == CISTPL_FUNCE_LAN_NODE_ID)
+-			break;
+-		res = pcmcia_get_next_tuple(bus->host_pcmcia, &tuple);
+-		GOTO_ERROR_ON(res != 0, "MAC next tpl");
+-		res = pcmcia_get_tuple_data(bus->host_pcmcia, &tuple);
+-		GOTO_ERROR_ON(res != 0, "MAC next tpl data");
++	res = pcmcia_loop_tuple(bus->host_pcmcia, CISTPL_FUNCE,
++				ssb_pcmcia_get_mac, sprom);
++	if (res != 0) {
++		ssb_printk(KERN_ERR PFX
++			"PCMCIA: Failed to fetch MAC address\n");
++		return -ENODEV;
+ 	}
+-	GOTO_ERROR_ON(tuple.TupleDataLen != ETH_ALEN + 2, "MAC tpl size");
+-	memcpy(sprom->il0mac, &tuple.TupleData[2], ETH_ALEN);
+ 
+ 	/* Fetch the vendor specific tuples. */
+-	memset(&tuple, 0, sizeof(tuple));
+-	tuple.DesiredTuple = SSB_PCMCIA_CIS;
+-	tuple.TupleData = buf;
+-	tuple.TupleDataMax = sizeof(buf);
+-	res = pcmcia_get_first_tuple(bus->host_pcmcia, &tuple);
+-	GOTO_ERROR_ON(res != 0, "VEN first tpl");
+-	res = pcmcia_get_tuple_data(bus->host_pcmcia, &tuple);
+-	GOTO_ERROR_ON(res != 0, "VEN first tpl data");
+-	while (1) {
+-		GOTO_ERROR_ON(tuple.TupleDataLen < 1, "VEN tpl < 1");
+-		switch (tuple.TupleData[0]) {
+-		case SSB_PCMCIA_CIS_ID:
+-			GOTO_ERROR_ON((tuple.TupleDataLen != 5) &&
+-				      (tuple.TupleDataLen != 7),
+-				      "id tpl size");
+-			bi->vendor = tuple.TupleData[1] |
+-			       ((u16)tuple.TupleData[2] << 8);
+-			break;
+-		case SSB_PCMCIA_CIS_BOARDREV:
+-			GOTO_ERROR_ON(tuple.TupleDataLen != 2,
+-				      "boardrev tpl size");
+-			sprom->board_rev = tuple.TupleData[1];
+-			break;
+-		case SSB_PCMCIA_CIS_PA:
+-			GOTO_ERROR_ON((tuple.TupleDataLen != 9) &&
+-				      (tuple.TupleDataLen != 10),
+-				      "pa tpl size");
+-			sprom->pa0b0 = tuple.TupleData[1] |
+-				 ((u16)tuple.TupleData[2] << 8);
+-			sprom->pa0b1 = tuple.TupleData[3] |
+-				 ((u16)tuple.TupleData[4] << 8);
+-			sprom->pa0b2 = tuple.TupleData[5] |
+-				 ((u16)tuple.TupleData[6] << 8);
+-			sprom->itssi_a = tuple.TupleData[7];
+-			sprom->itssi_bg = tuple.TupleData[7];
+-			sprom->maxpwr_a = tuple.TupleData[8];
+-			sprom->maxpwr_bg = tuple.TupleData[8];
+-			break;
+-		case SSB_PCMCIA_CIS_OEMNAME:
+-			/* We ignore this. */
+-			break;
+-		case SSB_PCMCIA_CIS_CCODE:
+-			GOTO_ERROR_ON(tuple.TupleDataLen != 2,
+-				      "ccode tpl size");
+-			sprom->country_code = tuple.TupleData[1];
+-			break;
+-		case SSB_PCMCIA_CIS_ANTENNA:
+-			GOTO_ERROR_ON(tuple.TupleDataLen != 2,
+-				      "ant tpl size");
+-			sprom->ant_available_a = tuple.TupleData[1];
+-			sprom->ant_available_bg = tuple.TupleData[1];
+-			break;
+-		case SSB_PCMCIA_CIS_ANTGAIN:
+-			GOTO_ERROR_ON(tuple.TupleDataLen != 2,
+-				      "antg tpl size");
+-			sprom->antenna_gain.ghz24.a0 = tuple.TupleData[1];
+-			sprom->antenna_gain.ghz24.a1 = tuple.TupleData[1];
+-			sprom->antenna_gain.ghz24.a2 = tuple.TupleData[1];
+-			sprom->antenna_gain.ghz24.a3 = tuple.TupleData[1];
+-			sprom->antenna_gain.ghz5.a0 = tuple.TupleData[1];
+-			sprom->antenna_gain.ghz5.a1 = tuple.TupleData[1];
+-			sprom->antenna_gain.ghz5.a2 = tuple.TupleData[1];
+-			sprom->antenna_gain.ghz5.a3 = tuple.TupleData[1];
+-			break;
+-		case SSB_PCMCIA_CIS_BFLAGS:
+-			GOTO_ERROR_ON((tuple.TupleDataLen != 3) &&
+-				      (tuple.TupleDataLen != 5),
+-				      "bfl tpl size");
+-			sprom->boardflags_lo = tuple.TupleData[1] |
+-					 ((u16)tuple.TupleData[2] << 8);
+-			break;
+-		case SSB_PCMCIA_CIS_LEDS:
+-			GOTO_ERROR_ON(tuple.TupleDataLen != 5,
+-				      "leds tpl size");
+-			sprom->gpio0 = tuple.TupleData[1];
+-			sprom->gpio1 = tuple.TupleData[2];
+-			sprom->gpio2 = tuple.TupleData[3];
+-			sprom->gpio3 = tuple.TupleData[4];
+-			break;
+-		}
+-		res = pcmcia_get_next_tuple(bus->host_pcmcia, &tuple);
+-		if (res == -ENOSPC)
+-			break;
+-		GOTO_ERROR_ON(res != 0, "VEN next tpl");
+-		res = pcmcia_get_tuple_data(bus->host_pcmcia, &tuple);
+-		GOTO_ERROR_ON(res != 0, "VEN next tpl data");
+-	}
++	res = pcmcia_loop_tuple(bus->host_pcmcia, SSB_PCMCIA_CIS,
++				ssb_pcmcia_do_get_invariants, iv);
++	if ((res == 0) || (res == -ENOSPC))
++		return 0;
+ 
+-	return 0;
+-error:
+ 	ssb_printk(KERN_ERR PFX
+-		   "PCMCIA: Failed to fetch device invariants: %s\n",
+-		   error_description);
++			"PCMCIA: Failed to fetch device invariants\n");
+ 	return -ENODEV;
+ }
+ 
+--- a/drivers/ssb/scan.c
++++ b/drivers/ssb/scan.c
+@@ -2,7 +2,7 @@
+  * Sonics Silicon Backplane
+  * Bus scanning
+  *
+- * Copyright (C) 2005-2007 Michael Buesch <mb@bu3sch.de>
++ * Copyright (C) 2005-2007 Michael Buesch <m@bues.ch>
+  * Copyright (C) 2005 Martin Langer <martin-langer@gmx.de>
+  * Copyright (C) 2005 Stefano Brivio <st3@riseup.net>
+  * Copyright (C) 2005 Danny van Dyk <kugelfang@gentoo.org>
+@@ -162,6 +162,8 @@ static u8 chipid_to_nrcores(u16 chipid)
+ static u32 scan_read32(struct ssb_bus *bus, u8 current_coreidx,
+ 		       u16 offset)
+ {
++	u32 lo, hi;
++
+ 	switch (bus->bustype) {
+ 	case SSB_BUSTYPE_SSB:
+ 		offset += current_coreidx * SSB_CORE_SIZE;
+@@ -174,7 +176,12 @@ static u32 scan_read32(struct ssb_bus *b
+ 			offset -= 0x800;
+ 		} else
+ 			ssb_pcmcia_switch_segment(bus, 0);
+-		break;
++		lo = readw(bus->mmio + offset);
++		hi = readw(bus->mmio + offset + 2);
++		return lo | (hi << 16);
++	case SSB_BUSTYPE_SDIO:
++		offset += current_coreidx * SSB_CORE_SIZE;
++		return ssb_sdio_scan_read32(bus, offset);
+ 	}
+ 	return readl(bus->mmio + offset);
+ }
+@@ -188,6 +195,8 @@ static int scan_switchcore(struct ssb_bu
+ 		return ssb_pci_switch_coreidx(bus, coreidx);
+ 	case SSB_BUSTYPE_PCMCIA:
+ 		return ssb_pcmcia_switch_coreidx(bus, coreidx);
++	case SSB_BUSTYPE_SDIO:
++		return ssb_sdio_scan_switch_coreidx(bus, coreidx);
+ 	}
+ 	return 0;
+ }
+@@ -206,6 +215,8 @@ void ssb_iounmap(struct ssb_bus *bus)
+ 		SSB_BUG_ON(1); /* Can't reach this code. */
+ #endif
+ 		break;
++	case SSB_BUSTYPE_SDIO:
++		break;
+ 	}
+ 	bus->mmio = NULL;
+ 	bus->mapped_device = NULL;
+@@ -230,6 +241,10 @@ static void __iomem *ssb_ioremap(struct
+ 		SSB_BUG_ON(1); /* Can't reach this code. */
+ #endif
+ 		break;
++	case SSB_BUSTYPE_SDIO:
++		/* Nothing to ioremap in the SDIO case, just fake it */
++		mmio = (void __iomem *)baseaddr;
++		break;
+ 	}
+ 
+ 	return mmio;
+@@ -245,7 +260,10 @@ static int we_support_multiple_80211_cor
+ #ifdef CONFIG_SSB_PCIHOST
+ 	if (bus->bustype == SSB_BUSTYPE_PCI) {
+ 		if (bus->host_pci->vendor == PCI_VENDOR_ID_BROADCOM &&
+-		    bus->host_pci->device == 0x4324)
++		    ((bus->host_pci->device == 0x4313) ||
++		     (bus->host_pci->device == 0x431A) ||
++		     (bus->host_pci->device == 0x4321) ||
++		     (bus->host_pci->device == 0x4324)))
+ 			return 1;
+ 	}
+ #endif /* CONFIG_SSB_PCIHOST */
+@@ -294,8 +312,7 @@ int ssb_bus_scan(struct ssb_bus *bus,
+ 	} else {
+ 		if (bus->bustype == SSB_BUSTYPE_PCI) {
+ 			bus->chip_id = pcidev_to_chipid(bus->host_pci);
+-			pci_read_config_word(bus->host_pci, PCI_REVISION_ID,
+-					     &bus->chip_rev);
++			bus->chip_rev = bus->host_pci->revision;
+ 			bus->chip_package = 0;
+ 		} else {
+ 			bus->chip_id = 0x4710;
+@@ -303,6 +320,9 @@ int ssb_bus_scan(struct ssb_bus *bus,
+ 			bus->chip_package = 0;
+ 		}
+ 	}
++	ssb_printk(KERN_INFO PFX "Found chip with id 0x%04X, rev 0x%02X and "
++		   "package 0x%02X\n", bus->chip_id, bus->chip_rev,
++		   bus->chip_package);
+ 	if (!bus->nr_devices)
+ 		bus->nr_devices = chipid_to_nrcores(bus->chip_id);
+ 	if (bus->nr_devices > ARRAY_SIZE(bus->devices)) {
+@@ -339,7 +359,7 @@ int ssb_bus_scan(struct ssb_bus *bus,
+ 		dev->bus = bus;
+ 		dev->ops = bus->ops;
+ 
+-		ssb_dprintk(KERN_INFO PFX
++		printk(KERN_DEBUG PFX
+ 			    "Core %d found: %s "
+ 			    "(cc 0x%03X, rev 0x%02X, vendor 0x%04X)\n",
+ 			    i, ssb_core_name(dev->id.coreid),
+@@ -407,6 +427,16 @@ int ssb_bus_scan(struct ssb_bus *bus,
+ 			bus->pcicore.dev = dev;
+ #endif /* CONFIG_SSB_DRIVER_PCICORE */
+ 			break;
++		case SSB_DEV_ETHERNET:
++			if (bus->bustype == SSB_BUSTYPE_PCI) {
++				if (bus->host_pci->vendor == PCI_VENDOR_ID_BROADCOM &&
++				    (bus->host_pci->device & 0xFF00) == 0x4300) {
++					/* This is a dangling ethernet core on a
++					 * wireless device. Ignore it. */
++					continue;
++				}
++			}
++			break;
+ 		default:
+ 			break;
+ 		}
+--- /dev/null
++++ b/drivers/ssb/sdio.c
+@@ -0,0 +1,606 @@
++/*
++ * Sonics Silicon Backplane
++ * SDIO-Hostbus related functions
++ *
++ * Copyright 2009 Albert Herranz <albert_herranz@yahoo.es>
++ *
++ * Based on drivers/ssb/pcmcia.c
++ * Copyright 2006 Johannes Berg <johannes@sipsolutions.net>
++ * Copyright 2007-2008 Michael Buesch <m@bues.ch>
++ *
++ * Licensed under the GNU/GPL. See COPYING for details.
++ *
++ */
++
++#include <linux/ssb/ssb.h>
++#include <linux/delay.h>
++#include <linux/io.h>
++#include <linux/etherdevice.h>
++#include <linux/mmc/sdio_func.h>
++
++#include "ssb_private.h"
++
++/* Define the following to 1 to enable a printk on each coreswitch. */
++#define SSB_VERBOSE_SDIOCORESWITCH_DEBUG		0
++
++
++/* Hardware invariants CIS tuples */
++#define SSB_SDIO_CIS			0x80
++#define  SSB_SDIO_CIS_SROMREV		0x00
++#define  SSB_SDIO_CIS_ID		0x01
++#define  SSB_SDIO_CIS_BOARDREV		0x02
++#define  SSB_SDIO_CIS_PA		0x03
++#define   SSB_SDIO_CIS_PA_PA0B0_LO	0
++#define   SSB_SDIO_CIS_PA_PA0B0_HI	1
++#define   SSB_SDIO_CIS_PA_PA0B1_LO	2
++#define   SSB_SDIO_CIS_PA_PA0B1_HI	3
++#define   SSB_SDIO_CIS_PA_PA0B2_LO	4
++#define   SSB_SDIO_CIS_PA_PA0B2_HI	5
++#define   SSB_SDIO_CIS_PA_ITSSI		6
++#define   SSB_SDIO_CIS_PA_MAXPOW	7
++#define  SSB_SDIO_CIS_OEMNAME		0x04
++#define  SSB_SDIO_CIS_CCODE		0x05
++#define  SSB_SDIO_CIS_ANTENNA		0x06
++#define  SSB_SDIO_CIS_ANTGAIN		0x07
++#define  SSB_SDIO_CIS_BFLAGS		0x08
++#define  SSB_SDIO_CIS_LEDS		0x09
++
++#define CISTPL_FUNCE_LAN_NODE_ID        0x04	/* same as in PCMCIA */
++
++
++/*
++ * Function 1 miscellaneous registers.
++ *
++ * Definitions match src/include/sbsdio.h from the
++ * Android Open Source Project
++ * http://android.git.kernel.org/?p=platform/system/wlan/broadcom.git
++ *
++ */
++#define SBSDIO_FUNC1_SBADDRLOW	0x1000a	/* SB Address window Low (b15) */
++#define SBSDIO_FUNC1_SBADDRMID	0x1000b	/* SB Address window Mid (b23-b16) */
++#define SBSDIO_FUNC1_SBADDRHIGH	0x1000c	/* SB Address window High (b24-b31) */
++
++/* valid bits in SBSDIO_FUNC1_SBADDRxxx regs */
++#define SBSDIO_SBADDRLOW_MASK	0x80	/* Valid address bits in SBADDRLOW */
++#define SBSDIO_SBADDRMID_MASK	0xff	/* Valid address bits in SBADDRMID */
++#define SBSDIO_SBADDRHIGH_MASK	0xff	/* Valid address bits in SBADDRHIGH */
++
++#define SBSDIO_SB_OFT_ADDR_MASK	0x7FFF	/* sb offset addr is <= 15 bits, 32k */
++
++/* REVISIT: this flag doesn't seem to matter */
++#define SBSDIO_SB_ACCESS_2_4B_FLAG	0x8000	/* forces 32-bit SB access */
++
++
++/*
++ * Address map within the SDIO function address space (128K).
++ *
++ *   Start   End     Description
++ *   ------- ------- ------------------------------------------
++ *   0x00000 0x0ffff selected backplane address window (64K)
++ *   0x10000 0x1ffff backplane control registers (max 64K)
++ *
++ * The current address window is configured by writing to registers
++ * SBADDRLOW, SBADDRMID and SBADDRHIGH.
++ *
++ * In order to access the contents of a 32-bit Silicon Backplane address
++ * the backplane address window must be first loaded with the highest
++ * 16 bits of the target address. Then, an access must be done to the
++ * SDIO function address space using the lower 15 bits of the address.
++ * Bit 15 of the address must be set when doing 32 bit accesses.
++ *
++ * 10987654321098765432109876543210
++ * WWWWWWWWWWWWWWWWW                 SB Address Window
++ *                 OOOOOOOOOOOOOOOO  Offset within SB Address Window
++ *                 a                 32-bit access flag
++ */
++
++
++/*
++ * SSB I/O via SDIO.
++ *
++ * NOTE: SDIO address @addr is 17 bits long (SDIO address space is 128K).
++ */
++
++static inline struct device *ssb_sdio_dev(struct ssb_bus *bus)
++{
++	return &bus->host_sdio->dev;
++}
++
++/* host claimed */
++static int ssb_sdio_writeb(struct ssb_bus *bus, unsigned int addr, u8 val)
++{
++	int error = 0;
++
++	sdio_writeb(bus->host_sdio, val, addr, &error);
++	if (unlikely(error)) {
++		dev_dbg(ssb_sdio_dev(bus), "%08X <- %02x, error %d\n",
++			addr, val, error);
++	}
++
++	return error;
++}
++
++#if 0
++static u8 ssb_sdio_readb(struct ssb_bus *bus, unsigned int addr)
++{
++	u8 val;
++	int error = 0;
++
++	val = sdio_readb(bus->host_sdio, addr, &error);
++	if (unlikely(error)) {
++		dev_dbg(ssb_sdio_dev(bus), "%08X -> %02x, error %d\n",
++			addr, val, error);
++	}
++
++	return val;
++}
++#endif
++
++/* host claimed */
++static int ssb_sdio_set_sbaddr_window(struct ssb_bus *bus, u32 address)
++{
++	int error;
++
++	error = ssb_sdio_writeb(bus, SBSDIO_FUNC1_SBADDRLOW,
++				(address >> 8) & SBSDIO_SBADDRLOW_MASK);
++	if (error)
++		goto out;
++	error = ssb_sdio_writeb(bus, SBSDIO_FUNC1_SBADDRMID,
++				(address >> 16) & SBSDIO_SBADDRMID_MASK);
++	if (error)
++		goto out;
++	error = ssb_sdio_writeb(bus, SBSDIO_FUNC1_SBADDRHIGH,
++				(address >> 24) & SBSDIO_SBADDRHIGH_MASK);
++	if (error)
++		goto out;
++	bus->sdio_sbaddr = address;
++out:
++	if (error) {
++		dev_dbg(ssb_sdio_dev(bus), "failed to set address window"
++			" to 0x%08x, error %d\n", address, error);
++	}
++
++	return error;
++}
++
++/* for enumeration use only */
++u32 ssb_sdio_scan_read32(struct ssb_bus *bus, u16 offset)
++{
++	u32 val;
++	int error;
++
++	sdio_claim_host(bus->host_sdio);
++	val = sdio_readl(bus->host_sdio, offset, &error);
++	sdio_release_host(bus->host_sdio);
++	if (unlikely(error)) {
++		dev_dbg(ssb_sdio_dev(bus), "%04X:%04X > %08x, error %d\n",
++			bus->sdio_sbaddr >> 16, offset, val, error);
++	}
++
++	return val;
++}
++
++/* for enumeration use only */
++int ssb_sdio_scan_switch_coreidx(struct ssb_bus *bus, u8 coreidx)
++{
++	u32 sbaddr;
++	int error;
++
++	sbaddr = (coreidx * SSB_CORE_SIZE) + SSB_ENUM_BASE;
++	sdio_claim_host(bus->host_sdio);
++	error = ssb_sdio_set_sbaddr_window(bus, sbaddr);
++	sdio_release_host(bus->host_sdio);
++	if (error) {
++		dev_err(ssb_sdio_dev(bus), "failed to switch to core %u,"
++			" error %d\n", coreidx, error);
++		goto out;
++	}
++out:
++	return error;
++}
++
++/* host must be already claimed */
++int ssb_sdio_switch_core(struct ssb_bus *bus, struct ssb_device *dev)
++{
++	u8 coreidx = dev->core_index;
++	u32 sbaddr;
++	int error = 0;
++
++	sbaddr = (coreidx * SSB_CORE_SIZE) + SSB_ENUM_BASE;
++	if (unlikely(bus->sdio_sbaddr != sbaddr)) {
++#if SSB_VERBOSE_SDIOCORESWITCH_DEBUG
++		dev_info(ssb_sdio_dev(bus),
++			   "switching to %s core, index %d\n",
++			   ssb_core_name(dev->id.coreid), coreidx);
++#endif
++		error = ssb_sdio_set_sbaddr_window(bus, sbaddr);
++		if (error) {
++			dev_dbg(ssb_sdio_dev(bus), "failed to switch to"
++				" core %u, error %d\n", coreidx, error);
++			goto out;
++		}
++		bus->mapped_device = dev;
++	}
++
++out:
++	return error;
++}
++
++static u8 ssb_sdio_read8(struct ssb_device *dev, u16 offset)
++{
++	struct ssb_bus *bus = dev->bus;
++	u8 val = 0xff;
++	int error = 0;
++
++	sdio_claim_host(bus->host_sdio);
++	if (unlikely(ssb_sdio_switch_core(bus, dev)))
++		goto out;
++	offset |= bus->sdio_sbaddr & 0xffff;
++	offset &= SBSDIO_SB_OFT_ADDR_MASK;
++	val = sdio_readb(bus->host_sdio, offset, &error);
++	if (error) {
++		dev_dbg(ssb_sdio_dev(bus), "%04X:%04X > %02x, error %d\n",
++			bus->sdio_sbaddr >> 16, offset, val, error);
++	}
++out:
++	sdio_release_host(bus->host_sdio);
++
++	return val;
++}
++
++static u16 ssb_sdio_read16(struct ssb_device *dev, u16 offset)
++{
++	struct ssb_bus *bus = dev->bus;
++	u16 val = 0xffff;
++	int error = 0;
++
++	sdio_claim_host(bus->host_sdio);
++	if (unlikely(ssb_sdio_switch_core(bus, dev)))
++		goto out;
++	offset |= bus->sdio_sbaddr & 0xffff;
++	offset &= SBSDIO_SB_OFT_ADDR_MASK;
++	val = sdio_readw(bus->host_sdio, offset, &error);
++	if (error) {
++		dev_dbg(ssb_sdio_dev(bus), "%04X:%04X > %04x, error %d\n",
++			bus->sdio_sbaddr >> 16, offset, val, error);
++	}
++out:
++	sdio_release_host(bus->host_sdio);
++
++	return val;
++}
++
++static u32 ssb_sdio_read32(struct ssb_device *dev, u16 offset)
++{
++	struct ssb_bus *bus = dev->bus;
++	u32 val = 0xffffffff;
++	int error = 0;
++
++	sdio_claim_host(bus->host_sdio);
++	if (unlikely(ssb_sdio_switch_core(bus, dev)))
++		goto out;
++	offset |= bus->sdio_sbaddr & 0xffff;
++	offset &= SBSDIO_SB_OFT_ADDR_MASK;
++	offset |= SBSDIO_SB_ACCESS_2_4B_FLAG;	/* 32 bit data access */
++	val = sdio_readl(bus->host_sdio, offset, &error);
++	if (error) {
++		dev_dbg(ssb_sdio_dev(bus), "%04X:%04X > %08x, error %d\n",
++			bus->sdio_sbaddr >> 16, offset, val, error);
++	}
++out:
++	sdio_release_host(bus->host_sdio);
++
++	return val;
++}
++
++#ifdef CONFIG_SSB_BLOCKIO
++static void ssb_sdio_block_read(struct ssb_device *dev, void *buffer,
++				  size_t count, u16 offset, u8 reg_width)
++{
++	size_t saved_count = count;
++	struct ssb_bus *bus = dev->bus;
++	int error = 0;
++
++	sdio_claim_host(bus->host_sdio);
++	if (unlikely(ssb_sdio_switch_core(bus, dev))) {
++		error = -EIO;
++		memset(buffer, 0xff, count);
++		goto err_out;
++	}
++	offset |= bus->sdio_sbaddr & 0xffff;
++	offset &= SBSDIO_SB_OFT_ADDR_MASK;
++
++	switch (reg_width) {
++	case sizeof(u8): {
++		error = sdio_readsb(bus->host_sdio, buffer, offset, count);
++		break;
++	}
++	case sizeof(u16): {
++		SSB_WARN_ON(count & 1);
++		error = sdio_readsb(bus->host_sdio, buffer, offset, count);
++		break;
++	}
++	case sizeof(u32): {
++		SSB_WARN_ON(count & 3);
++		offset |= SBSDIO_SB_ACCESS_2_4B_FLAG;	/* 32 bit data access */
++		error = sdio_readsb(bus->host_sdio, buffer, offset, count);
++		break;
++	}
++	default:
++		SSB_WARN_ON(1);
++	}
++	if (!error)
++		goto out;
++
++err_out:
++	dev_dbg(ssb_sdio_dev(bus), "%04X:%04X (width=%u, len=%zu), error %d\n",
++		bus->sdio_sbaddr >> 16, offset, reg_width, saved_count, error);
++out:
++	sdio_release_host(bus->host_sdio);
++}
++#endif /* CONFIG_SSB_BLOCKIO */
++
++static void ssb_sdio_write8(struct ssb_device *dev, u16 offset, u8 val)
++{
++	struct ssb_bus *bus = dev->bus;
++	int error = 0;
++
++	sdio_claim_host(bus->host_sdio);
++	if (unlikely(ssb_sdio_switch_core(bus, dev)))
++		goto out;
++	offset |= bus->sdio_sbaddr & 0xffff;
++	offset &= SBSDIO_SB_OFT_ADDR_MASK;
++	sdio_writeb(bus->host_sdio, val, offset, &error);
++	if (error) {
++		dev_dbg(ssb_sdio_dev(bus), "%04X:%04X < %02x, error %d\n",
++			bus->sdio_sbaddr >> 16, offset, val, error);
++	}
++out:
++	sdio_release_host(bus->host_sdio);
++}
++
++static void ssb_sdio_write16(struct ssb_device *dev, u16 offset, u16 val)
++{
++	struct ssb_bus *bus = dev->bus;
++	int error = 0;
++
++	sdio_claim_host(bus->host_sdio);
++	if (unlikely(ssb_sdio_switch_core(bus, dev)))
++		goto out;
++	offset |= bus->sdio_sbaddr & 0xffff;
++	offset &= SBSDIO_SB_OFT_ADDR_MASK;
++	sdio_writew(bus->host_sdio, val, offset, &error);
++	if (error) {
++		dev_dbg(ssb_sdio_dev(bus), "%04X:%04X < %04x, error %d\n",
++			bus->sdio_sbaddr >> 16, offset, val, error);
++	}
++out:
++	sdio_release_host(bus->host_sdio);
++}
++
++static void ssb_sdio_write32(struct ssb_device *dev, u16 offset, u32 val)
++{
++	struct ssb_bus *bus = dev->bus;
++	int error = 0;
++
++	sdio_claim_host(bus->host_sdio);
++	if (unlikely(ssb_sdio_switch_core(bus, dev)))
++		goto out;
++	offset |= bus->sdio_sbaddr & 0xffff;
++	offset &= SBSDIO_SB_OFT_ADDR_MASK;
++	offset |= SBSDIO_SB_ACCESS_2_4B_FLAG;	/* 32 bit data access */
++	sdio_writel(bus->host_sdio, val, offset, &error);
++	if (error) {
++		dev_dbg(ssb_sdio_dev(bus), "%04X:%04X < %08x, error %d\n",
++			bus->sdio_sbaddr >> 16, offset, val, error);
++	}
++	if (bus->quirks & SSB_QUIRK_SDIO_READ_AFTER_WRITE32)
++		sdio_readl(bus->host_sdio, 0, &error);
++out:
++	sdio_release_host(bus->host_sdio);
++}
++
++#ifdef CONFIG_SSB_BLOCKIO
++static void ssb_sdio_block_write(struct ssb_device *dev, const void *buffer,
++				   size_t count, u16 offset, u8 reg_width)
++{
++	size_t saved_count = count;
++	struct ssb_bus *bus = dev->bus;
++	int error = 0;
++
++	sdio_claim_host(bus->host_sdio);
++	if (unlikely(ssb_sdio_switch_core(bus, dev))) {
++		error = -EIO;
++		memset((void *)buffer, 0xff, count);
++		goto err_out;
++	}
++	offset |= bus->sdio_sbaddr & 0xffff;
++	offset &= SBSDIO_SB_OFT_ADDR_MASK;
++
++	switch (reg_width) {
++	case sizeof(u8):
++		error = sdio_writesb(bus->host_sdio, offset,
++				     (void *)buffer, count);
++		break;
++	case sizeof(u16):
++		SSB_WARN_ON(count & 1);
++		error = sdio_writesb(bus->host_sdio, offset,
++				     (void *)buffer, count);
++		break;
++	case sizeof(u32):
++		SSB_WARN_ON(count & 3);
++		offset |= SBSDIO_SB_ACCESS_2_4B_FLAG;	/* 32 bit data access */
++		error = sdio_writesb(bus->host_sdio, offset,
++				     (void *)buffer, count);
++		break;
++	default:
++		SSB_WARN_ON(1);
++	}
++	if (!error)
++		goto out;
++
++err_out:
++	dev_dbg(ssb_sdio_dev(bus), "%04X:%04X (width=%u, len=%zu), error %d\n",
++		bus->sdio_sbaddr >> 16, offset, reg_width, saved_count, error);
++out:
++	sdio_release_host(bus->host_sdio);
++}
++
++#endif /* CONFIG_SSB_BLOCKIO */
++
++/* Not "static", as it's used in main.c */
++const struct ssb_bus_ops ssb_sdio_ops = {
++	.read8		= ssb_sdio_read8,
++	.read16		= ssb_sdio_read16,
++	.read32		= ssb_sdio_read32,
++	.write8		= ssb_sdio_write8,
++	.write16	= ssb_sdio_write16,
++	.write32	= ssb_sdio_write32,
++#ifdef CONFIG_SSB_BLOCKIO
++	.block_read	= ssb_sdio_block_read,
++	.block_write	= ssb_sdio_block_write,
++#endif
++};
++
++#define GOTO_ERROR_ON(condition, description) do {	\
++	if (unlikely(condition)) {			\
++		error_description = description;	\
++		goto error;				\
++	}						\
++  } while (0)
++
++int ssb_sdio_get_invariants(struct ssb_bus *bus,
++			    struct ssb_init_invariants *iv)
++{
++	struct ssb_sprom *sprom = &iv->sprom;
++	struct ssb_boardinfo *bi = &iv->boardinfo;
++	const char *error_description = "none";
++	struct sdio_func_tuple *tuple;
++	void *mac;
++
++	memset(sprom, 0xFF, sizeof(*sprom));
++	sprom->boardflags_lo = 0;
++	sprom->boardflags_hi = 0;
++
++	tuple = bus->host_sdio->tuples;
++	while (tuple) {
++		switch (tuple->code) {
++		case 0x22: /* extended function */
++			switch (tuple->data[0]) {
++			case CISTPL_FUNCE_LAN_NODE_ID:
++				GOTO_ERROR_ON((tuple->size != 7) &&
++					      (tuple->data[1] != 6),
++					      "mac tpl size");
++				/* fetch the MAC address. */
++				mac = tuple->data + 2;
++				memcpy(sprom->il0mac, mac, ETH_ALEN);
++				memcpy(sprom->et1mac, mac, ETH_ALEN);
++				break;
++			default:
++				break;
++			}
++			break;
++		case 0x80: /* vendor specific tuple */
++			switch (tuple->data[0]) {
++			case SSB_SDIO_CIS_SROMREV:
++				GOTO_ERROR_ON(tuple->size != 2,
++					      "sromrev tpl size");
++				sprom->revision = tuple->data[1];
++				break;
++			case SSB_SDIO_CIS_ID:
++				GOTO_ERROR_ON((tuple->size != 5) &&
++					      (tuple->size != 7),
++					      "id tpl size");
++				bi->vendor = tuple->data[1] |
++					     (tuple->data[2]<<8);
++				break;
++			case SSB_SDIO_CIS_BOARDREV:
++				GOTO_ERROR_ON(tuple->size != 2,
++					      "boardrev tpl size");
++				sprom->board_rev = tuple->data[1];
++				break;
++			case SSB_SDIO_CIS_PA:
++				GOTO_ERROR_ON((tuple->size != 9) &&
++					      (tuple->size != 10),
++					      "pa tpl size");
++				sprom->pa0b0 = tuple->data[1] |
++					 ((u16)tuple->data[2] << 8);
++				sprom->pa0b1 = tuple->data[3] |
++					 ((u16)tuple->data[4] << 8);
++				sprom->pa0b2 = tuple->data[5] |
++					 ((u16)tuple->data[6] << 8);
++				sprom->itssi_a = tuple->data[7];
++				sprom->itssi_bg = tuple->data[7];
++				sprom->maxpwr_a = tuple->data[8];
++				sprom->maxpwr_bg = tuple->data[8];
++				break;
++			case SSB_SDIO_CIS_OEMNAME:
++				/* Not present */
++				break;
++			case SSB_SDIO_CIS_CCODE:
++				GOTO_ERROR_ON(tuple->size != 2,
++					      "ccode tpl size");
++				sprom->country_code = tuple->data[1];
++				break;
++			case SSB_SDIO_CIS_ANTENNA:
++				GOTO_ERROR_ON(tuple->size != 2,
++					      "ant tpl size");
++				sprom->ant_available_a = tuple->data[1];
++				sprom->ant_available_bg = tuple->data[1];
++				break;
++			case SSB_SDIO_CIS_ANTGAIN:
++				GOTO_ERROR_ON(tuple->size != 2,
++					      "antg tpl size");
++				sprom->antenna_gain.a0 = tuple->data[1];
++				sprom->antenna_gain.a1 = tuple->data[1];
++				sprom->antenna_gain.a2 = tuple->data[1];
++				sprom->antenna_gain.a3 = tuple->data[1];
++				break;
++			case SSB_SDIO_CIS_BFLAGS:
++				GOTO_ERROR_ON((tuple->size != 3) &&
++					      (tuple->size != 5),
++					      "bfl tpl size");
++				sprom->boardflags_lo = tuple->data[1] |
++						 ((u16)tuple->data[2] << 8);
++				break;
++			case SSB_SDIO_CIS_LEDS:
++				GOTO_ERROR_ON(tuple->size != 5,
++					      "leds tpl size");
++				sprom->gpio0 = tuple->data[1];
++				sprom->gpio1 = tuple->data[2];
++				sprom->gpio2 = tuple->data[3];
++				sprom->gpio3 = tuple->data[4];
++				break;
++			default:
++				break;
++			}
++			break;
++		default:
++			break;
++		}
++		tuple = tuple->next;
++	}
++
++	return 0;
++error:
++	dev_err(ssb_sdio_dev(bus), "failed to fetch device invariants: %s\n",
++		error_description);
++	return -ENODEV;
++}
++
++void ssb_sdio_exit(struct ssb_bus *bus)
++{
++	if (bus->bustype != SSB_BUSTYPE_SDIO)
++		return;
++	/* Nothing to do here. */
++}
++
++int ssb_sdio_init(struct ssb_bus *bus)
++{
++	if (bus->bustype != SSB_BUSTYPE_SDIO)
++		return 0;
++
++	bus->sdio_sbaddr = ~0;
++
++	return 0;
++}
+--- a/drivers/ssb/sprom.c
++++ b/drivers/ssb/sprom.c
+@@ -2,7 +2,7 @@
+  * Sonics Silicon Backplane
+  * Common SPROM support routines
+  *
+- * Copyright (C) 2005-2008 Michael Buesch <mb@bu3sch.de>
++ * Copyright (C) 2005-2008 Michael Buesch <m@bues.ch>
+  * Copyright (C) 2005 Martin Langer <martin-langer@gmx.de>
+  * Copyright (C) 2005 Stefano Brivio <st3@riseup.net>
+  * Copyright (C) 2005 Danny van Dyk <kugelfang@gentoo.org>
+@@ -14,9 +14,10 @@
+ #include "ssb_private.h"
+ 
+ #include <linux/ctype.h>
++#include <linux/slab.h>
+ 
+ 
+-static const struct ssb_sprom *fallback_sprom;
++static int(*get_fallback_sprom)(struct ssb_bus *dev, struct ssb_sprom *out);
+ 
+ 
+ static int sprom2hex(const u16 *sprom, char *buf, size_t buf_len,
+@@ -102,6 +103,7 @@ ssize_t ssb_attr_sprom_store(struct ssb_
+ 	u16 *sprom;
+ 	int res = 0, err = -ENOMEM;
+ 	size_t sprom_size_words = bus->sprom_size;
++	struct ssb_freeze_context freeze;
+ 
+ 	sprom = kcalloc(bus->sprom_size, sizeof(u16), GFP_KERNEL);
+ 	if (!sprom)
+@@ -123,18 +125,13 @@ ssize_t ssb_attr_sprom_store(struct ssb_
+ 	err = -ERESTARTSYS;
+ 	if (mutex_lock_interruptible(&bus->sprom_mutex))
+ 		goto out_kfree;
+-	err = ssb_devices_freeze(bus);
+-	if (err == -EOPNOTSUPP) {
+-		ssb_printk(KERN_ERR PFX "SPROM write: Could not freeze devices. "
+-			   "No suspend support. Is CONFIG_PM enabled?\n");
+-		goto out_unlock;
+-	}
++	err = ssb_devices_freeze(bus, &freeze);
+ 	if (err) {
+ 		ssb_printk(KERN_ERR PFX "SPROM write: Could not freeze all devices\n");
+ 		goto out_unlock;
+ 	}
+ 	res = sprom_write(bus, sprom);
+-	err = ssb_devices_thaw(bus);
++	err = ssb_devices_thaw(&freeze);
+ 	if (err)
+ 		ssb_printk(KERN_ERR PFX "SPROM write: Could not thaw all devices\n");
+ out_unlock:
+@@ -148,34 +145,56 @@ out:
+ }
+ 
+ /**
+- * ssb_arch_set_fallback_sprom - Set a fallback SPROM for use if no SPROM is found.
+- *
+- * @sprom: The SPROM data structure to register.
++ * ssb_arch_register_fallback_sprom - Registers a method providing a
++ * fallback SPROM if no SPROM is found.
+  *
+- * With this function the architecture implementation may register a fallback
+- * SPROM data structure. The fallback is only used for PCI based SSB devices,
+- * where no valid SPROM can be found in the shadow registers.
++ * @sprom_callback: The callback function.
+  *
+- * This function is useful for weird architectures that have a half-assed SSB device
+- * hardwired to their PCI bus.
++ * With this function the architecture implementation may register a
++ * callback handler which fills the SPROM data structure. The fallback is
++ * only used for PCI based SSB devices, where no valid SPROM can be found
++ * in the shadow registers.
++ *
++ * This function is useful for weird architectures that have a half-assed
++ * SSB device hardwired to their PCI bus.
++ *
++ * Note that it does only work with PCI attached SSB devices. PCMCIA
++ * devices currently don't use this fallback.
++ * Architectures must provide the SPROM for native SSB devices anyway, so
++ * the fallback also isn't used for native devices.
+  *
+- * Note that it does only work with PCI attached SSB devices. PCMCIA devices currently
+- * don't use this fallback.
+- * Architectures must provide the SPROM for native SSB devices anyway,
+- * so the fallback also isn't used for native devices.
+- *
+- * This function is available for architecture code, only. So it is not exported.
++ * This function is available for architecture code, only. So it is not
++ * exported.
+  */
+-int ssb_arch_set_fallback_sprom(const struct ssb_sprom *sprom)
++int ssb_arch_register_fallback_sprom(int (*sprom_callback)(struct ssb_bus *bus,
++				     struct ssb_sprom *out))
+ {
+-	if (fallback_sprom)
++	if (get_fallback_sprom)
+ 		return -EEXIST;
+-	fallback_sprom = sprom;
++	get_fallback_sprom = sprom_callback;
+ 
+ 	return 0;
+ }
+ 
+-const struct ssb_sprom *ssb_get_fallback_sprom(void)
++int ssb_fill_sprom_with_fallback(struct ssb_bus *bus, struct ssb_sprom *out)
+ {
+-	return fallback_sprom;
++	if (!get_fallback_sprom)
++		return -ENOENT;
++
++	return get_fallback_sprom(bus, out);
++}
++
++/* http://bcm-v4.sipsolutions.net/802.11/IsSpromAvailable */
++bool ssb_is_sprom_available(struct ssb_bus *bus)
++{
++	/* status register only exists on chipcomon rev >= 11 and we need check
++	   for >= 31 only */
++	/* this routine differs from specs as we do not access SPROM directly
++	   on PCMCIA */
++	if (bus->bustype == SSB_BUSTYPE_PCI &&
++	    bus->chipco.dev &&	/* can be unavailable! */
++	    bus->chipco.dev->id.revision >= 31)
++		return bus->chipco.capabilities & SSB_CHIPCO_CAP_SPROM;
++
++	return true;
+ }
+--- a/drivers/ssb/ssb_private.h
++++ b/drivers/ssb/ssb_private.h
+@@ -114,6 +114,46 @@ static inline int ssb_pcmcia_init(struct
+ }
+ #endif /* CONFIG_SSB_PCMCIAHOST */
+ 
++/* sdio.c */
++#ifdef CONFIG_SSB_SDIOHOST
++extern int ssb_sdio_get_invariants(struct ssb_bus *bus,
++				     struct ssb_init_invariants *iv);
++
++extern u32 ssb_sdio_scan_read32(struct ssb_bus *bus, u16 offset);
++extern int ssb_sdio_switch_core(struct ssb_bus *bus, struct ssb_device *dev);
++extern int ssb_sdio_scan_switch_coreidx(struct ssb_bus *bus, u8 coreidx);
++extern int ssb_sdio_hardware_setup(struct ssb_bus *bus);
++extern void ssb_sdio_exit(struct ssb_bus *bus);
++extern int ssb_sdio_init(struct ssb_bus *bus);
++
++extern const struct ssb_bus_ops ssb_sdio_ops;
++#else /* CONFIG_SSB_SDIOHOST */
++static inline u32 ssb_sdio_scan_read32(struct ssb_bus *bus, u16 offset)
++{
++	return 0;
++}
++static inline int ssb_sdio_switch_core(struct ssb_bus *bus,
++					 struct ssb_device *dev)
++{
++	return 0;
++}
++static inline int ssb_sdio_scan_switch_coreidx(struct ssb_bus *bus, u8 coreidx)
++{
++	return 0;
++}
++static inline int ssb_sdio_hardware_setup(struct ssb_bus *bus)
++{
++	return 0;
++}
++static inline void ssb_sdio_exit(struct ssb_bus *bus)
++{
++}
++static inline int ssb_sdio_init(struct ssb_bus *bus)
++{
++	return 0;
++}
++#endif /* CONFIG_SSB_SDIOHOST */
++
+ 
+ /* scan.c */
+ extern const char *ssb_core_name(u16 coreid);
+@@ -131,24 +171,33 @@ ssize_t ssb_attr_sprom_store(struct ssb_
+ 			     const char *buf, size_t count,
+ 			     int (*sprom_check_crc)(const u16 *sprom, size_t size),
+ 			     int (*sprom_write)(struct ssb_bus *bus, const u16 *sprom));
+-extern const struct ssb_sprom *ssb_get_fallback_sprom(void);
++extern int ssb_fill_sprom_with_fallback(struct ssb_bus *bus,
++					struct ssb_sprom *out);
+ 
+ 
+ /* core.c */
+ extern u32 ssb_calc_clock_rate(u32 plltype, u32 n, u32 m);
+-extern int ssb_devices_freeze(struct ssb_bus *bus);
+-extern int ssb_devices_thaw(struct ssb_bus *bus);
+ extern struct ssb_bus *ssb_pci_dev_to_bus(struct pci_dev *pdev);
+ int ssb_for_each_bus_call(unsigned long data,
+ 			  int (*func)(struct ssb_bus *bus, unsigned long data));
+ extern struct ssb_bus *ssb_pcmcia_dev_to_bus(struct pcmcia_device *pdev);
+ 
++struct ssb_freeze_context {
++	/* Pointer to the bus */
++	struct ssb_bus *bus;
++	/* Boolean list to indicate whether a device is frozen on this bus. */
++	bool device_frozen[SSB_MAX_NR_CORES];
++};
++extern int ssb_devices_freeze(struct ssb_bus *bus, struct ssb_freeze_context *ctx);
++extern int ssb_devices_thaw(struct ssb_freeze_context *ctx);
++
++
+ 
+ /* b43_pci_bridge.c */
+ #ifdef CONFIG_SSB_B43_PCI_BRIDGE
+ extern int __init b43_pci_ssb_bridge_init(void);
+ extern void __exit b43_pci_ssb_bridge_exit(void);
+-#else /* CONFIG_SSB_B43_PCI_BRIDGR */
++#else /* CONFIG_SSB_B43_PCI_BRIDGE */
+ static inline int b43_pci_ssb_bridge_init(void)
+ {
+ 	return 0;
+@@ -156,6 +205,10 @@ static inline int b43_pci_ssb_bridge_ini
+ static inline void b43_pci_ssb_bridge_exit(void)
+ {
+ }
+-#endif /* CONFIG_SSB_PCIHOST */
++#endif /* CONFIG_SSB_B43_PCI_BRIDGE */
++
++/* driver_chipcommon_pmu.c */
++extern u32 ssb_pmu_get_cpu_clock(struct ssb_chipcommon *cc);
++extern u32 ssb_pmu_get_controlclock(struct ssb_chipcommon *cc);
+ 
+ #endif /* LINUX_SSB_PRIVATE_H_ */
+--- a/include/linux/pci_ids.h
++++ b/include/linux/pci_ids.h
+@@ -2017,6 +2017,7 @@
+ #define PCI_DEVICE_ID_AFAVLAB_P030	0x2182
+ #define PCI_SUBDEVICE_ID_AFAVLAB_P061		0x2150
+ 
++#define PCI_VENDOR_ID_BCM_GVC          0x14a4
+ #define PCI_VENDOR_ID_BROADCOM		0x14e4
+ #define PCI_DEVICE_ID_TIGON3_5752	0x1600
+ #define PCI_DEVICE_ID_TIGON3_5752M	0x1601
+--- a/include/linux/ssb/ssb.h
++++ b/include/linux/ssb/ssb.h
+@@ -16,6 +16,12 @@ struct pcmcia_device;
+ struct ssb_bus;
+ struct ssb_driver;
+ 
++struct ssb_sprom_core_pwr_info {
++	u8 itssi_2g, itssi_5g;
++	u8 maxpwr_2g, maxpwr_5gl, maxpwr_5g, maxpwr_5gh;
++	u16 pa_2g[4], pa_5gl[4], pa_5g[4], pa_5gh[4];
++};
++
+ struct ssb_sprom {
+ 	u8 revision;
+ 	u8 il0mac[6];		/* MAC address for 802.11b/g */
+@@ -25,47 +31,164 @@ struct ssb_sprom {
+ 	u8 et1phyaddr;		/* MII address for enet1 */
+ 	u8 et0mdcport;		/* MDIO for enet0 */
+ 	u8 et1mdcport;		/* MDIO for enet1 */
+-	u8 board_rev;		/* Board revision number from SPROM. */
++	u16 board_rev;		/* Board revision number from SPROM. */
++	u16 board_num;		/* Board number from SPROM. */
++	u16 board_type;		/* Board type from SPROM. */
+ 	u8 country_code;	/* Country Code */
+-	u8 ant_available_a;	/* A-PHY antenna available bits (up to 4) */
+-	u8 ant_available_bg;	/* B/G-PHY antenna available bits (up to 4) */
++	char alpha2[2];		/* Country Code as two chars like EU or US */
++	u8 leddc_on_time;	/* LED Powersave Duty Cycle On Count */
++	u8 leddc_off_time;	/* LED Powersave Duty Cycle Off Count */
++	u8 ant_available_a;	/* 2GHz antenna available bits (up to 4) */
++	u8 ant_available_bg;	/* 5GHz antenna available bits (up to 4) */
+ 	u16 pa0b0;
+ 	u16 pa0b1;
+ 	u16 pa0b2;
+ 	u16 pa1b0;
+ 	u16 pa1b1;
+ 	u16 pa1b2;
++	u16 pa1lob0;
++	u16 pa1lob1;
++	u16 pa1lob2;
++	u16 pa1hib0;
++	u16 pa1hib1;
++	u16 pa1hib2;
+ 	u8 gpio0;		/* GPIO pin 0 */
+ 	u8 gpio1;		/* GPIO pin 1 */
+ 	u8 gpio2;		/* GPIO pin 2 */
+ 	u8 gpio3;		/* GPIO pin 3 */
+-	u16 maxpwr_a;		/* A-PHY Amplifier Max Power (in dBm Q5.2) */
+-	u16 maxpwr_bg;		/* B/G-PHY Amplifier Max Power (in dBm Q5.2) */
++	u8 maxpwr_bg;		/* 2.4GHz Amplifier Max Power (in dBm Q5.2) */
++	u8 maxpwr_al;		/* 5.2GHz Amplifier Max Power (in dBm Q5.2) */
++	u8 maxpwr_a;		/* 5.3GHz Amplifier Max Power (in dBm Q5.2) */
++	u8 maxpwr_ah;		/* 5.8GHz Amplifier Max Power (in dBm Q5.2) */
+ 	u8 itssi_a;		/* Idle TSSI Target for A-PHY */
+ 	u8 itssi_bg;		/* Idle TSSI Target for B/G-PHY */
+-	u16 boardflags_lo;	/* Boardflags (low 16 bits) */
+-	u16 boardflags_hi;	/* Boardflags (high 16 bits) */
++	u8 tri2g;		/* 2.4GHz TX isolation */
++	u8 tri5gl;		/* 5.2GHz TX isolation */
++	u8 tri5g;		/* 5.3GHz TX isolation */
++	u8 tri5gh;		/* 5.8GHz TX isolation */
++	u8 txpid2g[4];		/* 2GHz TX power index */
++	u8 txpid5gl[4];		/* 4.9 - 5.1GHz TX power index */
++	u8 txpid5g[4];		/* 5.1 - 5.5GHz TX power index */
++	u8 txpid5gh[4];		/* 5.5 - ...GHz TX power index */
++	s8 rxpo2g;		/* 2GHz RX power offset */
++	s8 rxpo5g;		/* 5GHz RX power offset */
++	u8 rssisav2g;		/* 2GHz RSSI params */
++	u8 rssismc2g;
++	u8 rssismf2g;
++	u8 bxa2g;		/* 2GHz BX arch */
++	u8 rssisav5g;		/* 5GHz RSSI params */
++	u8 rssismc5g;
++	u8 rssismf5g;
++	u8 bxa5g;		/* 5GHz BX arch */
++	u16 cck2gpo;		/* CCK power offset */
++	u32 ofdm2gpo;		/* 2.4GHz OFDM power offset */
++	u32 ofdm5glpo;		/* 5.2GHz OFDM power offset */
++	u32 ofdm5gpo;		/* 5.3GHz OFDM power offset */
++	u32 ofdm5ghpo;		/* 5.8GHz OFDM power offset */
++	u16 boardflags_lo;	/* Board flags (bits 0-15) */
++	u16 boardflags_hi;	/* Board flags (bits 16-31) */
++	u16 boardflags2_lo;	/* Board flags (bits 32-47) */
++	u16 boardflags2_hi;	/* Board flags (bits 48-63) */
++	/* TODO store board flags in a single u64 */
++
++	struct ssb_sprom_core_pwr_info core_pwr_info[4];
+ 
+ 	/* Antenna gain values for up to 4 antennas
+ 	 * on each band. Values in dBm/4 (Q5.2). Negative gain means the
+ 	 * loss in the connectors is bigger than the gain. */
+ 	struct {
+-		struct {
+-			s8 a0, a1, a2, a3;
+-		} ghz24;	/* 2.4GHz band */
+-		struct {
+-			s8 a0, a1, a2, a3;
+-		} ghz5;		/* 5GHz band */
++		s8 a0, a1, a2, a3;
+ 	} antenna_gain;
+ 
+-	/* TODO - add any parameters needed from rev 2, 3, or 4 SPROMs */
++	struct {
++		struct {
++			u8 tssipos, extpa_gain, pdet_range, tr_iso, antswlut;
++		} ghz2;
++		struct {
++			u8 tssipos, extpa_gain, pdet_range, tr_iso, antswlut;
++		} ghz5;
++	} fem;
++
++	u16 mcs2gpo[8];
++	u16 mcs5gpo[8];
++	u16 mcs5glpo[8];
++	u16 mcs5ghpo[8];
++	u8 opo;
++
++	u8 rxgainerr2ga[3];
++	u8 rxgainerr5gla[3];
++	u8 rxgainerr5gma[3];
++	u8 rxgainerr5gha[3];
++	u8 rxgainerr5gua[3];
++
++	u8 noiselvl2ga[3];
++	u8 noiselvl5gla[3];
++	u8 noiselvl5gma[3];
++	u8 noiselvl5gha[3];
++	u8 noiselvl5gua[3];
++
++	u8 regrev;
++	u8 txchain;
++	u8 rxchain;
++	u8 antswitch;
++	u16 cddpo;
++	u16 stbcpo;
++	u16 bw40po;
++	u16 bwduppo;
++
++	u8 tempthresh;
++	u8 tempoffset;
++	u16 rawtempsense;
++	u8 measpower;
++	u8 tempsense_slope;
++	u8 tempcorrx;
++	u8 tempsense_option;
++	u8 freqoffset_corr;
++	u8 iqcal_swp_dis;
++	u8 hw_iqcal_en;
++	u8 elna2g;
++	u8 elna5g;
++	u8 phycal_tempdelta;
++	u8 temps_period;
++	u8 temps_hysteresis;
++	u8 measpower1;
++	u8 measpower2;
++	u8 pcieingress_war;
++
++	/* power per rate from sromrev 9 */
++	u16 cckbw202gpo;
++	u16 cckbw20ul2gpo;
++	u32 legofdmbw202gpo;
++	u32 legofdmbw20ul2gpo;
++	u32 legofdmbw205glpo;
++	u32 legofdmbw20ul5glpo;
++	u32 legofdmbw205gmpo;
++	u32 legofdmbw20ul5gmpo;
++	u32 legofdmbw205ghpo;
++	u32 legofdmbw20ul5ghpo;
++	u32 mcsbw202gpo;
++	u32 mcsbw20ul2gpo;
++	u32 mcsbw402gpo;
++	u32 mcsbw205glpo;
++	u32 mcsbw20ul5glpo;
++	u32 mcsbw405glpo;
++	u32 mcsbw205gmpo;
++	u32 mcsbw20ul5gmpo;
++	u32 mcsbw405gmpo;
++	u32 mcsbw205ghpo;
++	u32 mcsbw20ul5ghpo;
++	u32 mcsbw405ghpo;
++	u16 mcs32po;
++	u16 legofdm40duppo;
++	u8 sar2g;
++	u8 sar5g;
+ };
+ 
+ /* Information about the PCB the circuitry is soldered on. */
+ struct ssb_boardinfo {
+ 	u16 vendor;
+ 	u16 type;
+-	u16 rev;
++	u8  rev;
+ };
+ 
+ 
+@@ -137,7 +260,7 @@ struct ssb_device {
+ 	 * is an optimization. */
+ 	const struct ssb_bus_ops *ops;
+ 
+-	struct device *dev;
++	struct device *dev, *dma_dev;
+ 
+ 	struct ssb_bus *bus;
+ 	struct ssb_device_id id;
+@@ -195,10 +318,9 @@ struct ssb_driver {
+ #define drv_to_ssb_drv(_drv) container_of(_drv, struct ssb_driver, drv)
+ 
+ extern int __ssb_driver_register(struct ssb_driver *drv, struct module *owner);
+-static inline int ssb_driver_register(struct ssb_driver *drv)
+-{
+-	return __ssb_driver_register(drv, THIS_MODULE);
+-}
++#define ssb_driver_register(drv) \
++	__ssb_driver_register(drv, THIS_MODULE)
++
+ extern void ssb_driver_unregister(struct ssb_driver *drv);
+ 
+ 
+@@ -208,6 +330,7 @@ enum ssb_bustype {
+ 	SSB_BUSTYPE_SSB,	/* This SSB bus is the system bus */
+ 	SSB_BUSTYPE_PCI,	/* SSB is connected to PCI bus */
+ 	SSB_BUSTYPE_PCMCIA,	/* SSB is connected to PCMCIA bus */
++	SSB_BUSTYPE_SDIO,	/* SSB is connected to SDIO bus */
+ };
+ 
+ /* board_vendor */
+@@ -238,20 +361,33 @@ struct ssb_bus {
+ 
+ 	const struct ssb_bus_ops *ops;
+ 
+-	/* The core in the basic address register window. (PCI bus only) */
++	/* The core currently mapped into the MMIO window.
++	 * Not valid on all host-buses. So don't use outside of SSB. */
+ 	struct ssb_device *mapped_device;
+-	/* Currently mapped PCMCIA segment. (bustype == SSB_BUSTYPE_PCMCIA only) */
+-	u8 mapped_pcmcia_seg;
++	union {
++		/* Currently mapped PCMCIA segment. (bustype == SSB_BUSTYPE_PCMCIA only) */
++		u8 mapped_pcmcia_seg;
++		/* Current SSB base address window for SDIO. */
++		u32 sdio_sbaddr;
++	};
+ 	/* Lock for core and segment switching.
+ 	 * On PCMCIA-host busses this is used to protect the whole MMIO access. */
+ 	spinlock_t bar_lock;
+ 
+-	/* The bus this backplane is running on. */
++	/* The host-bus this backplane is running on. */
+ 	enum ssb_bustype bustype;
+-	/* Pointer to the PCI bus (only valid if bustype == SSB_BUSTYPE_PCI). */
+-	struct pci_dev *host_pci;
+-	/* Pointer to the PCMCIA device (only if bustype == SSB_BUSTYPE_PCMCIA). */
+-	struct pcmcia_device *host_pcmcia;
++	/* Pointers to the host-bus. Check bustype before using any of these pointers. */
++	union {
++		/* Pointer to the PCI bus (only valid if bustype == SSB_BUSTYPE_PCI). */
++		struct pci_dev *host_pci;
++		/* Pointer to the PCMCIA device (only if bustype == SSB_BUSTYPE_PCMCIA). */
++		struct pcmcia_device *host_pcmcia;
++		/* Pointer to the SDIO device (only if bustype == SSB_BUSTYPE_SDIO). */
++		struct sdio_func *host_sdio;
++	};
++
++	/* See enum ssb_quirks */
++	unsigned int quirks;
+ 
+ #ifdef CONFIG_SSB_SPROM
+ 	/* Mutex to protect the SPROM writing. */
+@@ -260,7 +396,8 @@ struct ssb_bus {
+ 
+ 	/* ID information about the Chip. */
+ 	u16 chip_id;
+-	u16 chip_rev;
++	u8 chip_rev;
++	u16 sprom_offset;
+ 	u16 sprom_size;		/* number of words in sprom */
+ 	u8 chip_package;
+ 
+@@ -306,6 +443,11 @@ struct ssb_bus {
+ #endif /* DEBUG */
+ };
+ 
++enum ssb_quirks {
++	/* SDIO connected card requires performing a read after writing a 32-bit value */
++	SSB_QUIRK_SDIO_READ_AFTER_WRITE32	= (1 << 0),
++};
++
+ /* The initialization-invariants. */
+ struct ssb_init_invariants {
+ 	/* Versioning information about the PCB. */
+@@ -336,12 +478,23 @@ extern int ssb_bus_pcmciabus_register(st
+ 				      struct pcmcia_device *pcmcia_dev,
+ 				      unsigned long baseaddr);
+ #endif /* CONFIG_SSB_PCMCIAHOST */
++#ifdef CONFIG_SSB_SDIOHOST
++extern int ssb_bus_sdiobus_register(struct ssb_bus *bus,
++				    struct sdio_func *sdio_func,
++				    unsigned int quirks);
++#endif /* CONFIG_SSB_SDIOHOST */
++
+ 
+ extern void ssb_bus_unregister(struct ssb_bus *bus);
+ 
++/* Does the device have an SPROM? */
++extern bool ssb_is_sprom_available(struct ssb_bus *bus);
++
+ /* Set a fallback SPROM.
+  * See kdoc at the function definition for complete documentation. */
+-extern int ssb_arch_set_fallback_sprom(const struct ssb_sprom *sprom);
++extern int ssb_arch_register_fallback_sprom(
++		int (*sprom_callback)(struct ssb_bus *bus,
++		struct ssb_sprom *out));
+ 
+ /* Suspend a SSB bus.
+  * Call this from the parent bus suspend routine. */
+@@ -612,6 +765,7 @@ extern int ssb_bus_may_powerdown(struct
+  * Otherwise static always-on powercontrol will be used. */
+ extern int ssb_bus_powerup(struct ssb_bus *bus, bool dynamic_pctl);
+ 
++extern void ssb_commit_settings(struct ssb_bus *bus);
+ 
+ /* Various helper functions */
+ extern u32 ssb_admatch_base(u32 adm);
+--- a/include/linux/ssb/ssb_driver_chipcommon.h
++++ b/include/linux/ssb/ssb_driver_chipcommon.h
+@@ -8,7 +8,7 @@
+  * gpio interface, extbus, and support for serial and parallel flashes.
+  *
+  * Copyright 2005, Broadcom Corporation
+- * Copyright 2006, Michael Buesch <mb@bu3sch.de>
++ * Copyright 2006, Michael Buesch <m@bues.ch>
+  *
+  * Licensed under the GPL version 2. See COPYING for details.
+  */
+@@ -53,6 +53,7 @@
+ #define  SSB_CHIPCO_CAP_64BIT		0x08000000	/* 64-bit Backplane */
+ #define  SSB_CHIPCO_CAP_PMU		0x10000000	/* PMU available (rev >= 20) */
+ #define  SSB_CHIPCO_CAP_ECI		0x20000000	/* ECI available (rev >= 20) */
++#define  SSB_CHIPCO_CAP_SPROM		0x40000000	/* SPROM present */
+ #define SSB_CHIPCO_CORECTL		0x0008
+ #define  SSB_CHIPCO_CORECTL_UARTCLK0	0x00000001	/* Drive UART with internal clock */
+ #define	 SSB_CHIPCO_CORECTL_SE		0x00000002	/* sync clk out enable (corerev >= 3) */
+@@ -122,6 +123,8 @@
+ #define SSB_CHIPCO_FLASHDATA		0x0048
+ #define SSB_CHIPCO_BCAST_ADDR		0x0050
+ #define SSB_CHIPCO_BCAST_DATA		0x0054
++#define SSB_CHIPCO_GPIOPULLUP		0x0058		/* Rev >= 20 only */
++#define SSB_CHIPCO_GPIOPULLDOWN		0x005C		/* Rev >= 20 only */
+ #define SSB_CHIPCO_GPIOIN		0x0060
+ #define SSB_CHIPCO_GPIOOUT		0x0064
+ #define SSB_CHIPCO_GPIOOUTEN		0x0068
+@@ -130,6 +133,9 @@
+ #define SSB_CHIPCO_GPIOIRQ		0x0074
+ #define SSB_CHIPCO_WATCHDOG		0x0080
+ #define SSB_CHIPCO_GPIOTIMER		0x0088		/* LED powersave (corerev >= 16) */
++#define  SSB_CHIPCO_GPIOTIMER_OFFTIME	0x0000FFFF
++#define  SSB_CHIPCO_GPIOTIMER_OFFTIME_SHIFT	0
++#define  SSB_CHIPCO_GPIOTIMER_ONTIME	0xFFFF0000
+ #define  SSB_CHIPCO_GPIOTIMER_ONTIME_SHIFT	16
+ #define SSB_CHIPCO_GPIOTOUTM		0x008C		/* LED powersave (corerev >= 16) */
+ #define SSB_CHIPCO_CLOCK_N		0x0090
+@@ -188,8 +194,10 @@
+ #define  SSB_CHIPCO_CLKCTLST_HAVEALPREQ	0x00000008 /* ALP available request */
+ #define  SSB_CHIPCO_CLKCTLST_HAVEHTREQ	0x00000010 /* HT available request */
+ #define  SSB_CHIPCO_CLKCTLST_HWCROFF	0x00000020 /* Force HW clock request off */
+-#define  SSB_CHIPCO_CLKCTLST_HAVEHT	0x00010000 /* HT available */
+-#define  SSB_CHIPCO_CLKCTLST_HAVEALP	0x00020000 /* APL available */
++#define  SSB_CHIPCO_CLKCTLST_HAVEALP	0x00010000 /* ALP available */
++#define  SSB_CHIPCO_CLKCTLST_HAVEHT	0x00020000 /* HT available */
++#define  SSB_CHIPCO_CLKCTLST_4328A0_HAVEHT	0x00010000 /* 4328a0 has reversed bits */
++#define  SSB_CHIPCO_CLKCTLST_4328A0_HAVEALP	0x00020000 /* 4328a0 has reversed bits */
+ #define SSB_CHIPCO_HW_WORKAROUND	0x01E4 /* Hardware workaround (rev >= 20) */
+ #define SSB_CHIPCO_UART0_DATA		0x0300
+ #define SSB_CHIPCO_UART0_IMR		0x0304
+@@ -385,6 +393,7 @@
+ 
+ 
+ /** Chip specific Chip-Status register contents. */
++#define SSB_CHIPCO_CHST_4322_SPROM_EXISTS	0x00000040 /* SPROM present */
+ #define SSB_CHIPCO_CHST_4325_SPROM_OTP_SEL	0x00000003
+ #define SSB_CHIPCO_CHST_4325_DEFCIS_SEL		0 /* OTP is powered up, use def. CIS, no SPROM */
+ #define SSB_CHIPCO_CHST_4325_SPROM_SEL		1 /* OTP is powered up, SPROM is present */
+@@ -398,6 +407,18 @@
+ #define SSB_CHIPCO_CHST_4325_RCAL_VALUE_SHIFT	4
+ #define SSB_CHIPCO_CHST_4325_PMUTOP_2B 		0x00000200 /* 1 for 2b, 0 for to 2a */
+ 
++/** Macros to determine SPROM presence based on Chip-Status register. */
++#define SSB_CHIPCO_CHST_4312_SPROM_PRESENT(status) \
++	((status & SSB_CHIPCO_CHST_4325_SPROM_OTP_SEL) != \
++		SSB_CHIPCO_CHST_4325_OTP_SEL)
++#define SSB_CHIPCO_CHST_4322_SPROM_PRESENT(status) \
++	(status & SSB_CHIPCO_CHST_4322_SPROM_EXISTS)
++#define SSB_CHIPCO_CHST_4325_SPROM_PRESENT(status) \
++	(((status & SSB_CHIPCO_CHST_4325_SPROM_OTP_SEL) != \
++		SSB_CHIPCO_CHST_4325_DEFCIS_SEL) && \
++	 ((status & SSB_CHIPCO_CHST_4325_SPROM_OTP_SEL) != \
++		SSB_CHIPCO_CHST_4325_OTP_SEL))
++
+ 
+ 
+ /** Clockcontrol masks and values **/
+@@ -564,6 +585,7 @@ struct ssb_chipcommon_pmu {
+ struct ssb_chipcommon {
+ 	struct ssb_device *dev;
+ 	u32 capabilities;
++	u32 status;
+ 	/* Fast Powerup Delay constant */
+ 	u16 fast_pwrup_delay;
+ 	struct ssb_chipcommon_pmu pmu;
+@@ -629,5 +651,15 @@ extern int ssb_chipco_serial_init(struct
+ /* PMU support */
+ extern void ssb_pmu_init(struct ssb_chipcommon *cc);
+ 
++enum ssb_pmu_ldo_volt_id {
++	LDO_PAREF = 0,
++	LDO_VOLT1,
++	LDO_VOLT2,
++	LDO_VOLT3,
++};
++
++void ssb_pmu_set_ldo_voltage(struct ssb_chipcommon *cc,
++			     enum ssb_pmu_ldo_volt_id id, u32 voltage);
++void ssb_pmu_set_ldo_paref(struct ssb_chipcommon *cc, bool on);
+ 
+ #endif /* LINUX_SSB_CHIPCO_H_ */
+--- a/include/linux/ssb/ssb_regs.h
++++ b/include/linux/ssb/ssb_regs.h
+@@ -85,6 +85,8 @@
+ #define  SSB_IMSTATE_AP_RSV	0x00000030 /* Reserved */
+ #define  SSB_IMSTATE_IBE	0x00020000 /* In Band Error */
+ #define  SSB_IMSTATE_TO		0x00040000 /* Timeout */
++#define  SSB_IMSTATE_BUSY	0x01800000 /* Busy (Backplane rev >= 2.3 only) */
++#define  SSB_IMSTATE_REJECT	0x02000000 /* Reject (Backplane rev >= 2.3 only) */
+ #define SSB_INTVEC		0x0F94     /* SB Interrupt Mask */
+ #define  SSB_INTVEC_PCI		0x00000001 /* Enable interrupts for PCI */
+ #define  SSB_INTVEC_ENET0	0x00000002 /* Enable interrupts for enet 0 */
+@@ -95,7 +97,7 @@
+ #define  SSB_INTVEC_ENET1	0x00000040 /* Enable interrupts for enet 1 */
+ #define SSB_TMSLOW		0x0F98     /* SB Target State Low */
+ #define  SSB_TMSLOW_RESET	0x00000001 /* Reset */
+-#define  SSB_TMSLOW_REJECT_22	0x00000002 /* Reject (Backplane rev 2.2) */
++#define  SSB_TMSLOW_REJECT	0x00000002 /* Reject (Standard Backplane) */
+ #define  SSB_TMSLOW_REJECT_23	0x00000004 /* Reject (Backplane rev 2.3) */
+ #define  SSB_TMSLOW_CLOCK	0x00010000 /* Clock Enable */
+ #define  SSB_TMSLOW_FGC		0x00020000 /* Force Gated Clocks On */
+@@ -162,7 +164,7 @@
+ 
+ /* SPROM shadow area. If not otherwise noted, fields are
+  * two bytes wide. Note that the SPROM can _only_ be read
+- * in two-byte quantinies.
++ * in two-byte quantities.
+  */
+ #define SSB_SPROMSIZE_WORDS		64
+ #define SSB_SPROMSIZE_BYTES		(SSB_SPROMSIZE_WORDS * sizeof(u16))
+@@ -170,26 +172,27 @@
+ #define SSB_SPROMSIZE_WORDS_R4		220
+ #define SSB_SPROMSIZE_BYTES_R123	(SSB_SPROMSIZE_WORDS_R123 * sizeof(u16))
+ #define SSB_SPROMSIZE_BYTES_R4		(SSB_SPROMSIZE_WORDS_R4 * sizeof(u16))
+-#define SSB_SPROM_BASE			0x1000
+-#define SSB_SPROM_REVISION		0x107E
++#define SSB_SPROM_BASE1			0x1000
++#define SSB_SPROM_BASE31		0x0800
++#define SSB_SPROM_REVISION		0x007E
+ #define  SSB_SPROM_REVISION_REV		0x00FF	/* SPROM Revision number */
+ #define  SSB_SPROM_REVISION_CRC		0xFF00	/* SPROM CRC8 value */
+ #define  SSB_SPROM_REVISION_CRC_SHIFT	8
+ 
+ /* SPROM Revision 1 */
+-#define SSB_SPROM1_SPID			0x1004	/* Subsystem Product ID for PCI */
+-#define SSB_SPROM1_SVID			0x1006	/* Subsystem Vendor ID for PCI */
+-#define SSB_SPROM1_PID			0x1008	/* Product ID for PCI */
+-#define SSB_SPROM1_IL0MAC		0x1048	/* 6 bytes MAC address for 802.11b/g */
+-#define SSB_SPROM1_ET0MAC		0x104E	/* 6 bytes MAC address for Ethernet */
+-#define SSB_SPROM1_ET1MAC		0x1054	/* 6 bytes MAC address for 802.11a */
+-#define SSB_SPROM1_ETHPHY		0x105A	/* Ethernet PHY settings */
++#define SSB_SPROM1_SPID			0x0004	/* Subsystem Product ID for PCI */
++#define SSB_SPROM1_SVID			0x0006	/* Subsystem Vendor ID for PCI */
++#define SSB_SPROM1_PID			0x0008	/* Product ID for PCI */
++#define SSB_SPROM1_IL0MAC		0x0048	/* 6 bytes MAC address for 802.11b/g */
++#define SSB_SPROM1_ET0MAC		0x004E	/* 6 bytes MAC address for Ethernet */
++#define SSB_SPROM1_ET1MAC		0x0054	/* 6 bytes MAC address for 802.11a */
++#define SSB_SPROM1_ETHPHY		0x005A	/* Ethernet PHY settings */
+ #define  SSB_SPROM1_ETHPHY_ET0A		0x001F	/* MII Address for enet0 */
+ #define  SSB_SPROM1_ETHPHY_ET1A		0x03E0	/* MII Address for enet1 */
+ #define  SSB_SPROM1_ETHPHY_ET1A_SHIFT	5
+ #define  SSB_SPROM1_ETHPHY_ET0M		(1<<14)	/* MDIO for enet0 */
+ #define  SSB_SPROM1_ETHPHY_ET1M		(1<<15)	/* MDIO for enet1 */
+-#define SSB_SPROM1_BINF			0x105C	/* Board info */
++#define SSB_SPROM1_BINF			0x005C	/* Board info */
+ #define  SSB_SPROM1_BINF_BREV		0x00FF	/* Board Revision */
+ #define  SSB_SPROM1_BINF_CCODE		0x0F00	/* Country Code */
+ #define  SSB_SPROM1_BINF_CCODE_SHIFT	8
+@@ -197,63 +200,63 @@
+ #define  SSB_SPROM1_BINF_ANTBG_SHIFT	12
+ #define  SSB_SPROM1_BINF_ANTA		0xC000	/* Available A-PHY antennas */
+ #define  SSB_SPROM1_BINF_ANTA_SHIFT	14
+-#define SSB_SPROM1_PA0B0		0x105E
+-#define SSB_SPROM1_PA0B1		0x1060
+-#define SSB_SPROM1_PA0B2		0x1062
+-#define SSB_SPROM1_GPIOA		0x1064	/* General Purpose IO pins 0 and 1 */
++#define SSB_SPROM1_PA0B0		0x005E
++#define SSB_SPROM1_PA0B1		0x0060
++#define SSB_SPROM1_PA0B2		0x0062
++#define SSB_SPROM1_GPIOA		0x0064	/* General Purpose IO pins 0 and 1 */
+ #define  SSB_SPROM1_GPIOA_P0		0x00FF	/* Pin 0 */
+ #define  SSB_SPROM1_GPIOA_P1		0xFF00	/* Pin 1 */
+ #define  SSB_SPROM1_GPIOA_P1_SHIFT	8
+-#define SSB_SPROM1_GPIOB		0x1066	/* General Purpuse IO pins 2 and 3 */
++#define SSB_SPROM1_GPIOB		0x0066	/* General Purpuse IO pins 2 and 3 */
+ #define  SSB_SPROM1_GPIOB_P2		0x00FF	/* Pin 2 */
+ #define  SSB_SPROM1_GPIOB_P3		0xFF00	/* Pin 3 */
+ #define  SSB_SPROM1_GPIOB_P3_SHIFT	8
+-#define SSB_SPROM1_MAXPWR		0x1068	/* Power Amplifier Max Power */
++#define SSB_SPROM1_MAXPWR		0x0068	/* Power Amplifier Max Power */
+ #define  SSB_SPROM1_MAXPWR_BG		0x00FF	/* B-PHY and G-PHY (in dBm Q5.2) */
+ #define  SSB_SPROM1_MAXPWR_A		0xFF00	/* A-PHY (in dBm Q5.2) */
+ #define  SSB_SPROM1_MAXPWR_A_SHIFT	8
+-#define SSB_SPROM1_PA1B0		0x106A
+-#define SSB_SPROM1_PA1B1		0x106C
+-#define SSB_SPROM1_PA1B2		0x106E
+-#define SSB_SPROM1_ITSSI		0x1070	/* Idle TSSI Target */
++#define SSB_SPROM1_PA1B0		0x006A
++#define SSB_SPROM1_PA1B1		0x006C
++#define SSB_SPROM1_PA1B2		0x006E
++#define SSB_SPROM1_ITSSI		0x0070	/* Idle TSSI Target */
+ #define  SSB_SPROM1_ITSSI_BG		0x00FF	/* B-PHY and G-PHY*/
+ #define  SSB_SPROM1_ITSSI_A		0xFF00	/* A-PHY */
+ #define  SSB_SPROM1_ITSSI_A_SHIFT	8
+-#define SSB_SPROM1_BFLLO		0x1072	/* Boardflags (low 16 bits) */
+-#define SSB_SPROM1_AGAIN		0x1074	/* Antenna Gain (in dBm Q5.2) */
++#define SSB_SPROM1_BFLLO		0x0072	/* Boardflags (low 16 bits) */
++#define SSB_SPROM1_AGAIN		0x0074	/* Antenna Gain (in dBm Q5.2) */
+ #define  SSB_SPROM1_AGAIN_BG		0x00FF	/* B-PHY and G-PHY */
+ #define  SSB_SPROM1_AGAIN_BG_SHIFT	0
+ #define  SSB_SPROM1_AGAIN_A		0xFF00	/* A-PHY */
+ #define  SSB_SPROM1_AGAIN_A_SHIFT	8
+ 
+ /* SPROM Revision 2 (inherits from rev 1) */
+-#define SSB_SPROM2_BFLHI		0x1038	/* Boardflags (high 16 bits) */
+-#define SSB_SPROM2_MAXP_A		0x103A	/* A-PHY Max Power */
++#define SSB_SPROM2_BFLHI		0x0038	/* Boardflags (high 16 bits) */
++#define SSB_SPROM2_MAXP_A		0x003A	/* A-PHY Max Power */
+ #define  SSB_SPROM2_MAXP_A_HI		0x00FF	/* Max Power High */
+ #define  SSB_SPROM2_MAXP_A_LO		0xFF00	/* Max Power Low */
+ #define  SSB_SPROM2_MAXP_A_LO_SHIFT	8
+-#define SSB_SPROM2_PA1LOB0		0x103C	/* A-PHY PowerAmplifier Low Settings */
+-#define SSB_SPROM2_PA1LOB1		0x103E	/* A-PHY PowerAmplifier Low Settings */
+-#define SSB_SPROM2_PA1LOB2		0x1040	/* A-PHY PowerAmplifier Low Settings */
+-#define SSB_SPROM2_PA1HIB0		0x1042	/* A-PHY PowerAmplifier High Settings */
+-#define SSB_SPROM2_PA1HIB1		0x1044	/* A-PHY PowerAmplifier High Settings */
+-#define SSB_SPROM2_PA1HIB2		0x1046	/* A-PHY PowerAmplifier High Settings */
+-#define SSB_SPROM2_OPO			0x1078	/* OFDM Power Offset from CCK Level */
++#define SSB_SPROM2_PA1LOB0		0x003C	/* A-PHY PowerAmplifier Low Settings */
++#define SSB_SPROM2_PA1LOB1		0x003E	/* A-PHY PowerAmplifier Low Settings */
++#define SSB_SPROM2_PA1LOB2		0x0040	/* A-PHY PowerAmplifier Low Settings */
++#define SSB_SPROM2_PA1HIB0		0x0042	/* A-PHY PowerAmplifier High Settings */
++#define SSB_SPROM2_PA1HIB1		0x0044	/* A-PHY PowerAmplifier High Settings */
++#define SSB_SPROM2_PA1HIB2		0x0046	/* A-PHY PowerAmplifier High Settings */
++#define SSB_SPROM2_OPO			0x0078	/* OFDM Power Offset from CCK Level */
+ #define  SSB_SPROM2_OPO_VALUE		0x00FF
+ #define  SSB_SPROM2_OPO_UNUSED		0xFF00
+-#define SSB_SPROM2_CCODE		0x107C	/* Two char Country Code */
++#define SSB_SPROM2_CCODE		0x007C	/* Two char Country Code */
+ 
+ /* SPROM Revision 3 (inherits most data from rev 2) */
+-#define SSB_SPROM3_IL0MAC		0x104A	/* 6 bytes MAC address for 802.11b/g */
+-#define SSB_SPROM3_OFDMAPO		0x102C	/* A-PHY OFDM Mid Power Offset (4 bytes, BigEndian) */
+-#define SSB_SPROM3_OFDMALPO		0x1030	/* A-PHY OFDM Low Power Offset (4 bytes, BigEndian) */
+-#define SSB_SPROM3_OFDMAHPO		0x1034	/* A-PHY OFDM High Power Offset (4 bytes, BigEndian) */
+-#define SSB_SPROM3_GPIOLDC		0x1042	/* GPIO LED Powersave Duty Cycle (4 bytes, BigEndian) */
++#define SSB_SPROM3_OFDMAPO		0x002C	/* A-PHY OFDM Mid Power Offset (4 bytes, BigEndian) */
++#define SSB_SPROM3_OFDMALPO		0x0030	/* A-PHY OFDM Low Power Offset (4 bytes, BigEndian) */
++#define SSB_SPROM3_OFDMAHPO		0x0034	/* A-PHY OFDM High Power Offset (4 bytes, BigEndian) */
++#define SSB_SPROM3_GPIOLDC		0x0042	/* GPIO LED Powersave Duty Cycle (4 bytes, BigEndian) */
+ #define  SSB_SPROM3_GPIOLDC_OFF		0x0000FF00	/* Off Count */
+ #define  SSB_SPROM3_GPIOLDC_OFF_SHIFT	8
+ #define  SSB_SPROM3_GPIOLDC_ON		0x00FF0000	/* On Count */
+ #define  SSB_SPROM3_GPIOLDC_ON_SHIFT	16
+-#define SSB_SPROM3_CCKPO		0x1078	/* CCK Power Offset */
++#define SSB_SPROM3_IL0MAC		0x004A	/* 6 bytes MAC address for 802.11b/g */
++#define SSB_SPROM3_CCKPO		0x0078	/* CCK Power Offset */
+ #define  SSB_SPROM3_CCKPO_1M		0x000F	/* 1M Rate PO */
+ #define  SSB_SPROM3_CCKPO_2M		0x00F0	/* 2M Rate PO */
+ #define  SSB_SPROM3_CCKPO_2M_SHIFT	4
+@@ -264,104 +267,291 @@
+ #define  SSB_SPROM3_OFDMGPO		0x107A	/* G-PHY OFDM Power Offset (4 bytes, BigEndian) */
+ 
+ /* SPROM Revision 4 */
+-#define SSB_SPROM4_IL0MAC		0x104C	/* 6 byte MAC address for a/b/g/n */
+-#define SSB_SPROM4_ETHPHY		0x105A	/* Ethernet PHY settings ?? */
++#define SSB_SPROM4_BFLLO		0x0044	/* Boardflags (low 16 bits) */
++#define SSB_SPROM4_BFLHI		0x0046  /* Board Flags Hi */
++#define SSB_SPROM4_BFL2LO		0x0048	/* Board flags 2 (low 16 bits) */
++#define SSB_SPROM4_BFL2HI		0x004A	/* Board flags 2 Hi */
++#define SSB_SPROM4_IL0MAC		0x004C	/* 6 byte MAC address for a/b/g/n */
++#define SSB_SPROM4_CCODE		0x0052	/* Country Code (2 bytes) */
++#define SSB_SPROM4_GPIOA		0x0056	/* Gen. Purpose IO # 0 and 1 */
++#define  SSB_SPROM4_GPIOA_P0		0x00FF	/* Pin 0 */
++#define  SSB_SPROM4_GPIOA_P1		0xFF00	/* Pin 1 */
++#define  SSB_SPROM4_GPIOA_P1_SHIFT	8
++#define SSB_SPROM4_GPIOB		0x0058	/* Gen. Purpose IO # 2 and 3 */
++#define  SSB_SPROM4_GPIOB_P2		0x00FF	/* Pin 2 */
++#define  SSB_SPROM4_GPIOB_P3		0xFF00	/* Pin 3 */
++#define  SSB_SPROM4_GPIOB_P3_SHIFT	8
++#define SSB_SPROM4_ETHPHY		0x005A	/* Ethernet PHY settings ?? */
+ #define  SSB_SPROM4_ETHPHY_ET0A		0x001F	/* MII Address for enet0 */
+ #define  SSB_SPROM4_ETHPHY_ET1A		0x03E0	/* MII Address for enet1 */
+ #define  SSB_SPROM4_ETHPHY_ET1A_SHIFT	5
+ #define  SSB_SPROM4_ETHPHY_ET0M		(1<<14)	/* MDIO for enet0 */
+ #define  SSB_SPROM4_ETHPHY_ET1M		(1<<15)	/* MDIO for enet1 */
+-#define SSB_SPROM4_CCODE		0x1052	/* Country Code (2 bytes) */
+-#define SSB_SPROM4_ANTAVAIL		0x105D  /* Antenna available bitfields */
+-#define SSB_SPROM4_ANTAVAIL_A		0x00FF	/* A-PHY bitfield */
+-#define SSB_SPROM4_ANTAVAIL_A_SHIFT	0
+-#define SSB_SPROM4_ANTAVAIL_BG		0xFF00	/* B-PHY and G-PHY bitfield */
+-#define SSB_SPROM4_ANTAVAIL_BG_SHIFT	8
+-#define SSB_SPROM4_BFLLO		0x1044	/* Boardflags (low 16 bits) */
+-#define SSB_SPROM4_AGAIN01		0x105E	/* Antenna Gain (in dBm Q5.2) */
++#define SSB_SPROM4_ANTAVAIL		0x005D  /* Antenna available bitfields */
++#define  SSB_SPROM4_ANTAVAIL_A		0x00FF	/* A-PHY bitfield */
++#define  SSB_SPROM4_ANTAVAIL_A_SHIFT	0
++#define  SSB_SPROM4_ANTAVAIL_BG		0xFF00	/* B-PHY and G-PHY bitfield */
++#define  SSB_SPROM4_ANTAVAIL_BG_SHIFT	8
++#define SSB_SPROM4_AGAIN01		0x005E	/* Antenna Gain (in dBm Q5.2) */
+ #define  SSB_SPROM4_AGAIN0		0x00FF	/* Antenna 0 */
+ #define  SSB_SPROM4_AGAIN0_SHIFT	0
+ #define  SSB_SPROM4_AGAIN1		0xFF00	/* Antenna 1 */
+ #define  SSB_SPROM4_AGAIN1_SHIFT	8
+-#define SSB_SPROM4_AGAIN23		0x1060
++#define SSB_SPROM4_AGAIN23		0x0060
+ #define  SSB_SPROM4_AGAIN2		0x00FF	/* Antenna 2 */
+ #define  SSB_SPROM4_AGAIN2_SHIFT	0
+ #define  SSB_SPROM4_AGAIN3		0xFF00	/* Antenna 3 */
+ #define  SSB_SPROM4_AGAIN3_SHIFT	8
+-#define SSB_SPROM4_BFLHI		0x1046  /* Board Flags Hi */
+-#define SSB_SPROM4_MAXP_BG		0x1080  /* Max Power BG in path 1 */
++#define SSB_SPROM4_TXPID2G01		0x0062 	/* TX Power Index 2GHz */
++#define  SSB_SPROM4_TXPID2G0		0x00FF
++#define  SSB_SPROM4_TXPID2G0_SHIFT	0
++#define  SSB_SPROM4_TXPID2G1		0xFF00
++#define  SSB_SPROM4_TXPID2G1_SHIFT	8
++#define SSB_SPROM4_TXPID2G23		0x0064 	/* TX Power Index 2GHz */
++#define  SSB_SPROM4_TXPID2G2		0x00FF
++#define  SSB_SPROM4_TXPID2G2_SHIFT	0
++#define  SSB_SPROM4_TXPID2G3		0xFF00
++#define  SSB_SPROM4_TXPID2G3_SHIFT	8
++#define SSB_SPROM4_TXPID5G01		0x0066 	/* TX Power Index 5GHz middle subband */
++#define  SSB_SPROM4_TXPID5G0		0x00FF
++#define  SSB_SPROM4_TXPID5G0_SHIFT	0
++#define  SSB_SPROM4_TXPID5G1		0xFF00
++#define  SSB_SPROM4_TXPID5G1_SHIFT	8
++#define SSB_SPROM4_TXPID5G23		0x0068 	/* TX Power Index 5GHz middle subband */
++#define  SSB_SPROM4_TXPID5G2		0x00FF
++#define  SSB_SPROM4_TXPID5G2_SHIFT	0
++#define  SSB_SPROM4_TXPID5G3		0xFF00
++#define  SSB_SPROM4_TXPID5G3_SHIFT	8
++#define SSB_SPROM4_TXPID5GL01		0x006A 	/* TX Power Index 5GHz low subband */
++#define  SSB_SPROM4_TXPID5GL0		0x00FF
++#define  SSB_SPROM4_TXPID5GL0_SHIFT	0
++#define  SSB_SPROM4_TXPID5GL1		0xFF00
++#define  SSB_SPROM4_TXPID5GL1_SHIFT	8
++#define SSB_SPROM4_TXPID5GL23		0x006C 	/* TX Power Index 5GHz low subband */
++#define  SSB_SPROM4_TXPID5GL2		0x00FF
++#define  SSB_SPROM4_TXPID5GL2_SHIFT	0
++#define  SSB_SPROM4_TXPID5GL3		0xFF00
++#define  SSB_SPROM4_TXPID5GL3_SHIFT	8
++#define SSB_SPROM4_TXPID5GH01		0x006E 	/* TX Power Index 5GHz high subband */
++#define  SSB_SPROM4_TXPID5GH0		0x00FF
++#define  SSB_SPROM4_TXPID5GH0_SHIFT	0
++#define  SSB_SPROM4_TXPID5GH1		0xFF00
++#define  SSB_SPROM4_TXPID5GH1_SHIFT	8
++#define SSB_SPROM4_TXPID5GH23		0x0070 	/* TX Power Index 5GHz high subband */
++#define  SSB_SPROM4_TXPID5GH2		0x00FF
++#define  SSB_SPROM4_TXPID5GH2_SHIFT	0
++#define  SSB_SPROM4_TXPID5GH3		0xFF00
++#define  SSB_SPROM4_TXPID5GH3_SHIFT	8
++#define SSB_SPROM4_MAXP_BG		0x0080  /* Max Power BG in path 1 */
+ #define  SSB_SPROM4_MAXP_BG_MASK	0x00FF  /* Mask for Max Power BG */
+ #define  SSB_SPROM4_ITSSI_BG		0xFF00	/* Mask for path 1 itssi_bg */
+ #define  SSB_SPROM4_ITSSI_BG_SHIFT	8
+-#define SSB_SPROM4_MAXP_A		0x108A  /* Max Power A in path 1 */
++#define SSB_SPROM4_MAXP_A		0x008A  /* Max Power A in path 1 */
+ #define  SSB_SPROM4_MAXP_A_MASK		0x00FF  /* Mask for Max Power A */
+ #define  SSB_SPROM4_ITSSI_A		0xFF00	/* Mask for path 1 itssi_a */
+ #define  SSB_SPROM4_ITSSI_A_SHIFT	8
+-#define SSB_SPROM4_GPIOA		0x1056	/* Gen. Purpose IO # 0 and 1 */
+-#define  SSB_SPROM4_GPIOA_P0		0x00FF	/* Pin 0 */
+-#define  SSB_SPROM4_GPIOA_P1		0xFF00	/* Pin 1 */
+-#define  SSB_SPROM4_GPIOA_P1_SHIFT	8
+-#define SSB_SPROM4_GPIOB		0x1058	/* Gen. Purpose IO # 2 and 3 */
+-#define  SSB_SPROM4_GPIOB_P2		0x00FF	/* Pin 2 */
+-#define  SSB_SPROM4_GPIOB_P3		0xFF00	/* Pin 3 */
+-#define  SSB_SPROM4_GPIOB_P3_SHIFT	8
+-#define SSB_SPROM4_PA0B0		0x1082	/* The paXbY locations are */
+-#define SSB_SPROM4_PA0B1		0x1084	/*   only guesses */
+-#define SSB_SPROM4_PA0B2		0x1086
+-#define SSB_SPROM4_PA1B0		0x108E
+-#define SSB_SPROM4_PA1B1		0x1090
+-#define SSB_SPROM4_PA1B2		0x1092
++#define SSB_SPROM4_PA0B0		0x0082	/* The paXbY locations are */
++#define SSB_SPROM4_PA0B1		0x0084	/*   only guesses */
++#define SSB_SPROM4_PA0B2		0x0086
++#define SSB_SPROM4_PA1B0		0x008E
++#define SSB_SPROM4_PA1B1		0x0090
++#define SSB_SPROM4_PA1B2		0x0092
+ 
+ /* SPROM Revision 5 (inherits most data from rev 4) */
+-#define SSB_SPROM5_BFLLO		0x104A	/* Boardflags (low 16 bits) */
+-#define SSB_SPROM5_BFLHI		0x104C  /* Board Flags Hi */
+-#define SSB_SPROM5_IL0MAC		0x1052	/* 6 byte MAC address for a/b/g/n */
+-#define SSB_SPROM5_CCODE		0x1044	/* Country Code (2 bytes) */
+-#define SSB_SPROM5_GPIOA		0x1076	/* Gen. Purpose IO # 0 and 1 */
++#define SSB_SPROM5_CCODE		0x0044	/* Country Code (2 bytes) */
++#define SSB_SPROM5_BFLLO		0x004A	/* Boardflags (low 16 bits) */
++#define SSB_SPROM5_BFLHI		0x004C  /* Board Flags Hi */
++#define SSB_SPROM5_BFL2LO		0x004E	/* Board flags 2 (low 16 bits) */
++#define SSB_SPROM5_BFL2HI		0x0050	/* Board flags 2 Hi */
++#define SSB_SPROM5_IL0MAC		0x0052	/* 6 byte MAC address for a/b/g/n */
++#define SSB_SPROM5_GPIOA		0x0076	/* Gen. Purpose IO # 0 and 1 */
+ #define  SSB_SPROM5_GPIOA_P0		0x00FF	/* Pin 0 */
+ #define  SSB_SPROM5_GPIOA_P1		0xFF00	/* Pin 1 */
+ #define  SSB_SPROM5_GPIOA_P1_SHIFT	8
+-#define SSB_SPROM5_GPIOB		0x1078	/* Gen. Purpose IO # 2 and 3 */
++#define SSB_SPROM5_GPIOB		0x0078	/* Gen. Purpose IO # 2 and 3 */
+ #define  SSB_SPROM5_GPIOB_P2		0x00FF	/* Pin 2 */
+ #define  SSB_SPROM5_GPIOB_P3		0xFF00	/* Pin 3 */
+ #define  SSB_SPROM5_GPIOB_P3_SHIFT	8
+ 
+ /* SPROM Revision 8 */
+-#define SSB_SPROM8_BFLLO		0x1084	/* Boardflags (low 16 bits) */
+-#define SSB_SPROM8_BFLHI		0x1086	/* Boardflags Hi */
+-#define SSB_SPROM8_IL0MAC		0x108C	/* 6 byte MAC address */
+-#define SSB_SPROM8_CCODE		0x1092	/* 2 byte country code */
+-#define SSB_SPROM8_ANTAVAIL		0x109C  /* Antenna available bitfields*/
+-#define SSB_SPROM8_ANTAVAIL_A		0xFF00	/* A-PHY bitfield */
+-#define SSB_SPROM8_ANTAVAIL_A_SHIFT	8
+-#define SSB_SPROM8_ANTAVAIL_BG		0x00FF	/* B-PHY and G-PHY bitfield */
+-#define SSB_SPROM8_ANTAVAIL_BG_SHIFT	0
+-#define SSB_SPROM8_AGAIN01		0x109E	/* Antenna Gain (in dBm Q5.2) */
++#define SSB_SPROM8_BOARDREV		0x0082	/* Board revision */
++#define SSB_SPROM8_BFLLO		0x0084	/* Board flags (bits 0-15) */
++#define SSB_SPROM8_BFLHI		0x0086	/* Board flags (bits 16-31) */
++#define SSB_SPROM8_BFL2LO		0x0088	/* Board flags (bits 32-47) */
++#define SSB_SPROM8_BFL2HI		0x008A	/* Board flags (bits 48-63) */
++#define SSB_SPROM8_IL0MAC		0x008C	/* 6 byte MAC address */
++#define SSB_SPROM8_CCODE		0x0092	/* 2 byte country code */
++#define SSB_SPROM8_GPIOA		0x0096	/*Gen. Purpose IO # 0 and 1 */
++#define  SSB_SPROM8_GPIOA_P0		0x00FF	/* Pin 0 */
++#define  SSB_SPROM8_GPIOA_P1		0xFF00	/* Pin 1 */
++#define  SSB_SPROM8_GPIOA_P1_SHIFT	8
++#define SSB_SPROM8_GPIOB		0x0098	/* Gen. Purpose IO # 2 and 3 */
++#define  SSB_SPROM8_GPIOB_P2		0x00FF	/* Pin 2 */
++#define  SSB_SPROM8_GPIOB_P3		0xFF00	/* Pin 3 */
++#define  SSB_SPROM8_GPIOB_P3_SHIFT	8
++#define SSB_SPROM8_ANTAVAIL		0x009C  /* Antenna available bitfields*/
++#define  SSB_SPROM8_ANTAVAIL_A		0xFF00	/* A-PHY bitfield */
++#define  SSB_SPROM8_ANTAVAIL_A_SHIFT	8
++#define  SSB_SPROM8_ANTAVAIL_BG		0x00FF	/* B-PHY and G-PHY bitfield */
++#define  SSB_SPROM8_ANTAVAIL_BG_SHIFT	0
++#define SSB_SPROM8_AGAIN01		0x009E	/* Antenna Gain (in dBm Q5.2) */
+ #define  SSB_SPROM8_AGAIN0		0x00FF	/* Antenna 0 */
+ #define  SSB_SPROM8_AGAIN0_SHIFT	0
+ #define  SSB_SPROM8_AGAIN1		0xFF00	/* Antenna 1 */
+ #define  SSB_SPROM8_AGAIN1_SHIFT	8
+-#define SSB_SPROM8_AGAIN23		0x10A0
++#define SSB_SPROM8_AGAIN23		0x00A0
+ #define  SSB_SPROM8_AGAIN2		0x00FF	/* Antenna 2 */
+ #define  SSB_SPROM8_AGAIN2_SHIFT	0
+ #define  SSB_SPROM8_AGAIN3		0xFF00	/* Antenna 3 */
+ #define  SSB_SPROM8_AGAIN3_SHIFT	8
+-#define SSB_SPROM8_GPIOA		0x1096	/*Gen. Purpose IO # 0 and 1 */
+-#define  SSB_SPROM8_GPIOA_P0		0x00FF	/* Pin 0 */
+-#define  SSB_SPROM8_GPIOA_P1		0xFF00	/* Pin 1 */
+-#define  SSB_SPROM8_GPIOA_P1_SHIFT	8
+-#define SSB_SPROM8_GPIOB		0x1098	/* Gen. Purpose IO # 2 and 3 */
+-#define  SSB_SPROM8_GPIOB_P2		0x00FF	/* Pin 2 */
+-#define  SSB_SPROM8_GPIOB_P3		0xFF00	/* Pin 3 */
+-#define  SSB_SPROM8_GPIOB_P3_SHIFT	8
+-#define SSB_SPROM8_MAXP_BG		0x10C0  /* Max Power BG in path 1 */
+-#define  SSB_SPROM8_MAXP_BG_MASK	0x00FF  /* Mask for Max Power BG */
++#define SSB_SPROM8_RSSIPARM2G		0x00A4	/* RSSI params for 2GHz */
++#define  SSB_SPROM8_RSSISMF2G		0x000F
++#define  SSB_SPROM8_RSSISMC2G		0x00F0
++#define  SSB_SPROM8_RSSISMC2G_SHIFT	4
++#define  SSB_SPROM8_RSSISAV2G		0x0700
++#define  SSB_SPROM8_RSSISAV2G_SHIFT	8
++#define  SSB_SPROM8_BXA2G		0x1800
++#define  SSB_SPROM8_BXA2G_SHIFT		11
++#define SSB_SPROM8_RSSIPARM5G		0x00A6	/* RSSI params for 5GHz */
++#define  SSB_SPROM8_RSSISMF5G		0x000F
++#define  SSB_SPROM8_RSSISMC5G		0x00F0
++#define  SSB_SPROM8_RSSISMC5G_SHIFT	4
++#define  SSB_SPROM8_RSSISAV5G		0x0700
++#define  SSB_SPROM8_RSSISAV5G_SHIFT	8
++#define  SSB_SPROM8_BXA5G		0x1800
++#define  SSB_SPROM8_BXA5G_SHIFT		11
++#define SSB_SPROM8_TRI25G		0x00A8	/* TX isolation 2.4&5.3GHz */
++#define  SSB_SPROM8_TRI2G		0x00FF	/* TX isolation 2.4GHz */
++#define  SSB_SPROM8_TRI5G		0xFF00	/* TX isolation 5.3GHz */
++#define  SSB_SPROM8_TRI5G_SHIFT		8
++#define SSB_SPROM8_TRI5GHL		0x00AA	/* TX isolation 5.2/5.8GHz */
++#define  SSB_SPROM8_TRI5GL		0x00FF	/* TX isolation 5.2GHz */
++#define  SSB_SPROM8_TRI5GH		0xFF00	/* TX isolation 5.8GHz */
++#define  SSB_SPROM8_TRI5GH_SHIFT	8
++#define SSB_SPROM8_RXPO			0x00AC  /* RX power offsets */
++#define  SSB_SPROM8_RXPO2G		0x00FF	/* 2GHz RX power offset */
++#define  SSB_SPROM8_RXPO5G		0xFF00	/* 5GHz RX power offset */
++#define  SSB_SPROM8_RXPO5G_SHIFT	8
++#define SSB_SPROM8_FEM2G		0x00AE
++#define SSB_SPROM8_FEM5G		0x00B0
++#define  SSB_SROM8_FEM_TSSIPOS		0x0001
++#define  SSB_SROM8_FEM_TSSIPOS_SHIFT	0
++#define  SSB_SROM8_FEM_EXTPA_GAIN	0x0006
++#define  SSB_SROM8_FEM_EXTPA_GAIN_SHIFT	1
++#define  SSB_SROM8_FEM_PDET_RANGE	0x00F8
++#define  SSB_SROM8_FEM_PDET_RANGE_SHIFT	3
++#define  SSB_SROM8_FEM_TR_ISO		0x0700
++#define  SSB_SROM8_FEM_TR_ISO_SHIFT	8
++#define  SSB_SROM8_FEM_ANTSWLUT		0xF800
++#define  SSB_SROM8_FEM_ANTSWLUT_SHIFT	11
++#define SSB_SPROM8_THERMAL		0x00B2
++#define SSB_SPROM8_MPWR_RAWTS		0x00B4
++#define SSB_SPROM8_TS_SLP_OPT_CORRX	0x00B6
++#define SSB_SPROM8_FOC_HWIQ_IQSWP	0x00B8
++#define SSB_SPROM8_PHYCAL_TEMPDELTA	0x00BA
++
++/* There are 4 blocks with power info sharing the same layout */
++#define SSB_SROM8_PWR_INFO_CORE0	0x00C0
++#define SSB_SROM8_PWR_INFO_CORE1	0x00E0
++#define SSB_SROM8_PWR_INFO_CORE2	0x0100
++#define SSB_SROM8_PWR_INFO_CORE3	0x0120
++
++#define SSB_SROM8_2G_MAXP_ITSSI		0x00
++#define  SSB_SPROM8_2G_MAXP		0x00FF
++#define  SSB_SPROM8_2G_ITSSI		0xFF00
++#define  SSB_SPROM8_2G_ITSSI_SHIFT	8
++#define SSB_SROM8_2G_PA_0		0x02	/* 2GHz power amp settings */
++#define SSB_SROM8_2G_PA_1		0x04
++#define SSB_SROM8_2G_PA_2		0x06
++#define SSB_SROM8_5G_MAXP_ITSSI		0x08	/* 5GHz ITSSI and 5.3GHz Max Power */
++#define  SSB_SPROM8_5G_MAXP		0x00FF
++#define  SSB_SPROM8_5G_ITSSI		0xFF00
++#define  SSB_SPROM8_5G_ITSSI_SHIFT	8
++#define SSB_SPROM8_5GHL_MAXP		0x0A	/* 5.2GHz and 5.8GHz Max Power */
++#define  SSB_SPROM8_5GH_MAXP		0x00FF
++#define  SSB_SPROM8_5GL_MAXP		0xFF00
++#define  SSB_SPROM8_5GL_MAXP_SHIFT	8
++#define SSB_SROM8_5G_PA_0		0x0C	/* 5.3GHz power amp settings */
++#define SSB_SROM8_5G_PA_1		0x0E
++#define SSB_SROM8_5G_PA_2		0x10
++#define SSB_SROM8_5GL_PA_0		0x12	/* 5.2GHz power amp settings */
++#define SSB_SROM8_5GL_PA_1		0x14
++#define SSB_SROM8_5GL_PA_2		0x16
++#define SSB_SROM8_5GH_PA_0		0x18	/* 5.8GHz power amp settings */
++#define SSB_SROM8_5GH_PA_1		0x1A
++#define SSB_SROM8_5GH_PA_2		0x1C
++
++/* TODO: Make it deprecated */
++#define SSB_SPROM8_MAXP_BG		0x00C0  /* Max Power 2GHz in path 1 */
++#define  SSB_SPROM8_MAXP_BG_MASK	0x00FF  /* Mask for Max Power 2GHz */
+ #define  SSB_SPROM8_ITSSI_BG		0xFF00	/* Mask for path 1 itssi_bg */
+ #define  SSB_SPROM8_ITSSI_BG_SHIFT	8
+-#define SSB_SPROM8_MAXP_A		0x10C8  /* Max Power A in path 1 */
+-#define  SSB_SPROM8_MAXP_A_MASK		0x00FF  /* Mask for Max Power A */
++#define SSB_SPROM8_PA0B0		0x00C2	/* 2GHz power amp settings */
++#define SSB_SPROM8_PA0B1		0x00C4
++#define SSB_SPROM8_PA0B2		0x00C6
++#define SSB_SPROM8_MAXP_A		0x00C8  /* Max Power 5.3GHz */
++#define  SSB_SPROM8_MAXP_A_MASK		0x00FF  /* Mask for Max Power 5.3GHz */
+ #define  SSB_SPROM8_ITSSI_A		0xFF00	/* Mask for path 1 itssi_a */
+ #define  SSB_SPROM8_ITSSI_A_SHIFT	8
++#define SSB_SPROM8_MAXP_AHL		0x00CA  /* Max Power 5.2/5.8GHz */
++#define  SSB_SPROM8_MAXP_AH_MASK	0x00FF  /* Mask for Max Power 5.8GHz */
++#define  SSB_SPROM8_MAXP_AL_MASK	0xFF00  /* Mask for Max Power 5.2GHz */
++#define  SSB_SPROM8_MAXP_AL_SHIFT	8
++#define SSB_SPROM8_PA1B0		0x00CC	/* 5.3GHz power amp settings */
++#define SSB_SPROM8_PA1B1		0x00CE
++#define SSB_SPROM8_PA1B2		0x00D0
++#define SSB_SPROM8_PA1LOB0		0x00D2	/* 5.2GHz power amp settings */
++#define SSB_SPROM8_PA1LOB1		0x00D4
++#define SSB_SPROM8_PA1LOB2		0x00D6
++#define SSB_SPROM8_PA1HIB0		0x00D8	/* 5.8GHz power amp settings */
++#define SSB_SPROM8_PA1HIB1		0x00DA
++#define SSB_SPROM8_PA1HIB2		0x00DC
++
++#define SSB_SPROM8_CCK2GPO		0x0140	/* CCK power offset */
++#define SSB_SPROM8_OFDM2GPO		0x0142	/* 2.4GHz OFDM power offset */
++#define SSB_SPROM8_OFDM5GPO		0x0146	/* 5.3GHz OFDM power offset */
++#define SSB_SPROM8_OFDM5GLPO		0x014A	/* 5.2GHz OFDM power offset */
++#define SSB_SPROM8_OFDM5GHPO		0x014E	/* 5.8GHz OFDM power offset */
++
++/* Values for boardflags_lo read from SPROM */
++#define SSB_BFL_BTCOEXIST		0x0001	/* implements Bluetooth coexistance */
++#define SSB_BFL_PACTRL			0x0002	/* GPIO 9 controlling the PA */
++#define SSB_BFL_AIRLINEMODE		0x0004	/* implements GPIO 13 radio disable indication */
++#define SSB_BFL_RSSI			0x0008	/* software calculates nrssi slope. */
++#define SSB_BFL_ENETSPI			0x0010	/* has ephy roboswitch spi */
++#define SSB_BFL_XTAL_NOSLOW		0x0020	/* no slow clock available */
++#define SSB_BFL_CCKHIPWR		0x0040	/* can do high power CCK transmission */
++#define SSB_BFL_ENETADM			0x0080	/* has ADMtek switch */
++#define SSB_BFL_ENETVLAN		0x0100	/* can do vlan */
++#define SSB_BFL_AFTERBURNER		0x0200	/* supports Afterburner mode */
++#define SSB_BFL_NOPCI			0x0400	/* board leaves PCI floating */
++#define SSB_BFL_FEM			0x0800	/* supports the Front End Module */
++#define SSB_BFL_EXTLNA			0x1000	/* has an external LNA */
++#define SSB_BFL_HGPA			0x2000	/* had high gain PA */
++#define SSB_BFL_BTCMOD			0x4000	/* BFL_BTCOEXIST is given in alternate GPIOs */
++#define SSB_BFL_ALTIQ			0x8000	/* alternate I/Q settings */
++
++/* Values for boardflags_hi read from SPROM */
++#define SSB_BFH_NOPA			0x0001	/* has no PA */
++#define SSB_BFH_RSSIINV			0x0002	/* RSSI uses positive slope (not TSSI) */
++#define SSB_BFH_PAREF			0x0004	/* uses the PARef LDO */
++#define SSB_BFH_3TSWITCH		0x0008	/* uses a triple throw switch shared with bluetooth */
++#define SSB_BFH_PHASESHIFT		0x0010	/* can support phase shifter */
++#define SSB_BFH_BUCKBOOST		0x0020	/* has buck/booster */
++#define SSB_BFH_FEM_BT			0x0040	/* has FEM and switch to share antenna with bluetooth */
++
++/* Values for boardflags2_lo read from SPROM */
++#define SSB_BFL2_RXBB_INT_REG_DIS	0x0001	/* external RX BB regulator present */
++#define SSB_BFL2_APLL_WAR		0x0002	/* alternative A-band PLL settings implemented */
++#define SSB_BFL2_TXPWRCTRL_EN 		0x0004	/* permits enabling TX Power Control */
++#define SSB_BFL2_2X4_DIV		0x0008	/* 2x4 diversity switch */
++#define SSB_BFL2_5G_PWRGAIN		0x0010	/* supports 5G band power gain */
++#define SSB_BFL2_PCIEWAR_OVR		0x0020	/* overrides ASPM and Clkreq settings */
++#define SSB_BFL2_CAESERS_BRD		0x0040	/* is Caesers board (unused) */
++#define SSB_BFL2_BTC3WIRE		0x0080	/* used 3-wire bluetooth coexist */
++#define SSB_BFL2_SKWRKFEM_BRD		0x0100	/* 4321mcm93 uses Skyworks FEM */
++#define SSB_BFL2_SPUR_WAR		0x0200	/* has a workaround for clock-harmonic spurs */
++#define SSB_BFL2_GPLL_WAR		0x0400	/* altenative G-band PLL settings implemented */
+ 
+ /* Values for SSB_SPROM1_BINF_CCODE */
+ enum {
+--- a/drivers/ssb/driver_extif.c
++++ b/drivers/ssb/driver_extif.c
+@@ -3,7 +3,7 @@
+  * Broadcom EXTIF core driver
+  *
+  * Copyright 2005, Broadcom Corporation
+- * Copyright 2006, 2007, Michael Buesch <mb@bu3sch.de>
++ * Copyright 2006, 2007, Michael Buesch <m@bues.ch>
+  * Copyright 2006, 2007, Felix Fietkau <nbd@openwrt.org>
+  * Copyright 2007, Aurelien Jarno <aurelien@aurel32.net>
+  *
+--- a/drivers/ssb/embedded.c
++++ b/drivers/ssb/embedded.c
+@@ -3,7 +3,7 @@
+  * Embedded systems support code
+  *
+  * Copyright 2005-2008, Broadcom Corporation
+- * Copyright 2006-2008, Michael Buesch <mb@bu3sch.de>
++ * Copyright 2006-2008, Michael Buesch <m@bues.ch>
+  *
+  * Licensed under the GNU/GPL. See COPYING for details.
+  */
+--- a/include/linux/ssb/ssb_driver_gige.h
++++ b/include/linux/ssb/ssb_driver_gige.h
+@@ -2,6 +2,7 @@
+ #define LINUX_SSB_DRIVER_GIGE_H_
+ 
+ #include <linux/ssb/ssb.h>
++#include <linux/bug.h>
+ #include <linux/pci.h>
+ #include <linux/spinlock.h>
+ 
diff -Nru a/target/linux/generic/patches-2.6.31/951-revert_gcc4_4_fixes.patch b/target/linux/generic/patches-2.6.31/951-revert_gcc4_4_fixes.patch
--- a/target/linux/generic/patches-2.6.31/951-revert_gcc4_4_fixes.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/951-revert_gcc4_4_fixes.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,524 @@
+--- a/arch/powerpc/boot/crtsavres.S
++++ /dev/null
+@@ -1,233 +0,0 @@
+-/*
+- * Special support for eabi and SVR4
+- *
+- *   Copyright (C) 1995, 1996, 1998, 2000, 2001 Free Software Foundation, Inc.
+- *   Copyright 2008 Freescale Semiconductor, Inc.
+- *   Written By Michael Meissner
+- *
+- * Based on gcc/config/rs6000/crtsavres.asm from gcc
+- *
+- * This file is free software; you can redistribute it and/or modify it
+- * under the terms of the GNU General Public License as published by the
+- * Free Software Foundation; either version 2, or (at your option) any
+- * later version.
+- *
+- * In addition to the permissions in the GNU General Public License, the
+- * Free Software Foundation gives you unlimited permission to link the
+- * compiled version of this file with other programs, and to distribute
+- * those programs without any restriction coming from the use of this
+- * file.  (The General Public License restrictions do apply in other
+- * respects; for example, they cover modification of the file, and
+- * distribution when not linked into another program.)
+- *
+- * This file is distributed in the hope that it will be useful, but
+- * WITHOUT ANY WARRANTY; without even the implied warranty of
+- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+- * General Public License for more details.
+- *
+- * You should have received a copy of the GNU General Public License
+- * along with this program; see the file COPYING.  If not, write to
+- * the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+- * Boston, MA 02110-1301, USA.
+- *
+- *    As a special exception, if you link this library with files
+- *    compiled with GCC to produce an executable, this does not cause
+- *    the resulting executable to be covered by the GNU General Public License.
+- *    This exception does not however invalidate any other reasons why
+- *    the executable file might be covered by the GNU General Public License.
+- */
+-
+-	.file	"crtsavres.S"
+-	.section ".text"
+-
+-/* On PowerPC64 Linux, these functions are provided by the linker.  */
+-#ifndef __powerpc64__
+-
+-#define _GLOBAL(name) \
+-	.type name,@function; \
+-	.globl name; \
+-name:
+-
+-/* Routines for saving integer registers, called by the compiler.  */
+-/* Called with r11 pointing to the stack header word of the caller of the */
+-/* function, just beyond the end of the integer save area.  */
+-
+-_GLOBAL(_savegpr_14)
+-_GLOBAL(_save32gpr_14)
+-	stw	14,-72(11)	/* save gp registers */
+-_GLOBAL(_savegpr_15)
+-_GLOBAL(_save32gpr_15)
+-	stw	15,-68(11)
+-_GLOBAL(_savegpr_16)
+-_GLOBAL(_save32gpr_16)
+-	stw	16,-64(11)
+-_GLOBAL(_savegpr_17)
+-_GLOBAL(_save32gpr_17)
+-	stw	17,-60(11)
+-_GLOBAL(_savegpr_18)
+-_GLOBAL(_save32gpr_18)
+-	stw	18,-56(11)
+-_GLOBAL(_savegpr_19)
+-_GLOBAL(_save32gpr_19)
+-	stw	19,-52(11)
+-_GLOBAL(_savegpr_20)
+-_GLOBAL(_save32gpr_20)
+-	stw	20,-48(11)
+-_GLOBAL(_savegpr_21)
+-_GLOBAL(_save32gpr_21)
+-	stw	21,-44(11)
+-_GLOBAL(_savegpr_22)
+-_GLOBAL(_save32gpr_22)
+-	stw	22,-40(11)
+-_GLOBAL(_savegpr_23)
+-_GLOBAL(_save32gpr_23)
+-	stw	23,-36(11)
+-_GLOBAL(_savegpr_24)
+-_GLOBAL(_save32gpr_24)
+-	stw	24,-32(11)
+-_GLOBAL(_savegpr_25)
+-_GLOBAL(_save32gpr_25)
+-	stw	25,-28(11)
+-_GLOBAL(_savegpr_26)
+-_GLOBAL(_save32gpr_26)
+-	stw	26,-24(11)
+-_GLOBAL(_savegpr_27)
+-_GLOBAL(_save32gpr_27)
+-	stw	27,-20(11)
+-_GLOBAL(_savegpr_28)
+-_GLOBAL(_save32gpr_28)
+-	stw	28,-16(11)
+-_GLOBAL(_savegpr_29)
+-_GLOBAL(_save32gpr_29)
+-	stw	29,-12(11)
+-_GLOBAL(_savegpr_30)
+-_GLOBAL(_save32gpr_30)
+-	stw	30,-8(11)
+-_GLOBAL(_savegpr_31)
+-_GLOBAL(_save32gpr_31)
+-	stw	31,-4(11)
+-	blr
+-
+-/* Routines for restoring integer registers, called by the compiler.  */
+-/* Called with r11 pointing to the stack header word of the caller of the */
+-/* function, just beyond the end of the integer restore area.  */
+-
+-_GLOBAL(_restgpr_14)
+-_GLOBAL(_rest32gpr_14)
+-	lwz	14,-72(11)	/* restore gp registers */
+-_GLOBAL(_restgpr_15)
+-_GLOBAL(_rest32gpr_15)
+-	lwz	15,-68(11)
+-_GLOBAL(_restgpr_16)
+-_GLOBAL(_rest32gpr_16)
+-	lwz	16,-64(11)
+-_GLOBAL(_restgpr_17)
+-_GLOBAL(_rest32gpr_17)
+-	lwz	17,-60(11)
+-_GLOBAL(_restgpr_18)
+-_GLOBAL(_rest32gpr_18)
+-	lwz	18,-56(11)
+-_GLOBAL(_restgpr_19)
+-_GLOBAL(_rest32gpr_19)
+-	lwz	19,-52(11)
+-_GLOBAL(_restgpr_20)
+-_GLOBAL(_rest32gpr_20)
+-	lwz	20,-48(11)
+-_GLOBAL(_restgpr_21)
+-_GLOBAL(_rest32gpr_21)
+-	lwz	21,-44(11)
+-_GLOBAL(_restgpr_22)
+-_GLOBAL(_rest32gpr_22)
+-	lwz	22,-40(11)
+-_GLOBAL(_restgpr_23)
+-_GLOBAL(_rest32gpr_23)
+-	lwz	23,-36(11)
+-_GLOBAL(_restgpr_24)
+-_GLOBAL(_rest32gpr_24)
+-	lwz	24,-32(11)
+-_GLOBAL(_restgpr_25)
+-_GLOBAL(_rest32gpr_25)
+-	lwz	25,-28(11)
+-_GLOBAL(_restgpr_26)
+-_GLOBAL(_rest32gpr_26)
+-	lwz	26,-24(11)
+-_GLOBAL(_restgpr_27)
+-_GLOBAL(_rest32gpr_27)
+-	lwz	27,-20(11)
+-_GLOBAL(_restgpr_28)
+-_GLOBAL(_rest32gpr_28)
+-	lwz	28,-16(11)
+-_GLOBAL(_restgpr_29)
+-_GLOBAL(_rest32gpr_29)
+-	lwz	29,-12(11)
+-_GLOBAL(_restgpr_30)
+-_GLOBAL(_rest32gpr_30)
+-	lwz	30,-8(11)
+-_GLOBAL(_restgpr_31)
+-_GLOBAL(_rest32gpr_31)
+-	lwz	31,-4(11)
+-	blr
+-
+-/* Routines for restoring integer registers, called by the compiler.  */
+-/* Called with r11 pointing to the stack header word of the caller of the */
+-/* function, just beyond the end of the integer restore area.  */
+-
+-_GLOBAL(_restgpr_14_x)
+-_GLOBAL(_rest32gpr_14_x)
+-	lwz	14,-72(11)	/* restore gp registers */
+-_GLOBAL(_restgpr_15_x)
+-_GLOBAL(_rest32gpr_15_x)
+-	lwz	15,-68(11)
+-_GLOBAL(_restgpr_16_x)
+-_GLOBAL(_rest32gpr_16_x)
+-	lwz	16,-64(11)
+-_GLOBAL(_restgpr_17_x)
+-_GLOBAL(_rest32gpr_17_x)
+-	lwz	17,-60(11)
+-_GLOBAL(_restgpr_18_x)
+-_GLOBAL(_rest32gpr_18_x)
+-	lwz	18,-56(11)
+-_GLOBAL(_restgpr_19_x)
+-_GLOBAL(_rest32gpr_19_x)
+-	lwz	19,-52(11)
+-_GLOBAL(_restgpr_20_x)
+-_GLOBAL(_rest32gpr_20_x)
+-	lwz	20,-48(11)
+-_GLOBAL(_restgpr_21_x)
+-_GLOBAL(_rest32gpr_21_x)
+-	lwz	21,-44(11)
+-_GLOBAL(_restgpr_22_x)
+-_GLOBAL(_rest32gpr_22_x)
+-	lwz	22,-40(11)
+-_GLOBAL(_restgpr_23_x)
+-_GLOBAL(_rest32gpr_23_x)
+-	lwz	23,-36(11)
+-_GLOBAL(_restgpr_24_x)
+-_GLOBAL(_rest32gpr_24_x)
+-	lwz	24,-32(11)
+-_GLOBAL(_restgpr_25_x)
+-_GLOBAL(_rest32gpr_25_x)
+-	lwz	25,-28(11)
+-_GLOBAL(_restgpr_26_x)
+-_GLOBAL(_rest32gpr_26_x)
+-	lwz	26,-24(11)
+-_GLOBAL(_restgpr_27_x)
+-_GLOBAL(_rest32gpr_27_x)
+-	lwz	27,-20(11)
+-_GLOBAL(_restgpr_28_x)
+-_GLOBAL(_rest32gpr_28_x)
+-	lwz	28,-16(11)
+-_GLOBAL(_restgpr_29_x)
+-_GLOBAL(_rest32gpr_29_x)
+-	lwz	29,-12(11)
+-_GLOBAL(_restgpr_30_x)
+-_GLOBAL(_rest32gpr_30_x)
+-	lwz	30,-8(11)
+-_GLOBAL(_restgpr_31_x)
+-_GLOBAL(_rest32gpr_31_x)
+-	lwz	0,4(11)
+-	lwz	31,-4(11)
+-	mtlr	0
+-	mr	1,11
+-	blr
+-#endif
+--- a/arch/powerpc/boot/Makefile
++++ b/arch/powerpc/boot/Makefile
+@@ -59,7 +59,7 @@ libfdtheader := fdt.h libfdt.h libfdt_in
+ $(addprefix $(obj)/,$(libfdt) libfdt-wrapper.o simpleboot.o): \
+ 	$(addprefix $(obj)/,$(libfdtheader))
+ 
+-src-wlib := string.S crt0.S crtsavres.S stdio.c main.c \
++src-wlib := string.S crt0.S stdio.c main.c \
+ 		$(libfdt) libfdt-wrapper.c \
+ 		ns16550.c serial.c simple_alloc.c div64.S util.S \
+ 		gunzip_util.c elf_util.c $(zlib) devtree.c oflib.c ofconsole.c \
+--- a/arch/powerpc/kernel/prom_init_check.sh
++++ b/arch/powerpc/kernel/prom_init_check.sh
+@@ -48,20 +48,6 @@ do
+ 		fi
+ 	done
+ 
+-	# ignore register save/restore funcitons
+-	if [ "${UNDEF:0:9}" = "_restgpr_" ]; then
+-		OK=1
+-	fi
+-	if [ "${UNDEF:0:11}" = "_rest32gpr_" ]; then
+-		OK=1
+-	fi
+-	if [ "${UNDEF:0:9}" = "_savegpr_" ]; then
+-		OK=1
+-	fi
+-	if [ "${UNDEF:0:11}" = "_save32gpr_" ]; then
+-		OK=1
+-	fi
+-
+ 	if [ $OK -eq 0 ]; then
+ 		ERROR=1
+ 		echo "Error: External symbol '$UNDEF' referenced" \
+--- a/arch/powerpc/lib/crtsavres.S
++++ /dev/null
+@@ -1,229 +0,0 @@
+-/*
+- * Special support for eabi and SVR4
+- *
+- *   Copyright (C) 1995, 1996, 1998, 2000, 2001 Free Software Foundation, Inc.
+- *   Copyright 2008 Freescale Semiconductor, Inc.
+- *   Written By Michael Meissner
+- *
+- * Based on gcc/config/rs6000/crtsavres.asm from gcc
+- *
+- * This file is free software; you can redistribute it and/or modify it
+- * under the terms of the GNU General Public License as published by the
+- * Free Software Foundation; either version 2, or (at your option) any
+- * later version.
+- *
+- * In addition to the permissions in the GNU General Public License, the
+- * Free Software Foundation gives you unlimited permission to link the
+- * compiled version of this file with other programs, and to distribute
+- * those programs without any restriction coming from the use of this
+- * file.  (The General Public License restrictions do apply in other
+- * respects; for example, they cover modification of the file, and
+- * distribution when not linked into another program.)
+- *
+- * This file is distributed in the hope that it will be useful, but
+- * WITHOUT ANY WARRANTY; without even the implied warranty of
+- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+- * General Public License for more details.
+- *
+- * You should have received a copy of the GNU General Public License
+- * along with this program; see the file COPYING.  If not, write to
+- * the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+- * Boston, MA 02110-1301, USA.
+- *
+- *    As a special exception, if you link this library with files
+- *    compiled with GCC to produce an executable, this does not cause
+- *    the resulting executable to be covered by the GNU General Public License.
+- *    This exception does not however invalidate any other reasons why
+- *    the executable file might be covered by the GNU General Public License.
+- */
+-
+-#include <asm/ppc_asm.h>
+-
+-	.file	"crtsavres.S"
+-	.section ".text"
+-
+-#ifdef CONFIG_CC_OPTIMIZE_FOR_SIZE
+-
+-/* Routines for saving integer registers, called by the compiler.  */
+-/* Called with r11 pointing to the stack header word of the caller of the */
+-/* function, just beyond the end of the integer save area.  */
+-
+-_GLOBAL(_savegpr_14)
+-_GLOBAL(_save32gpr_14)
+-	stw	14,-72(11)	/* save gp registers */
+-_GLOBAL(_savegpr_15)
+-_GLOBAL(_save32gpr_15)
+-	stw	15,-68(11)
+-_GLOBAL(_savegpr_16)
+-_GLOBAL(_save32gpr_16)
+-	stw	16,-64(11)
+-_GLOBAL(_savegpr_17)
+-_GLOBAL(_save32gpr_17)
+-	stw	17,-60(11)
+-_GLOBAL(_savegpr_18)
+-_GLOBAL(_save32gpr_18)
+-	stw	18,-56(11)
+-_GLOBAL(_savegpr_19)
+-_GLOBAL(_save32gpr_19)
+-	stw	19,-52(11)
+-_GLOBAL(_savegpr_20)
+-_GLOBAL(_save32gpr_20)
+-	stw	20,-48(11)
+-_GLOBAL(_savegpr_21)
+-_GLOBAL(_save32gpr_21)
+-	stw	21,-44(11)
+-_GLOBAL(_savegpr_22)
+-_GLOBAL(_save32gpr_22)
+-	stw	22,-40(11)
+-_GLOBAL(_savegpr_23)
+-_GLOBAL(_save32gpr_23)
+-	stw	23,-36(11)
+-_GLOBAL(_savegpr_24)
+-_GLOBAL(_save32gpr_24)
+-	stw	24,-32(11)
+-_GLOBAL(_savegpr_25)
+-_GLOBAL(_save32gpr_25)
+-	stw	25,-28(11)
+-_GLOBAL(_savegpr_26)
+-_GLOBAL(_save32gpr_26)
+-	stw	26,-24(11)
+-_GLOBAL(_savegpr_27)
+-_GLOBAL(_save32gpr_27)
+-	stw	27,-20(11)
+-_GLOBAL(_savegpr_28)
+-_GLOBAL(_save32gpr_28)
+-	stw	28,-16(11)
+-_GLOBAL(_savegpr_29)
+-_GLOBAL(_save32gpr_29)
+-	stw	29,-12(11)
+-_GLOBAL(_savegpr_30)
+-_GLOBAL(_save32gpr_30)
+-	stw	30,-8(11)
+-_GLOBAL(_savegpr_31)
+-_GLOBAL(_save32gpr_31)
+-	stw	31,-4(11)
+-	blr
+-
+-/* Routines for restoring integer registers, called by the compiler.  */
+-/* Called with r11 pointing to the stack header word of the caller of the */
+-/* function, just beyond the end of the integer restore area.  */
+-
+-_GLOBAL(_restgpr_14)
+-_GLOBAL(_rest32gpr_14)
+-	lwz	14,-72(11)	/* restore gp registers */
+-_GLOBAL(_restgpr_15)
+-_GLOBAL(_rest32gpr_15)
+-	lwz	15,-68(11)
+-_GLOBAL(_restgpr_16)
+-_GLOBAL(_rest32gpr_16)
+-	lwz	16,-64(11)
+-_GLOBAL(_restgpr_17)
+-_GLOBAL(_rest32gpr_17)
+-	lwz	17,-60(11)
+-_GLOBAL(_restgpr_18)
+-_GLOBAL(_rest32gpr_18)
+-	lwz	18,-56(11)
+-_GLOBAL(_restgpr_19)
+-_GLOBAL(_rest32gpr_19)
+-	lwz	19,-52(11)
+-_GLOBAL(_restgpr_20)
+-_GLOBAL(_rest32gpr_20)
+-	lwz	20,-48(11)
+-_GLOBAL(_restgpr_21)
+-_GLOBAL(_rest32gpr_21)
+-	lwz	21,-44(11)
+-_GLOBAL(_restgpr_22)
+-_GLOBAL(_rest32gpr_22)
+-	lwz	22,-40(11)
+-_GLOBAL(_restgpr_23)
+-_GLOBAL(_rest32gpr_23)
+-	lwz	23,-36(11)
+-_GLOBAL(_restgpr_24)
+-_GLOBAL(_rest32gpr_24)
+-	lwz	24,-32(11)
+-_GLOBAL(_restgpr_25)
+-_GLOBAL(_rest32gpr_25)
+-	lwz	25,-28(11)
+-_GLOBAL(_restgpr_26)
+-_GLOBAL(_rest32gpr_26)
+-	lwz	26,-24(11)
+-_GLOBAL(_restgpr_27)
+-_GLOBAL(_rest32gpr_27)
+-	lwz	27,-20(11)
+-_GLOBAL(_restgpr_28)
+-_GLOBAL(_rest32gpr_28)
+-	lwz	28,-16(11)
+-_GLOBAL(_restgpr_29)
+-_GLOBAL(_rest32gpr_29)
+-	lwz	29,-12(11)
+-_GLOBAL(_restgpr_30)
+-_GLOBAL(_rest32gpr_30)
+-	lwz	30,-8(11)
+-_GLOBAL(_restgpr_31)
+-_GLOBAL(_rest32gpr_31)
+-	lwz	31,-4(11)
+-	blr
+-
+-/* Routines for restoring integer registers, called by the compiler.  */
+-/* Called with r11 pointing to the stack header word of the caller of the */
+-/* function, just beyond the end of the integer restore area.  */
+-
+-_GLOBAL(_restgpr_14_x)
+-_GLOBAL(_rest32gpr_14_x)
+-	lwz	14,-72(11)	/* restore gp registers */
+-_GLOBAL(_restgpr_15_x)
+-_GLOBAL(_rest32gpr_15_x)
+-	lwz	15,-68(11)
+-_GLOBAL(_restgpr_16_x)
+-_GLOBAL(_rest32gpr_16_x)
+-	lwz	16,-64(11)
+-_GLOBAL(_restgpr_17_x)
+-_GLOBAL(_rest32gpr_17_x)
+-	lwz	17,-60(11)
+-_GLOBAL(_restgpr_18_x)
+-_GLOBAL(_rest32gpr_18_x)
+-	lwz	18,-56(11)
+-_GLOBAL(_restgpr_19_x)
+-_GLOBAL(_rest32gpr_19_x)
+-	lwz	19,-52(11)
+-_GLOBAL(_restgpr_20_x)
+-_GLOBAL(_rest32gpr_20_x)
+-	lwz	20,-48(11)
+-_GLOBAL(_restgpr_21_x)
+-_GLOBAL(_rest32gpr_21_x)
+-	lwz	21,-44(11)
+-_GLOBAL(_restgpr_22_x)
+-_GLOBAL(_rest32gpr_22_x)
+-	lwz	22,-40(11)
+-_GLOBAL(_restgpr_23_x)
+-_GLOBAL(_rest32gpr_23_x)
+-	lwz	23,-36(11)
+-_GLOBAL(_restgpr_24_x)
+-_GLOBAL(_rest32gpr_24_x)
+-	lwz	24,-32(11)
+-_GLOBAL(_restgpr_25_x)
+-_GLOBAL(_rest32gpr_25_x)
+-	lwz	25,-28(11)
+-_GLOBAL(_restgpr_26_x)
+-_GLOBAL(_rest32gpr_26_x)
+-	lwz	26,-24(11)
+-_GLOBAL(_restgpr_27_x)
+-_GLOBAL(_rest32gpr_27_x)
+-	lwz	27,-20(11)
+-_GLOBAL(_restgpr_28_x)
+-_GLOBAL(_rest32gpr_28_x)
+-	lwz	28,-16(11)
+-_GLOBAL(_restgpr_29_x)
+-_GLOBAL(_rest32gpr_29_x)
+-	lwz	29,-12(11)
+-_GLOBAL(_restgpr_30_x)
+-_GLOBAL(_rest32gpr_30_x)
+-	lwz	30,-8(11)
+-_GLOBAL(_restgpr_31_x)
+-_GLOBAL(_rest32gpr_31_x)
+-	lwz	0,4(11)
+-	lwz	31,-4(11)
+-	mtlr	0
+-	mr	1,11
+-	blr
+-#endif
+--- a/arch/powerpc/lib/Makefile
++++ b/arch/powerpc/lib/Makefile
+@@ -13,7 +13,7 @@ CFLAGS_REMOVE_feature-fixups.o = -pg
+ 
+ obj-y			:= string.o alloc.o \
+ 			   checksum_$(CONFIG_WORD_SIZE).o
+-obj-$(CONFIG_PPC32)	+= div64.o copy_32.o crtsavres.o
++obj-$(CONFIG_PPC32)	+= div64.o copy_32.o
+ obj-$(CONFIG_HAS_IOMEM)	+= devres.o
+ 
+ obj-$(CONFIG_PPC64)	+= copypage_64.o copyuser_64.o \
+--- a/arch/powerpc/Makefile
++++ b/arch/powerpc/Makefile
+@@ -92,8 +92,6 @@ endif
+ else
+ 	KBUILD_CFLAGS += $(call cc-option,-mtune=power4)
+ endif
+-else
+-LDFLAGS_MODULE	+= arch/powerpc/lib/crtsavres.o
+ endif
+ 
+ ifeq ($(CONFIG_TUNE_CELL),y)
diff -Nru a/target/linux/generic/patches-2.6.31/965-arm_restore_sigmask_v2.patch b/target/linux/generic/patches-2.6.31/965-arm_restore_sigmask_v2.patch
--- a/target/linux/generic/patches-2.6.31/965-arm_restore_sigmask_v2.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/965-arm_restore_sigmask_v2.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,354 @@
+From: Mikael Pettersson <mikpe@it.uu.se>
+Date: Sat, 15 Aug 2009 11:58:11 +0000 (+0100)
+Subject: ARM: 5677/1: ARM support for TIF_RESTORE_SIGMASK/pselect6/ppoll/epoll_pwait
+X-Git-Tag: next-20090817~86^2~1^6
+X-Git-Url: http://git.kernel.org/?p=linux%2Fkernel%2Fgit%2Fnext%2Flinux-next.git;a=commitdiff_plain;h=369842658a36bcea28ecb643ba4bdb53919330dd
+
+ARM: 5677/1: ARM support for TIF_RESTORE_SIGMASK/pselect6/ppoll/epoll_pwait
+
+This patch adds support for TIF_RESTORE_SIGMASK to ARM's
+signal handling, which allows to hook up the pselect6, ppoll,
+and epoll_pwait syscalls on ARM.
+
+Tested here with eabi userspace and a test program with a
+deliberate race between a child's exit and the parent's
+sigprocmask/select sequence. Using sys_pselect6() instead
+of sigprocmask/select reliably prevents the race.
+
+The other arch's support for TIF_RESTORE_SIGMASK has evolved
+over time:
+
+In 2.6.16:
+- add TIF_RESTORE_SIGMASK which parallels TIF_SIGPENDING
+- test both when checking for pending signal [changed later]
+- reimplement sys_sigsuspend() to use current->saved_sigmask,
+  TIF_RESTORE_SIGMASK [changed later], and -ERESTARTNOHAND;
+  ditto for sys_rt_sigsuspend(), but drop private code and
+  use common code via __ARCH_WANT_SYS_RT_SIGSUSPEND;
+- there are now no "extra" calls to do_signal() so its oldset
+  parameter is always &current->blocked so need not be passed,
+  also its return value is changed to void
+- change handle_signal() to return 0/-errno
+- change do_signal() to honor TIF_RESTORE_SIGMASK:
+  + get oldset from current->saved_sigmask if TIF_RESTORE_SIGMASK
+    is set
+  + if handle_signal() was successful then clear TIF_RESTORE_SIGMASK
+  + if no signal was delivered and TIF_RESTORE_SIGMASK is set then
+    clear it and restore the sigmask
+- hook up sys_pselect6() and sys_ppoll()
+
+In 2.6.19:
+- hook up sys_epoll_pwait()
+
+In 2.6.26:
+- allow archs to override how TIF_RESTORE_SIGMASK is implemented;
+  default set_restore_sigmask() sets both TIF_RESTORE_SIGMASK and
+  TIF_SIGPENDING; archs need now just test TIF_SIGPENDING again
+  when checking for pending signal work; some archs now implement
+  TIF_RESTORE_SIGMASK as a secondary/non-atomic thread flag bit
+- call set_restore_sigmask() in sys_sigsuspend() instead of setting
+  TIF_RESTORE_SIGMASK
+
+In 2.6.29-rc:
+- kill sys_pselect7() which no arch wanted
+
+So for 2.6.31-rc6/ARM this patch does the following:
+- Add TIF_RESTORE_SIGMASK. Use the generic set_restore_sigmask()
+  which sets both TIF_SIGPENDING and TIF_RESTORE_SIGMASK, so
+  TIF_RESTORE_SIGMASK need not claim one of the scarce low thread
+  flags, and existing TIF_SIGPENDING and _TIF_WORK_MASK tests need
+  not be extended for TIF_RESTORE_SIGMASK.
+- sys_sigsuspend() is reimplemented to use current->saved_sigmask
+  and set_restore_sigmask(), making it identical to most other archs
+- The private code for sys_rt_sigsuspend() is removed, instead
+  generic code supplies it via __ARCH_WANT_SYS_RT_SIGSUSPEND.
+- sys_sigsuspend() and sys_rt_sigsuspend() no longer need a pt_regs
+  parameter, so their assembly code wrappers are removed.
+- handle_signal() is changed to return 0 on success or -errno.
+- The oldset parameter to do_signal() is now redundant and removed,
+  and the return value is now also redundant and changed to void.
+- do_signal() is changed to honor TIF_RESTORE_SIGMASK:
+  + get oldset from current->saved_sigmask if TIF_RESTORE_SIGMASK
+    is set
+  + if handle_signal() was successful then clear TIF_RESTORE_SIGMASK
+  + if no signal was delivered and TIF_RESTORE_SIGMASK is set then
+    clear it and restore the sigmask
+- Hook up sys_pselect6, sys_ppoll, and sys_epoll_pwait.
+
+Signed-off-by: Mikael Pettersson <mikpe@it.uu.se>
+Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
+---
+
+--- a/arch/arm/include/asm/thread_info.h
++++ b/arch/arm/include/asm/thread_info.h
+@@ -140,6 +140,7 @@ extern void vfp_sync_state(struct thread
+ #define TIF_USING_IWMMXT	17
+ #define TIF_MEMDIE		18
+ #define TIF_FREEZE		19
++#define TIF_RESTORE_SIGMASK	20
+ 
+ #define _TIF_SIGPENDING		(1 << TIF_SIGPENDING)
+ #define _TIF_NEED_RESCHED	(1 << TIF_NEED_RESCHED)
+@@ -147,6 +148,7 @@ extern void vfp_sync_state(struct thread
+ #define _TIF_POLLING_NRFLAG	(1 << TIF_POLLING_NRFLAG)
+ #define _TIF_USING_IWMMXT	(1 << TIF_USING_IWMMXT)
+ #define _TIF_FREEZE		(1 << TIF_FREEZE)
++#define _TIF_RESTORE_SIGMASK	(1 << TIF_RESTORE_SIGMASK)
+ 
+ /*
+  * Change these and you break ASM code in entry-common.S
+--- a/arch/arm/include/asm/unistd.h
++++ b/arch/arm/include/asm/unistd.h
+@@ -360,8 +360,8 @@
+ #define __NR_readlinkat			(__NR_SYSCALL_BASE+332)
+ #define __NR_fchmodat			(__NR_SYSCALL_BASE+333)
+ #define __NR_faccessat			(__NR_SYSCALL_BASE+334)
+-					/* 335 for pselect6 */
+-					/* 336 for ppoll */
++#define __NR_pselect6			(__NR_SYSCALL_BASE+335)
++#define __NR_ppoll			(__NR_SYSCALL_BASE+336)
+ #define __NR_unshare			(__NR_SYSCALL_BASE+337)
+ #define __NR_set_robust_list		(__NR_SYSCALL_BASE+338)
+ #define __NR_get_robust_list		(__NR_SYSCALL_BASE+339)
+@@ -372,7 +372,7 @@
+ #define __NR_vmsplice			(__NR_SYSCALL_BASE+343)
+ #define __NR_move_pages			(__NR_SYSCALL_BASE+344)
+ #define __NR_getcpu			(__NR_SYSCALL_BASE+345)
+-					/* 346 for epoll_pwait */
++#define __NR_epoll_pwait		(__NR_SYSCALL_BASE+346)
+ #define __NR_kexec_load			(__NR_SYSCALL_BASE+347)
+ #define __NR_utimensat			(__NR_SYSCALL_BASE+348)
+ #define __NR_signalfd			(__NR_SYSCALL_BASE+349)
+@@ -432,6 +432,7 @@
+ #define __ARCH_WANT_SYS_SIGPENDING
+ #define __ARCH_WANT_SYS_SIGPROCMASK
+ #define __ARCH_WANT_SYS_RT_SIGACTION
++#define __ARCH_WANT_SYS_RT_SIGSUSPEND
+ 
+ #if !defined(CONFIG_AEABI) || defined(CONFIG_OABI_COMPAT)
+ #define __ARCH_WANT_SYS_TIME
+--- a/arch/arm/kernel/calls.S
++++ b/arch/arm/kernel/calls.S
+@@ -81,7 +81,7 @@
+ 		CALL(sys_ni_syscall)		/* was sys_ssetmask */
+ /* 70 */	CALL(sys_setreuid16)
+ 		CALL(sys_setregid16)
+-		CALL(sys_sigsuspend_wrapper)
++		CALL(sys_sigsuspend)
+ 		CALL(sys_sigpending)
+ 		CALL(sys_sethostname)
+ /* 75 */	CALL(sys_setrlimit)
+@@ -188,7 +188,7 @@
+ 		CALL(sys_rt_sigpending)
+ 		CALL(sys_rt_sigtimedwait)
+ 		CALL(sys_rt_sigqueueinfo)
+-		CALL(sys_rt_sigsuspend_wrapper)
++		CALL(sys_rt_sigsuspend)
+ /* 180 */	CALL(ABI(sys_pread64, sys_oabi_pread64))
+ 		CALL(ABI(sys_pwrite64, sys_oabi_pwrite64))
+ 		CALL(sys_chown16)
+@@ -344,8 +344,8 @@
+ 		CALL(sys_readlinkat)
+ 		CALL(sys_fchmodat)
+ 		CALL(sys_faccessat)
+-/* 335 */	CALL(sys_ni_syscall)		/* eventually pselect6 */
+-		CALL(sys_ni_syscall)		/* eventually ppoll */
++/* 335 */	CALL(sys_pselect6)
++		CALL(sys_ppoll)
+ 		CALL(sys_unshare)
+ 		CALL(sys_set_robust_list)
+ 		CALL(sys_get_robust_list)
+@@ -355,7 +355,7 @@
+ 		CALL(sys_vmsplice)
+ 		CALL(sys_move_pages)
+ /* 345 */	CALL(sys_getcpu)
+-		CALL(sys_ni_syscall)		/* eventually epoll_pwait */
++		CALL(sys_epoll_pwait)
+ 		CALL(sys_kexec_load)
+ 		CALL(sys_utimensat)
+ 		CALL(sys_signalfd)
+--- a/arch/arm/kernel/entry-common.S
++++ b/arch/arm/kernel/entry-common.S
+@@ -373,16 +373,6 @@ sys_clone_wrapper:
+ 		b	sys_clone
+ ENDPROC(sys_clone_wrapper)
+ 
+-sys_sigsuspend_wrapper:
+-		add	r3, sp, #S_OFF
+-		b	sys_sigsuspend
+-ENDPROC(sys_sigsuspend_wrapper)
+-
+-sys_rt_sigsuspend_wrapper:
+-		add	r2, sp, #S_OFF
+-		b	sys_rt_sigsuspend
+-ENDPROC(sys_rt_sigsuspend_wrapper)
+-
+ sys_sigreturn_wrapper:
+ 		add	r0, sp, #S_OFF
+ 		b	sys_sigreturn
+--- a/arch/arm/kernel/signal.c
++++ b/arch/arm/kernel/signal.c
+@@ -47,57 +47,22 @@ const unsigned long sigreturn_codes[7] =
+ 	MOV_R7_NR_RT_SIGRETURN, SWI_SYS_RT_SIGRETURN, SWI_THUMB_RT_SIGRETURN,
+ };
+ 
+-static int do_signal(sigset_t *oldset, struct pt_regs * regs, int syscall);
+-
+ /*
+  * atomically swap in the new signal mask, and wait for a signal.
+  */
+-asmlinkage int sys_sigsuspend(int restart, unsigned long oldmask, old_sigset_t mask, struct pt_regs *regs)
++asmlinkage int sys_sigsuspend(int restart, unsigned long oldmask, old_sigset_t mask)
+ {
+-	sigset_t saveset;
+-
+ 	mask &= _BLOCKABLE;
+ 	spin_lock_irq(&current->sighand->siglock);
+-	saveset = current->blocked;
++	current->saved_sigmask = current->blocked;
+ 	siginitset(&current->blocked, mask);
+ 	recalc_sigpending();
+ 	spin_unlock_irq(&current->sighand->siglock);
+-	regs->ARM_r0 = -EINTR;
+-
+-	while (1) {
+-		current->state = TASK_INTERRUPTIBLE;
+-		schedule();
+-		if (do_signal(&saveset, regs, 0))
+-			return regs->ARM_r0;
+-	}
+-}
+-
+-asmlinkage int
+-sys_rt_sigsuspend(sigset_t __user *unewset, size_t sigsetsize, struct pt_regs *regs)
+-{
+-	sigset_t saveset, newset;
+-
+-	/* XXX: Don't preclude handling different sized sigset_t's. */
+-	if (sigsetsize != sizeof(sigset_t))
+-		return -EINVAL;
+-
+-	if (copy_from_user(&newset, unewset, sizeof(newset)))
+-		return -EFAULT;
+-	sigdelsetmask(&newset, ~_BLOCKABLE);
+-
+-	spin_lock_irq(&current->sighand->siglock);
+-	saveset = current->blocked;
+-	current->blocked = newset;
+-	recalc_sigpending();
+-	spin_unlock_irq(&current->sighand->siglock);
+-	regs->ARM_r0 = -EINTR;
+ 
+-	while (1) {
+-		current->state = TASK_INTERRUPTIBLE;
+-		schedule();
+-		if (do_signal(&saveset, regs, 0))
+-			return regs->ARM_r0;
+-	}
++	current->state = TASK_INTERRUPTIBLE;
++	schedule();
++	set_restore_sigmask();
++	return -ERESTARTNOHAND;
+ }
+ 
+ asmlinkage int 
+@@ -545,7 +510,7 @@ static inline void setup_syscall_restart
+ /*
+  * OK, we're invoking a handler
+  */	
+-static void
++static int
+ handle_signal(unsigned long sig, struct k_sigaction *ka,
+ 	      siginfo_t *info, sigset_t *oldset,
+ 	      struct pt_regs * regs, int syscall)
+@@ -596,7 +561,7 @@ handle_signal(unsigned long sig, struct
+ 
+ 	if (ret != 0) {
+ 		force_sigsegv(sig, tsk);
+-		return;
++		return ret;
+ 	}
+ 
+ 	/*
+@@ -610,6 +575,7 @@ handle_signal(unsigned long sig, struct
+ 	recalc_sigpending();
+ 	spin_unlock_irq(&tsk->sighand->siglock);
+ 
++	return 0;
+ }
+ 
+ /*
+@@ -621,11 +587,12 @@ handle_signal(unsigned long sig, struct
+  * the kernel can handle, and then we build all the user-level signal handling
+  * stack-frames in one go after that.
+  */
+-static int do_signal(sigset_t *oldset, struct pt_regs *regs, int syscall)
++static void do_signal(struct pt_regs *regs, int syscall)
+ {
+ 	struct k_sigaction ka;
+ 	siginfo_t info;
+ 	int signr;
++	sigset_t *oldset;
+ 
+ 	/*
+ 	 * We want the common case to go fast, which
+@@ -634,18 +601,32 @@ static int do_signal(sigset_t *oldset, s
+ 	 * if so.
+ 	 */
+ 	if (!user_mode(regs))
+-		return 0;
++		return;
+ 
+ 	if (try_to_freeze())
+ 		goto no_signal;
+ 
+ 	single_step_clear(current);
+ 
++	if (test_thread_flag(TIF_RESTORE_SIGMASK))
++		oldset = &current->saved_sigmask;
++	else
++		oldset = &current->blocked;
++
+ 	signr = get_signal_to_deliver(&info, &ka, regs, NULL);
+ 	if (signr > 0) {
+-		handle_signal(signr, &ka, &info, oldset, regs, syscall);
++		if (handle_signal(signr, &ka, &info, oldset, regs, syscall) == 0) {
++			/*
++			 * A signal was successfully delivered; the saved
++			 * sigmask will have been stored in the signal frame,
++			 * and will be restored by sigreturn, so we can simply
++			 * clear the TIF_RESTORE_SIGMASK flag.
++			 */
++			if (test_thread_flag(TIF_RESTORE_SIGMASK))
++				clear_thread_flag(TIF_RESTORE_SIGMASK);
++		}
+ 		single_step_set(current);
+-		return 1;
++		return;
+ 	}
+ 
+  no_signal:
+@@ -697,14 +678,21 @@ static int do_signal(sigset_t *oldset, s
+ 		    regs->ARM_r0 == -ERESTARTNOINTR) {
+ 			setup_syscall_restart(regs);
+ 		}
++
++		/* If there's no signal to deliver, we just put the saved sigmask
++		 * back.
++		 */
++		if (test_thread_flag(TIF_RESTORE_SIGMASK)) {
++			clear_thread_flag(TIF_RESTORE_SIGMASK);
++			sigprocmask(SIG_SETMASK, &current->saved_sigmask, NULL);
++		}
+ 	}
+ 	single_step_set(current);
+-	return 0;
+ }
+ 
+ asmlinkage void
+ do_notify_resume(struct pt_regs *regs, unsigned int thread_flags, int syscall)
+ {
+ 	if (thread_flags & _TIF_SIGPENDING)
+-		do_signal(&current->blocked, regs, syscall);
++		do_signal(regs, syscall);
+ }
diff -Nru a/target/linux/generic/patches-2.6.31/970-ocf_kbuild_integration.patch b/target/linux/generic/patches-2.6.31/970-ocf_kbuild_integration.patch
--- a/target/linux/generic/patches-2.6.31/970-ocf_kbuild_integration.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/970-ocf_kbuild_integration.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,20 @@
+--- a/crypto/Kconfig
++++ b/crypto/Kconfig
+@@ -791,3 +791,6 @@ config CRYPTO_ANSI_CPRNG
+ source "drivers/crypto/Kconfig"
+ 
+ endif	# if CRYPTO
++
++source "crypto/ocf/Kconfig"
++
+--- a/crypto/Makefile
++++ b/crypto/Makefile
+@@ -84,6 +84,8 @@ obj-$(CONFIG_CRYPTO_RNG2) += krng.o
+ obj-$(CONFIG_CRYPTO_ANSI_CPRNG) += ansi_cprng.o
+ obj-$(CONFIG_CRYPTO_TEST) += tcrypt.o
+ 
++obj-$(CONFIG_OCF_OCF) += ocf/
++
+ #
+ # generic algorithms and the async_tx api
+ #
diff -Nru a/target/linux/generic/patches-2.6.31/971-ocf_20110720.patch b/target/linux/generic/patches-2.6.31/971-ocf_20110720.patch
--- a/target/linux/generic/patches-2.6.31/971-ocf_20110720.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/971-ocf_20110720.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,131 @@
+--- a/drivers/char/random.c
++++ b/drivers/char/random.c
+@@ -129,6 +129,9 @@
+  *                                unsigned int value);
+  * 	void add_interrupt_randomness(int irq);
+  *
++ *      void random_input_words(__u32 *buf, size_t wordcount, int ent_count)
++ *      int random_input_wait(void);
++ *
+  * add_input_randomness() uses the input layer interrupt timing, as well as
+  * the event type information from the hardware.
+  *
+@@ -140,6 +143,13 @@
+  * a better measure, since the timing of the disk interrupts are more
+  * unpredictable.
+  *
++ * random_input_words() just provides a raw block of entropy to the input
++ * pool, such as from a hardware entropy generator.
++ *
++ * random_input_wait() suspends the caller until such time as the
++ * entropy pool falls below the write threshold, and returns a count of how
++ * much entropy (in bits) is needed to sustain the pool.
++ *
+  * All of these routines try to estimate how many bits of randomness a
+  * particular randomness source.  They do this by keeping track of the
+  * first and second order deltas of the event timings.
+@@ -712,6 +722,61 @@ void add_disk_randomness(struct gendisk
+ }
+ #endif
+ 
++/*
++ * random_input_words - add bulk entropy to pool
++ *
++ * @buf: buffer to add
++ * @wordcount: number of __u32 words to add
++ * @ent_count: total amount of entropy (in bits) to credit
++ *
++ * this provides bulk input of entropy to the input pool
++ *
++ */
++void random_input_words(__u32 *buf, size_t wordcount, int ent_count)
++{
++	mix_pool_bytes(&input_pool, buf, wordcount*4);
++
++	credit_entropy_bits(&input_pool, ent_count);
++
++	DEBUG_ENT("crediting %d bits => %d\n",
++		  ent_count, input_pool.entropy_count);
++	/*
++	 * Wake up waiting processes if we have enough
++	 * entropy.
++	 */
++	if (input_pool.entropy_count >= random_read_wakeup_thresh)
++		wake_up_interruptible(&random_read_wait);
++}
++EXPORT_SYMBOL(random_input_words);
++
++/*
++ * random_input_wait - wait until random needs entropy
++ *
++ * this function sleeps until the /dev/random subsystem actually
++ * needs more entropy, and then return the amount of entropy
++ * that it would be nice to have added to the system.
++ */
++int random_input_wait(void)
++{
++	int count;
++
++	wait_event_interruptible(random_write_wait, 
++			 input_pool.entropy_count < random_write_wakeup_thresh);
++
++	count = random_write_wakeup_thresh - input_pool.entropy_count;
++
++        /* likely we got woken up due to a signal */
++	if (count <= 0) count = random_read_wakeup_thresh; 
++
++	DEBUG_ENT("requesting %d bits from input_wait()er %d<%d\n",
++		  count,
++		  input_pool.entropy_count, random_write_wakeup_thresh);
++
++	return count;
++}
++EXPORT_SYMBOL(random_input_wait);
++
++
+ #define EXTRACT_SIZE 10
+ 
+ /*********************************************************************
+--- a/fs/fcntl.c
++++ b/fs/fcntl.c
+@@ -195,6 +195,7 @@ static int setfl(int fd, struct file * f
+  out:
+ 	return error;
+ }
++EXPORT_SYMBOL(sys_dup);
+ 
+ static void f_modown(struct file *filp, struct pid *pid, enum pid_type type,
+                      int force)
+--- a/include/linux/miscdevice.h
++++ b/include/linux/miscdevice.h
+@@ -12,6 +12,7 @@
+ #define APOLLO_MOUSE_MINOR	7
+ #define PC110PAD_MINOR		9
+ /*#define ADB_MOUSE_MINOR	10	FIXME OBSOLETE */
++#define CRYPTODEV_MINOR		70	/* /dev/crypto */
+ #define WATCHDOG_MINOR		130	/* Watchdog timer     */
+ #define TEMP_MINOR		131	/* Temperature Sensor */
+ #define RTC_MINOR		135
+--- a/include/linux/random.h
++++ b/include/linux/random.h
+@@ -50,6 +50,10 @@ extern void add_input_randomness(unsigne
+ 				 unsigned int value);
+ extern void add_interrupt_randomness(int irq);
+ 
++extern void random_input_words(__u32 *buf, size_t wordcount, int ent_count);
++extern int random_input_wait(void);
++#define HAS_RANDOM_INPUT_WAIT 1
++
+ extern void get_random_bytes(void *buf, int nbytes);
+ void generate_random_uuid(unsigned char uuid_out[16]);
+ 
+--- a/kernel/pid.c
++++ b/kernel/pid.c
+@@ -387,6 +387,7 @@ struct task_struct *find_task_by_vpid(pi
+ {
+ 	return find_task_by_pid_ns(vnr, current->nsproxy->pid_ns);
+ }
++EXPORT_SYMBOL(find_task_by_vpid);
+ 
+ struct pid *get_task_pid(struct task_struct *task, enum pid_type type)
+ {
diff -Nru a/target/linux/generic/patches-2.6.31/974-ssb_b43_default_on.patch b/target/linux/generic/patches-2.6.31/974-ssb_b43_default_on.patch
--- a/target/linux/generic/patches-2.6.31/974-ssb_b43_default_on.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/974-ssb_b43_default_on.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,29 @@
+--- a/drivers/ssb/Kconfig
++++ b/drivers/ssb/Kconfig
+@@ -29,6 +29,7 @@ config SSB_SPROM
+ config SSB_BLOCKIO
+ 	bool
+ 	depends on SSB
++	default y
+ 
+ config SSB_PCIHOST_POSSIBLE
+ 	bool
+@@ -49,7 +50,7 @@ config SSB_PCIHOST
+ config SSB_B43_PCI_BRIDGE
+ 	bool
+ 	depends on SSB_PCIHOST
+-	default n
++	default y
+ 
+ config SSB_PCMCIAHOST_POSSIBLE
+ 	bool
+--- a/drivers/bcma/Kconfig
++++ b/drivers/bcma/Kconfig
+@@ -17,6 +17,7 @@ config BCMA
+ config BCMA_BLOCKIO
+ 	bool
+ 	depends on BCMA
++	default y
+ 
+ config BCMA_HOST_PCI_POSSIBLE
+ 	bool
diff -Nru a/target/linux/generic/patches-2.6.31/975-hifn795x-byteswap.patch b/target/linux/generic/patches-2.6.31/975-hifn795x-byteswap.patch
--- a/target/linux/generic/patches-2.6.31/975-hifn795x-byteswap.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/975-hifn795x-byteswap.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,17 @@
+--- a/drivers/crypto/hifn_795x.c
++++ b/drivers/crypto/hifn_795x.c
+@@ -682,12 +682,12 @@ static inline u32 hifn_read_1(struct hif
+ 
+ static inline void hifn_write_0(struct hifn_device *dev, u32 reg, u32 val)
+ {
+-	writel((__force u32)cpu_to_le32(val), dev->bar[0] + reg);
++	writel(val, dev->bar[0] + reg);
+ }
+ 
+ static inline void hifn_write_1(struct hifn_device *dev, u32 reg, u32 val)
+ {
+-	writel((__force u32)cpu_to_le32(val), dev->bar[1] + reg);
++	writel(val, dev->bar[1] + reg);
+ }
+ 
+ static void hifn_wait_puc(struct hifn_device *dev)
diff -Nru a/target/linux/generic/patches-2.6.31/977-textsearch_kconfig_hacks.patch b/target/linux/generic/patches-2.6.31/977-textsearch_kconfig_hacks.patch
--- a/target/linux/generic/patches-2.6.31/977-textsearch_kconfig_hacks.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/977-textsearch_kconfig_hacks.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,23 @@
+--- a/lib/Kconfig
++++ b/lib/Kconfig
+@@ -152,16 +152,16 @@ config REED_SOLOMON_DEC16
+ # Textsearch support is select'ed if needed
+ #
+ config TEXTSEARCH
+-	boolean
++	boolean	"Textsearch support"
+ 
+ config TEXTSEARCH_KMP
+-	tristate
++	tristate "Textsearch KMP"
+ 
+ config TEXTSEARCH_BM
+-	tristate
++	tristate "Textsearch BM"
+ 
+ config TEXTSEARCH_FSM
+-	tristate
++	tristate "Textsearch FSM"
+ 
+ config HAS_IOMEM
+ 	boolean
diff -Nru a/target/linux/generic/patches-2.6.31/978-lib80211_kconfig_hacks.patch b/target/linux/generic/patches-2.6.31/978-lib80211_kconfig_hacks.patch
--- a/target/linux/generic/patches-2.6.31/978-lib80211_kconfig_hacks.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/978-lib80211_kconfig_hacks.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,19 @@
+--- a/net/wireless/Kconfig
++++ b/net/wireless/Kconfig
+@@ -72,13 +72,13 @@ config LIB80211
+ 	  you want this built into your kernel.
+ 
+ config LIB80211_CRYPT_WEP
+-	tristate
++	tristate "LIB80211_CRYPT_WEP"
+ 
+ config LIB80211_CRYPT_CCMP
+-	tristate
++	tristate "LIB80211_CRYPT_CCMP"
+ 
+ config LIB80211_CRYPT_TKIP
+-	tristate
++	tristate "LIB80211_CRYPT_TKIP"
+ 
+ config LIB80211_DEBUG
+ 	bool "lib80211 debugging messages"
diff -Nru a/target/linux/generic/patches-2.6.31/979-crypto_add_kconfig_prompts.patch b/target/linux/generic/patches-2.6.31/979-crypto_add_kconfig_prompts.patch
--- a/target/linux/generic/patches-2.6.31/979-crypto_add_kconfig_prompts.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/979-crypto_add_kconfig_prompts.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,47 @@
+--- a/crypto/Kconfig
++++ b/crypto/Kconfig
+@@ -30,7 +30,7 @@ config CRYPTO_FIPS
+ 	  this is.
+ 
+ config CRYPTO_ALGAPI
+-	tristate
++	tristate "ALGAPI"
+ 	select CRYPTO_ALGAPI2
+ 	help
+ 	  This option provides the API for cryptographic algorithms.
+@@ -39,7 +39,7 @@ config CRYPTO_ALGAPI2
+ 	tristate
+ 
+ config CRYPTO_AEAD
+-	tristate
++	tristate "AEAD"
+ 	select CRYPTO_AEAD2
+ 	select CRYPTO_ALGAPI
+ 
+@@ -48,7 +48,7 @@ config CRYPTO_AEAD2
+ 	select CRYPTO_ALGAPI2
+ 
+ config CRYPTO_BLKCIPHER
+-	tristate
++	tristate "BLKCIPHER"
+ 	select CRYPTO_BLKCIPHER2
+ 	select CRYPTO_ALGAPI
+ 
+@@ -59,7 +59,7 @@ config CRYPTO_BLKCIPHER2
+ 	select CRYPTO_WORKQUEUE
+ 
+ config CRYPTO_HASH
+-	tristate
++	tristate "HASH"
+ 	select CRYPTO_HASH2
+ 	select CRYPTO_ALGAPI
+ 
+@@ -68,7 +68,7 @@ config CRYPTO_HASH2
+ 	select CRYPTO_ALGAPI2
+ 
+ config CRYPTO_RNG
+-	tristate
++	tristate "RNG"
+ 	select CRYPTO_RNG2
+ 	select CRYPTO_ALGAPI
+ 
diff -Nru a/target/linux/generic/patches-2.6.31/980-vm_exports.patch b/target/linux/generic/patches-2.6.31/980-vm_exports.patch
--- a/target/linux/generic/patches-2.6.31/980-vm_exports.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/980-vm_exports.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,135 @@
+--- a/mm/shmem.c
++++ b/mm/shmem.c
+@@ -2602,6 +2602,16 @@ int shmem_unuse(swp_entry_t entry, struc
+ 
+ /* common code */
+ 
++void shmem_set_file(struct vm_area_struct *vma, struct file *file)
++{
++	ima_counts_get(file);
++	if (vma->vm_file)
++		fput(vma->vm_file);
++	vma->vm_file = file;
++	vma->vm_ops = &shmem_vm_ops;
++}
++EXPORT_SYMBOL_GPL(shmem_set_file);
++
+ /**
+  * shmem_file_setup - get an unlinked file living in tmpfs
+  * @name: name for dentry (to be seen in /proc/<pid>/maps
+@@ -2681,10 +2691,7 @@ int shmem_zero_setup(struct vm_area_stru
+ 	if (IS_ERR(file))
+ 		return PTR_ERR(file);
+ 
+-	if (vma->vm_file)
+-		fput(vma->vm_file);
+-	vma->vm_file = file;
+-	vma->vm_ops = &shmem_vm_ops;
++	shmem_set_file(vma, file);
+ 	return 0;
+ }
+ 
+--- a/fs/file.c
++++ b/fs/file.c
+@@ -270,6 +270,7 @@ int expand_files(struct files_struct *fi
+ 	/* All good, so we try */
+ 	return expand_fdtable(files, nr);
+ }
++EXPORT_SYMBOL_GPL(expand_files);
+ 
+ static int count_open_files(struct fdtable *fdt)
+ {
+--- a/kernel/exit.c
++++ b/kernel/exit.c
+@@ -507,6 +507,7 @@ struct files_struct *get_files_struct(st
+ 
+ 	return files;
+ }
++EXPORT_SYMBOL_GPL(get_files_struct);
+ 
+ void put_files_struct(struct files_struct *files)
+ {
+@@ -526,6 +527,7 @@ void put_files_struct(struct files_struc
+ 		free_fdtable(fdt);
+ 	}
+ }
++EXPORT_SYMBOL_GPL(put_files_struct);
+ 
+ void reset_files_struct(struct files_struct *files)
+ {
+--- a/kernel/fork.c
++++ b/kernel/fork.c
+@@ -159,6 +159,7 @@ void __put_task_struct(struct task_struc
+ 	if (!profile_handoff_task(tsk))
+ 		free_task(tsk);
+ }
++EXPORT_SYMBOL_GPL(__put_task_struct);
+ 
+ /*
+  * macro override instead of weak attribute alias, to workaround
+--- a/kernel/sched.c
++++ b/kernel/sched.c
+@@ -5981,6 +5981,7 @@ int can_nice(const struct task_struct *p
+ 	return (nice_rlim <= p->signal->rlim[RLIMIT_NICE].rlim_cur ||
+ 		capable(CAP_SYS_NICE));
+ }
++EXPORT_SYMBOL_GPL(can_nice);
+ 
+ #ifdef __ARCH_WANT_SYS_NICE
+ 
+--- a/mm/memory.c
++++ b/mm/memory.c
+@@ -1064,6 +1064,7 @@ unsigned long zap_page_range(struct vm_a
+ 		tlb_finish_mmu(tlb, address, end);
+ 	return end;
+ }
++EXPORT_SYMBOL_GPL(zap_page_range);
+ 
+ /**
+  * zap_vma_ptes - remove ptes mapping the vma
+@@ -2490,6 +2491,7 @@ int vmtruncate_range(struct inode *inode
+ 
+ 	return 0;
+ }
++EXPORT_SYMBOL_GPL(vmtruncate_range);
+ 
+ /*
+  * We enter with non-exclusive mmap_sem (to exclude vma changes,
+--- a/mm/vmalloc.c
++++ b/mm/vmalloc.c
+@@ -1099,6 +1099,7 @@ void unmap_kernel_range(unsigned long ad
+ 	vunmap_page_range(addr, end);
+ 	flush_tlb_kernel_range(addr, end);
+ }
++EXPORT_SYMBOL_GPL(unmap_kernel_range);
+ 
+ int map_vm_area(struct vm_struct *area, pgprot_t prot, struct page ***pages)
+ {
+@@ -1212,6 +1213,7 @@ struct vm_struct *get_vm_area(unsigned l
+ 	return __get_vm_area_node(size, flags, VMALLOC_START, VMALLOC_END,
+ 				-1, GFP_KERNEL, __builtin_return_address(0));
+ }
++EXPORT_SYMBOL_GPL(get_vm_area);
+ 
+ struct vm_struct *get_vm_area_caller(unsigned long size, unsigned long flags,
+ 				void *caller)
+--- a/include/linux/mm.h
++++ b/include/linux/mm.h
+@@ -712,6 +712,7 @@ static inline int shmem_lock(struct file
+ #endif
+ struct file *shmem_file_setup(const char *name, loff_t size, unsigned long flags);
+ 
++void shmem_set_file(struct vm_area_struct *vma, struct file *file);
+ int shmem_zero_setup(struct vm_area_struct *);
+ 
+ #ifndef CONFIG_MMU
+--- a/kernel/signal.c
++++ b/kernel/signal.c
+@@ -1062,6 +1062,7 @@ struct sighand_struct *lock_task_sighand
+ 
+ 	return sighand;
+ }
++EXPORT_SYMBOL(lock_task_sighand);
+ 
+ /*
+  * send signal info to all the members of a group
diff -Nru a/target/linux/generic/patches-2.6.31/991-ppc4xx_optimization.patch b/target/linux/generic/patches-2.6.31/991-ppc4xx_optimization.patch
--- a/target/linux/generic/patches-2.6.31/991-ppc4xx_optimization.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/991-ppc4xx_optimization.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,30 @@
+Upstream doesn't optimize the kernel and bootwrappers for ppc44x because
+they still want to support gcc 3.3 -- well, we don't.
+
+--- a/arch/powerpc/Makefile
++++ b/arch/powerpc/Makefile
+@@ -123,7 +123,8 @@ ifeq ($(CONFIG_FUNCTION_TRACER),y)
+ KBUILD_CFLAGS		+= -mno-sched-epilog
+ endif
+ 
+-cpu-as-$(CONFIG_4xx)		+= -Wa,-m405
++cpu-as-$(CONFIG_40x)		+= -Wa,-m405
++cpu-as-$(CONFIG_44x)		+= -Wa,-m440
+ cpu-as-$(CONFIG_6xx)		+= -Wa,-maltivec
+ cpu-as-$(CONFIG_POWER4)		+= -Wa,-maltivec
+ cpu-as-$(CONFIG_E500)		+= -Wa,-me500
+--- a/arch/powerpc/boot/Makefile
++++ b/arch/powerpc/boot/Makefile
+@@ -38,9 +38,9 @@ BOOTCFLAGS	+= -I$(obj) -I$(srctree)/$(ob
+ DTS_FLAGS	?= -p 1024
+ 
+ $(obj)/4xx.o: BOOTCFLAGS += -mcpu=405
+-$(obj)/ebony.o: BOOTCFLAGS += -mcpu=405
+-$(obj)/cuboot-taishan.o: BOOTCFLAGS += -mcpu=405
+-$(obj)/cuboot-katmai.o: BOOTCFLAGS += -mcpu=405
++$(obj)/ebony.o: BOOTCFLAGS += -mcpu=440
++$(obj)/cuboot-taishan.o: BOOTCFLAGS += -mcpu=440
++$(obj)/cuboot-katmai.o: BOOTCFLAGS += -mcpu=440
+ $(obj)/cuboot-acadia.o: BOOTCFLAGS += -mcpu=405
+ $(obj)/treeboot-walnut.o: BOOTCFLAGS += -mcpu=405
+ $(obj)/virtex405-head.o: BOOTAFLAGS += -mcpu=405
diff -Nru a/target/linux/generic/patches-2.6.31/998-openwrt_lzma_options.patch b/target/linux/generic/patches-2.6.31/998-openwrt_lzma_options.patch
--- a/target/linux/generic/patches-2.6.31/998-openwrt_lzma_options.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/998-openwrt_lzma_options.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,44 @@
+--- a/scripts/Makefile.lib
++++ b/scripts/Makefile.lib
+@@ -228,7 +228,7 @@ cmd_bzip2 = (cat $(filter-out FORCE,$^)
+ 
+ quiet_cmd_lzma = LZMA    $@
+ cmd_lzma = (cat $(filter-out FORCE,$^) | \
+-	lzma -9 && $(call size_append, $(filter-out FORCE,$^))) > $@ || \
++	lzma e -lc1 -lp2 -pb2 -eos -si -so && $(call size_append, $(filter-out FORCE,$^))) > $@ || \
+ 	(rm -f $@ ; false)
+ 
+ quiet_cmd_lzo = LZO    $@
+--- a/scripts/gen_initramfs_list.sh
++++ b/scripts/gen_initramfs_list.sh
+@@ -225,7 +225,7 @@ cpio_list=
+ output="/dev/stdout"
+ output_file=""
+ is_cpio_compressed=
+-compr="gzip -9 -f"
++compr="gzip -9 -f -"
+ 
+ arg="$1"
+ case "$arg" in
+@@ -239,9 +239,9 @@ case "$arg" in
+ 		output_file="$1"
+ 		cpio_list="$(mktemp ${TMPDIR:-/tmp}/cpiolist.XXXXXX)"
+ 		output=${cpio_list}
+-		echo "$output_file" | grep -q "\.gz$" && compr="gzip -9 -f"
+-		echo "$output_file" | grep -q "\.bz2$" && compr="bzip2 -9 -f"
+-		echo "$output_file" | grep -q "\.lzma$" && compr="lzma -9 -f"
++		echo "$output_file" | grep -q "\.gz$" && compr="gzip -9 -f -"
++		echo "$output_file" | grep -q "\.bz2$" && compr="bzip2 -9 -f -"
++		echo "$output_file" | grep -q "\.lzma$" && compr="lzma e -lc1 -lp2 -pb2 -eos -si -so"
+ 		echo "$output_file" | grep -q "\.cpio$" && compr="cat"
+ 		shift
+ 		;;
+@@ -292,7 +292,7 @@ if [ ! -z ${output_file} ]; then
+ 	if [ "${is_cpio_compressed}" = "compressed" ]; then
+ 		cat ${cpio_tfile} > ${output_file}
+ 	else
+-		(cat ${cpio_tfile} | ${compr}  - > ${output_file}) \
++		(cat ${cpio_tfile} | ${compr} > ${output_file}) \
+ 		|| (rm -f ${output_file} ; false)
+ 	fi
+ 	[ -z ${cpio_file} ] && rm ${cpio_tfile}
diff -Nru a/target/linux/generic/patches-2.6.31/999-use_preinit_as_init.patch b/target/linux/generic/patches-2.6.31/999-use_preinit_as_init.patch
--- a/target/linux/generic/patches-2.6.31/999-use_preinit_as_init.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/generic/patches-2.6.31/999-use_preinit_as_init.patch	2013-07-22 22:05:44.000000000 +0200
@@ -0,0 +1,14 @@
+--- a/init/main.c
++++ b/init/main.c
+@@ -863,10 +863,7 @@ static noinline int init_post(void)
+ 		printk(KERN_WARNING "Failed to execute %s.  Attempting "
+ 					"defaults...\n", execute_command);
+ 	}
+-	run_init_process("/sbin/init");
+-	run_init_process("/etc/init");
+-	run_init_process("/bin/init");
+-	run_init_process("/bin/sh");
++	run_init_process("/etc/preinit");
+ 
+ 	panic("No init found.  Try passing init= option to kernel.");
+ }
diff -Nru a/target/linux/mr-mips/base-files/etc/hotplug2-init.rules b/target/linux/mr-mips/base-files/etc/hotplug2-init.rules
--- a/target/linux/mr-mips/base-files/etc/hotplug2-init.rules	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/mr-mips/base-files/etc/hotplug2-init.rules	2013-07-22 22:25:00.415082259 +0200
@@ -0,0 +1,7 @@
+$include /etc/hotplug2-common.rules
+
+DEVICENAME ~~ (hvc) {
+        nothrottle
+        makedev /dev/%DEVICENAME% 0666
+        next
+}
diff -Nru a/target/linux/mr-mips/base-files/etc/inittab b/target/linux/mr-mips/base-files/etc/inittab
--- a/target/linux/mr-mips/base-files/etc/inittab	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/mr-mips/base-files/etc/inittab	2013-07-22 22:25:00.415082259 +0200
@@ -0,0 +1,3 @@
+::sysinit:/etc/init.d/rcS S boot
+::shutdown:/etc/init.d/rcS K stop
+hvc0::askfirst:/bin/ash --login
diff -Nru a/target/linux/mr-mips/config-2.6.31 b/target/linux/mr-mips/config-2.6.31
--- a/target/linux/mr-mips/config-2.6.31	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/mr-mips/config-2.6.31	2013-07-22 22:25:00.414082301 +0200
@@ -0,0 +1,229 @@
+CONFIG_MIPS=y
+
+#
+# Machine selection
+#
+# CONFIG_MACH_ALCHEMY is not set
+# CONFIG_AR7 is not set
+# CONFIG_BASLER_EXCITE is not set
+# CONFIG_BCM47XX is not set
+# CONFIG_MIPS_COBALT is not set
+# CONFIG_MACH_DECSTATION is not set
+# CONFIG_MACH_JAZZ is not set
+# CONFIG_LASAT is not set
+# CONFIG_LEMOTE_FULONG is not set
+# CONFIG_MIPS_MALTA is not set
+# CONFIG_MIPS_SIM is not set
+# CONFIG_NEC_MARKEINS is not set
+# CONFIG_MACH_VR41XX is not set
+# CONFIG_NXP_STB220 is not set
+# CONFIG_NXP_STB225 is not set
+# CONFIG_PNX8550_JBS is not set
+# CONFIG_PNX8550_STB810 is not set
+# CONFIG_PMC_MSP is not set
+# CONFIG_PMC_YOSEMITE is not set
+# CONFIG_SGI_IP22 is not set
+# CONFIG_SGI_IP27 is not set
+# CONFIG_SGI_IP28 is not set
+# CONFIG_SGI_IP32 is not set
+# CONFIG_SIBYTE_CRHINE is not set
+# CONFIG_SIBYTE_CARMEL is not set
+# CONFIG_SIBYTE_CRHONE is not set
+# CONFIG_SIBYTE_RHONE is not set
+# CONFIG_SIBYTE_SWARM is not set
+# CONFIG_SIBYTE_LITTLESUR is not set
+# CONFIG_SIBYTE_SENTOSA is not set
+# CONFIG_SIBYTE_BIGSUR is not set
+# CONFIG_SNI_RM is not set
+# CONFIG_MACH_TX39XX is not set
+# CONFIG_MACH_TX49XX is not set
+# CONFIG_MIKROTIK_RB532 is not set
+CONFIG_METAROUTER=y
+# CONFIG_WR_PPMC is not set
+# CONFIG_CAVIUM_OCTEON_SIMULATOR is not set
+# CONFIG_CAVIUM_OCTEON_REFERENCE_BOARD is not set
+# CONFIG_ALCHEMY_GPIO_INDIRECT is not set
+# CONFIG_WR_PPMC is not set
+CONFIG_MAPPED_KERNEL=y
+CONFIG_RWSEM_GENERIC_SPINLOCK=y
+# CONFIG_ARCH_HAS_ILOG2_U32 is not set
+# CONFIG_ARCH_HAS_ILOG2_U64 is not set
+CONFIG_ARCH_SUPPORTS_OPROFILE=y
+CONFIG_GENERIC_FIND_NEXT_BIT=y
+CONFIG_GENERIC_HWEIGHT=y
+CONFIG_GENERIC_CALIBRATE_DELAY=y
+CONFIG_GENERIC_CLOCKEVENTS=y
+CONFIG_GENERIC_TIME=y
+CONFIG_GENERIC_CMOS_UPDATE=y
+CONFIG_SCHED_NO_NO_OMIT_FRAME_POINTER=y
+# CONFIG_GENERIC_HARDIRQS_NO__DO_IRQ is not set
+CONFIG_CEVT_R4K=y
+CONFIG_CSRC_R4K=y
+CONFIG_DMA_NONCOHERENT=y
+CONFIG_DMA_NEED_PCI_MAP_STATE=y
+# CONFIG_HOTPLUG_CPU is not set
+# CONFIG_NO_IOPORT is not set
+CONFIG_CPU_BIG_ENDIAN=y
+# CONFIG_CPU_LITTLE_ENDIAN is not set
+CONFIG_SYS_SUPPORTS_BIG_ENDIAN=y
+CONFIG_IRQ_CPU=y
+CONFIG_MIPS_L1_CACHE_SHIFT=5
+
+#
+# CPU selection
+#
+# CONFIG_CPU_LOONGSON2 is not set
+CONFIG_CPU_MIPS32_R1=y
+# CONFIG_CPU_MIPS32_R2 is not set
+# CONFIG_CPU_MIPS64_R1 is not set
+# CONFIG_CPU_MIPS64_R2 is not set
+# CONFIG_CPU_R3000 is not set
+# CONFIG_CPU_TX39XX is not set
+# CONFIG_CPU_VR41XX is not set
+# CONFIG_CPU_R4300 is not set
+# CONFIG_CPU_R4X00 is not set
+# CONFIG_CPU_TX49XX is not set
+# CONFIG_CPU_R5000 is not set
+# CONFIG_CPU_R5432 is not set
+# CONFIG_CPU_R6000 is not set
+# CONFIG_CPU_NEVADA is not set
+# CONFIG_CPU_R8000 is not set
+# CONFIG_CPU_R10000 is not set
+# CONFIG_CPU_RM7000 is not set
+# CONFIG_CPU_RM9000 is not set
+# CONFIG_CPU_SB1 is not set
+CONFIG_SYS_HAS_CPU_MIPS32_R1=y
+CONFIG_CPU_MIPS32=y
+CONFIG_CPU_MIPSR1=y
+CONFIG_SYS_SUPPORTS_32BIT_KERNEL=y
+CONFIG_CPU_SUPPORTS_32BIT_KERNEL=y
+
+#
+# Kernel type
+#
+CONFIG_32BIT=y
+# CONFIG_64BIT is not set
+CONFIG_PAGE_SIZE_4KB=y
+# CONFIG_PAGE_SIZE_8KB is not set
+# CONFIG_PAGE_SIZE_16KB is not set
+# CONFIG_PAGE_SIZE_64KB is not set
+CONFIG_CPU_HAS_PREFETCH=y
+CONFIG_MIPS_MT_DISABLED=y
+# CONFIG_MIPS_MT_SMP is not set
+# CONFIG_MIPS_MT_SMTC is not set
+CONFIG_CPU_HAS_LLSC=y
+CONFIG_CPU_HAS_SYNC=y
+CONFIG_GENERIC_HARDIRQS=y
+CONFIG_GENERIC_IRQ_PROBE=y
+CONFIG_CPU_SUPPORTS_HIGHMEM=y
+CONFIG_ARCH_FLATMEM_ENABLE=y
+CONFIG_ARCH_POPULATES_NODE_MAP=y
+CONFIG_FLATMEM=y
+CONFIG_FLAT_NODE_MEM_MAP=y
+# CONFIG_SPARSEMEM_STATIC is not set
+# CONFIG_SPARSEMEM_VMEMMAP_ENABLE is not set
+CONFIG_PAGEFLAGS_EXTENDED=y
+CONFIG_SPLIT_PTLOCK_CPUS=4
+# CONFIG_RESOURCES_64BIT is not set
+CONFIG_ZONE_DMA_FLAG=0
+CONFIG_VIRT_TO_BUS=y
+# CONFIG_TICK_ONESHOT is not set
+# CONFIG_NO_HZ is not set
+# CONFIG_HIGH_RES_TIMERS is not set
+CONFIG_GENERIC_CLOCKEVENTS_BUILD=y
+# CONFIG_HZ_48 is not set
+# CONFIG_HZ_100 is not set
+# CONFIG_HZ_128 is not set
+CONFIG_HZ_250=y
+# CONFIG_HZ_256 is not set
+# CONFIG_HZ_1000 is not set
+# CONFIG_HZ_1024 is not set
+CONFIG_SYS_SUPPORTS_ARBIT_HZ=y
+CONFIG_HZ=250
+CONFIG_PREEMPT_NONE=y
+# CONFIG_PREEMPT_VOLUNTARY is not set
+# CONFIG_PREEMPT is not set
+CONFIG_SECCOMP=y
+CONFIG_LOCKDEP_SUPPORT=y
+CONFIG_STACKTRACE_SUPPORT=y
+CONFIG_DEFCONFIG_LIST="/lib/modules/$UNAME_RELEASE/.config"
+
+# CONFIG_PCSPKR_PLATFORM is not set
+# CONFIG_PROBE_INITRD_HEADER is not set
+# CONFIG_MTD is not set
+
+
+CONFIG_NETDEVICES=y
+CONFIG_NET_ETHERNET=y
+# CONFIG_MII is not set
+# CONFIG_AX88796 is not set
+CONFIG_MT_VETH=y
+# CONFIG_DM9000 is not set
+# CONFIG_IBM_NEW_EMAC_ZMII is not set
+# CONFIG_IBM_NEW_EMAC_RGMII is not set
+# CONFIG_IBM_NEW_EMAC_TAH is not set
+# CONFIG_IBM_NEW_EMAC_EMAC4 is not set
+# CONFIG_B44 is not set
+# CONFIG_NETDEV_1000 is not set
+# CONFIG_NETDEV_10000 is not set
+
+
+CONFIG_INPUT=y
+# CONFIG_INPUT_FF_MEMLESS is not set
+# CONFIG_INPUT_POLLDEV is not set
+
+# CONFIG_VGA_CONSOLE is not set
+
+#
+# Userland interfaces
+#
+# CONFIG_INPUT_MOUSEDEV is not set
+# CONFIG_INPUT_JOYDEV is not set
+# CONFIG_INPUT_EVDEV is not set
+# CONFIG_INPUT_EVBUG is not set
+
+#
+# Input Device Drivers
+#
+# CONFIG_INPUT_KEYBOARD is not set
+# CONFIG_INPUT_MOUSE is not set
+# CONFIG_INPUT_JOYSTICK is not set
+# CONFIG_INPUT_TABLET is not set
+# CONFIG_INPUT_TOUCHSCREEN is not set
+# CONFIG_INPUT_MISC is not set
+
+#
+# Hardware I/O ports
+#
+# CONFIG_SERIO is not set
+# CONFIG_GAMEPORT is not set
+
+#
+# Serial drivers
+#
+# CONFIG_SERIAL_8250 is not set
+
+#
+# Non-8250 serial port support
+#
+CONFIG_UNIX98_PTYS=y
+CONFIG_LEGACY_PTYS=y
+CONFIG_LEGACY_PTY_COUNT=256
+CONFIG_HVC_DRIVER=y
+CONFIG_HVC_IRQ=y
+CONFIG_HVC_META=y
+# CONFIG_IPMI_HANDLER is not set
+# CONFIG_HW_RANDOM is not set
+# CONFIG_R3964 is not set
+# CONFIG_RAW_DRIVER is not set
+# CONFIG_I2C is not set
+# CONFIG_SPI is not set
+# CONFIG_W1 is not set
+# CONFIG_POWER_SUPPLY is not set
+# CONFIG_HWMON is not set
+# CONFIG_THERMAL is not set
+# CONFIG_THERMAL_HWMON is not set
+# CONFIG_WATCHDOG is not set
+
+CONFIG_META_FS=y
+CONFIG_CMDLINE="init=/etc/preinit"
diff -Nru a/target/linux/mr-mips/config-3.3 b/target/linux/mr-mips/config-3.3
--- a/target/linux/mr-mips/config-3.3	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/mr-mips/config-3.3	2013-07-23 00:32:41.342847383 +0200
@@ -0,0 +1,229 @@
+CONFIG_MIPS=y
+
+#
+# Machine selection
+#
+# CONFIG_MACH_ALCHEMY is not set
+# CONFIG_AR7 is not set
+# CONFIG_BASLER_EXCITE is not set
+# CONFIG_BCM47XX is not set
+# CONFIG_MIPS_COBALT is not set
+# CONFIG_MACH_DECSTATION is not set
+# CONFIG_MACH_JAZZ is not set
+# CONFIG_LASAT is not set
+# CONFIG_LEMOTE_FULONG is not set
+# CONFIG_MIPS_MALTA is not set
+# CONFIG_MIPS_SIM is not set
+# CONFIG_NEC_MARKEINS is not set
+# CONFIG_MACH_VR41XX is not set
+# CONFIG_NXP_STB220 is not set
+# CONFIG_NXP_STB225 is not set
+# CONFIG_PNX8550_JBS is not set
+# CONFIG_PNX8550_STB810 is not set
+# CONFIG_PMC_MSP is not set
+# CONFIG_PMC_YOSEMITE is not set
+# CONFIG_SGI_IP22 is not set
+# CONFIG_SGI_IP27 is not set
+# CONFIG_SGI_IP28 is not set
+# CONFIG_SGI_IP32 is not set
+# CONFIG_SIBYTE_CRHINE is not set
+# CONFIG_SIBYTE_CARMEL is not set
+# CONFIG_SIBYTE_CRHONE is not set
+# CONFIG_SIBYTE_RHONE is not set
+# CONFIG_SIBYTE_SWARM is not set
+# CONFIG_SIBYTE_LITTLESUR is not set
+# CONFIG_SIBYTE_SENTOSA is not set
+# CONFIG_SIBYTE_BIGSUR is not set
+# CONFIG_SNI_RM is not set
+# CONFIG_MACH_TX39XX is not set
+# CONFIG_MACH_TX49XX is not set
+# CONFIG_MIKROTIK_RB532 is not set
+CONFIG_METAROUTER=y
+# CONFIG_WR_PPMC is not set
+# CONFIG_CAVIUM_OCTEON_SIMULATOR is not set
+# CONFIG_CAVIUM_OCTEON_REFERENCE_BOARD is not set
+# CONFIG_ALCHEMY_GPIO_INDIRECT is not set
+# CONFIG_WR_PPMC is not set
+CONFIG_MAPPED_KERNEL=y
+CONFIG_RWSEM_GENERIC_SPINLOCK=y
+# CONFIG_ARCH_HAS_ILOG2_U32 is not set
+# CONFIG_ARCH_HAS_ILOG2_U64 is not set
+CONFIG_ARCH_SUPPORTS_OPROFILE=y
+CONFIG_GENERIC_FIND_NEXT_BIT=y
+CONFIG_GENERIC_HWEIGHT=y
+CONFIG_GENERIC_CALIBRATE_DELAY=y
+CONFIG_GENERIC_CLOCKEVENTS=y
+CONFIG_GENERIC_TIME=y
+CONFIG_GENERIC_CMOS_UPDATE=y
+CONFIG_SCHED_NO_NO_OMIT_FRAME_POINTER=y
+# CONFIG_GENERIC_HARDIRQS_NO__DO_IRQ is not set
+CONFIG_CEVT_R4K=y
+CONFIG_CSRC_R4K=y
+CONFIG_DMA_NONCOHERENT=y
+CONFIG_DMA_NEED_PCI_MAP_STATE=y
+# CONFIG_HOTPLUG_CPU is not set
+# CONFIG_NO_IOPORT is not set
+CONFIG_CPU_BIG_ENDIAN=y
+# CONFIG_CPU_LITTLE_ENDIAN is not set
+CONFIG_SYS_SUPPORTS_BIG_ENDIAN=y
+CONFIG_IRQ_CPU=y
+CONFIG_MIPS_L1_CACHE_SHIFT=5
+
+#
+# CPU selection
+#
+# CONFIG_CPU_LOONGSON2 is not set
+CONFIG_CPU_MIPS32_R1=y
+# CONFIG_CPU_MIPS32_R2 is not set
+# CONFIG_CPU_MIPS64_R1 is not set
+# CONFIG_CPU_MIPS64_R2 is not set
+# CONFIG_CPU_R3000 is not set
+# CONFIG_CPU_TX39XX is not set
+# CONFIG_CPU_VR41XX is not set
+# CONFIG_CPU_R4300 is not set
+# CONFIG_CPU_R4X00 is not set
+# CONFIG_CPU_TX49XX is not set
+# CONFIG_CPU_R5000 is not set
+# CONFIG_CPU_R5432 is not set
+# CONFIG_CPU_R6000 is not set
+# CONFIG_CPU_NEVADA is not set
+# CONFIG_CPU_R8000 is not set
+# CONFIG_CPU_R10000 is not set
+# CONFIG_CPU_RM7000 is not set
+# CONFIG_CPU_RM9000 is not set
+# CONFIG_CPU_SB1 is not set
+CONFIG_SYS_HAS_CPU_MIPS32_R1=y
+CONFIG_CPU_MIPS32=y
+CONFIG_CPU_MIPSR1=y
+CONFIG_SYS_SUPPORTS_32BIT_KERNEL=y
+CONFIG_CPU_SUPPORTS_32BIT_KERNEL=y
+
+#
+# Kernel type
+#
+CONFIG_32BIT=y
+# CONFIG_64BIT is not set
+CONFIG_PAGE_SIZE_4KB=y
+# CONFIG_PAGE_SIZE_8KB is not set
+# CONFIG_PAGE_SIZE_16KB is not set
+# CONFIG_PAGE_SIZE_64KB is not set
+CONFIG_CPU_HAS_PREFETCH=y
+CONFIG_MIPS_MT_DISABLED=y
+# CONFIG_MIPS_MT_SMP is not set
+# CONFIG_MIPS_MT_SMTC is not set
+CONFIG_CPU_HAS_LLSC=y
+CONFIG_CPU_HAS_SYNC=y
+CONFIG_GENERIC_HARDIRQS=y
+CONFIG_GENERIC_IRQ_PROBE=y
+CONFIG_CPU_SUPPORTS_HIGHMEM=y
+CONFIG_ARCH_FLATMEM_ENABLE=y
+CONFIG_ARCH_POPULATES_NODE_MAP=y
+CONFIG_FLATMEM=y
+CONFIG_FLAT_NODE_MEM_MAP=y
+# CONFIG_SPARSEMEM_STATIC is not set
+# CONFIG_SPARSEMEM_VMEMMAP_ENABLE is not set
+CONFIG_PAGEFLAGS_EXTENDED=y
+CONFIG_SPLIT_PTLOCK_CPUS=4
+# CONFIG_RESOURCES_64BIT is not set
+CONFIG_ZONE_DMA_FLAG=0
+CONFIG_VIRT_TO_BUS=y
+# CONFIG_TICK_ONESHOT is not set
+# CONFIG_NO_HZ is not set
+# CONFIG_HIGH_RES_TIMERS is not set
+CONFIG_GENERIC_CLOCKEVENTS_BUILD=y
+# CONFIG_HZ_48 is not set
+# CONFIG_HZ_100 is not set
+# CONFIG_HZ_128 is not set
+CONFIG_HZ_250=y
+# CONFIG_HZ_256 is not set
+# CONFIG_HZ_1000 is not set
+# CONFIG_HZ_1024 is not set
+CONFIG_SYS_SUPPORTS_ARBIT_HZ=y
+CONFIG_HZ=250
+CONFIG_PREEMPT_NONE=y
+# CONFIG_PREEMPT_VOLUNTARY is not set
+# CONFIG_PREEMPT is not set
+CONFIG_SECCOMP=y
+CONFIG_LOCKDEP_SUPPORT=y
+CONFIG_STACKTRACE_SUPPORT=y
+CONFIG_DEFCONFIG_LIST="/lib/modules/$UNAME_RELEASE/.config"
+
+# CONFIG_PCSPKR_PLATFORM is not set
+# CONFIG_PROBE_INITRD_HEADER is not set
+# CONFIG_MTD is not set
+
+
+CONFIG_NETDEVICES=y
+CONFIG_NET_ETHERNET=y
+# CONFIG_MII is not set
+# CONFIG_AX88796 is not set
+CONFIG_MT_VETH=y
+# CONFIG_DM9000 is not set
+# CONFIG_IBM_NEW_EMAC_ZMII is not set
+# CONFIG_IBM_NEW_EMAC_RGMII is not set
+# CONFIG_IBM_NEW_EMAC_TAH is not set
+# CONFIG_IBM_NEW_EMAC_EMAC4 is not set
+# CONFIG_B44 is not set
+# CONFIG_NETDEV_1000 is not set
+# CONFIG_NETDEV_10000 is not set
+
+
+CONFIG_INPUT=y
+# CONFIG_INPUT_FF_MEMLESS is not set
+# CONFIG_INPUT_POLLDEV is not set
+
+# CONFIG_VGA_CONSOLE is not set
+
+#
+# Userland interfaces
+#
+# CONFIG_INPUT_MOUSEDEV is not set
+# CONFIG_INPUT_JOYDEV is not set
+# CONFIG_INPUT_EVDEV is not set
+# CONFIG_INPUT_EVBUG is not set
+
+#
+# Input Device Drivers
+#
+# CONFIG_INPUT_KEYBOARD is not set
+# CONFIG_INPUT_MOUSE is not set
+# CONFIG_INPUT_JOYSTICK is not set
+# CONFIG_INPUT_TABLET is not set
+# CONFIG_INPUT_TOUCHSCREEN is not set
+# CONFIG_INPUT_MISC is not set
+
+#
+# Hardware I/O ports
+#
+# CONFIG_SERIO is not set
+# CONFIG_GAMEPORT is not set
+
+#
+# Serial drivers
+#
+# CONFIG_SERIAL_8250 is not set
+
+#
+# Non-8250 serial port support
+#
+CONFIG_UNIX98_PTYS=y
+CONFIG_LEGACY_PTYS=y
+CONFIG_LEGACY_PTY_COUNT=256
+CONFIG_HVC_DRIVER=y
+CONFIG_HVC_IRQ=y
+CONFIG_HVC_META=y
+# CONFIG_IPMI_HANDLER is not set
+# CONFIG_HW_RANDOM is not set
+# CONFIG_R3964 is not set
+# CONFIG_RAW_DRIVER is not set
+# CONFIG_I2C is not set
+# CONFIG_SPI is not set
+# CONFIG_W1 is not set
+# CONFIG_POWER_SUPPLY is not set
+# CONFIG_HWMON is not set
+# CONFIG_THERMAL is not set
+# CONFIG_THERMAL_HWMON is not set
+# CONFIG_WATCHDOG is not set
+
+CONFIG_META_FS=y
+CONFIG_CMDLINE="init=/etc/preinit"
diff -Nru a/target/linux/mr-mips/image/Makefile b/target/linux/mr-mips/image/Makefile
--- a/target/linux/mr-mips/image/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/mr-mips/image/Makefile	2013-07-22 22:25:00.414082301 +0200
@@ -0,0 +1,14 @@
+# 
+# Copyright (C) 2006 OpenWrt.org
+#
+# This is free software, licensed under the GNU General Public License v2.
+# See /LICENSE for more information.
+#
+include $(TOPDIR)/rules.mk
+include $(INCLUDE_DIR)/image.mk
+
+define Image/BuildKernel
+	cp $(KDIR)/vmlinux.elf $(TARGET_DIR)/kernel
+endef
+
+$(eval $(call BuildImage))
diff -Nru a/target/linux/mr-mips/Makefile b/target/linux/mr-mips/Makefile
--- a/target/linux/mr-mips/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/mr-mips/Makefile	2013-07-22 22:25:00.417082182 +0200
@@ -0,0 +1,17 @@
+#
+# Copyright (C) 2007-2008 OpenWrt.org
+#
+# This is free software, licensed under the GNU General Public License v2.
+# See /LICENSE for more information.
+#
+include $(TOPDIR)/rules.mk
+
+ARCH:=mips
+BOARD:=mr-mips
+BOARDNAME:=Mikrotik MetaROUTER MIPS
+FEATURES:=targz
+
+LINUX_VERSION:=2.6.31.10
+
+include $(INCLUDE_DIR)/target.mk
+$(eval $(call BuildTarget))
diff -Nru a/target/linux/mr-mips/patches-2.6.31/000-linux-metarouter.patch b/target/linux/mr-mips/patches-2.6.31/000-linux-metarouter.patch
--- a/target/linux/mr-mips/patches-2.6.31/000-linux-metarouter.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/mr-mips/patches-2.6.31/000-linux-metarouter.patch	2013-07-22 22:25:00.417082182 +0200
@@ -0,0 +1,2360 @@
+diff -uNr linux-2.6.31.10/arch/mips/include/asm/fixmap.h linux-2.6.31.10.new/arch/mips/include/asm/fixmap.h
+--- linux-2.6.31.10/arch/mips/include/asm/fixmap.h	2010-01-07 00:27:24.000000000 +0200
++++ linux-2.6.31.10.new/arch/mips/include/asm/fixmap.h	2010-04-12 15:54:46.000000000 +0300
+@@ -70,7 +70,11 @@
+ #if defined(CONFIG_CPU_TX39XX) || defined(CONFIG_CPU_TX49XX)
+ #define FIXADDR_TOP	((unsigned long)(long)(int)(0xff000000 - 0x20000))
+ #else
++#ifndef CONFIG_MAPPED_KERNEL
+ #define FIXADDR_TOP	((unsigned long)(long)(int)0xfffe0000)
++#else
++#define FIXADDR_TOP	((unsigned long)(long)(int)0xdffe0000)
++#endif
+ #endif
+ #define FIXADDR_SIZE	(__end_of_fixed_addresses << PAGE_SHIFT)
+ #define FIXADDR_START	(FIXADDR_TOP - FIXADDR_SIZE)
+diff -uNr linux-2.6.31.10/arch/mips/include/asm/io.h linux-2.6.31.10.new/arch/mips/include/asm/io.h
+--- linux-2.6.31.10/arch/mips/include/asm/io.h	2010-01-07 00:27:24.000000000 +0200
++++ linux-2.6.31.10.new/arch/mips/include/asm/io.h	2010-04-12 15:54:46.000000000 +0300
+@@ -199,6 +199,7 @@
+ 		if (!size || last_addr < phys_addr)
+ 			return NULL;
+ 
++#ifndef CONFIG_MAPPED_KERNEL
+ 		/*
+ 		 * Map uncached objects in the low 512MB of address
+ 		 * space using KSEG1.
+@@ -207,6 +208,7 @@
+ 		    flags == _CACHE_UNCACHED)
+ 			return (void __iomem *)
+ 				(unsigned long)CKSEG1ADDR(phys_addr);
++#endif
+ 	}
+ 
+ 	return __ioremap(offset, size, flags);
+diff -uNr linux-2.6.31.10/arch/mips/include/asm/mach-metarouter/kernel-entry-init.h linux-2.6.31.10.new/arch/mips/include/asm/mach-metarouter/kernel-entry-init.h
+--- linux-2.6.31.10/arch/mips/include/asm/mach-metarouter/kernel-entry-init.h	1970-01-01 03:00:00.000000000 +0300
++++ linux-2.6.31.10.new/arch/mips/include/asm/mach-metarouter/kernel-entry-init.h	2010-04-12 15:54:46.000000000 +0300
+@@ -0,0 +1,44 @@
++#ifndef __ASM_MACH_METAROUTER_KERNEL_ENTRY_H
++#define __ASM_MACH_METAROUTER_KERNEL_ENTRY_H
++
++.macro	kernel_entry_setup
++#ifdef CONFIG_MAPPED_KERNEL
++	.set	push
++	.set	mips32r2
++	/* check whether we are running under 0xc0000000 address space */
++	lui	t0, 0xf000
++	bal	1f
++1:	and	t1, ra, t0
++	li	t0, 0xc0000000
++	beq	t0, t1, 2f
++	/* set up 0xc0000000 address space */
++	mtc0	t0, CP0_ENTRYHI
++	li	t0, 0x1f
++	mtc0	t0, CP0_ENTRYLO0
++	li	t0, 0x0010001f
++	mtc0	t0, CP0_ENTRYLO1
++	li	t0, PM_64M
++	mtc0	t0, CP0_PAGEMASK
++	li	t0, 0
++	mtc0	t0, CP0_INDEX
++	li	t0, 2
++	mtc0	t0, CP0_WIRED
++	ehb
++	tlbwi
++
++	li	t0, 0xc8000000
++	mtc0	t0, CP0_ENTRYHI
++	li	t0, 0x0020001f
++	mtc0	t0, CP0_ENTRYLO0
++	li	t0, 0x0030001f
++	mtc0	t0, CP0_ENTRYLO1
++	li	t0, 1
++	mtc0	t0, CP0_INDEX
++	ehb
++	tlbwi
++2:
++	.set	pop
++#endif
++.endm
++
++#endif
+diff -uNr linux-2.6.31.10/arch/mips/include/asm/mach-metarouter/spaces.h linux-2.6.31.10.new/arch/mips/include/asm/mach-metarouter/spaces.h
+--- linux-2.6.31.10/arch/mips/include/asm/mach-metarouter/spaces.h	1970-01-01 03:00:00.000000000 +0300
++++ linux-2.6.31.10.new/arch/mips/include/asm/mach-metarouter/spaces.h	2010-04-12 15:54:46.000000000 +0300
+@@ -0,0 +1,24 @@
++#ifndef _ASM_MACH_METAROUTER_SPACES_H
++#define _ASM_MACH_METAROUTER_SPACES_H
++
++#include <linux/const.h>
++
++#define PHYS_OFFSET		_AC(0, UL)
++
++#ifdef CONFIG_MAPPED_KERNEL
++#define CAC_BASE		_AC(0xc0000000, UL)
++#else
++#define CAC_BASE		_AC(0x80000000, UL)
++#endif
++#define IO_BASE			_AC(0xa0000000, UL)
++#define UNCAC_BASE		_AC(0xa0000000, UL)
++
++#ifndef MAP_BASE
++#define MAP_BASE		_AC(0xd0000000, UL)
++#endif
++
++#define HIGHMEM_START		_AC(0x20000000, UL)
++
++#define PAGE_OFFSET		(CAC_BASE + PHYS_OFFSET)
++
++#endif
+diff -uNr linux-2.6.31.10/arch/mips/include/asm/mach-metarouter/war.h linux-2.6.31.10.new/arch/mips/include/asm/mach-metarouter/war.h
+--- linux-2.6.31.10/arch/mips/include/asm/mach-metarouter/war.h	1970-01-01 03:00:00.000000000 +0300
++++ linux-2.6.31.10.new/arch/mips/include/asm/mach-metarouter/war.h	2010-04-12 15:54:46.000000000 +0300
+@@ -0,0 +1,18 @@
++#ifndef __ASM_MIPS_MACH_METAROUTER_WAR_H
++#define __ASM_MIPS_MACH_METAROUTER_WAR_H
++
++#define R4600_V1_INDEX_ICACHEOP_WAR	0
++#define R4600_V1_HIT_CACHEOP_WAR	0
++#define R4600_V2_HIT_CACHEOP_WAR	0
++#define R5432_CP0_INTERRUPT_WAR		0
++#define BCM1250_M3_WAR			0
++#define SIBYTE_1956_WAR			0
++#define MIPS4K_ICACHE_REFILL_WAR	0
++#define MIPS_CACHE_SYNC_WAR		0
++#define TX49XX_ICACHE_INDEX_INV_WAR	0
++#define RM9000_CDEX_SMP_WAR		0
++#define ICACHE_REFILLS_WORKAROUND_WAR   0
++#define R10000_LLSC_WAR			0
++#define MIPS34K_MISSED_ITLB_WAR		0
++
++#endif
+diff -uNr linux-2.6.31.10/arch/mips/include/asm/vm.h linux-2.6.31.10.new/arch/mips/include/asm/vm.h
+--- linux-2.6.31.10/arch/mips/include/asm/vm.h	1970-01-01 03:00:00.000000000 +0300
++++ linux-2.6.31.10.new/arch/mips/include/asm/vm.h	2010-04-12 15:54:46.000000000 +0300
+@@ -0,0 +1,45 @@
++#ifndef MT_VM_H
++#define MT_VM_H
++
++#define GFP_HYPERVISOR	GFP_KERNEL
++
++#define VIRQ_BASE	64
++
++#define hypercall(name, nr, ...)		\
++	asm(					\
++		".global " #name ";"		\
++		".align 2;"			\
++		".set	push;"			\
++		".set	noreorder;"		\
++		".type " #name ",@function;"	\
++		".ent " #name ",0;"		\
++		#name ": .frame $sp,0,$ra;"	\
++		"li $3, " #nr ";"		\
++		"li $2, -22;"			\
++		"mtc0 $0, $1;"			\
++		"jr $ra;"			\
++		"nop;"				\
++		".end " #name ";"		\
++		".size " #name ",.-" #name ";"	\
++		".set	pop"			\
++        );					\
++	asmlinkage extern int name(__VA_ARGS__);
++
++/* NOTE: do not allow vdma_descr to span multiple pages, so align it */
++struct vdma_descr {
++	unsigned addr;
++	unsigned size;
++	unsigned next;
++} __attribute__((aligned(16)));
++
++#define DONE		0x80000000
++
++static inline unsigned get_virq_nr(unsigned hwirq)
++{
++	return VIRQ_BASE + hwirq;
++}
++
++extern int vm_running(void);
++#define hc_yield() asm volatile ("wait")
++
++#endif
+diff -uNr linux-2.6.31.10/arch/mips/Kconfig linux-2.6.31.10.new/arch/mips/Kconfig
+--- linux-2.6.31.10/arch/mips/Kconfig	2010-01-07 00:27:24.000000000 +0200
++++ linux-2.6.31.10.new/arch/mips/Kconfig	2010-04-12 15:54:46.000000000 +0300
+@@ -591,6 +591,19 @@
+ 	  Support the Mikrotik(tm) RouterBoard 532 series,
+ 	  based on the IDT RC32434 SoC.
+ 
++config METAROUTER
++	bool "Mikrotik MetaROUTER"
++	select CEVT_R4K
++	select CSRC_R4K
++	select IRQ_CPU
++	select DMA_NONCOHERENT
++	select SYS_HAS_CPU_MIPS32_R1
++	select SYS_SUPPORTS_BIG_ENDIAN
++	select SYS_SUPPORTS_32BIT_KERNEL
++	select MAPPED_KERNEL
++	help
++	  Support the Mikrotik(tm) MetaROUTER.
++
+ config WR_PPMC
+ 	bool "Wind River PPMC board"
+ 	select CEVT_R4K
+diff -uNr linux-2.6.31.10/arch/mips/Makefile linux-2.6.31.10.new/arch/mips/Makefile
+--- linux-2.6.31.10/arch/mips/Makefile	2010-04-12 15:51:55.000000000 +0300
++++ linux-2.6.31.10.new/arch/mips/Makefile	2010-04-12 15:54:46.000000000 +0300
+@@ -571,6 +571,15 @@
+ endif
+ all-$(CONFIG_SNI_RM)		:= vmlinux.ecoff
+ 
++# Mikrotik MetaROUTER
++#
++core-$(CONFIG_METAROUTER) += arch/mips/metarouter/
++cflags-$(CONFIG_METAROUTER) += -I$(srctree)/arch/mips/include/asm/mach-metarouter
++load-$(CONFIG_METAROUTER) += 0xffffffffc0101000
++ifdef CONFIG_METAROUTER
++OBJCOPYFLAGS += --change-addresses=0xc0000000
++endif
++
+ #
+ # Common TXx9
+ #
+diff -uNr linux-2.6.31.10/arch/mips/metarouter/irq.c linux-2.6.31.10.new/arch/mips/metarouter/irq.c
+--- linux-2.6.31.10/arch/mips/metarouter/irq.c	1970-01-01 03:00:00.000000000 +0300
++++ linux-2.6.31.10.new/arch/mips/metarouter/irq.c	2010-04-12 15:54:46.000000000 +0300
+@@ -0,0 +1,97 @@
++#include <linux/init.h>
++#include <linux/linkage.h>
++#include <linux/irq.h>
++#include <linux/interrupt.h>
++#include <linux/bitops.h>
++#include <linux/module.h>
++#include <asm/signal.h>
++#include <asm/mipsregs.h>
++#include <asm/irq_cpu.h>
++#include <asm/bootinfo.h>
++#include <asm/vm.h>
++
++asmlinkage void plat_irq_dispatch(void) {
++	unsigned pending = read_c0_status() & read_c0_cause() & 0xfe00;
++
++	if (pending)
++		do_IRQ(fls(pending) - 9);
++}
++
++volatile unsigned long virqs;
++EXPORT_SYMBOL(virqs);
++
++static void ack_virq(unsigned int irq)
++{
++	clear_bit(irq - VIRQ_BASE, &virqs);
++}
++
++static inline void unmask_virq(unsigned int irq)
++{
++}
++
++static inline void mask_virq(unsigned int irq)
++{
++}
++
++static struct irq_chip virq_controller = {
++	.name	= "virq",
++	.ack	= ack_virq,
++	.unmask = unmask_virq,
++	.mask	= mask_virq,
++};
++
++static irqreturn_t virq_cascade_irq(int irq, void *dev_id)
++{
++	unsigned i;
++	unsigned irqs = virqs;
++
++	for (i = 0; irqs; ++i) {
++		if (irqs & (1 << i)) {
++			do_IRQ(i + VIRQ_BASE);
++			irqs ^= (1 << i);
++		}
++	}
++	return IRQ_HANDLED;
++}
++
++static struct irqaction virq_cascade  = {
++	.handler = virq_cascade_irq,
++	.name = "virq-cascade",
++};
++
++static void soft_irq_ack(unsigned int irq)
++{
++	clear_c0_cause(0x100 << (irq - MIPS_CPU_IRQ_BASE));
++}
++
++static inline void unmask_soft_irq(unsigned int irq)
++ {
++	set_c0_status(0x100 << (irq - MIPS_CPU_IRQ_BASE));
++	irq_enable_hazard();
++ }
++ 
++static inline void mask_soft_irq(unsigned int irq)
++{
++	clear_c0_status(0x100 << (irq - MIPS_CPU_IRQ_BASE));
++	irq_disable_hazard();
++}
++
++static struct irq_chip soft_irq_controller = {
++	.name	= "SoftIRQ",
++	.ack	= soft_irq_ack,
++	.unmask = unmask_soft_irq,
++	.mask	= mask_soft_irq,
++};
++
++void __init arch_init_irq(void)
++{
++	unsigned i;
++
++	mips_cpu_irq_init();
++
++	set_irq_chip_and_handler(1, &soft_irq_controller, handle_percpu_irq);
++	setup_irq(1, &virq_cascade);
++
++	for (i = VIRQ_BASE;  i < VIRQ_BASE + 32; ++i)
++		set_irq_chip_and_handler(i, &virq_controller, handle_edge_irq);
++}
+diff -uNr linux-2.6.31.10/arch/mips/metarouter/Makefile linux-2.6.31.10.new/arch/mips/metarouter/Makefile
+--- linux-2.6.31.10/arch/mips/metarouter/Makefile	1970-01-01 03:00:00.000000000 +0300
++++ linux-2.6.31.10.new/arch/mips/metarouter/Makefile	2010-04-12 15:54:46.000000000 +0300
+@@ -0,0 +1 @@
++obj-y += prom.o irq.o setup.o
+diff -uNr linux-2.6.31.10/arch/mips/metarouter/prom.c linux-2.6.31.10.new/arch/mips/metarouter/prom.c
+--- linux-2.6.31.10/arch/mips/metarouter/prom.c	1970-01-01 03:00:00.000000000 +0300
++++ linux-2.6.31.10.new/arch/mips/metarouter/prom.c	2010-04-12 15:54:46.000000000 +0300
+@@ -0,0 +1,66 @@
++#include <linux/init.h>
++#include <linux/mm.h>
++#include <linux/module.h>
++#include <linux/string.h>
++#include <linux/console.h>
++#include <asm/bootinfo.h>
++#include <linux/bootmem.h>
++#include <linux/ioport.h>
++#include <linux/ctype.h>
++#include <linux/irq.h>
++
++extern char arcs_cmdline[COMMAND_LINE_SIZE];
++
++extern unsigned long totalram_pages;
++extern unsigned long mips_hpt_frequency;
++
++void __init prom_init(void)
++{
++	int argc = fw_arg0;
++	char **argv = (char **) fw_arg1;
++	unsigned i;
++	unsigned offset = strlen(arcs_cmdline);
++	if (offset > 0)
++		offset += snprintf(arcs_cmdline + offset,
++				   sizeof(arcs_cmdline) - offset,
++				   " ");
++
++	/* HZ must be parsed here because otherwise it's too late */
++	for (i = 0; (i < argc && argv[i] != NULL); i++) {
++		if (strncmp(argv[i], "HZ=", 3) == 0) {
++			mips_hpt_frequency = 
++			    simple_strtoul(argv[i] + 3, 0, 10);
++			continue;
++		}
++		offset += snprintf(arcs_cmdline + offset,
++				   sizeof(arcs_cmdline) - offset,
++				   "%s ", argv[i]);
++	}
++}
++
++void __init prom_free_prom_memory(void)
++{
++	unsigned long addr, end;
++	extern char _text;
++
++	/*
++	 * Free everything below the kernel itself but leave
++	 * the first page reserved for the exception handlers.
++	 */
++
++	end = __pa(&_text);
++	addr = PAGE_SIZE;
++
++	while (addr < end) {
++		ClearPageReserved(virt_to_page(__va(addr)));
++		init_page_count(virt_to_page(__va(addr)));
++		free_page((unsigned long)__va(addr));
++		addr += PAGE_SIZE;
++		++totalram_pages;
++	}
++}
++
++unsigned long long sched_clock(void)
++{
++	return read_c0_count() * 1000000000 / mips_hpt_frequency;
++}
+diff -uNr linux-2.6.31.10/arch/mips/metarouter/setup.c linux-2.6.31.10.new/arch/mips/metarouter/setup.c
+--- linux-2.6.31.10/arch/mips/metarouter/setup.c	1970-01-01 03:00:00.000000000 +0300
++++ linux-2.6.31.10.new/arch/mips/metarouter/setup.c	2010-04-12 15:54:46.000000000 +0300
+@@ -0,0 +1,147 @@
++#include <linux/interrupt.h>
++#include <linux/sched.h>
++#include <asm/reboot.h>
++#include <asm/vm.h>
++
++#define BUF_SIZE	256
++#define BUF_COUNT	4
++
++hypercall(vm_create_queue, 4, unsigned id, unsigned irq,
++		 unsigned tx, unsigned rx);
++hypercall(vm_release_queue, 5, unsigned id);
++hypercall(vm_running, 6, void);
++hypercall(vm_setup_irqs, 14, unsigned *irqs, unsigned count);
++
++static volatile struct vdma_descr tx_chain[BUF_COUNT];
++static volatile struct vdma_descr rx_chain[BUF_COUNT];
++static unsigned char tx_buffers[BUF_COUNT][BUF_SIZE];
++static unsigned char rx_buffers[BUF_COUNT][BUF_SIZE];
++
++static unsigned cur_tx;
++static unsigned cur_rx;
++
++static int send_message(const unsigned char *buf, int len)
++{
++	unsigned long flags;
++
++	local_irq_save(flags);
++
++	/* drop some data if full buffer */
++	while (tx_chain[cur_tx].size & DONE)
++		asm volatile ("wait");
++
++	len = min_t(int, len, BUF_SIZE);
++	memcpy(tx_buffers[cur_tx], buf, len);
++	tx_chain[cur_tx].size = len | DONE;
++
++	cur_tx = (cur_tx + 1) % BUF_COUNT;
++
++	local_irq_restore(flags);
++
++	return len;
++}
++
++static int recv_message(char *buf, int len)
++{
++	unsigned long flags;
++
++	local_irq_save(flags);
++
++	if (!(rx_chain[cur_rx].size & DONE)) {
++		local_irq_restore(flags);
++		return 0;
++	}
++	
++	len = min_t(int, len, rx_chain[cur_rx].size & ~DONE);
++	memcpy(buf, rx_buffers[cur_rx], len);
++
++	rx_chain[cur_rx].size = BUF_SIZE;
++	cur_rx = (cur_rx + 1) % BUF_COUNT;
++
++	local_irq_restore(flags);
++
++	return len;
++}
++
++static irqreturn_t ctrl_interrupt(int irq, void *dev_id)
++{
++	struct task_struct *init;
++	char buf[256];
++	int len;
++
++	len = recv_message(buf, sizeof(buf));
++	if (len <= 0)
++		return IRQ_HANDLED;
++
++	if (strncmp(buf, "restart", len) == 0) {
++		printk("RESTART\n");
++		init = find_task_by_pid_ns(1, &init_pid_ns);
++		if (init)
++			send_sig(SIGINT, init, 1);
++	} else if (strncmp(buf, "halt", len) == 0) {
++	    printk("HALT\n");
++		init = find_task_by_pid_ns(1, &init_pid_ns);
++		if (init)
++			send_sig(SIGWINCH, init, 1);
++	}
++
++	return IRQ_HANDLED;
++}
++
++static void rbvm_machine_restart(char *command)
++{
++	char msg[] = "restart";
++
++	send_message(msg, sizeof(msg));
++}
++
++static void rbvm_machine_halt(void)
++{
++	char msg[] = "halt";
++
++	send_message(msg, sizeof(msg));
++}
++
++const char *get_system_type(void)
++{
++	return "Mikrotik MetaROUTER";
++}
++
++void __init plat_mem_setup(void)
++{
++	extern unsigned long virqs;
++	int i;
++
++	vm_setup_irqs((unsigned *) &virqs, 32);
++
++	for (i = 0; i < BUF_COUNT; ++i) {
++		rx_chain[i].addr = (unsigned) rx_buffers[i];
++		rx_chain[i].size = BUF_SIZE;
++		rx_chain[i].next = (unsigned) &rx_chain[i + 1];
++		
++		tx_chain[i].addr = (unsigned) tx_buffers[i];
++		tx_chain[i].size = 0;
++		tx_chain[i].next = (unsigned) &tx_chain[i + 1];
++	}
++	rx_chain[BUF_COUNT - 1].next = (unsigned) &rx_chain[0];
++	tx_chain[BUF_COUNT - 1].next = (unsigned) &tx_chain[0];
++
++	vm_create_queue(0, 0, (unsigned) &tx_chain[0],
++			(unsigned) &rx_chain[0]);
++
++	_machine_restart = rbvm_machine_restart;
++	_machine_halt = rbvm_machine_halt;
++}
++
++void __init plat_time_init(void)
++{
++}
++
++int __init init_ctrl_interrupt(void)
++{
++	if (request_irq(VIRQ_BASE + 0, ctrl_interrupt, 0, "ctrl", (void *) 1))
++		return -EBUSY;
++	return 0;
++
++}
++arch_initcall(init_ctrl_interrupt);
+diff -uNr linux-2.6.31.10/arch/powerpc/include/asm/mtvic.h linux-2.6.31.10.new/arch/powerpc/include/asm/mtvic.h
+--- linux-2.6.31.10/arch/powerpc/include/asm/mtvic.h	1970-01-01 03:00:00.000000000 +0300
++++ linux-2.6.31.10.new/arch/powerpc/include/asm/mtvic.h	2010-04-12 15:54:46.000000000 +0300
+@@ -0,0 +1,8 @@
++#ifndef _ASM_POWERPC_MTVIC_H
++#define _ASM_POWERPC_MTVIC_H
++
++void __init mtvic_init(int def);
++unsigned mtvic_get_irq(void);
++unsigned rb_get_irq(void);
++
++#endif
+diff -uNr linux-2.6.31.10/arch/powerpc/include/asm/pgtable-ppc32.h linux-2.6.31.10.new/arch/powerpc/include/asm/pgtable-ppc32.h
+--- linux-2.6.31.10/arch/powerpc/include/asm/pgtable-ppc32.h	2010-01-07 00:27:24.000000000 +0200
++++ linux-2.6.31.10.new/arch/powerpc/include/asm/pgtable-ppc32.h	2010-04-12 15:54:46.000000000 +0300
+@@ -63,7 +63,7 @@
+ #ifdef CONFIG_HIGHMEM
+ #define KVIRT_TOP	PKMAP_BASE
+ #else
+-#define KVIRT_TOP	(0xfe000000UL)	/* for now, could be FIXMAP_BASE ? */
++#define KVIRT_TOP	(0xf0000000UL)	/* for now, could be FIXMAP_BASE ? */
+ #endif
+ 
+ /*
+diff -uNr linux-2.6.31.10/arch/powerpc/include/asm/vm.h linux-2.6.31.10.new/arch/powerpc/include/asm/vm.h
+--- linux-2.6.31.10/arch/powerpc/include/asm/vm.h	1970-01-01 03:00:00.000000000 +0300
++++ linux-2.6.31.10.new/arch/powerpc/include/asm/vm.h	2010-04-12 15:54:46.000000000 +0300
+@@ -0,0 +1,35 @@
++#ifndef MT_VM_H
++#define MT_VM_H
++
++#define hypercall(name, nr, ...)		\
++	asm(					\
++		".global " #name ";"		\
++		".align 2;"			\
++		".type " #name ",@function;"	\
++		#name ":;"			\
++		"li 0, " #nr ";"		\
++		"crset so;"			\
++		"mtspr 1023, 0;"		\
++		"bnslr;"			\
++		"li 3, -22;"			\
++		"blr"				\
++        );					\
++	asmlinkage extern int name(__VA_ARGS__);
++
++/* NOTE: do not allow vdma_descr to span multiple pages, so align it */
++struct vdma_descr {
++	unsigned addr;
++	unsigned size;
++	unsigned next;
++} __attribute__((aligned(16)));
++
++#define DONE		0x80000000
++
++unsigned get_virq_nr(unsigned hwirq);
++int vm_yield(void);
++int vm_running(void);
++
++#define hc_yield() vm_yield()
++
++
++#endif
+diff -uNr linux-2.6.31.10/arch/powerpc/platforms/85xx/Kconfig linux-2.6.31.10.new/arch/powerpc/platforms/85xx/Kconfig
+--- linux-2.6.31.10/arch/powerpc/platforms/85xx/Kconfig	2010-01-07 00:27:24.000000000 +0200
++++ linux-2.6.31.10.new/arch/powerpc/platforms/85xx/Kconfig	2010-04-12 15:54:46.000000000 +0300
+@@ -135,6 +135,12 @@
+ 	help
+ 	  This option enables support for the Wind River SBC8560 board
+ 
++config METAROUTER
++	bool "Mikrotik MetaROUTER"
++	select MT_VIC
++	help
++	  This option enables support for the Mikrotik MetaROUTER
++
+ endif # MPC85xx
+ 
+ config TQM85xx
+diff -uNr linux-2.6.31.10/arch/powerpc/platforms/85xx/Makefile linux-2.6.31.10.new/arch/powerpc/platforms/85xx/Makefile
+--- linux-2.6.31.10/arch/powerpc/platforms/85xx/Makefile	2010-01-07 00:27:24.000000000 +0200
++++ linux-2.6.31.10.new/arch/powerpc/platforms/85xx/Makefile	2010-04-12 15:54:46.000000000 +0300
+@@ -9,10 +9,11 @@
+ obj-$(CONFIG_MPC8536_DS)  += mpc8536_ds.o
+ obj-$(CONFIG_MPC85xx_DS)  += mpc85xx_ds.o
+ obj-$(CONFIG_MPC85xx_MDS) += mpc85xx_mds.o
++obj-$(CONFIG_METAROUTER)  += metarouter.o
+ obj-$(CONFIG_STX_GP3)	  += stx_gp3.o
+ obj-$(CONFIG_TQM85xx)	  += tqm85xx.o
+ obj-$(CONFIG_SBC8560)     += sbc8560.o
+ obj-$(CONFIG_SBC8548)     += sbc8548.o
+ obj-$(CONFIG_SOCRATES)    += socrates.o socrates_fpga_pic.o
+ obj-$(CONFIG_KSI8560)	  += ksi8560.o
+-obj-$(CONFIG_XES_MPC85xx) += xes_mpc85xx.o
+\ No newline at end of file
++obj-$(CONFIG_XES_MPC85xx) += xes_mpc85xx.o
+diff -uNr linux-2.6.31.10/arch/powerpc/platforms/85xx/metarouter.c linux-2.6.31.10.new/arch/powerpc/platforms/85xx/metarouter.c
+--- linux-2.6.31.10/arch/powerpc/platforms/85xx/metarouter.c	1970-01-01 03:00:00.000000000 +0300
++++ linux-2.6.31.10.new/arch/powerpc/platforms/85xx/metarouter.c	2010-04-12 15:54:59.000000000 +0300
+@@ -0,0 +1,190 @@
++#include <linux/interrupt.h>
++#include <linux/of_platform.h>
++#include <mm/mmu_decl.h>
++#include <asm/time.h>
++#include <asm/machdep.h>
++#include <asm/mtvic.h>
++#include <asm/vm.h>
++
++#define BUF_SIZE	256
++#define BUF_COUNT	4
++
++hypercall(vm_create_queue, 4, unsigned id, unsigned irq,
++	  unsigned tx, unsigned rx);
++hypercall(vm_release_queue, 5, unsigned id);
++hypercall(vm_running, 6, void);
++
++hypercall(vm_setup_irqs, 14, unsigned *irqs, unsigned count);
++hypercall(vm_yield, 16, void);
++
++EXPORT_SYMBOL(vm_yield);
++
++static volatile struct vdma_descr tx_chain[BUF_COUNT];
++static volatile struct vdma_descr rx_chain[BUF_COUNT];
++static unsigned char tx_buffers[BUF_COUNT][BUF_SIZE];
++static unsigned char rx_buffers[BUF_COUNT][BUF_SIZE];
++
++static unsigned cur_tx;
++static unsigned cur_rx;
++
++static int send_message(const unsigned char *buf, int len)
++{
++	unsigned long flags;
++
++	local_irq_save(flags);
++
++	/* drop some data if full buffer */
++	while (tx_chain[cur_tx].size & DONE)
++		hc_yield();
++
++	len = min_t(int, len, BUF_SIZE);
++	memcpy(tx_buffers[cur_tx], buf, len);
++	tx_chain[cur_tx].size = len | DONE;
++
++	cur_tx = (cur_tx + 1) % BUF_COUNT;
++
++	local_irq_restore(flags);
++
++	return len;
++}
++
++static int recv_message(char *buf, int len)
++{
++	unsigned long flags;
++
++	local_irq_save(flags);
++
++	if (!(rx_chain[cur_rx].size & DONE)) {
++		local_irq_restore(flags);
++		return 0;
++	}
++	
++	len = min_t(int, len, rx_chain[cur_rx].size & ~DONE);
++	memcpy(buf, rx_buffers[cur_rx], len);
++
++	rx_chain[cur_rx].size = BUF_SIZE;
++	cur_rx = (cur_rx + 1) % BUF_COUNT;
++
++	local_irq_restore(flags);
++
++	return len;
++}
++
++static irqreturn_t ctrl_interrupt(int irq, void *dev_id)
++{
++	struct task_struct *init;
++	char buf[256];
++	int len;
++
++	len = recv_message(buf, sizeof(buf));
++	if (len <= 0)
++		return IRQ_HANDLED;
++
++	if (strncmp(buf, "restart", len) == 0) {
++		printk("RESTART\n");
++		init = find_task_by_pid_ns(1, &init_pid_ns);
++		if (init)
++			send_sig(SIGINT, init, 1);
++	} else if (strncmp(buf, "halt", len) == 0) {
++	    printk("HALT\n");
++		init = find_task_by_pid_ns(1, &init_pid_ns);
++		if (init)
++			send_sig(SIGWINCH, init, 1);
++	}
++
++	return IRQ_HANDLED;
++}
++
++static void rbvm_restart(char *command)
++{
++	char msg[] = "restart";
++
++	send_message(msg, sizeof(msg));
++
++	local_irq_disable();
++	while (1);
++}
++
++static void rbvm_power_off(void)
++{
++	char msg[] = "halt";
++
++	send_message(msg, sizeof(msg));
++}
++
++static int __init rbvm_probe(void)
++{
++	char *model;
++
++	model = of_get_flat_dt_prop(of_get_flat_dt_root(), "model", NULL);
++
++	if (!model)
++		return 0;
++
++	return strcmp(model, "RB MetaROUTER") == 0;
++}
++
++static void __init rbvm_pic_init(void)
++{
++	extern struct irq_host *virq_host;
++
++	mtvic_init(1);
++	vm_setup_irqs(virq_host->host_data, 32);
++}
++
++static void rb_idle(void) {
++	local_irq_enable();
++	vm_yield();
++	local_irq_disable();
++}
++
++static void rb_show_cpuinfo(struct seq_file *m)
++{
++	seq_printf(m, "Vendor\t\t: Mikrotik\n");
++	seq_printf(m, "Machine\t\t: %s\n", ppc_md.name);
++	seq_printf(m, "Memory\t\t: %u MB\n", total_memory / (1024 * 1024));
++}
++
++static void __init rbvm_setup_arch(void)
++{
++	unsigned i;
++
++	for (i = 0; i < BUF_COUNT; ++i) {
++		rx_chain[i].addr = (unsigned) rx_buffers[i];
++		rx_chain[i].size = BUF_SIZE;
++		rx_chain[i].next = (unsigned) &rx_chain[i + 1];
++		
++		tx_chain[i].addr = (unsigned) tx_buffers[i];
++		tx_chain[i].size = 0;
++		tx_chain[i].next = (unsigned) &tx_chain[i + 1];
++	}
++	rx_chain[BUF_COUNT - 1].next = (unsigned) &rx_chain[0];
++	tx_chain[BUF_COUNT - 1].next = (unsigned) &tx_chain[0];
++
++	vm_create_queue(0, 0, (unsigned) &tx_chain[0],
++			(unsigned) &rx_chain[0]);
++
++	ppc_md.power_save = rb_idle;
++}
++
++int __init init_ctrl_interrupt(void)
++{
++	if (request_irq(get_virq_nr(0), ctrl_interrupt,
++			0, "ctrl", (void *) 1));
++
++	return 0;
++}
++machine_device_initcall(rbvm, init_ctrl_interrupt);
++
++define_machine(rbvm) {
++	.name			= "RB MetaROUTER",
++	.probe			= rbvm_probe,
++	.setup_arch		= rbvm_setup_arch,
++	.show_cpuinfo		= rb_show_cpuinfo,
++	.get_irq		= mtvic_get_irq,
++	.init_IRQ		= rbvm_pic_init,
++	.calibrate_decr		= generic_calibrate_decr,
++	.restart		= rbvm_restart,
++	.power_off		= rbvm_power_off,
++	.halt			= rbvm_power_off,
++};
+diff -uNr linux-2.6.31.10/arch/powerpc/sysdev/Kconfig linux-2.6.31.10.new/arch/powerpc/sysdev/Kconfig
+--- linux-2.6.31.10/arch/powerpc/sysdev/Kconfig	2010-01-07 00:27:24.000000000 +0200
++++ linux-2.6.31.10.new/arch/powerpc/sysdev/Kconfig	2010-04-12 15:54:46.000000000 +0300
+@@ -12,3 +12,6 @@
+ 	depends on PCI_MSI
+ 	default y if MPIC
+ 	default y if FSL_PCI
++
++config MT_VIC
++	bool
+diff -uNr linux-2.6.31.10/arch/powerpc/sysdev/Makefile linux-2.6.31.10.new/arch/powerpc/sysdev/Makefile
+--- linux-2.6.31.10/arch/powerpc/sysdev/Makefile	2010-01-07 00:27:24.000000000 +0200
++++ linux-2.6.31.10.new/arch/powerpc/sysdev/Makefile	2010-04-12 15:54:46.000000000 +0300
+@@ -7,6 +7,7 @@
+ mpic-msi-obj-$(CONFIG_PCI_MSI)	+= mpic_msi.o mpic_u3msi.o mpic_pasemi_msi.o
+ obj-$(CONFIG_MPIC)		+= mpic.o $(mpic-msi-obj-y)
+ fsl-msi-obj-$(CONFIG_PCI_MSI)	+= fsl_msi.o
++obj-$(CONFIG_MT_VIC)		+= mtvic.o
+ obj-$(CONFIG_PPC_MSI_BITMAP)	+= msi_bitmap.o
+ 
+ obj-$(CONFIG_PPC_MPC106)	+= grackle.o
+diff -uNr linux-2.6.31.10/arch/powerpc/sysdev/mtvic.c linux-2.6.31.10.new/arch/powerpc/sysdev/mtvic.c
+--- linux-2.6.31.10/arch/powerpc/sysdev/mtvic.c	1970-01-01 03:00:00.000000000 +0300
++++ linux-2.6.31.10.new/arch/powerpc/sysdev/mtvic.c	2010-04-12 15:54:46.000000000 +0300
+@@ -0,0 +1,73 @@
++#include <linux/module.h>
++#include <linux/irq.h>
++#include <asm/mpic.h>
++#include <asm/mtvic.h>
++
++struct irq_host *virq_host;
++EXPORT_SYMBOL(virq_host);
++
++unsigned get_virq_nr(unsigned hwirq)
++{
++	return irq_create_mapping(virq_host, hwirq);
++}
++EXPORT_SYMBOL(get_virq_nr);
++
++void mtvic_mask_irq(unsigned int irq)
++{
++}
++
++void mtvic_unmask_irq(unsigned int irq)
++{
++}
++
++static struct irq_chip softirq_chip = {
++	.mask	= mtvic_mask_irq,
++	.unmask	= mtvic_unmask_irq,
++};
++
++static int mtvic_map(struct irq_host *h, unsigned int virq, irq_hw_number_t hw)
++{
++	set_irq_chip_and_handler(virq, &softirq_chip, handle_simple_irq);
++	return 0;
++}
++
++static struct irq_host_ops mtvic_ops = {
++	.map = mtvic_map,
++};
++
++void __init mtvic_init(int def)
++{
++	static unsigned virqs;
++
++	virq_host = irq_alloc_host(NULL, IRQ_HOST_MAP_LINEAR, 32,
++				   &mtvic_ops, 32);
++	virq_host->host_data = &virqs;
++
++	if (def)
++		irq_set_default_host(virq_host);
++}
++
++unsigned mtvic_get_irq(void)
++{
++	static unsigned i = 0;
++	unsigned *irqs = virq_host->host_data;
++
++	if (!irqs)
++		return NO_IRQ;
++
++	for (i = (i + 1) & 31; *irqs; i = (i + 1) & 31) {
++		if (*irqs & (1 << i)) {
++			atomic_sub(1 << i, (atomic_t *) irqs);
++			return irq_linear_revmap(virq_host, i);
++		}
++	}
++	return NO_IRQ;
++}
++
++unsigned rb_get_irq(void)
++{
++	unsigned irq = mtvic_get_irq();
++	if (irq != NO_IRQ) return irq;
++
++	return mpic_get_irq();
++}
+diff -uNr linux-2.6.31.10/drivers/char/hvc_meta.c linux-2.6.31.10.new/drivers/char/hvc_meta.c
+--- linux-2.6.31.10/drivers/char/hvc_meta.c	1970-01-01 03:00:00.000000000 +0300
++++ linux-2.6.31.10.new/drivers/char/hvc_meta.c	2010-04-12 15:54:46.000000000 +0300
+@@ -0,0 +1,134 @@
++#include <linux/kernel.h>
++#include <linux/init.h>
++#include <linux/string.h>
++#include <linux/errno.h>
++#include <linux/mm.h>
++#include <linux/bootmem.h>
++#include <asm/vm.h>
++#include <asm/irq.h>
++#include "hvc_console.h"
++
++extern int vm_create_queue(unsigned id, unsigned irq,
++			   unsigned tx, unsigned rx);
++extern int vm_release_queue(unsigned id);
++
++#define BUF_SIZE	4096
++
++static volatile struct vdma_descr tx_descr;
++static volatile struct vdma_descr rx_descr;
++
++static unsigned rx_offset;
++static DEFINE_SPINLOCK(lock);
++
++static int put_chars(u32 vtermno, const char *buf, int count)
++{
++	unsigned long flags;
++	int i;
++
++	spin_lock_irqsave(&lock, flags);
++
++#ifdef __powerpc__
++	for (i = 0; i < 2000000; ++i) {
++#else
++	for (i = 0; i < 2; ++i) {
++#endif
++		unsigned size = xchg(&tx_descr.size, 0);
++
++		if (!(size & DONE)) {
++			count = min(count, BUF_SIZE);
++			memcpy((char *) tx_descr.addr, buf, count);
++			tx_descr.size = count | DONE;
++
++			spin_unlock_irqrestore(&lock, flags);
++			return count;
++		}
++
++		if (size == (BUF_SIZE | DONE)) {
++			if (i == 0) {
++				tx_descr.size = size;
++				hc_yield();
++				continue;
++			} else {
++				unsigned drop = BUF_SIZE / 4;
++				size = BUF_SIZE - drop;
++				memcpy((char *) tx_descr.addr,
++				       (char *) tx_descr.addr + drop,
++				       size);
++			}
++		}
++
++		size &= ~DONE;
++		count = min(BUF_SIZE - (int) size, count);
++		memcpy((char *) tx_descr.addr + size, buf, count);
++		tx_descr.size = (size + count) | DONE;
++
++		spin_unlock_irqrestore(&lock, flags);
++		return count;
++	}
++
++	spin_unlock_irqrestore(&lock, flags);
++	return 0;
++}
++
++static int get_chars(u32 vtermno, char *buf, int count)
++{
++	unsigned long flags;
++	unsigned size;
++
++	spin_lock_irqsave(&lock, flags);
++
++	if (!(rx_descr.size & DONE)) {
++		spin_unlock_irqrestore(&lock, flags);
++		return -EAGAIN;
++	}
++	
++	size = (rx_descr.size & ~DONE) - rx_offset;
++	count = min(count, (int) size);
++
++	memcpy(buf, (char *) rx_descr.addr + rx_offset, count);
++
++	if (count == size) {
++		rx_descr.size = BUF_SIZE;
++		rx_offset = 0;
++	} else {
++		rx_offset += count;
++	}
++
++	spin_unlock_irqrestore(&lock, flags);
++	return count;
++}
++
++static struct hv_ops cons = {
++	.put_chars = put_chars,
++	.get_chars = get_chars,
++	.notifier_add = notifier_add_irq,
++	.notifier_del = notifier_del_irq,
++};
++
++static int __init cons_init(void)
++{
++	if (vm_running() != 0)
++		return 0;
++
++	rx_descr.addr = (unsigned) kmalloc(BUF_SIZE, GFP_KERNEL);
++	rx_descr.size = BUF_SIZE;
++	rx_descr.next = (unsigned) &rx_descr;
++	
++	tx_descr.addr = (unsigned) kmalloc(BUF_SIZE, GFP_KERNEL);
++	tx_descr.size = 0;
++	tx_descr.next = (unsigned) &tx_descr;
++
++	vm_create_queue(1, 1,
++			(unsigned) &tx_descr, (unsigned) &rx_descr);
++
++	return hvc_instantiate(0, 0, &cons);
++}
++console_initcall(cons_init);
++
++int vm_init(void)
++{
++	if (vm_running() == 0) 
++		hvc_alloc(0, get_virq_nr(1), &cons, 256);
++	return 0;
++}
++module_init(vm_init);
+diff -uNr linux-2.6.31.10/drivers/char/Kconfig linux-2.6.31.10.new/drivers/char/Kconfig
+--- linux-2.6.31.10/drivers/char/Kconfig	2010-01-07 00:27:24.000000000 +0200
++++ linux-2.6.31.10.new/drivers/char/Kconfig	2010-04-12 15:54:46.000000000 +0300
+@@ -672,6 +672,13 @@
+        select HVC_DRIVER
+        default n
+ 
++config HVC_META
++	bool "MetaROUTER Hypervisor Console support"
++	depends on METAROUTER
++	select HVC_DRIVER
++	select HVC_IRQ
++	default y
++
+ config VIRTIO_CONSOLE
+ 	tristate "Virtio console"
+ 	depends on VIRTIO
+diff -uNr linux-2.6.31.10/drivers/char/Makefile linux-2.6.31.10.new/drivers/char/Makefile
+--- linux-2.6.31.10/drivers/char/Makefile	2010-01-07 00:27:24.000000000 +0200
++++ linux-2.6.31.10.new/drivers/char/Makefile	2010-04-12 15:54:46.000000000 +0300
+@@ -51,6 +51,7 @@
+ obj-$(CONFIG_HVC_DRIVER)	+= hvc_console.o
+ obj-$(CONFIG_HVC_IRQ)		+= hvc_irq.o
+ obj-$(CONFIG_HVC_XEN)		+= hvc_xen.o
++obj-$(CONFIG_HVC_META)		+= hvc_meta.o
+ obj-$(CONFIG_HVC_IUCV)		+= hvc_iucv.o
+ obj-$(CONFIG_HVC_UDBG)		+= hvc_udbg.o
+ obj-$(CONFIG_VIRTIO_CONSOLE)	+= virtio_console.o
+diff -uNr linux-2.6.31.10/drivers/net/Kconfig linux-2.6.31.10.new/drivers/net/Kconfig
+--- linux-2.6.31.10/drivers/net/Kconfig	2010-01-07 00:27:24.000000000 +0200
++++ linux-2.6.31.10.new/drivers/net/Kconfig	2010-04-12 15:54:46.000000000 +0300
+@@ -457,6 +457,11 @@
+ 	  If you have a Mikrotik RouterBoard 500 or IDT RC32434
+ 	  based system say Y. Otherwise say N.
+ 
++config MT_VETH
++	bool "MetaROUTER Virtual Ethernet support"
++	depends on METAROUTER
++	default y
++
+ config MIPS_JAZZ_SONIC
+ 	tristate "MIPS JAZZ onboard SONIC Ethernet support"
+ 	depends on MACH_JAZZ
+diff -uNr linux-2.6.31.10/drivers/net/Makefile linux-2.6.31.10.new/drivers/net/Makefile
+--- linux-2.6.31.10/drivers/net/Makefile	2010-01-07 00:27:24.000000000 +0200
++++ linux-2.6.31.10.new/drivers/net/Makefile	2010-04-12 15:54:46.000000000 +0300
+@@ -208,6 +208,7 @@
+ obj-$(CONFIG_MVME147_NET) += mvme147.o 7990.o
+ obj-$(CONFIG_EQUALIZER) += eql.o
+ obj-$(CONFIG_KORINA) += korina.o
++obj-$(CONFIG_MT_VETH) += mtveth.o
+ obj-$(CONFIG_MIPS_JAZZ_SONIC) += jazzsonic.o
+ obj-$(CONFIG_MIPS_AU1X00_ENET) += au1000_eth.o
+ obj-$(CONFIG_MIPS_SIM_NET) += mipsnet.o
+diff -uNr linux-2.6.31.10/drivers/net/mtveth.c linux-2.6.31.10.new/drivers/net/mtveth.c
+--- linux-2.6.31.10/drivers/net/mtveth.c	1970-01-01 03:00:00.000000000 +0300
++++ linux-2.6.31.10.new/drivers/net/mtveth.c	2010-04-12 15:54:46.000000000 +0300
+@@ -0,0 +1,284 @@
++#include <linux/skbuff.h>
++#include <linux/netdevice.h>
++#include <linux/etherdevice.h>
++#include <linux/interrupt.h>
++#include <asm/vm.h>
++
++#define MAX_IFACES	8
++
++#define TXBUF_COUNT	1024
++#define RXBUF_COUNT	128
++
++#define RXBUF_SIZE	1600
++
++extern int vm_create_queue(unsigned id, unsigned irq,
++			   unsigned tx, unsigned rx);
++extern int vm_release_queue(unsigned id);
++
++#define CMD_NEWIFACE	0
++#define CMD_DELIFACE	1
++
++struct ctrl_msg {
++	unsigned cmd;
++	unsigned short id;
++	unsigned char hwaddr[6];
++} __attribute__((packed));
++
++static volatile struct vdma_descr rx_descr[RXBUF_COUNT];
++static volatile struct vdma_descr tx_descr[TXBUF_COUNT];
++static struct sk_buff *rx_skbs[RXBUF_COUNT];
++static struct sk_buff *tx_skbs[TXBUF_COUNT];
++
++static unsigned last_tx;
++static atomic_t cur_tx;
++static unsigned cur_rx;
++static unsigned max_tx;
++
++static struct net_device *devs[MAX_IFACES];
++
++struct veth_private {
++	unsigned id;
++	atomic_t pending_tx;
++};
++
++static void ctrl_receiver(struct work_struct *work);
++
++static struct sk_buff_head ctrl_queue;
++static DECLARE_WORK(ctrl_work, ctrl_receiver);
++
++static int veth_xmit(struct sk_buff *skb, struct net_device *dev)
++{
++	struct veth_private *veth = netdev_priv(dev);
++	unsigned cur = atomic_read(&cur_tx) % TXBUF_COUNT;
++    
++	if (skb_padto(skb, ETH_ZLEN))
++		return NETDEV_TX_OK;
++
++	if (tx_descr[cur].size & DONE) {
++		dev->stats.tx_dropped++;
++		dev_kfree_skb_any(skb);
++		return NETDEV_TX_OK;
++	}
++
++	if (skb_headroom(skb) < 2) {
++		struct sk_buff *s = skb;
++		skb = skb_realloc_headroom(s, 2);
++		dev_kfree_skb_any(s);
++	} else {
++		skb = skb_unshare(skb, GFP_ATOMIC);
++	}
++	if (!skb) {
++		dev->stats.tx_dropped++;
++		return NETDEV_TX_OK;
++	}
++	*(u16 *) skb_push(skb, 2) = veth->id;
++
++	dev->stats.tx_packets++;
++	dev->stats.tx_bytes += skb->len;
++
++	tx_descr[cur].addr = (unsigned) skb->data;
++	tx_descr[cur].size = skb->len | DONE;
++
++	if (tx_skbs[cur]) {
++		/* should not happen */
++		dev->stats.tx_dropped++;
++		dev_kfree_skb_any(skb);
++		return NETDEV_TX_BUSY;
++	}
++
++	tx_skbs[cur] = skb;
++	atomic_add(1, &cur_tx);
++
++	if (atomic_add_return(1, &veth->pending_tx) >= max_tx) {
++		netif_stop_queue(dev);
++
++		/* in case we got rewaken right before stop */
++		if (atomic_read(&veth->pending_tx) < max_tx)
++			netif_wake_queue(dev);
++	}
++
++	return 0;
++}
++
++static irqreturn_t veth_interrupt(int irq, void *dev_id)
++{
++	unsigned cur;
++
++	while (last_tx != atomic_read(&cur_tx)) {
++		unsigned last = last_tx % TXBUF_COUNT;
++		struct net_device *dev;
++		struct veth_private *veth;
++
++		if (tx_descr[last].size & DONE)
++			break;
++
++		dev = tx_skbs[last]->dev;
++		veth = netdev_priv(dev);
++		dev_kfree_skb_irq(tx_skbs[last]);
++		tx_skbs[last] = NULL;
++
++		++last_tx;
++
++		if (atomic_sub_return(1, &veth->pending_tx) < max_tx)
++			netif_wake_queue(dev);
++	}
++
++	cur = cur_rx % RXBUF_COUNT;
++	while ((rx_descr[cur].size & DONE)) {
++		struct sk_buff *skb = rx_skbs[cur];
++		struct net_device *dev;
++		unsigned id;
++
++		skb_put(skb, rx_descr[cur].size & ~DONE);
++		if (skb->len < 2) {
++			dev_kfree_skb_irq(skb);
++			goto next;
++		}
++
++		id = *(u16 *) skb->data;
++		skb_pull(skb, 2);
++
++		if (id == 0) {
++			__skb_queue_tail(&ctrl_queue, skb);
++			schedule_work(&ctrl_work);
++			goto next;
++		}
++		if (id >= MAX_IFACES || !devs[id]) {
++			dev_kfree_skb_irq(skb);
++			goto next;
++		}
++		dev = devs[id];
++
++		skb->dev = dev;
++		skb->protocol = eth_type_trans(skb, dev);
++
++		dev->last_rx = jiffies;
++		++dev->stats.rx_packets;
++		dev->stats.rx_bytes += skb->len;
++
++		netif_rx(skb);
++
++	  next:
++		skb = dev_alloc_skb(RXBUF_SIZE);
++		rx_skbs[cur] = skb;
++		if (skb) {
++			rx_descr[cur].addr = (unsigned) skb->data;
++			rx_descr[cur].size = RXBUF_SIZE;
++		} else {
++			rx_descr[cur].size = 0;
++		}
++
++		++cur_rx;
++		cur = cur_rx % RXBUF_COUNT;
++	}
++
++	return IRQ_HANDLED;
++}
++
++static const struct net_device_ops veth_netdev_ops = {
++	.ndo_start_xmit		= veth_xmit,
++};
++
++static int veth_alloc_dev(unsigned id, const unsigned char *hwaddr)
++{
++	struct veth_private *veth;
++	struct net_device *dev;
++	int err;
++
++	//SET_NETDEV_DEV(dev, &pdev->dev);
++	//platform_set_drvdata(pdev, dev);
++
++	dev = alloc_etherdev(sizeof(struct veth_private));
++	if (!dev)
++		return -ENOMEM;
++
++	veth = netdev_priv(dev);
++	veth->id = id;
++	atomic_set(&veth->pending_tx, 1);
++	memcpy(dev->dev_addr, hwaddr, 6);
++	dev->netdev_ops = &veth_netdev_ops;
++
++	err = register_netdev(dev);
++	if (err < 0) {
++		printk("cannot register net device %u\n", err);
++		goto netdev_err;
++	}
++
++	devs[id] = dev;
++	return 0;
++
++  netdev_err:
++	free_netdev(dev);
++	return err;
++}
++
++static int recv_ctrl_msg(struct sk_buff *skb)
++{
++	struct ctrl_msg *msg = (struct ctrl_msg *) skb->data;
++
++	if (skb->len < sizeof(struct ctrl_msg))
++		return -EINVAL;
++
++	if (msg->cmd == CMD_NEWIFACE) {
++		if (msg->id >= MAX_IFACES || devs[msg->id])
++			return -EBUSY;
++
++		veth_alloc_dev(msg->id, msg->hwaddr);
++		return 0;
++	} else if (msg->cmd == CMD_DELIFACE) {
++		struct net_device *dev;
++
++		if (msg->id >= MAX_IFACES || !devs[msg->id])
++			return -EINVAL;
++		
++		dev = devs[msg->id];
++		devs[msg->id] = NULL;
++
++		unregister_netdev(dev);
++	}
++	return -EINVAL;
++}
++
++static void ctrl_receiver(struct work_struct *work)
++{
++	struct sk_buff *skb;
++
++	while ((skb = skb_dequeue(&ctrl_queue)))
++		recv_ctrl_msg(skb);
++}
++
++int veth_init(void)
++{
++	unsigned i;
++
++	if (vm_running() != 0)
++		return 0;
++
++	skb_queue_head_init(&ctrl_queue);
++
++	if (request_irq(get_virq_nr(3), veth_interrupt, IRQF_SHARED,
++			"veth", (void *) 1))
++		return -EBUSY;
++
++	for (i = 0; i < TXBUF_COUNT; ++i) {
++		tx_descr[i].addr = 0;
++		tx_descr[i].size = 0;
++		tx_descr[i].next = (unsigned) &tx_descr[i + 1];
++	}
++	for (i = 0; i < RXBUF_COUNT; ++i) {
++		rx_skbs[i] = dev_alloc_skb(RXBUF_SIZE);
++		rx_descr[i].addr = (unsigned) rx_skbs[i]->data;
++		rx_descr[i].size = RXBUF_SIZE;
++		rx_descr[i].next = (unsigned) &rx_descr[i + 1];
++	}
++	tx_descr[TXBUF_COUNT - 1].next = (unsigned) &tx_descr[0];
++	rx_descr[RXBUF_COUNT - 1].next = (unsigned) &rx_descr[0];
++	
++	vm_create_queue(3, 3,
++			(unsigned) &tx_descr[0], (unsigned) &rx_descr[0]);
++
++	max_tx = TXBUF_COUNT / MAX_IFACES;
++
++	return 0;
++}
++module_init(veth_init);
+diff -uNr linux-2.6.31.10/fs/Kconfig linux-2.6.31.10.new/fs/Kconfig
+--- linux-2.6.31.10/fs/Kconfig	2010-01-07 00:27:24.000000000 +0200
++++ linux-2.6.31.10.new/fs/Kconfig	2010-04-12 15:54:46.000000000 +0300
+@@ -173,6 +173,7 @@
+ source "fs/bfs/Kconfig"
+ source "fs/efs/Kconfig"
+ source "fs/jffs2/Kconfig"
++source "fs/metafs/Kconfig"
+ # UBIFS File system configuration
+ source "fs/ubifs/Kconfig"
+ source "fs/cramfs/Kconfig"
+diff -uNr linux-2.6.31.10/fs/Makefile linux-2.6.31.10.new/fs/Makefile
+--- linux-2.6.31.10/fs/Makefile	2010-01-07 00:27:24.000000000 +0200
++++ linux-2.6.31.10.new/fs/Makefile	2010-04-12 15:54:46.000000000 +0300
+@@ -73,6 +73,7 @@
+ obj-$(CONFIG_JBD)		+= jbd/
+ obj-$(CONFIG_JBD2)		+= jbd2/
+ obj-$(CONFIG_CRAMFS)		+= cramfs/
++obj-$(CONFIG_META_FS)		+= metafs/
+ obj-$(CONFIG_SQUASHFS)		+= squashfs/
+ obj-y				+= ramfs/
+ obj-$(CONFIG_HUGETLBFS)		+= hugetlbfs/
+diff -uNr linux-2.6.31.10/fs/metafs/inode.c linux-2.6.31.10.new/fs/metafs/inode.c
+--- linux-2.6.31.10/fs/metafs/inode.c	1970-01-01 03:00:00.000000000 +0300
++++ linux-2.6.31.10.new/fs/metafs/inode.c	2010-04-12 15:54:46.000000000 +0300
+@@ -0,0 +1,902 @@
++#include <linux/module.h>
++#include <linux/fs.h>
++#include <linux/statfs.h>
++#include <linux/pagemap.h>
++#include <linux/namei.h>
++#include <asm/vm.h>
++
++#define CMD_GETINODE		0
++#define CMD_RELEASE_INODE	1
++#define CMD_LOOKUP		2
++#define CMD_READPAGE		3
++#define CMD_READLINK		4
++#define CMD_READDIR		5
++#define CMD_WRITEPAGE		6
++#define CMD_CREATE		7
++#define CMD_UNLINK		8
++#define CMD_SYMLINK		9
++#define CMD_RENAME		10
++#define CMD_SETINODE		11
++#define CMD_STATFS		12
++#define CMD_HLINK		13
++#define CMD_FSYNC		14
++
++struct hptime {
++	unsigned sec;
++	unsigned nsec;
++};
++
++struct getinode_req {
++	unsigned short id;
++	unsigned short cmd;
++	unsigned long long ino;
++} __attribute__((packed));
++
++struct inode_rep {
++	int status;
++	unsigned long long ino;
++	unsigned long long size;
++	unsigned mode;
++	unsigned nlink;
++	unsigned uid;
++	unsigned gid;
++	unsigned rdev;
++	struct hptime atime;
++	struct hptime mtime;
++	struct hptime ctime;
++	unsigned long blksize;
++	unsigned long long blocks;
++} __attribute__((packed));
++
++struct setinode_req {
++	unsigned short id;
++	unsigned short cmd;
++	unsigned long long ino;
++	unsigned long long size;
++	unsigned mode;
++	unsigned uid;
++	unsigned gid;
++	unsigned rdev;
++} __attribute__((packed));
++
++struct lookup_req {
++	unsigned short id;
++	unsigned short cmd;
++	unsigned long long parent_ino;
++	char name[0];
++} __attribute__((packed));
++
++struct create_req {
++	unsigned short id;
++	unsigned short cmd;
++	unsigned long long parent_ino;
++	unsigned mode;
++	unsigned dev;
++	char name[0];
++} __attribute__((packed));
++
++struct unlink_req {
++	unsigned short id;
++	unsigned short cmd;
++	unsigned long long parent_ino;
++	char name[0];
++} __attribute__((packed));
++
++struct symlink_req {
++	unsigned short id;
++	unsigned short cmd;
++	unsigned long long parent_ino;
++	unsigned namelen;
++	char names[0];
++} __attribute__((packed));
++
++struct hlink_req {
++	unsigned short id;
++	unsigned short cmd;
++	unsigned long long parent_ino;
++	unsigned long long ino;
++	char name[0];
++} __attribute__((packed));
++
++struct rename_req {
++	unsigned short id;
++	unsigned short cmd;
++	unsigned long long old_parent_ino;
++	unsigned long long new_parent_ino;
++	unsigned old_namelen;
++	char names[0];
++} __attribute__((packed));
++
++struct readpage_req {
++	unsigned short id;
++	unsigned short cmd;
++	unsigned long long ino;
++	unsigned long long offset;
++	unsigned size;
++} __attribute__((packed));
++
++struct writepage_req {
++	unsigned short id;
++	unsigned short cmd;
++	unsigned long long ino;
++	unsigned long long offset;
++	unsigned size;
++} __attribute__((packed));
++
++struct fsync_req {
++	unsigned short id;
++	unsigned short cmd;
++	unsigned long long ino;
++} __attribute__((packed));
++
++struct readlink_req {
++	unsigned short id;
++	unsigned short cmd;
++	unsigned long long ino;
++} __attribute__((packed));
++
++struct readlink_rep {
++	int status;
++	char target[0];
++} __attribute__((packed));
++
++struct readdir_req {
++	unsigned short id;
++	unsigned short cmd;
++	unsigned long long ino;
++	unsigned long long offset;
++	unsigned size;
++} __attribute__((packed));
++
++struct dirnode {
++	unsigned long long ino;
++	unsigned long long offset;
++	unsigned char type;
++	unsigned short len;
++	char name[0];
++} __attribute__((packed));
++
++struct readdir_rep {
++	int status;
++	unsigned long long offset;
++	struct dirnode entries[0];
++} __attribute__((packed));
++
++struct statfs_req {
++	unsigned short id;
++	unsigned short cmd;
++} __attribute__((packed));
++
++struct statfs_rep {
++	int status;
++	unsigned blocks;
++	unsigned bfree;
++} __attribute__((packed));
++
++#define BUF_COUNT	16
++
++extern int vm_create_queue(unsigned id, unsigned irq,
++			   unsigned tx, unsigned rx);
++extern int vm_release_queue(unsigned id);
++
++static volatile struct vdma_descr rx_descr[BUF_COUNT];
++static volatile struct vdma_descr tx_descr[BUF_COUNT];
++
++#define MFS_ID(sb) ((unsigned) sb->s_fs_info)
++
++
++static void mfs_update_inode(struct inode *i, struct inode_rep *rep);
++static struct inode *mfs_new_inode(struct super_block *sb,
++				   struct inode_rep *rep);
++
++static void start_new_request(unsigned *tx_idx, unsigned tx_slots,
++			      unsigned *rx_idx, unsigned rx_slots)
++{
++	static DEFINE_MUTEX(mfs_lock);
++	static unsigned cur_tx;
++	static unsigned cur_rx;
++
++	mutex_lock(&mfs_lock);
++
++	*tx_idx = cur_tx;
++	cur_tx += tx_slots;
++
++	*rx_idx = cur_rx;
++	cur_rx += rx_slots;
++
++	mutex_unlock(&mfs_lock);
++}
++
++static void prepare_receive(unsigned idx, void *resp, unsigned rp_size)
++{
++	idx = idx & (BUF_COUNT - 1);
++
++	rx_descr[idx].addr = (unsigned) resp;
++	rx_descr[idx].size = rp_size;
++}
++
++static void post_request(unsigned idx, const void *req, unsigned rq_size)
++{
++	idx = idx & (BUF_COUNT - 1);
++
++	while (tx_descr[idx].size & DONE) {
++		hc_yield();
++	}
++
++	tx_descr[idx].addr = (unsigned) req;
++	tx_descr[idx].size = rq_size | DONE;
++}
++
++static unsigned wait_for_reply(unsigned idx)
++{
++	idx = idx & (BUF_COUNT - 1);
++
++	while (!(rx_descr[idx].size & DONE)) {
++		hc_yield();
++	}
++	return rx_descr[idx].size & ~(PAGE_MASK<<1);
++}
++
++static unsigned send_request(const void *req, unsigned rq_size,
++			     void *resp, unsigned rp_size)
++{
++	unsigned tx;
++	unsigned rx;
++
++	start_new_request(&tx, 1, &rx, 1);
++	prepare_receive(rx, resp, rp_size);
++	post_request(tx, req, rq_size);
++	return wait_for_reply(rx);
++}
++
++static struct kmem_cache *mfs_inode_cachep;
++
++static struct inode *mfs_alloc_inode(struct super_block *sb)
++{
++	return kmem_cache_alloc(mfs_inode_cachep, GFP_KERNEL);
++}
++
++static void mfs_destroy_inode(struct inode *inode)
++{
++	kmem_cache_free(mfs_inode_cachep, inode);
++}
++
++static struct dentry *mfs_lookup(struct inode *dir,
++				 struct dentry *dentry, struct nameidata *nd)
++{
++	unsigned size = sizeof(struct lookup_req) + dentry->d_name.len;
++	unsigned char buf[size];
++	struct lookup_req *req = (struct lookup_req *) buf;
++	struct inode_rep rep;
++	struct inode *inode = NULL;
++	struct dentry *res = NULL;
++	unsigned ret;
++
++	req->id = MFS_ID(dir->i_sb);
++	req->cmd = CMD_LOOKUP;
++	req->parent_ino = dir->i_ino;
++	memcpy(req->name, dentry->d_name.name, dentry->d_name.len);
++
++	rep.status = -EINVAL;
++	ret = send_request(req, size, &rep, sizeof(rep));
++	if (ret == sizeof(rep) && rep.status == 0)
++		inode = mfs_new_inode(dir->i_sb, &rep);
++	d_add(dentry, inode);
++	return res;
++}
++
++static int mfs_create_file(struct inode *dir, struct dentry *dentry,
++			   int mode, dev_t dev)
++{
++	unsigned size = sizeof(struct create_req) + dentry->d_name.len;
++	unsigned char buf[size];
++	struct create_req *req = (struct create_req *) buf;
++	struct inode_rep rep;
++	struct inode *inode = NULL;
++	unsigned ret;
++
++	req->id = MFS_ID(dir->i_sb);
++	req->cmd = CMD_CREATE;
++	req->parent_ino = dir->i_ino;
++	req->mode = mode;
++	req->dev = (unsigned) dev;
++	memcpy(req->name, dentry->d_name.name, dentry->d_name.len);
++
++	rep.status = -EINVAL;
++	ret = send_request(req, size, &rep, sizeof(rep));
++	if (ret < sizeof(rep))
++		return rep.status;
++
++	inode = mfs_new_inode(dir->i_sb, &rep);
++	d_instantiate(dentry, inode);
++	return 0;
++}
++
++static int mfs_create(struct inode *dir, struct dentry *dentry, int mode,
++		      struct nameidata *nd)
++{
++	return mfs_create_file(dir, dentry, mode, MKDEV(0, 0));
++}
++
++static int mfs_unlink(struct inode *dir, struct dentry *dentry)
++{
++	unsigned size = sizeof(struct unlink_req) + dentry->d_name.len;
++	unsigned char buf[size];
++	struct unlink_req *req = (struct unlink_req *) buf;
++	int err = -EINVAL;
++    
++	req->id = MFS_ID(dir->i_sb);
++	req->cmd = CMD_UNLINK;
++	req->parent_ino = dir->i_ino;
++	memcpy(req->name, dentry->d_name.name, dentry->d_name.len);
++
++	send_request(req, size, &err, sizeof(err));
++	return err;
++}
++
++static int mfs_symlink(struct inode *dir, struct dentry *dentry,
++		       const char *target)
++{
++	unsigned tlen = strlen(target);
++	unsigned size = sizeof(struct symlink_req) + dentry->d_name.len + tlen;
++	unsigned char buf[size];
++	struct symlink_req *req = (struct symlink_req *) buf;
++	struct inode_rep rep;
++	struct inode *inode = NULL;
++	unsigned ret;
++    
++	req->id = MFS_ID(dir->i_sb);
++	req->cmd = CMD_SYMLINK;
++	req->parent_ino = dir->i_ino;
++	req->namelen = dentry->d_name.len;
++	memcpy(req->names, dentry->d_name.name, dentry->d_name.len);
++	memcpy(req->names + req->namelen, target, tlen);
++
++	rep.status = -EINVAL;
++	ret = send_request(req, size, &rep, sizeof(rep));
++	if (ret < sizeof(rep))
++		return rep.status;
++
++	inode = mfs_new_inode(dir->i_sb, &rep);
++	d_instantiate(dentry, inode);
++	return 0;
++}
++
++static int mfs_link(struct dentry *old_dentry, struct inode *dir,
++		    struct dentry *dentry)
++{
++	unsigned size = sizeof(struct hlink_req) + dentry->d_name.len;
++	unsigned char buf[size];
++	struct hlink_req *req = (struct hlink_req *) buf;
++	struct inode_rep rep;
++	unsigned ret;
++    
++	req->id = MFS_ID(dir->i_sb);
++	req->cmd = CMD_HLINK;
++	req->parent_ino = dir->i_ino;
++	req->ino = old_dentry->d_inode->i_ino;
++	memcpy(req->name, dentry->d_name.name, dentry->d_name.len);
++
++	rep.status = -EINVAL;
++	ret = send_request(req, size, &rep, sizeof(rep));
++	if (ret < sizeof(rep))
++		return rep.status;
++
++	mfs_update_inode(old_dentry->d_inode, &rep);
++
++	atomic_inc(&old_dentry->d_inode->i_count);
++	d_instantiate(dentry, old_dentry->d_inode);
++	return 0;
++}
++
++static int mfs_mkdir(struct inode *dir, struct dentry *dentry, int mode)
++{
++	return mfs_create_file(dir, dentry, mode | S_IFDIR, MKDEV(0, 0));
++}
++
++static int mfs_rmdir(struct inode *dir, struct dentry *dentry)
++{
++	return mfs_unlink(dir, dentry);
++}
++
++static int mfs_mknod(struct inode *dir, struct dentry *dentry, int mode,
++		     dev_t rdev) {
++	return mfs_create_file(dir, dentry, mode, rdev);
++}
++
++static int mfs_rename(struct inode *old_dir, struct dentry *old_dentry,
++		      struct inode *new_dir, struct dentry *new_dentry)
++{
++	unsigned size = sizeof(struct rename_req) +
++	    old_dentry->d_name.len + new_dentry->d_name.len;
++	unsigned char buf[size];
++	struct rename_req *req = (struct rename_req *) buf;
++	int err = -EINVAL;
++    
++	req->id = MFS_ID(old_dir->i_sb);
++	req->cmd = CMD_RENAME;
++	req->old_parent_ino = old_dir->i_ino;
++	req->new_parent_ino = new_dir->i_ino;
++	req->old_namelen = old_dentry->d_name.len;
++	memcpy(req->names, old_dentry->d_name.name, old_dentry->d_name.len);
++	memcpy(req->names + req->old_namelen,
++	       new_dentry->d_name.name, new_dentry->d_name.len);
++
++	send_request(req, size, &err, sizeof(err));
++	return err;
++}
++
++static int mfs_readdir(struct file *file, void *dirent, filldir_t filldir)
++{
++	struct readdir_req req;
++	struct readdir_rep *rep;
++	struct dirnode *dn;
++	unsigned len;
++	int res = -EINVAL;
++
++	rep = kmalloc(PAGE_SIZE, GFP_KERNEL);
++	if (!rep)
++		return -ENOMEM;
++
++	req.id = MFS_ID(file->f_dentry->d_inode->i_sb);
++	req.cmd = CMD_READDIR;
++	req.ino = file->f_dentry->d_inode->i_ino;
++	req.offset = file->f_pos;
++	req.size = PAGE_SIZE;
++
++	len = send_request(&req, sizeof(req), rep, PAGE_SIZE);
++	if (len <= sizeof(*rep)) {
++		if (len >= sizeof(int))
++			res = rep->status;
++		goto eod;
++	}
++	
++	dn = rep->entries;
++	res = 0;
++	while ((char *) dn + sizeof(struct dirnode) < (char *) rep + len) {
++		if ((char *) dn + dn->len > (char *) rep + len)
++			break;
++		if (filldir(dirent, dn->name, dn->len - sizeof(struct dirnode),
++			    dn->offset, dn->ino, dn->type) < 0)
++			break;
++		++res;
++		dn = (struct dirnode *) ((unsigned char *) dn + dn->len);
++	}
++	file->f_pos = rep->offset;
++
++  eod:
++	kfree(rep);
++	return res;
++}
++
++static int mfs_readpage(struct file *file, struct page *page)
++{
++	struct readpage_req req;
++	void *buf;
++	int res = -EIO;
++	unsigned len;
++	unsigned tx;
++	unsigned rx;
++
++	buf = kmap(page);
++	if (!buf)
++		goto err_out;
++
++	req.id = MFS_ID(file->f_dentry->d_inode->i_sb);
++	req.cmd = CMD_READPAGE;
++	req.ino = file->f_dentry->d_inode->i_ino;
++	req.offset = page_offset(page);
++	req.size = PAGE_SIZE;
++
++	start_new_request(&tx, 1, &rx, 2);
++	prepare_receive(rx, &res, sizeof(res));
++	prepare_receive(rx + 1, buf, PAGE_SIZE);
++	post_request(tx, &req, sizeof(req));
++
++	if (wait_for_reply(rx) < sizeof(res)) {
++		res = -EINVAL;
++		goto err_out;
++	}
++	if (res) {
++		memset(buf, 0, PAGE_SIZE);
++		SetPageError(page);
++		goto err_buf;
++	}
++	len = wait_for_reply(rx + 1);
++
++	memset(buf + len, 0, PAGE_SIZE - len);
++	SetPageUptodate(page);
++
++  err_buf:
++	kunmap(page);
++	flush_dcache_page(page);
++  err_out:
++	unlock_page(page);
++	return res;
++}
++
++static int mfs_write_begin(struct file *file, struct address_space *mapping,
++			   loff_t pos, unsigned len, unsigned flags,
++			   struct page **pagep, void **fsdata)
++{
++	pgoff_t index = pos >> PAGE_CACHE_SHIFT;
++
++	*pagep = grab_cache_page_write_begin(mapping, index, flags);
++	if (!*pagep)
++		return -ENOMEM;
++
++	// FIXME: do prereading
++
++	return 0;
++}
++
++static int mfs_write_end(struct file *file, struct address_space *mapping,
++			 loff_t pos, unsigned blen, unsigned copied,
++			 struct page *page, void *fsdata)
++{
++	struct inode *i = file->f_dentry->d_inode;
++	struct writepage_req req;
++	void *buf;
++	int len = -EFAULT;
++	unsigned tx;
++	unsigned rx;
++	unsigned size;
++
++	flush_dcache_page(page);
++
++	buf = kmap(page);
++	if (!buf)
++		return -EINVAL;
++
++	req.id = MFS_ID(i->i_sb);
++	req.cmd = CMD_WRITEPAGE;
++	req.ino = file->f_dentry->d_inode->i_ino;
++	req.offset = pos;
++	req.size = blen;
++
++	start_new_request(&tx, 2, &rx, 1);
++	prepare_receive(rx, &len, sizeof(len));
++	post_request(tx, &req, sizeof(req));
++	post_request(tx + 1, buf + (pos & (PAGE_CACHE_SIZE - 1)), blen);
++	wait_for_reply(rx);
++
++	if (len >= 0) {
++		if (len != blen) {
++			SetPageError(page);
++			ClearPageUptodate(page);
++		} else {
++			SetPageUptodate(page);
++		}
++
++		size = req.offset + len;
++		if (size > i_size_read(i)) i_size_write(i, size);
++	}
++
++	kunmap(page);
++	unlock_page(page);
++	page_cache_release(page);
++	return len;
++}
++
++static int mfs_fsync(struct file *file, struct dentry *dentry, int datasync)
++{
++	struct fsync_req req;
++	int err = -EINVAL;
++
++	req.id = MFS_ID(dentry->d_inode->i_sb);
++	req.cmd = CMD_FSYNC;
++	req.ino = file->f_dentry->d_inode->i_ino;
++
++	send_request(&req, sizeof(req), &err, sizeof(err));
++	return err;
++}
++
++static void *mfs_follow_link(struct dentry *dentry, struct nameidata *nd)
++{
++	struct readlink_req req;
++	struct readlink_rep *rep;
++	int len;
++
++	rep = kmalloc(256, GFP_KERNEL);
++	if (!rep)
++		return ERR_PTR(-ENOMEM);
++
++	req.id = MFS_ID(dentry->d_inode->i_sb);
++	req.cmd = CMD_READLINK;
++	req.ino = dentry->d_inode->i_ino;
++	
++	rep->status = -EINVAL;
++	len = send_request(&req, sizeof(req), rep, 255);
++	if (len < sizeof(*rep) + 1) {
++		kfree(rep);
++		return ERR_PTR(rep->status);
++	}
++
++	*((char *) rep + len) = 0;
++	nd_set_link(nd, rep->target);
++	return NULL;
++}
++
++static void mfs_put_link(struct dentry *direntry,
++			 struct nameidata *nd, void *cookie)
++{
++	char *p = nd_get_link(nd);
++
++	if (!IS_ERR(p))
++		kfree(p - sizeof(struct readlink_rep));
++}
++
++static int mfs_setattr(struct dentry *dentry, struct iattr *attr)
++{
++	struct setinode_req req;
++	struct inode_rep rep;
++	struct inode *i = dentry->d_inode;
++	unsigned ia = attr->ia_valid;
++	unsigned len;
++
++	req.id = MFS_ID(i->i_sb);
++	req.cmd = CMD_SETINODE;
++	req.ino = i->i_ino;
++	req.mode = ia & ATTR_MODE ? attr->ia_mode : i->i_mode;
++	req.uid = ia & ATTR_UID ? attr->ia_uid : i->i_uid;
++	req.gid = ia & ATTR_GID ? attr->ia_gid : i->i_gid;
++	req.size = ia & ATTR_SIZE ? attr->ia_size : i->i_size;
++
++	len = send_request(&req, sizeof(req), &rep, sizeof(rep));
++	if (len < sizeof(rep))
++		return -EINVAL;
++	    
++	if (rep.status)
++		return rep.status;
++
++	mfs_update_inode(i, &rep);
++	return 0;
++}
++
++static const struct file_operations mfs_dir_fops = {
++	.read		= generic_read_dir,
++	.readdir	= mfs_readdir,
++};
++
++static const struct inode_operations mfs_dir_ops = {
++	.lookup		= mfs_lookup,
++	.create		= mfs_create,
++	.link		= mfs_link,
++	.unlink		= mfs_unlink,
++	.symlink	= mfs_symlink,
++	.mkdir		= mfs_mkdir,
++	.rmdir		= mfs_rmdir,
++	.mknod		= mfs_mknod,
++	.rename		= mfs_rename,
++	.setattr	= mfs_setattr,
++};
++
++static const struct inode_operations mfs_file_ops = {
++	.setattr	= mfs_setattr,
++};
++
++static const struct file_operations mfs_fops = {
++	.llseek		= generic_file_llseek,
++	.read		= do_sync_read,
++	.write		= do_sync_write,
++	.aio_read	= generic_file_aio_read,
++	.aio_write	= generic_file_aio_write,
++	.mmap		= generic_file_readonly_mmap,
++	.splice_read	= generic_file_splice_read,
++	.fsync		= mfs_fsync,
++};
++
++static const struct address_space_operations mfs_aops = {
++	.readpage	= mfs_readpage,
++	.write_begin	= mfs_write_begin,
++	.write_end	= mfs_write_end,
++};
++
++static const struct inode_operations mfs_link_ops = {
++	.readlink	= generic_readlink,
++	.follow_link	= mfs_follow_link,
++	.put_link	= mfs_put_link,
++	.setattr	= mfs_setattr,
++};
++
++static void mfs_update_inode(struct inode *i, struct inode_rep *rep)
++{
++	i->i_ino = rep->ino;
++	i->i_mode = rep->mode;
++	i->i_nlink = rep->nlink;
++	i->i_uid = rep->uid;
++	i->i_gid = rep->gid;
++	i->i_size = rep->size;
++	i->i_atime.tv_sec = rep->atime.sec;
++	i->i_atime.tv_nsec = rep->atime.nsec;
++	i->i_mtime.tv_sec = rep->mtime.sec;
++	i->i_mtime.tv_nsec = rep->mtime.nsec;
++	i->i_ctime.tv_sec = rep->ctime.sec;
++	i->i_ctime.tv_nsec = rep->ctime.nsec;
++	i->i_blkbits = ffs(rep->blksize);
++	i->i_blocks = rep->blocks;
++
++	if (i->i_sb->s_flags & MS_RDONLY)
++		i->i_mode &= ~0222;
++}
++
++static struct inode *mfs_new_inode(struct super_block *sb,
++				   struct inode_rep *rep)
++{
++	struct inode *i = new_inode(sb);
++	if (!i) return NULL;
++
++	mfs_update_inode(i, rep);
++
++	if (S_ISREG(rep->mode)) {
++		i->i_op = &mfs_file_ops;
++		i->i_fop = &mfs_fops;
++		i->i_data.a_ops = &mfs_aops;
++	} else if (S_ISDIR(rep->mode)) {
++		i->i_op = &mfs_dir_ops;
++		i->i_fop = &mfs_dir_fops;
++	} else if (S_ISLNK(rep->mode)) {
++		i->i_op = &mfs_link_ops;
++	} else {
++		init_special_inode(i, rep->mode, (dev_t) rep->rdev);
++	}
++
++	insert_inode_hash(i);
++	return i;
++}
++
++static struct inode *mfs_getinode(struct super_block *sb,
++				  unsigned long long ino)
++{
++	struct getinode_req req;
++	struct inode_rep rep;
++	unsigned len;
++
++	req.id = MFS_ID(sb);
++	req.cmd = CMD_GETINODE;
++	req.ino = ino;
++	len = send_request(&req, sizeof(req), &rep, sizeof(rep));
++
++	if (len < sizeof(rep) || rep.status)
++		return NULL;
++
++	return mfs_new_inode(sb, &rep);
++}
++
++static void mfs_put_super(struct super_block *sb)
++{
++}
++
++static int mfs_statfs(struct dentry *dentry, struct kstatfs *buf)
++{
++	struct statfs_req req;
++	struct statfs_rep rep;
++	struct super_block *sb = dentry->d_sb;
++	unsigned len;
++
++	req.id = MFS_ID(sb);
++	req.cmd = CMD_STATFS;
++	rep.status = -EINVAL;
++	len = send_request(&req, sizeof(req), &rep, sizeof(rep));
++
++	if (len < sizeof(rep) || rep.status)
++		return rep.status;
++
++	buf->f_type = sb->s_magic;
++	buf->f_bsize = 512;
++	buf->f_blocks = rep.blocks;
++	buf->f_bfree = rep.bfree;
++	buf->f_bavail = rep.bfree;
++	buf->f_namelen = 255;
++
++	return 0;
++}
++
++static const struct super_operations mfs_ops = {
++	.alloc_inode	= mfs_alloc_inode,
++	.destroy_inode	= mfs_destroy_inode,
++	.put_super	= mfs_put_super,
++	.statfs		= mfs_statfs,
++};
++
++static int mfs_fill_super(struct super_block *sb, void *data, int silent)
++{
++	struct inode *root;
++	unsigned id;
++
++	if (*(char *) data == '/') ++data;
++	id = simple_strtoul((char *) data, NULL, 10);
++
++	sb->s_magic = 0xdeadbeef;
++	sb->s_op = &mfs_ops;
++	if (id == 0)
++		sb->s_flags |= MS_RDONLY;
++	sb->s_fs_info = (void *) id;
++
++	root = mfs_getinode(sb, 0);
++	if (!root)	    
++		goto out;
++
++	sb->s_root = d_alloc_root(root);
++	if (!sb->s_root)
++		goto outiput;
++
++	return 0;
++
++  outiput:
++	iput(root);
++  out:
++	return -EINVAL;
++}
++
++static int mfs_get_sb(struct file_system_type *fs_type,
++	int flags, const char *dev_name, void *data, struct vfsmount *mnt)
++{
++	return get_sb_nodev(fs_type, flags,
++			    (void *) dev_name, mfs_fill_super, mnt);
++}
++
++static struct file_system_type mfs_fs_type = {
++	.owner		= THIS_MODULE,
++	.name		= "metafs",
++	.get_sb		= mfs_get_sb,
++	.kill_sb	= kill_block_super,
++	.fs_flags	= FS_REQUIRES_DEV,
++};
++
++static void init_once(void *foo)
++{
++	struct inode * inode = (struct inode *) foo;
++
++	inode_init_once(inode);
++}
++
++static int __init init_mfs_fs(void)
++{
++	unsigned i;
++	int err;
++
++	if (vm_running() != 0)
++		return 0;
++
++	printk("MFS init\n");
++	mfs_inode_cachep = kmem_cache_create("metafs_inode_cache",
++					     sizeof(struct inode),
++					     0, (SLAB_RECLAIM_ACCOUNT|
++						 SLAB_MEM_SPREAD),
++					     init_once);
++	if (!mfs_inode_cachep)
++		return -ENOMEM;
++
++	for (i = 0; i < BUF_COUNT; ++i) {
++		tx_descr[i].addr = 0;
++		tx_descr[i].size = 0;
++		tx_descr[i].next = (unsigned) &tx_descr[i + 1];
++
++		rx_descr[i].addr = 0;
++		rx_descr[i].size = DONE;
++		rx_descr[i].next = (unsigned) &rx_descr[i + 1];
++	}
++	tx_descr[BUF_COUNT - 1].next = (unsigned) &tx_descr[0];
++	rx_descr[BUF_COUNT - 1].next = (unsigned) &rx_descr[0];
++	
++	vm_create_queue(2, -1u,
++			(unsigned) &tx_descr[0], (unsigned) &rx_descr[0]);
++
++        err = register_filesystem(&mfs_fs_type);
++	if (err != 0) {
++		kmem_cache_destroy(mfs_inode_cachep);
++		return err;
++	}
++
++	return 0;
++}
++
++static void __exit exit_mfs_fs(void)
++{
++	unregister_filesystem(&mfs_fs_type);
++	kmem_cache_destroy(mfs_inode_cachep);
++}
++
++module_init(init_mfs_fs);
++module_exit(exit_mfs_fs);
+diff -uNr linux-2.6.31.10/fs/metafs/Kconfig linux-2.6.31.10.new/fs/metafs/Kconfig
+--- linux-2.6.31.10/fs/metafs/Kconfig	1970-01-01 03:00:00.000000000 +0300
++++ linux-2.6.31.10.new/fs/metafs/Kconfig	2010-04-12 15:54:46.000000000 +0300
+@@ -0,0 +1,3 @@
++config META_FS
++	depends on METAROUTER
++	tristate "MetaFS on Mikrotik MetaROUTER"
+diff -uNr linux-2.6.31.10/fs/metafs/Makefile linux-2.6.31.10.new/fs/metafs/Makefile
+--- linux-2.6.31.10/fs/metafs/Makefile	1970-01-01 03:00:00.000000000 +0300
++++ linux-2.6.31.10.new/fs/metafs/Makefile	2010-04-12 15:54:46.000000000 +0300
+@@ -0,0 +1,3 @@
++obj-y += metafs.o
++
++metafs-objs := inode.o
diff -Nru a/target/linux/mr-mips/patches-2.6.31/099-mips_module_reloc_fix.patch b/target/linux/mr-mips/patches-2.6.31/099-mips_module_reloc_fix.patch
--- a/target/linux/mr-mips/patches-2.6.31/099-mips_module_reloc_fix.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/mr-mips/patches-2.6.31/099-mips_module_reloc_fix.patch	2013-07-22 22:25:00.417082182 +0200
@@ -0,0 +1,12 @@
+diff -uNr linux-2.6.31.10/arch/mips/kernel/module.c linux-2.6.31.10.mod/arch/mips/kernel/module.c
+--- linux-2.6.31.10/arch/mips/kernel/module.c	2010-04-12 13:37:22.000000000 +0300
++++ linux-2.6.31.10.mod/arch/mips/kernel/module.c	2010-04-12 13:42:46.000000000 +0300
+@@ -191,7 +191,7 @@
+ #ifdef CONFIG_64BIT
+ 	return (KSEGX((unsigned long)ptr) == CKSEG0);
+ #else
+-	return (KSEGX(ptr) == KSEG0);
++	return ((_ACAST32_ (ptr)) & 0xf0000000) == 0xc0000000;
+ #endif
+ }
+ 
diff -Nru a/target/linux/mr-mips/patches-2.6.31/100-Makefile.patch b/target/linux/mr-mips/patches-2.6.31/100-Makefile.patch
--- a/target/linux/mr-mips/patches-2.6.31/100-Makefile.patch	1970-01-01 01:00:00.000000000 +0100
+++ b/target/linux/mr-mips/patches-2.6.31/100-Makefile.patch	2013-07-23 03:10:23.384923343 +0200
@@ -0,0 +1,12 @@
+--- a/Makefile	2013-07-23 03:06:13.666973044 +0200
++++ b/Makefile	2013-07-23 03:06:21.097821808 +0200
+@@ -344,7 +344,8 @@
+ 		   -fno-strict-aliasing -fno-common \
+ 		   -Werror-implicit-function-declaration \
+ 		   -Wno-format-security \
+-		   -fno-delete-null-pointer-checks
++		   -fno-delete-null-pointer-checks \
++		   -Wno-error=unused-but-set-variable
+ KBUILD_AFLAGS   := -D__ASSEMBLY__
+ 
+ # Read KERNELRELEASE from include/config/kernel.release (if it exists)
